/data/xunjian_yin/mycode/MAP-NEO/Megatron-LM-NEO/megatron/checkpointing.py:422: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state_dict = torch.load(checkpoint_name, map_location='cpu')
/data/xunjian_yin/miniconda3/envs/apex1/lib/python3.10/site-packages/transformer_engine/pytorch/module/base.py:407: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state = torch.load(state, map_location='cuda')
/data/xunjian_yin/miniconda3/envs/apex1/lib/python3.10/site-packages/torch/distributed/c10d_logger.py:79: FutureWarning: `torch.distributed._all_gather_base` is a private function and will be deprecated. Please use `torch.distributed.all_gather_into_tensor` instead.
  return func(*args, **kwargs)
(min, max) time across ranks (ms):
    load-checkpoint ................................: (66770.57, 66770.66)
(min, max) time across ranks (ms):
    model-and-optimizer-setup ......................: (68453.70, 68790.04)
    train/valid/test-data-iterators-setup ..........: (227762.21, 231675.77)
/data/xunjian_yin/mycode/MAP-NEO/Megatron-LM-NEO/megatron/core/tensor_parallel/layers.py:396: FutureWarning: `torch.distributed._reduce_scatter_base` is a private function and will be deprecated. Please use `torch.distributed.reduce_scatter_tensor` instead.
  handle = torch.distributed._reduce_scatter_base(
/data/xunjian_yin/mycode/MAP-NEO/Megatron-LM-NEO/megatron/core/distributed/grad_buffer.py:104: FutureWarning: `torch.distributed._reduce_scatter_base` is a private function and will be deprecated. Please use `torch.distributed.reduce_scatter_tensor` instead.
  self.communication_handle = torch.distributed._reduce_scatter_base(
 iteration    25001/   51900 | consumed samples:     25601024 | elapsed time per iteration (ms): 47379.6 | learning rate: 1.210E-04 | global batch size:  1024 | lm loss: 1.832960E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
/data/xunjian_yin/mycode/MAP-NEO/Megatron-LM-NEO/megatron/training.py:533: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1720538438429/work/torch/csrc/tensor/python_tensor.cpp:78.)
  key, torch.cuda.FloatTensor([0.0])) + loss_dict[key]
 iteration    25002/   51900 | consumed samples:     25602048 | elapsed time per iteration (ms): 37660.1 | learning rate: 1.210E-04 | global batch size:  1024 | lm loss: 1.860769E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25003/   51900 | consumed samples:     25603072 | elapsed time per iteration (ms): 37765.5 | learning rate: 1.210E-04 | global batch size:  1024 | lm loss: 1.856791E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25004/   51900 | consumed samples:     25604096 | elapsed time per iteration (ms): 37616.5 | learning rate: 1.210E-04 | global batch size:  1024 | lm loss: 1.860790E+00 | loss scale: 1.0 | grad norm: 0.093 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25005/   51900 | consumed samples:     25605120 | elapsed time per iteration (ms): 37671.2 | learning rate: 1.210E-04 | global batch size:  1024 | lm loss: 1.848782E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25006/   51900 | consumed samples:     25606144 | elapsed time per iteration (ms): 37626.8 | learning rate: 1.210E-04 | global batch size:  1024 | lm loss: 1.870229E+00 | loss scale: 1.0 | grad norm: 0.088 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25007/   51900 | consumed samples:     25607168 | elapsed time per iteration (ms): 37660.4 | learning rate: 1.210E-04 | global batch size:  1024 | lm loss: 1.825736E+00 | loss scale: 1.0 | grad norm: 0.106 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25008/   51900 | consumed samples:     25608192 | elapsed time per iteration (ms): 37704.2 | learning rate: 1.210E-04 | global batch size:  1024 | lm loss: 1.880736E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25009/   51900 | consumed samples:     25609216 | elapsed time per iteration (ms): 37654.7 | learning rate: 1.210E-04 | global batch size:  1024 | lm loss: 1.861574E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25010/   51900 | consumed samples:     25610240 | elapsed time per iteration (ms): 37701.1 | learning rate: 1.210E-04 | global batch size:  1024 | lm loss: 1.847458E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25011/   51900 | consumed samples:     25611264 | elapsed time per iteration (ms): 37675.6 | learning rate: 1.210E-04 | global batch size:  1024 | lm loss: 1.853872E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25012/   51900 | consumed samples:     25612288 | elapsed time per iteration (ms): 37672.2 | learning rate: 1.210E-04 | global batch size:  1024 | lm loss: 1.863575E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25013/   51900 | consumed samples:     25613312 | elapsed time per iteration (ms): 37583.1 | learning rate: 1.209E-04 | global batch size:  1024 | lm loss: 1.844111E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25014/   51900 | consumed samples:     25614336 | elapsed time per iteration (ms): 37687.0 | learning rate: 1.209E-04 | global batch size:  1024 | lm loss: 1.865464E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25015/   51900 | consumed samples:     25615360 | elapsed time per iteration (ms): 37747.2 | learning rate: 1.209E-04 | global batch size:  1024 | lm loss: 1.869521E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25016/   51900 | consumed samples:     25616384 | elapsed time per iteration (ms): 37649.4 | learning rate: 1.209E-04 | global batch size:  1024 | lm loss: 1.861974E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25017/   51900 | consumed samples:     25617408 | elapsed time per iteration (ms): 37691.0 | learning rate: 1.209E-04 | global batch size:  1024 | lm loss: 1.869957E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25018/   51900 | consumed samples:     25618432 | elapsed time per iteration (ms): 37602.1 | learning rate: 1.209E-04 | global batch size:  1024 | lm loss: 1.878815E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25019/   51900 | consumed samples:     25619456 | elapsed time per iteration (ms): 37647.7 | learning rate: 1.209E-04 | global batch size:  1024 | lm loss: 1.845324E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25020/   51900 | consumed samples:     25620480 | elapsed time per iteration (ms): 37755.6 | learning rate: 1.209E-04 | global batch size:  1024 | lm loss: 1.867310E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25021/   51900 | consumed samples:     25621504 | elapsed time per iteration (ms): 37700.1 | learning rate: 1.209E-04 | global batch size:  1024 | lm loss: 1.845057E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25022/   51900 | consumed samples:     25622528 | elapsed time per iteration (ms): 37536.2 | learning rate: 1.209E-04 | global batch size:  1024 | lm loss: 1.864965E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25023/   51900 | consumed samples:     25623552 | elapsed time per iteration (ms): 37578.9 | learning rate: 1.209E-04 | global batch size:  1024 | lm loss: 1.853349E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25024/   51900 | consumed samples:     25624576 | elapsed time per iteration (ms): 37666.5 | learning rate: 1.209E-04 | global batch size:  1024 | lm loss: 1.872979E+00 | loss scale: 1.0 | grad norm: 0.090 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25025/   51900 | consumed samples:     25625600 | elapsed time per iteration (ms): 37735.9 | learning rate: 1.209E-04 | global batch size:  1024 | lm loss: 1.865103E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25026/   51900 | consumed samples:     25626624 | elapsed time per iteration (ms): 37656.7 | learning rate: 1.209E-04 | global batch size:  1024 | lm loss: 1.865088E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25027/   51900 | consumed samples:     25627648 | elapsed time per iteration (ms): 37643.8 | learning rate: 1.209E-04 | global batch size:  1024 | lm loss: 1.856998E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25028/   51900 | consumed samples:     25628672 | elapsed time per iteration (ms): 37824.8 | learning rate: 1.209E-04 | global batch size:  1024 | lm loss: 1.855977E+00 | loss scale: 1.0 | grad norm: 0.097 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25029/   51900 | consumed samples:     25629696 | elapsed time per iteration (ms): 37627.2 | learning rate: 1.209E-04 | global batch size:  1024 | lm loss: 1.861725E+00 | loss scale: 1.0 | grad norm: 0.095 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25030/   51900 | consumed samples:     25630720 | elapsed time per iteration (ms): 37613.2 | learning rate: 1.209E-04 | global batch size:  1024 | lm loss: 1.854953E+00 | loss scale: 1.0 | grad norm: 0.090 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25031/   51900 | consumed samples:     25631744 | elapsed time per iteration (ms): 37637.6 | learning rate: 1.208E-04 | global batch size:  1024 | lm loss: 1.844464E+00 | loss scale: 1.0 | grad norm: 0.112 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25032/   51900 | consumed samples:     25632768 | elapsed time per iteration (ms): 37656.6 | learning rate: 1.208E-04 | global batch size:  1024 | lm loss: 1.871068E+00 | loss scale: 1.0 | grad norm: 0.097 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25033/   51900 | consumed samples:     25633792 | elapsed time per iteration (ms): 37591.7 | learning rate: 1.208E-04 | global batch size:  1024 | lm loss: 1.864396E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25034/   51900 | consumed samples:     25634816 | elapsed time per iteration (ms): 37727.0 | learning rate: 1.208E-04 | global batch size:  1024 | lm loss: 1.837918E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25035/   51900 | consumed samples:     25635840 | elapsed time per iteration (ms): 37690.4 | learning rate: 1.208E-04 | global batch size:  1024 | lm loss: 1.864096E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25036/   51900 | consumed samples:     25636864 | elapsed time per iteration (ms): 37581.3 | learning rate: 1.208E-04 | global batch size:  1024 | lm loss: 1.842975E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25037/   51900 | consumed samples:     25637888 | elapsed time per iteration (ms): 37574.4 | learning rate: 1.208E-04 | global batch size:  1024 | lm loss: 1.852604E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25038/   51900 | consumed samples:     25638912 | elapsed time per iteration (ms): 37684.2 | learning rate: 1.208E-04 | global batch size:  1024 | lm loss: 1.857379E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25039/   51900 | consumed samples:     25639936 | elapsed time per iteration (ms): 37625.0 | learning rate: 1.208E-04 | global batch size:  1024 | lm loss: 1.881326E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25040/   51900 | consumed samples:     25640960 | elapsed time per iteration (ms): 37617.8 | learning rate: 1.208E-04 | global batch size:  1024 | lm loss: 1.868733E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25041/   51900 | consumed samples:     25641984 | elapsed time per iteration (ms): 37562.9 | learning rate: 1.208E-04 | global batch size:  1024 | lm loss: 1.873813E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25042/   51900 | consumed samples:     25643008 | elapsed time per iteration (ms): 37615.9 | learning rate: 1.208E-04 | global batch size:  1024 | lm loss: 1.855835E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25043/   51900 | consumed samples:     25644032 | elapsed time per iteration (ms): 37676.6 | learning rate: 1.208E-04 | global batch size:  1024 | lm loss: 1.863616E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25044/   51900 | consumed samples:     25645056 | elapsed time per iteration (ms): 37605.1 | learning rate: 1.208E-04 | global batch size:  1024 | lm loss: 1.861691E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25045/   51900 | consumed samples:     25646080 | elapsed time per iteration (ms): 37587.6 | learning rate: 1.208E-04 | global batch size:  1024 | lm loss: 1.878953E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25046/   51900 | consumed samples:     25647104 | elapsed time per iteration (ms): 37614.7 | learning rate: 1.208E-04 | global batch size:  1024 | lm loss: 1.847566E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25047/   51900 | consumed samples:     25648128 | elapsed time per iteration (ms): 37704.0 | learning rate: 1.208E-04 | global batch size:  1024 | lm loss: 1.860731E+00 | loss scale: 1.0 | grad norm: 0.091 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25048/   51900 | consumed samples:     25649152 | elapsed time per iteration (ms): 37548.0 | learning rate: 1.208E-04 | global batch size:  1024 | lm loss: 1.871453E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25049/   51900 | consumed samples:     25650176 | elapsed time per iteration (ms): 37754.7 | learning rate: 1.207E-04 | global batch size:  1024 | lm loss: 1.870984E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25050/   51900 | consumed samples:     25651200 | elapsed time per iteration (ms): 37573.5 | learning rate: 1.207E-04 | global batch size:  1024 | lm loss: 1.862883E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25051/   51900 | consumed samples:     25652224 | elapsed time per iteration (ms): 37573.1 | learning rate: 1.207E-04 | global batch size:  1024 | lm loss: 1.865777E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25052/   51900 | consumed samples:     25653248 | elapsed time per iteration (ms): 37661.8 | learning rate: 1.207E-04 | global batch size:  1024 | lm loss: 1.861190E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25053/   51900 | consumed samples:     25654272 | elapsed time per iteration (ms): 37673.2 | learning rate: 1.207E-04 | global batch size:  1024 | lm loss: 1.855512E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25054/   51900 | consumed samples:     25655296 | elapsed time per iteration (ms): 37692.1 | learning rate: 1.207E-04 | global batch size:  1024 | lm loss: 1.844120E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25055/   51900 | consumed samples:     25656320 | elapsed time per iteration (ms): 37471.2 | learning rate: 1.207E-04 | global batch size:  1024 | lm loss: 1.851162E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25056/   51900 | consumed samples:     25657344 | elapsed time per iteration (ms): 37623.8 | learning rate: 1.207E-04 | global batch size:  1024 | lm loss: 1.862437E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25057/   51900 | consumed samples:     25658368 | elapsed time per iteration (ms): 37759.8 | learning rate: 1.207E-04 | global batch size:  1024 | lm loss: 1.856250E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25058/   51900 | consumed samples:     25659392 | elapsed time per iteration (ms): 37761.8 | learning rate: 1.207E-04 | global batch size:  1024 | lm loss: 1.860534E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25059/   51900 | consumed samples:     25660416 | elapsed time per iteration (ms): 37592.2 | learning rate: 1.207E-04 | global batch size:  1024 | lm loss: 1.859408E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25060/   51900 | consumed samples:     25661440 | elapsed time per iteration (ms): 37495.0 | learning rate: 1.207E-04 | global batch size:  1024 | lm loss: 1.838680E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25061/   51900 | consumed samples:     25662464 | elapsed time per iteration (ms): 37622.9 | learning rate: 1.207E-04 | global batch size:  1024 | lm loss: 1.855091E+00 | loss scale: 1.0 | grad norm: 0.087 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25062/   51900 | consumed samples:     25663488 | elapsed time per iteration (ms): 37597.0 | learning rate: 1.207E-04 | global batch size:  1024 | lm loss: 1.844058E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25063/   51900 | consumed samples:     25664512 | elapsed time per iteration (ms): 37655.2 | learning rate: 1.207E-04 | global batch size:  1024 | lm loss: 1.849838E+00 | loss scale: 1.0 | grad norm: 0.087 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25064/   51900 | consumed samples:     25665536 | elapsed time per iteration (ms): 37582.5 | learning rate: 1.207E-04 | global batch size:  1024 | lm loss: 1.849033E+00 | loss scale: 1.0 | grad norm: 0.090 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25065/   51900 | consumed samples:     25666560 | elapsed time per iteration (ms): 37589.4 | learning rate: 1.207E-04 | global batch size:  1024 | lm loss: 1.854457E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25066/   51900 | consumed samples:     25667584 | elapsed time per iteration (ms): 37652.2 | learning rate: 1.207E-04 | global batch size:  1024 | lm loss: 1.854384E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25067/   51900 | consumed samples:     25668608 | elapsed time per iteration (ms): 37569.9 | learning rate: 1.206E-04 | global batch size:  1024 | lm loss: 1.865318E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25068/   51900 | consumed samples:     25669632 | elapsed time per iteration (ms): 37696.4 | learning rate: 1.206E-04 | global batch size:  1024 | lm loss: 1.868095E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25069/   51900 | consumed samples:     25670656 | elapsed time per iteration (ms): 37581.6 | learning rate: 1.206E-04 | global batch size:  1024 | lm loss: 1.852411E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25070/   51900 | consumed samples:     25671680 | elapsed time per iteration (ms): 37580.2 | learning rate: 1.206E-04 | global batch size:  1024 | lm loss: 1.878807E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25071/   51900 | consumed samples:     25672704 | elapsed time per iteration (ms): 37568.2 | learning rate: 1.206E-04 | global batch size:  1024 | lm loss: 1.864754E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25072/   51900 | consumed samples:     25673728 | elapsed time per iteration (ms): 37595.3 | learning rate: 1.206E-04 | global batch size:  1024 | lm loss: 1.846576E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25073/   51900 | consumed samples:     25674752 | elapsed time per iteration (ms): 37679.5 | learning rate: 1.206E-04 | global batch size:  1024 | lm loss: 1.850284E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25074/   51900 | consumed samples:     25675776 | elapsed time per iteration (ms): 37647.5 | learning rate: 1.206E-04 | global batch size:  1024 | lm loss: 1.856988E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25075/   51900 | consumed samples:     25676800 | elapsed time per iteration (ms): 37664.8 | learning rate: 1.206E-04 | global batch size:  1024 | lm loss: 1.846887E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25076/   51900 | consumed samples:     25677824 | elapsed time per iteration (ms): 37708.0 | learning rate: 1.206E-04 | global batch size:  1024 | lm loss: 1.851180E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25077/   51900 | consumed samples:     25678848 | elapsed time per iteration (ms): 37617.5 | learning rate: 1.206E-04 | global batch size:  1024 | lm loss: 1.847466E+00 | loss scale: 1.0 | grad norm: 0.088 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25078/   51900 | consumed samples:     25679872 | elapsed time per iteration (ms): 37622.2 | learning rate: 1.206E-04 | global batch size:  1024 | lm loss: 1.864190E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25079/   51900 | consumed samples:     25680896 | elapsed time per iteration (ms): 37557.9 | learning rate: 1.206E-04 | global batch size:  1024 | lm loss: 1.865352E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25080/   51900 | consumed samples:     25681920 | elapsed time per iteration (ms): 37641.7 | learning rate: 1.206E-04 | global batch size:  1024 | lm loss: 1.856564E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25081/   51900 | consumed samples:     25682944 | elapsed time per iteration (ms): 37530.0 | learning rate: 1.206E-04 | global batch size:  1024 | lm loss: 1.868462E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25082/   51900 | consumed samples:     25683968 | elapsed time per iteration (ms): 37625.4 | learning rate: 1.206E-04 | global batch size:  1024 | lm loss: 1.859552E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25083/   51900 | consumed samples:     25684992 | elapsed time per iteration (ms): 37604.7 | learning rate: 1.206E-04 | global batch size:  1024 | lm loss: 1.860485E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25084/   51900 | consumed samples:     25686016 | elapsed time per iteration (ms): 37625.7 | learning rate: 1.205E-04 | global batch size:  1024 | lm loss: 1.864183E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25085/   51900 | consumed samples:     25687040 | elapsed time per iteration (ms): 37712.5 | learning rate: 1.205E-04 | global batch size:  1024 | lm loss: 1.844557E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25086/   51900 | consumed samples:     25688064 | elapsed time per iteration (ms): 37671.8 | learning rate: 1.205E-04 | global batch size:  1024 | lm loss: 1.877411E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25087/   51900 | consumed samples:     25689088 | elapsed time per iteration (ms): 37659.1 | learning rate: 1.205E-04 | global batch size:  1024 | lm loss: 1.840824E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25088/   51900 | consumed samples:     25690112 | elapsed time per iteration (ms): 37599.1 | learning rate: 1.205E-04 | global batch size:  1024 | lm loss: 1.827814E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25089/   51900 | consumed samples:     25691136 | elapsed time per iteration (ms): 37626.5 | learning rate: 1.205E-04 | global batch size:  1024 | lm loss: 1.885753E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25090/   51900 | consumed samples:     25692160 | elapsed time per iteration (ms): 37511.1 | learning rate: 1.205E-04 | global batch size:  1024 | lm loss: 1.856603E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25091/   51900 | consumed samples:     25693184 | elapsed time per iteration (ms): 37700.3 | learning rate: 1.205E-04 | global batch size:  1024 | lm loss: 1.867672E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25092/   51900 | consumed samples:     25694208 | elapsed time per iteration (ms): 37581.8 | learning rate: 1.205E-04 | global batch size:  1024 | lm loss: 1.867767E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25093/   51900 | consumed samples:     25695232 | elapsed time per iteration (ms): 37634.4 | learning rate: 1.205E-04 | global batch size:  1024 | lm loss: 1.858589E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25094/   51900 | consumed samples:     25696256 | elapsed time per iteration (ms): 37574.8 | learning rate: 1.205E-04 | global batch size:  1024 | lm loss: 1.849627E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25095/   51900 | consumed samples:     25697280 | elapsed time per iteration (ms): 37650.4 | learning rate: 1.205E-04 | global batch size:  1024 | lm loss: 1.853333E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25096/   51900 | consumed samples:     25698304 | elapsed time per iteration (ms): 37575.7 | learning rate: 1.205E-04 | global batch size:  1024 | lm loss: 1.852947E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25097/   51900 | consumed samples:     25699328 | elapsed time per iteration (ms): 37632.6 | learning rate: 1.205E-04 | global batch size:  1024 | lm loss: 1.860918E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25098/   51900 | consumed samples:     25700352 | elapsed time per iteration (ms): 37663.6 | learning rate: 1.205E-04 | global batch size:  1024 | lm loss: 1.858127E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25099/   51900 | consumed samples:     25701376 | elapsed time per iteration (ms): 37555.4 | learning rate: 1.205E-04 | global batch size:  1024 | lm loss: 1.847437E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25100/   51900 | consumed samples:     25702400 | elapsed time per iteration (ms): 37701.6 | learning rate: 1.205E-04 | global batch size:  1024 | lm loss: 1.845727E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25101/   51900 | consumed samples:     25703424 | elapsed time per iteration (ms): 37694.7 | learning rate: 1.205E-04 | global batch size:  1024 | lm loss: 1.850151E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25102/   51900 | consumed samples:     25704448 | elapsed time per iteration (ms): 37748.4 | learning rate: 1.204E-04 | global batch size:  1024 | lm loss: 1.861413E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25103/   51900 | consumed samples:     25705472 | elapsed time per iteration (ms): 37565.5 | learning rate: 1.204E-04 | global batch size:  1024 | lm loss: 1.866396E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25104/   51900 | consumed samples:     25706496 | elapsed time per iteration (ms): 37709.4 | learning rate: 1.204E-04 | global batch size:  1024 | lm loss: 1.849895E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25105/   51900 | consumed samples:     25707520 | elapsed time per iteration (ms): 37631.9 | learning rate: 1.204E-04 | global batch size:  1024 | lm loss: 1.855801E+00 | loss scale: 1.0 | grad norm: 0.089 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25106/   51900 | consumed samples:     25708544 | elapsed time per iteration (ms): 37703.6 | learning rate: 1.204E-04 | global batch size:  1024 | lm loss: 1.840977E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25107/   51900 | consumed samples:     25709568 | elapsed time per iteration (ms): 37622.6 | learning rate: 1.204E-04 | global batch size:  1024 | lm loss: 1.832293E+00 | loss scale: 1.0 | grad norm: 0.089 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25108/   51900 | consumed samples:     25710592 | elapsed time per iteration (ms): 37558.7 | learning rate: 1.204E-04 | global batch size:  1024 | lm loss: 1.866167E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25109/   51900 | consumed samples:     25711616 | elapsed time per iteration (ms): 37534.9 | learning rate: 1.204E-04 | global batch size:  1024 | lm loss: 1.858374E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25110/   51900 | consumed samples:     25712640 | elapsed time per iteration (ms): 37614.8 | learning rate: 1.204E-04 | global batch size:  1024 | lm loss: 1.830057E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25111/   51900 | consumed samples:     25713664 | elapsed time per iteration (ms): 37789.7 | learning rate: 1.204E-04 | global batch size:  1024 | lm loss: 1.856262E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25112/   51900 | consumed samples:     25714688 | elapsed time per iteration (ms): 37714.3 | learning rate: 1.204E-04 | global batch size:  1024 | lm loss: 1.872301E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25113/   51900 | consumed samples:     25715712 | elapsed time per iteration (ms): 37645.8 | learning rate: 1.204E-04 | global batch size:  1024 | lm loss: 1.867572E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25114/   51900 | consumed samples:     25716736 | elapsed time per iteration (ms): 37650.8 | learning rate: 1.204E-04 | global batch size:  1024 | lm loss: 1.869147E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25115/   51900 | consumed samples:     25717760 | elapsed time per iteration (ms): 37612.3 | learning rate: 1.204E-04 | global batch size:  1024 | lm loss: 1.861000E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25116/   51900 | consumed samples:     25718784 | elapsed time per iteration (ms): 37673.4 | learning rate: 1.204E-04 | global batch size:  1024 | lm loss: 1.859362E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25117/   51900 | consumed samples:     25719808 | elapsed time per iteration (ms): 37613.6 | learning rate: 1.204E-04 | global batch size:  1024 | lm loss: 1.852476E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25118/   51900 | consumed samples:     25720832 | elapsed time per iteration (ms): 37692.2 | learning rate: 1.204E-04 | global batch size:  1024 | lm loss: 1.856918E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25119/   51900 | consumed samples:     25721856 | elapsed time per iteration (ms): 37617.3 | learning rate: 1.204E-04 | global batch size:  1024 | lm loss: 1.837642E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25120/   51900 | consumed samples:     25722880 | elapsed time per iteration (ms): 37670.1 | learning rate: 1.203E-04 | global batch size:  1024 | lm loss: 1.833825E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25121/   51900 | consumed samples:     25723904 | elapsed time per iteration (ms): 37680.5 | learning rate: 1.203E-04 | global batch size:  1024 | lm loss: 1.864900E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25122/   51900 | consumed samples:     25724928 | elapsed time per iteration (ms): 37629.0 | learning rate: 1.203E-04 | global batch size:  1024 | lm loss: 1.855161E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25123/   51900 | consumed samples:     25725952 | elapsed time per iteration (ms): 37579.0 | learning rate: 1.203E-04 | global batch size:  1024 | lm loss: 1.861807E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25124/   51900 | consumed samples:     25726976 | elapsed time per iteration (ms): 37634.8 | learning rate: 1.203E-04 | global batch size:  1024 | lm loss: 1.855559E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25125/   51900 | consumed samples:     25728000 | elapsed time per iteration (ms): 37535.3 | learning rate: 1.203E-04 | global batch size:  1024 | lm loss: 1.857983E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25126/   51900 | consumed samples:     25729024 | elapsed time per iteration (ms): 37673.8 | learning rate: 1.203E-04 | global batch size:  1024 | lm loss: 1.858823E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25127/   51900 | consumed samples:     25730048 | elapsed time per iteration (ms): 37777.0 | learning rate: 1.203E-04 | global batch size:  1024 | lm loss: 1.836701E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25128/   51900 | consumed samples:     25731072 | elapsed time per iteration (ms): 37681.7 | learning rate: 1.203E-04 | global batch size:  1024 | lm loss: 1.846553E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25129/   51900 | consumed samples:     25732096 | elapsed time per iteration (ms): 37669.6 | learning rate: 1.203E-04 | global batch size:  1024 | lm loss: 1.854815E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25130/   51900 | consumed samples:     25733120 | elapsed time per iteration (ms): 37696.5 | learning rate: 1.203E-04 | global batch size:  1024 | lm loss: 1.855353E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25131/   51900 | consumed samples:     25734144 | elapsed time per iteration (ms): 37781.3 | learning rate: 1.203E-04 | global batch size:  1024 | lm loss: 1.877903E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25132/   51900 | consumed samples:     25735168 | elapsed time per iteration (ms): 37599.2 | learning rate: 1.203E-04 | global batch size:  1024 | lm loss: 1.879490E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25133/   51900 | consumed samples:     25736192 | elapsed time per iteration (ms): 37614.6 | learning rate: 1.203E-04 | global batch size:  1024 | lm loss: 1.869599E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25134/   51900 | consumed samples:     25737216 | elapsed time per iteration (ms): 37629.5 | learning rate: 1.203E-04 | global batch size:  1024 | lm loss: 1.852961E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25135/   51900 | consumed samples:     25738240 | elapsed time per iteration (ms): 37475.6 | learning rate: 1.203E-04 | global batch size:  1024 | lm loss: 1.863750E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25136/   51900 | consumed samples:     25739264 | elapsed time per iteration (ms): 37588.2 | learning rate: 1.203E-04 | global batch size:  1024 | lm loss: 1.853748E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25137/   51900 | consumed samples:     25740288 | elapsed time per iteration (ms): 37620.1 | learning rate: 1.203E-04 | global batch size:  1024 | lm loss: 1.852886E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25138/   51900 | consumed samples:     25741312 | elapsed time per iteration (ms): 37667.9 | learning rate: 1.202E-04 | global batch size:  1024 | lm loss: 1.847030E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25139/   51900 | consumed samples:     25742336 | elapsed time per iteration (ms): 37597.7 | learning rate: 1.202E-04 | global batch size:  1024 | lm loss: 1.846737E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25140/   51900 | consumed samples:     25743360 | elapsed time per iteration (ms): 37617.1 | learning rate: 1.202E-04 | global batch size:  1024 | lm loss: 1.868079E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25141/   51900 | consumed samples:     25744384 | elapsed time per iteration (ms): 37703.2 | learning rate: 1.202E-04 | global batch size:  1024 | lm loss: 1.846502E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25142/   51900 | consumed samples:     25745408 | elapsed time per iteration (ms): 37667.2 | learning rate: 1.202E-04 | global batch size:  1024 | lm loss: 1.855980E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25143/   51900 | consumed samples:     25746432 | elapsed time per iteration (ms): 37565.7 | learning rate: 1.202E-04 | global batch size:  1024 | lm loss: 1.877555E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25144/   51900 | consumed samples:     25747456 | elapsed time per iteration (ms): 37636.2 | learning rate: 1.202E-04 | global batch size:  1024 | lm loss: 1.859522E+00 | loss scale: 1.0 | grad norm: 0.089 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25145/   51900 | consumed samples:     25748480 | elapsed time per iteration (ms): 37650.7 | learning rate: 1.202E-04 | global batch size:  1024 | lm loss: 1.869971E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25146/   51900 | consumed samples:     25749504 | elapsed time per iteration (ms): 37602.0 | learning rate: 1.202E-04 | global batch size:  1024 | lm loss: 1.839483E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25147/   51900 | consumed samples:     25750528 | elapsed time per iteration (ms): 37585.5 | learning rate: 1.202E-04 | global batch size:  1024 | lm loss: 1.837624E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25148/   51900 | consumed samples:     25751552 | elapsed time per iteration (ms): 37699.0 | learning rate: 1.202E-04 | global batch size:  1024 | lm loss: 1.860347E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25149/   51900 | consumed samples:     25752576 | elapsed time per iteration (ms): 37646.4 | learning rate: 1.202E-04 | global batch size:  1024 | lm loss: 1.840650E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25150/   51900 | consumed samples:     25753600 | elapsed time per iteration (ms): 37619.6 | learning rate: 1.202E-04 | global batch size:  1024 | lm loss: 1.859742E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25151/   51900 | consumed samples:     25754624 | elapsed time per iteration (ms): 37659.5 | learning rate: 1.202E-04 | global batch size:  1024 | lm loss: 1.857858E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25152/   51900 | consumed samples:     25755648 | elapsed time per iteration (ms): 37535.4 | learning rate: 1.202E-04 | global batch size:  1024 | lm loss: 1.857142E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25153/   51900 | consumed samples:     25756672 | elapsed time per iteration (ms): 37734.1 | learning rate: 1.202E-04 | global batch size:  1024 | lm loss: 1.850446E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25154/   51900 | consumed samples:     25757696 | elapsed time per iteration (ms): 37686.0 | learning rate: 1.202E-04 | global batch size:  1024 | lm loss: 1.862689E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25155/   51900 | consumed samples:     25758720 | elapsed time per iteration (ms): 37579.2 | learning rate: 1.201E-04 | global batch size:  1024 | lm loss: 1.858540E+00 | loss scale: 1.0 | grad norm: 0.091 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25156/   51900 | consumed samples:     25759744 | elapsed time per iteration (ms): 37708.4 | learning rate: 1.201E-04 | global batch size:  1024 | lm loss: 1.855509E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25157/   51900 | consumed samples:     25760768 | elapsed time per iteration (ms): 37644.5 | learning rate: 1.201E-04 | global batch size:  1024 | lm loss: 1.851195E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25158/   51900 | consumed samples:     25761792 | elapsed time per iteration (ms): 37619.4 | learning rate: 1.201E-04 | global batch size:  1024 | lm loss: 1.849047E+00 | loss scale: 1.0 | grad norm: 0.089 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25159/   51900 | consumed samples:     25762816 | elapsed time per iteration (ms): 37566.7 | learning rate: 1.201E-04 | global batch size:  1024 | lm loss: 1.871660E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25160/   51900 | consumed samples:     25763840 | elapsed time per iteration (ms): 37694.5 | learning rate: 1.201E-04 | global batch size:  1024 | lm loss: 1.865670E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25161/   51900 | consumed samples:     25764864 | elapsed time per iteration (ms): 37656.7 | learning rate: 1.201E-04 | global batch size:  1024 | lm loss: 1.860791E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25162/   51900 | consumed samples:     25765888 | elapsed time per iteration (ms): 37579.5 | learning rate: 1.201E-04 | global batch size:  1024 | lm loss: 1.855692E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25163/   51900 | consumed samples:     25766912 | elapsed time per iteration (ms): 37739.7 | learning rate: 1.201E-04 | global batch size:  1024 | lm loss: 1.848490E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25164/   51900 | consumed samples:     25767936 | elapsed time per iteration (ms): 37611.6 | learning rate: 1.201E-04 | global batch size:  1024 | lm loss: 1.875342E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25165/   51900 | consumed samples:     25768960 | elapsed time per iteration (ms): 37661.8 | learning rate: 1.201E-04 | global batch size:  1024 | lm loss: 1.852980E+00 | loss scale: 1.0 | grad norm: 0.095 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25166/   51900 | consumed samples:     25769984 | elapsed time per iteration (ms): 37727.7 | learning rate: 1.201E-04 | global batch size:  1024 | lm loss: 1.846765E+00 | loss scale: 1.0 | grad norm: 0.091 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25167/   51900 | consumed samples:     25771008 | elapsed time per iteration (ms): 37664.9 | learning rate: 1.201E-04 | global batch size:  1024 | lm loss: 1.864870E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25168/   51900 | consumed samples:     25772032 | elapsed time per iteration (ms): 37756.4 | learning rate: 1.201E-04 | global batch size:  1024 | lm loss: 1.853442E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25169/   51900 | consumed samples:     25773056 | elapsed time per iteration (ms): 37700.2 | learning rate: 1.201E-04 | global batch size:  1024 | lm loss: 1.842239E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25170/   51900 | consumed samples:     25774080 | elapsed time per iteration (ms): 37640.1 | learning rate: 1.201E-04 | global batch size:  1024 | lm loss: 1.835917E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25171/   51900 | consumed samples:     25775104 | elapsed time per iteration (ms): 37604.9 | learning rate: 1.201E-04 | global batch size:  1024 | lm loss: 1.840598E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25172/   51900 | consumed samples:     25776128 | elapsed time per iteration (ms): 37604.8 | learning rate: 1.201E-04 | global batch size:  1024 | lm loss: 1.869421E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25173/   51900 | consumed samples:     25777152 | elapsed time per iteration (ms): 37666.2 | learning rate: 1.200E-04 | global batch size:  1024 | lm loss: 1.851025E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25174/   51900 | consumed samples:     25778176 | elapsed time per iteration (ms): 37562.6 | learning rate: 1.200E-04 | global batch size:  1024 | lm loss: 1.858914E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25175/   51900 | consumed samples:     25779200 | elapsed time per iteration (ms): 37600.1 | learning rate: 1.200E-04 | global batch size:  1024 | lm loss: 1.848720E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25176/   51900 | consumed samples:     25780224 | elapsed time per iteration (ms): 37627.0 | learning rate: 1.200E-04 | global batch size:  1024 | lm loss: 1.851526E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25177/   51900 | consumed samples:     25781248 | elapsed time per iteration (ms): 37550.6 | learning rate: 1.200E-04 | global batch size:  1024 | lm loss: 1.859050E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25178/   51900 | consumed samples:     25782272 | elapsed time per iteration (ms): 37622.7 | learning rate: 1.200E-04 | global batch size:  1024 | lm loss: 1.849958E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25179/   51900 | consumed samples:     25783296 | elapsed time per iteration (ms): 37614.3 | learning rate: 1.200E-04 | global batch size:  1024 | lm loss: 1.835255E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25180/   51900 | consumed samples:     25784320 | elapsed time per iteration (ms): 37626.8 | learning rate: 1.200E-04 | global batch size:  1024 | lm loss: 1.847214E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25181/   51900 | consumed samples:     25785344 | elapsed time per iteration (ms): 37598.1 | learning rate: 1.200E-04 | global batch size:  1024 | lm loss: 1.871630E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25182/   51900 | consumed samples:     25786368 | elapsed time per iteration (ms): 37689.8 | learning rate: 1.200E-04 | global batch size:  1024 | lm loss: 1.870586E+00 | loss scale: 1.0 | grad norm: 0.109 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25183/   51900 | consumed samples:     25787392 | elapsed time per iteration (ms): 37577.1 | learning rate: 1.200E-04 | global batch size:  1024 | lm loss: 1.866517E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25184/   51900 | consumed samples:     25788416 | elapsed time per iteration (ms): 37630.4 | learning rate: 1.200E-04 | global batch size:  1024 | lm loss: 1.856006E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25185/   51900 | consumed samples:     25789440 | elapsed time per iteration (ms): 37627.4 | learning rate: 1.200E-04 | global batch size:  1024 | lm loss: 1.843623E+00 | loss scale: 1.0 | grad norm: 0.088 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25186/   51900 | consumed samples:     25790464 | elapsed time per iteration (ms): 37669.3 | learning rate: 1.200E-04 | global batch size:  1024 | lm loss: 1.843783E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25187/   51900 | consumed samples:     25791488 | elapsed time per iteration (ms): 37578.9 | learning rate: 1.200E-04 | global batch size:  1024 | lm loss: 1.849502E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25188/   51900 | consumed samples:     25792512 | elapsed time per iteration (ms): 37686.2 | learning rate: 1.200E-04 | global batch size:  1024 | lm loss: 1.860008E+00 | loss scale: 1.0 | grad norm: 0.088 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25189/   51900 | consumed samples:     25793536 | elapsed time per iteration (ms): 37566.6 | learning rate: 1.200E-04 | global batch size:  1024 | lm loss: 1.839457E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25190/   51900 | consumed samples:     25794560 | elapsed time per iteration (ms): 37609.6 | learning rate: 1.200E-04 | global batch size:  1024 | lm loss: 1.869977E+00 | loss scale: 1.0 | grad norm: 0.087 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25191/   51900 | consumed samples:     25795584 | elapsed time per iteration (ms): 37708.6 | learning rate: 1.199E-04 | global batch size:  1024 | lm loss: 1.863196E+00 | loss scale: 1.0 | grad norm: 0.092 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25192/   51900 | consumed samples:     25796608 | elapsed time per iteration (ms): 37611.9 | learning rate: 1.199E-04 | global batch size:  1024 | lm loss: 1.850594E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25193/   51900 | consumed samples:     25797632 | elapsed time per iteration (ms): 37591.8 | learning rate: 1.199E-04 | global batch size:  1024 | lm loss: 1.879624E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25194/   51900 | consumed samples:     25798656 | elapsed time per iteration (ms): 37590.8 | learning rate: 1.199E-04 | global batch size:  1024 | lm loss: 1.843737E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25195/   51900 | consumed samples:     25799680 | elapsed time per iteration (ms): 37666.7 | learning rate: 1.199E-04 | global batch size:  1024 | lm loss: 1.882374E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25196/   51900 | consumed samples:     25800704 | elapsed time per iteration (ms): 37715.2 | learning rate: 1.199E-04 | global batch size:  1024 | lm loss: 1.880151E+00 | loss scale: 1.0 | grad norm: 0.088 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25197/   51900 | consumed samples:     25801728 | elapsed time per iteration (ms): 37636.5 | learning rate: 1.199E-04 | global batch size:  1024 | lm loss: 1.870672E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25198/   51900 | consumed samples:     25802752 | elapsed time per iteration (ms): 37631.2 | learning rate: 1.199E-04 | global batch size:  1024 | lm loss: 1.836859E+00 | loss scale: 1.0 | grad norm: 0.102 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25199/   51900 | consumed samples:     25803776 | elapsed time per iteration (ms): 37598.0 | learning rate: 1.199E-04 | global batch size:  1024 | lm loss: 1.865678E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25200/   51900 | consumed samples:     25804800 | elapsed time per iteration (ms): 37636.5 | learning rate: 1.199E-04 | global batch size:  1024 | lm loss: 1.858081E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25201/   51900 | consumed samples:     25805824 | elapsed time per iteration (ms): 37625.3 | learning rate: 1.199E-04 | global batch size:  1024 | lm loss: 1.856228E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25202/   51900 | consumed samples:     25806848 | elapsed time per iteration (ms): 37624.4 | learning rate: 1.199E-04 | global batch size:  1024 | lm loss: 1.869160E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25203/   51900 | consumed samples:     25807872 | elapsed time per iteration (ms): 37566.9 | learning rate: 1.199E-04 | global batch size:  1024 | lm loss: 1.844670E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25204/   51900 | consumed samples:     25808896 | elapsed time per iteration (ms): 37609.5 | learning rate: 1.199E-04 | global batch size:  1024 | lm loss: 1.868808E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25205/   51900 | consumed samples:     25809920 | elapsed time per iteration (ms): 37699.8 | learning rate: 1.199E-04 | global batch size:  1024 | lm loss: 1.883717E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25206/   51900 | consumed samples:     25810944 | elapsed time per iteration (ms): 37723.0 | learning rate: 1.199E-04 | global batch size:  1024 | lm loss: 1.851830E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25207/   51900 | consumed samples:     25811968 | elapsed time per iteration (ms): 37601.3 | learning rate: 1.199E-04 | global batch size:  1024 | lm loss: 1.866251E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25208/   51900 | consumed samples:     25812992 | elapsed time per iteration (ms): 37548.2 | learning rate: 1.199E-04 | global batch size:  1024 | lm loss: 1.871649E+00 | loss scale: 1.0 | grad norm: 0.096 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25209/   51900 | consumed samples:     25814016 | elapsed time per iteration (ms): 37638.1 | learning rate: 1.198E-04 | global batch size:  1024 | lm loss: 1.856723E+00 | loss scale: 1.0 | grad norm: 0.092 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25210/   51900 | consumed samples:     25815040 | elapsed time per iteration (ms): 37777.8 | learning rate: 1.198E-04 | global batch size:  1024 | lm loss: 1.861603E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25211/   51900 | consumed samples:     25816064 | elapsed time per iteration (ms): 37747.5 | learning rate: 1.198E-04 | global batch size:  1024 | lm loss: 1.845073E+00 | loss scale: 1.0 | grad norm: 0.087 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25212/   51900 | consumed samples:     25817088 | elapsed time per iteration (ms): 37593.8 | learning rate: 1.198E-04 | global batch size:  1024 | lm loss: 1.845076E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25213/   51900 | consumed samples:     25818112 | elapsed time per iteration (ms): 37640.5 | learning rate: 1.198E-04 | global batch size:  1024 | lm loss: 1.834368E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25214/   51900 | consumed samples:     25819136 | elapsed time per iteration (ms): 37571.1 | learning rate: 1.198E-04 | global batch size:  1024 | lm loss: 1.861751E+00 | loss scale: 1.0 | grad norm: 0.087 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25215/   51900 | consumed samples:     25820160 | elapsed time per iteration (ms): 37621.3 | learning rate: 1.198E-04 | global batch size:  1024 | lm loss: 1.870358E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25216/   51900 | consumed samples:     25821184 | elapsed time per iteration (ms): 37642.3 | learning rate: 1.198E-04 | global batch size:  1024 | lm loss: 1.841273E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25217/   51900 | consumed samples:     25822208 | elapsed time per iteration (ms): 37604.3 | learning rate: 1.198E-04 | global batch size:  1024 | lm loss: 1.872805E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25218/   51900 | consumed samples:     25823232 | elapsed time per iteration (ms): 37608.3 | learning rate: 1.198E-04 | global batch size:  1024 | lm loss: 1.853127E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25219/   51900 | consumed samples:     25824256 | elapsed time per iteration (ms): 37740.1 | learning rate: 1.198E-04 | global batch size:  1024 | lm loss: 1.876592E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25220/   51900 | consumed samples:     25825280 | elapsed time per iteration (ms): 37614.1 | learning rate: 1.198E-04 | global batch size:  1024 | lm loss: 1.855486E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25221/   51900 | consumed samples:     25826304 | elapsed time per iteration (ms): 37702.2 | learning rate: 1.198E-04 | global batch size:  1024 | lm loss: 1.866993E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25222/   51900 | consumed samples:     25827328 | elapsed time per iteration (ms): 37754.5 | learning rate: 1.198E-04 | global batch size:  1024 | lm loss: 1.874786E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25223/   51900 | consumed samples:     25828352 | elapsed time per iteration (ms): 37585.1 | learning rate: 1.198E-04 | global batch size:  1024 | lm loss: 1.847544E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25224/   51900 | consumed samples:     25829376 | elapsed time per iteration (ms): 37568.9 | learning rate: 1.198E-04 | global batch size:  1024 | lm loss: 1.861774E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25225/   51900 | consumed samples:     25830400 | elapsed time per iteration (ms): 37701.1 | learning rate: 1.198E-04 | global batch size:  1024 | lm loss: 1.878804E+00 | loss scale: 1.0 | grad norm: 0.092 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25226/   51900 | consumed samples:     25831424 | elapsed time per iteration (ms): 37624.4 | learning rate: 1.197E-04 | global batch size:  1024 | lm loss: 1.856345E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25227/   51900 | consumed samples:     25832448 | elapsed time per iteration (ms): 37555.6 | learning rate: 1.197E-04 | global batch size:  1024 | lm loss: 1.873766E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25228/   51900 | consumed samples:     25833472 | elapsed time per iteration (ms): 37578.7 | learning rate: 1.197E-04 | global batch size:  1024 | lm loss: 1.852139E+00 | loss scale: 1.0 | grad norm: 0.088 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25229/   51900 | consumed samples:     25834496 | elapsed time per iteration (ms): 37686.9 | learning rate: 1.197E-04 | global batch size:  1024 | lm loss: 1.844757E+00 | loss scale: 1.0 | grad norm: 0.089 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25230/   51900 | consumed samples:     25835520 | elapsed time per iteration (ms): 37642.9 | learning rate: 1.197E-04 | global batch size:  1024 | lm loss: 1.862357E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25231/   51900 | consumed samples:     25836544 | elapsed time per iteration (ms): 37691.3 | learning rate: 1.197E-04 | global batch size:  1024 | lm loss: 1.874767E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25232/   51900 | consumed samples:     25837568 | elapsed time per iteration (ms): 37664.7 | learning rate: 1.197E-04 | global batch size:  1024 | lm loss: 1.843134E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25233/   51900 | consumed samples:     25838592 | elapsed time per iteration (ms): 37725.9 | learning rate: 1.197E-04 | global batch size:  1024 | lm loss: 1.860954E+00 | loss scale: 1.0 | grad norm: 0.088 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25234/   51900 | consumed samples:     25839616 | elapsed time per iteration (ms): 37764.0 | learning rate: 1.197E-04 | global batch size:  1024 | lm loss: 1.869573E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25235/   51900 | consumed samples:     25840640 | elapsed time per iteration (ms): 37782.6 | learning rate: 1.197E-04 | global batch size:  1024 | lm loss: 1.859137E+00 | loss scale: 1.0 | grad norm: 0.094 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25236/   51900 | consumed samples:     25841664 | elapsed time per iteration (ms): 37616.7 | learning rate: 1.197E-04 | global batch size:  1024 | lm loss: 1.873711E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25237/   51900 | consumed samples:     25842688 | elapsed time per iteration (ms): 37629.7 | learning rate: 1.197E-04 | global batch size:  1024 | lm loss: 1.853363E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25238/   51900 | consumed samples:     25843712 | elapsed time per iteration (ms): 37653.5 | learning rate: 1.197E-04 | global batch size:  1024 | lm loss: 1.844972E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25239/   51900 | consumed samples:     25844736 | elapsed time per iteration (ms): 37733.8 | learning rate: 1.197E-04 | global batch size:  1024 | lm loss: 1.845483E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25240/   51900 | consumed samples:     25845760 | elapsed time per iteration (ms): 37561.8 | learning rate: 1.197E-04 | global batch size:  1024 | lm loss: 1.867759E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25241/   51900 | consumed samples:     25846784 | elapsed time per iteration (ms): 37627.2 | learning rate: 1.197E-04 | global batch size:  1024 | lm loss: 1.866929E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25242/   51900 | consumed samples:     25847808 | elapsed time per iteration (ms): 37542.5 | learning rate: 1.197E-04 | global batch size:  1024 | lm loss: 1.850263E+00 | loss scale: 1.0 | grad norm: 0.089 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25243/   51900 | consumed samples:     25848832 | elapsed time per iteration (ms): 37632.1 | learning rate: 1.197E-04 | global batch size:  1024 | lm loss: 1.849331E+00 | loss scale: 1.0 | grad norm: 0.125 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25244/   51900 | consumed samples:     25849856 | elapsed time per iteration (ms): 37579.0 | learning rate: 1.196E-04 | global batch size:  1024 | lm loss: 1.861837E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25245/   51900 | consumed samples:     25850880 | elapsed time per iteration (ms): 37596.8 | learning rate: 1.196E-04 | global batch size:  1024 | lm loss: 1.859262E+00 | loss scale: 1.0 | grad norm: 0.090 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25246/   51900 | consumed samples:     25851904 | elapsed time per iteration (ms): 37638.6 | learning rate: 1.196E-04 | global batch size:  1024 | lm loss: 1.862935E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25247/   51900 | consumed samples:     25852928 | elapsed time per iteration (ms): 37616.7 | learning rate: 1.196E-04 | global batch size:  1024 | lm loss: 1.850028E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25248/   51900 | consumed samples:     25853952 | elapsed time per iteration (ms): 37623.2 | learning rate: 1.196E-04 | global batch size:  1024 | lm loss: 1.876281E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25249/   51900 | consumed samples:     25854976 | elapsed time per iteration (ms): 37644.3 | learning rate: 1.196E-04 | global batch size:  1024 | lm loss: 1.850008E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25250/   51900 | consumed samples:     25856000 | elapsed time per iteration (ms): 37642.5 | learning rate: 1.196E-04 | global batch size:  1024 | lm loss: 1.850887E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25251/   51900 | consumed samples:     25857024 | elapsed time per iteration (ms): 37597.0 | learning rate: 1.196E-04 | global batch size:  1024 | lm loss: 1.862289E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25252/   51900 | consumed samples:     25858048 | elapsed time per iteration (ms): 37594.0 | learning rate: 1.196E-04 | global batch size:  1024 | lm loss: 1.841193E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25253/   51900 | consumed samples:     25859072 | elapsed time per iteration (ms): 37546.1 | learning rate: 1.196E-04 | global batch size:  1024 | lm loss: 1.852454E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25254/   51900 | consumed samples:     25860096 | elapsed time per iteration (ms): 37671.1 | learning rate: 1.196E-04 | global batch size:  1024 | lm loss: 1.846719E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25255/   51900 | consumed samples:     25861120 | elapsed time per iteration (ms): 37555.3 | learning rate: 1.196E-04 | global batch size:  1024 | lm loss: 1.853769E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25256/   51900 | consumed samples:     25862144 | elapsed time per iteration (ms): 37716.9 | learning rate: 1.196E-04 | global batch size:  1024 | lm loss: 1.851286E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25257/   51900 | consumed samples:     25863168 | elapsed time per iteration (ms): 37634.2 | learning rate: 1.196E-04 | global batch size:  1024 | lm loss: 1.863731E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25258/   51900 | consumed samples:     25864192 | elapsed time per iteration (ms): 37714.6 | learning rate: 1.196E-04 | global batch size:  1024 | lm loss: 1.869113E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25259/   51900 | consumed samples:     25865216 | elapsed time per iteration (ms): 37602.6 | learning rate: 1.196E-04 | global batch size:  1024 | lm loss: 1.858702E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25260/   51900 | consumed samples:     25866240 | elapsed time per iteration (ms): 37663.1 | learning rate: 1.196E-04 | global batch size:  1024 | lm loss: 1.870942E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25261/   51900 | consumed samples:     25867264 | elapsed time per iteration (ms): 37744.3 | learning rate: 1.196E-04 | global batch size:  1024 | lm loss: 1.865024E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25262/   51900 | consumed samples:     25868288 | elapsed time per iteration (ms): 37640.7 | learning rate: 1.195E-04 | global batch size:  1024 | lm loss: 1.873461E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25263/   51900 | consumed samples:     25869312 | elapsed time per iteration (ms): 37661.8 | learning rate: 1.195E-04 | global batch size:  1024 | lm loss: 1.853621E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25264/   51900 | consumed samples:     25870336 | elapsed time per iteration (ms): 37644.4 | learning rate: 1.195E-04 | global batch size:  1024 | lm loss: 1.856234E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25265/   51900 | consumed samples:     25871360 | elapsed time per iteration (ms): 37761.0 | learning rate: 1.195E-04 | global batch size:  1024 | lm loss: 1.859094E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25266/   51900 | consumed samples:     25872384 | elapsed time per iteration (ms): 37572.6 | learning rate: 1.195E-04 | global batch size:  1024 | lm loss: 1.843661E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25267/   51900 | consumed samples:     25873408 | elapsed time per iteration (ms): 37716.5 | learning rate: 1.195E-04 | global batch size:  1024 | lm loss: 1.857621E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25268/   51900 | consumed samples:     25874432 | elapsed time per iteration (ms): 37663.7 | learning rate: 1.195E-04 | global batch size:  1024 | lm loss: 1.864477E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25269/   51900 | consumed samples:     25875456 | elapsed time per iteration (ms): 37616.0 | learning rate: 1.195E-04 | global batch size:  1024 | lm loss: 1.860035E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25270/   51900 | consumed samples:     25876480 | elapsed time per iteration (ms): 37632.6 | learning rate: 1.195E-04 | global batch size:  1024 | lm loss: 1.882128E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25271/   51900 | consumed samples:     25877504 | elapsed time per iteration (ms): 37567.5 | learning rate: 1.195E-04 | global batch size:  1024 | lm loss: 1.863309E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25272/   51900 | consumed samples:     25878528 | elapsed time per iteration (ms): 37565.7 | learning rate: 1.195E-04 | global batch size:  1024 | lm loss: 1.853939E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25273/   51900 | consumed samples:     25879552 | elapsed time per iteration (ms): 37562.9 | learning rate: 1.195E-04 | global batch size:  1024 | lm loss: 1.879605E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25274/   51900 | consumed samples:     25880576 | elapsed time per iteration (ms): 37718.6 | learning rate: 1.195E-04 | global batch size:  1024 | lm loss: 1.853679E+00 | loss scale: 1.0 | grad norm: 0.088 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25275/   51900 | consumed samples:     25881600 | elapsed time per iteration (ms): 37587.1 | learning rate: 1.195E-04 | global batch size:  1024 | lm loss: 1.882626E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25276/   51900 | consumed samples:     25882624 | elapsed time per iteration (ms): 37759.9 | learning rate: 1.195E-04 | global batch size:  1024 | lm loss: 1.853289E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25277/   51900 | consumed samples:     25883648 | elapsed time per iteration (ms): 37645.7 | learning rate: 1.195E-04 | global batch size:  1024 | lm loss: 1.865475E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25278/   51900 | consumed samples:     25884672 | elapsed time per iteration (ms): 37668.2 | learning rate: 1.195E-04 | global batch size:  1024 | lm loss: 1.858047E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25279/   51900 | consumed samples:     25885696 | elapsed time per iteration (ms): 37663.7 | learning rate: 1.195E-04 | global batch size:  1024 | lm loss: 1.862879E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25280/   51900 | consumed samples:     25886720 | elapsed time per iteration (ms): 37664.1 | learning rate: 1.194E-04 | global batch size:  1024 | lm loss: 1.859770E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25281/   51900 | consumed samples:     25887744 | elapsed time per iteration (ms): 37732.6 | learning rate: 1.194E-04 | global batch size:  1024 | lm loss: 1.871555E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25282/   51900 | consumed samples:     25888768 | elapsed time per iteration (ms): 37677.8 | learning rate: 1.194E-04 | global batch size:  1024 | lm loss: 1.858109E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25283/   51900 | consumed samples:     25889792 | elapsed time per iteration (ms): 37682.0 | learning rate: 1.194E-04 | global batch size:  1024 | lm loss: 1.833236E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25284/   51900 | consumed samples:     25890816 | elapsed time per iteration (ms): 37548.7 | learning rate: 1.194E-04 | global batch size:  1024 | lm loss: 1.865941E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25285/   51900 | consumed samples:     25891840 | elapsed time per iteration (ms): 37646.6 | learning rate: 1.194E-04 | global batch size:  1024 | lm loss: 1.842737E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25286/   51900 | consumed samples:     25892864 | elapsed time per iteration (ms): 37701.1 | learning rate: 1.194E-04 | global batch size:  1024 | lm loss: 1.875454E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25287/   51900 | consumed samples:     25893888 | elapsed time per iteration (ms): 37626.5 | learning rate: 1.194E-04 | global batch size:  1024 | lm loss: 1.850594E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25288/   51900 | consumed samples:     25894912 | elapsed time per iteration (ms): 37665.1 | learning rate: 1.194E-04 | global batch size:  1024 | lm loss: 1.855095E+00 | loss scale: 1.0 | grad norm: 0.094 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25289/   51900 | consumed samples:     25895936 | elapsed time per iteration (ms): 37728.6 | learning rate: 1.194E-04 | global batch size:  1024 | lm loss: 1.840661E+00 | loss scale: 1.0 | grad norm: 0.103 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25290/   51900 | consumed samples:     25896960 | elapsed time per iteration (ms): 37652.8 | learning rate: 1.194E-04 | global batch size:  1024 | lm loss: 1.856564E+00 | loss scale: 1.0 | grad norm: 0.209 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25291/   51900 | consumed samples:     25897984 | elapsed time per iteration (ms): 37628.7 | learning rate: 1.194E-04 | global batch size:  1024 | lm loss: 1.854574E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25292/   51900 | consumed samples:     25899008 | elapsed time per iteration (ms): 37657.0 | learning rate: 1.194E-04 | global batch size:  1024 | lm loss: 1.870812E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25293/   51900 | consumed samples:     25900032 | elapsed time per iteration (ms): 37578.3 | learning rate: 1.194E-04 | global batch size:  1024 | lm loss: 1.854981E+00 | loss scale: 1.0 | grad norm: 0.098 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25294/   51900 | consumed samples:     25901056 | elapsed time per iteration (ms): 37642.8 | learning rate: 1.194E-04 | global batch size:  1024 | lm loss: 1.851354E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25295/   51900 | consumed samples:     25902080 | elapsed time per iteration (ms): 37663.2 | learning rate: 1.194E-04 | global batch size:  1024 | lm loss: 1.835805E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25296/   51900 | consumed samples:     25903104 | elapsed time per iteration (ms): 37642.2 | learning rate: 1.194E-04 | global batch size:  1024 | lm loss: 1.855062E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25297/   51900 | consumed samples:     25904128 | elapsed time per iteration (ms): 37671.6 | learning rate: 1.193E-04 | global batch size:  1024 | lm loss: 1.850418E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25298/   51900 | consumed samples:     25905152 | elapsed time per iteration (ms): 37706.1 | learning rate: 1.193E-04 | global batch size:  1024 | lm loss: 1.875269E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25299/   51900 | consumed samples:     25906176 | elapsed time per iteration (ms): 37684.0 | learning rate: 1.193E-04 | global batch size:  1024 | lm loss: 1.843533E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25300/   51900 | consumed samples:     25907200 | elapsed time per iteration (ms): 37675.3 | learning rate: 1.193E-04 | global batch size:  1024 | lm loss: 1.867681E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25301/   51900 | consumed samples:     25908224 | elapsed time per iteration (ms): 37717.3 | learning rate: 1.193E-04 | global batch size:  1024 | lm loss: 1.862843E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25302/   51900 | consumed samples:     25909248 | elapsed time per iteration (ms): 37691.1 | learning rate: 1.193E-04 | global batch size:  1024 | lm loss: 1.864333E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25303/   51900 | consumed samples:     25910272 | elapsed time per iteration (ms): 37639.7 | learning rate: 1.193E-04 | global batch size:  1024 | lm loss: 1.854748E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25304/   51900 | consumed samples:     25911296 | elapsed time per iteration (ms): 37703.0 | learning rate: 1.193E-04 | global batch size:  1024 | lm loss: 1.852993E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25305/   51900 | consumed samples:     25912320 | elapsed time per iteration (ms): 37673.0 | learning rate: 1.193E-04 | global batch size:  1024 | lm loss: 1.856812E+00 | loss scale: 1.0 | grad norm: 0.199 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25306/   51900 | consumed samples:     25913344 | elapsed time per iteration (ms): 37784.0 | learning rate: 1.193E-04 | global batch size:  1024 | lm loss: 1.852083E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25307/   51900 | consumed samples:     25914368 | elapsed time per iteration (ms): 37613.8 | learning rate: 1.193E-04 | global batch size:  1024 | lm loss: 1.848033E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25308/   51900 | consumed samples:     25915392 | elapsed time per iteration (ms): 37670.6 | learning rate: 1.193E-04 | global batch size:  1024 | lm loss: 1.861572E+00 | loss scale: 1.0 | grad norm: 0.087 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25309/   51900 | consumed samples:     25916416 | elapsed time per iteration (ms): 37597.9 | learning rate: 1.193E-04 | global batch size:  1024 | lm loss: 1.858277E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25310/   51900 | consumed samples:     25917440 | elapsed time per iteration (ms): 37639.5 | learning rate: 1.193E-04 | global batch size:  1024 | lm loss: 1.841859E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25311/   51900 | consumed samples:     25918464 | elapsed time per iteration (ms): 37602.8 | learning rate: 1.193E-04 | global batch size:  1024 | lm loss: 1.845522E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25312/   51900 | consumed samples:     25919488 | elapsed time per iteration (ms): 37613.9 | learning rate: 1.193E-04 | global batch size:  1024 | lm loss: 1.843813E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25313/   51900 | consumed samples:     25920512 | elapsed time per iteration (ms): 37703.7 | learning rate: 1.193E-04 | global batch size:  1024 | lm loss: 1.825954E+00 | loss scale: 1.0 | grad norm: 0.090 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25314/   51900 | consumed samples:     25921536 | elapsed time per iteration (ms): 37616.9 | learning rate: 1.193E-04 | global batch size:  1024 | lm loss: 1.853349E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25315/   51900 | consumed samples:     25922560 | elapsed time per iteration (ms): 37687.9 | learning rate: 1.192E-04 | global batch size:  1024 | lm loss: 1.848906E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25316/   51900 | consumed samples:     25923584 | elapsed time per iteration (ms): 37660.1 | learning rate: 1.192E-04 | global batch size:  1024 | lm loss: 1.835082E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25317/   51900 | consumed samples:     25924608 | elapsed time per iteration (ms): 37543.7 | learning rate: 1.192E-04 | global batch size:  1024 | lm loss: 1.862113E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25318/   51900 | consumed samples:     25925632 | elapsed time per iteration (ms): 37586.2 | learning rate: 1.192E-04 | global batch size:  1024 | lm loss: 1.855040E+00 | loss scale: 1.0 | grad norm: 0.092 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25319/   51900 | consumed samples:     25926656 | elapsed time per iteration (ms): 37570.2 | learning rate: 1.192E-04 | global batch size:  1024 | lm loss: 1.858316E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25320/   51900 | consumed samples:     25927680 | elapsed time per iteration (ms): 37680.3 | learning rate: 1.192E-04 | global batch size:  1024 | lm loss: 1.836240E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25321/   51900 | consumed samples:     25928704 | elapsed time per iteration (ms): 37517.3 | learning rate: 1.192E-04 | global batch size:  1024 | lm loss: 1.859629E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25322/   51900 | consumed samples:     25929728 | elapsed time per iteration (ms): 37566.7 | learning rate: 1.192E-04 | global batch size:  1024 | lm loss: 1.846298E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25323/   51900 | consumed samples:     25930752 | elapsed time per iteration (ms): 37552.3 | learning rate: 1.192E-04 | global batch size:  1024 | lm loss: 1.853013E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25324/   51900 | consumed samples:     25931776 | elapsed time per iteration (ms): 37677.0 | learning rate: 1.192E-04 | global batch size:  1024 | lm loss: 1.863052E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25325/   51900 | consumed samples:     25932800 | elapsed time per iteration (ms): 37683.3 | learning rate: 1.192E-04 | global batch size:  1024 | lm loss: 1.844606E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25326/   51900 | consumed samples:     25933824 | elapsed time per iteration (ms): 37595.0 | learning rate: 1.192E-04 | global batch size:  1024 | lm loss: 1.849214E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25327/   51900 | consumed samples:     25934848 | elapsed time per iteration (ms): 37610.2 | learning rate: 1.192E-04 | global batch size:  1024 | lm loss: 1.845838E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25328/   51900 | consumed samples:     25935872 | elapsed time per iteration (ms): 37627.4 | learning rate: 1.192E-04 | global batch size:  1024 | lm loss: 1.857982E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25329/   51900 | consumed samples:     25936896 | elapsed time per iteration (ms): 37645.0 | learning rate: 1.192E-04 | global batch size:  1024 | lm loss: 1.855387E+00 | loss scale: 1.0 | grad norm: 0.088 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25330/   51900 | consumed samples:     25937920 | elapsed time per iteration (ms): 37545.4 | learning rate: 1.192E-04 | global batch size:  1024 | lm loss: 1.855792E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25331/   51900 | consumed samples:     25938944 | elapsed time per iteration (ms): 37555.2 | learning rate: 1.192E-04 | global batch size:  1024 | lm loss: 1.842769E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25332/   51900 | consumed samples:     25939968 | elapsed time per iteration (ms): 37647.4 | learning rate: 1.192E-04 | global batch size:  1024 | lm loss: 1.853860E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25333/   51900 | consumed samples:     25940992 | elapsed time per iteration (ms): 37650.9 | learning rate: 1.191E-04 | global batch size:  1024 | lm loss: 1.845926E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25334/   51900 | consumed samples:     25942016 | elapsed time per iteration (ms): 37563.3 | learning rate: 1.191E-04 | global batch size:  1024 | lm loss: 1.856967E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25335/   51900 | consumed samples:     25943040 | elapsed time per iteration (ms): 37535.1 | learning rate: 1.191E-04 | global batch size:  1024 | lm loss: 1.859876E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25336/   51900 | consumed samples:     25944064 | elapsed time per iteration (ms): 37583.6 | learning rate: 1.191E-04 | global batch size:  1024 | lm loss: 1.850896E+00 | loss scale: 1.0 | grad norm: 0.089 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25337/   51900 | consumed samples:     25945088 | elapsed time per iteration (ms): 37612.7 | learning rate: 1.191E-04 | global batch size:  1024 | lm loss: 1.854819E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25338/   51900 | consumed samples:     25946112 | elapsed time per iteration (ms): 37581.4 | learning rate: 1.191E-04 | global batch size:  1024 | lm loss: 1.866355E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25339/   51900 | consumed samples:     25947136 | elapsed time per iteration (ms): 37763.5 | learning rate: 1.191E-04 | global batch size:  1024 | lm loss: 1.842541E+00 | loss scale: 1.0 | grad norm: 0.088 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25340/   51900 | consumed samples:     25948160 | elapsed time per iteration (ms): 37576.0 | learning rate: 1.191E-04 | global batch size:  1024 | lm loss: 1.855959E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25341/   51900 | consumed samples:     25949184 | elapsed time per iteration (ms): 37576.4 | learning rate: 1.191E-04 | global batch size:  1024 | lm loss: 1.870955E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25342/   51900 | consumed samples:     25950208 | elapsed time per iteration (ms): 37544.1 | learning rate: 1.191E-04 | global batch size:  1024 | lm loss: 1.859978E+00 | loss scale: 1.0 | grad norm: 0.091 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25343/   51900 | consumed samples:     25951232 | elapsed time per iteration (ms): 37684.4 | learning rate: 1.191E-04 | global batch size:  1024 | lm loss: 1.860764E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25344/   51900 | consumed samples:     25952256 | elapsed time per iteration (ms): 37538.1 | learning rate: 1.191E-04 | global batch size:  1024 | lm loss: 1.851317E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25345/   51900 | consumed samples:     25953280 | elapsed time per iteration (ms): 37611.2 | learning rate: 1.191E-04 | global batch size:  1024 | lm loss: 1.884138E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25346/   51900 | consumed samples:     25954304 | elapsed time per iteration (ms): 37590.5 | learning rate: 1.191E-04 | global batch size:  1024 | lm loss: 1.864546E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25347/   51900 | consumed samples:     25955328 | elapsed time per iteration (ms): 37550.5 | learning rate: 1.191E-04 | global batch size:  1024 | lm loss: 1.880993E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25348/   51900 | consumed samples:     25956352 | elapsed time per iteration (ms): 37660.5 | learning rate: 1.191E-04 | global batch size:  1024 | lm loss: 1.848476E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25349/   51900 | consumed samples:     25957376 | elapsed time per iteration (ms): 37709.9 | learning rate: 1.191E-04 | global batch size:  1024 | lm loss: 1.876683E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25350/   51900 | consumed samples:     25958400 | elapsed time per iteration (ms): 37567.9 | learning rate: 1.191E-04 | global batch size:  1024 | lm loss: 1.847523E+00 | loss scale: 1.0 | grad norm: 0.095 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25351/   51900 | consumed samples:     25959424 | elapsed time per iteration (ms): 37616.1 | learning rate: 1.190E-04 | global batch size:  1024 | lm loss: 1.857942E+00 | loss scale: 1.0 | grad norm: 0.088 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25352/   51900 | consumed samples:     25960448 | elapsed time per iteration (ms): 37649.9 | learning rate: 1.190E-04 | global batch size:  1024 | lm loss: 1.877547E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25353/   51900 | consumed samples:     25961472 | elapsed time per iteration (ms): 37680.6 | learning rate: 1.190E-04 | global batch size:  1024 | lm loss: 1.844218E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25354/   51900 | consumed samples:     25962496 | elapsed time per iteration (ms): 37535.3 | learning rate: 1.190E-04 | global batch size:  1024 | lm loss: 1.856614E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25355/   51900 | consumed samples:     25963520 | elapsed time per iteration (ms): 37572.0 | learning rate: 1.190E-04 | global batch size:  1024 | lm loss: 1.840064E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25356/   51900 | consumed samples:     25964544 | elapsed time per iteration (ms): 37652.8 | learning rate: 1.190E-04 | global batch size:  1024 | lm loss: 1.857761E+00 | loss scale: 1.0 | grad norm: 0.090 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25357/   51900 | consumed samples:     25965568 | elapsed time per iteration (ms): 37665.2 | learning rate: 1.190E-04 | global batch size:  1024 | lm loss: 1.862648E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25358/   51900 | consumed samples:     25966592 | elapsed time per iteration (ms): 37496.7 | learning rate: 1.190E-04 | global batch size:  1024 | lm loss: 1.867785E+00 | loss scale: 1.0 | grad norm: 0.088 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25359/   51900 | consumed samples:     25967616 | elapsed time per iteration (ms): 37648.8 | learning rate: 1.190E-04 | global batch size:  1024 | lm loss: 1.859193E+00 | loss scale: 1.0 | grad norm: 0.087 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25360/   51900 | consumed samples:     25968640 | elapsed time per iteration (ms): 37692.6 | learning rate: 1.190E-04 | global batch size:  1024 | lm loss: 1.847810E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25361/   51900 | consumed samples:     25969664 | elapsed time per iteration (ms): 37570.3 | learning rate: 1.190E-04 | global batch size:  1024 | lm loss: 1.860798E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25362/   51900 | consumed samples:     25970688 | elapsed time per iteration (ms): 37684.4 | learning rate: 1.190E-04 | global batch size:  1024 | lm loss: 1.852167E+00 | loss scale: 1.0 | grad norm: 0.091 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25363/   51900 | consumed samples:     25971712 | elapsed time per iteration (ms): 37504.1 | learning rate: 1.190E-04 | global batch size:  1024 | lm loss: 1.866986E+00 | loss scale: 1.0 | grad norm: 0.094 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25364/   51900 | consumed samples:     25972736 | elapsed time per iteration (ms): 37672.0 | learning rate: 1.190E-04 | global batch size:  1024 | lm loss: 1.849911E+00 | loss scale: 1.0 | grad norm: 0.099 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25365/   51900 | consumed samples:     25973760 | elapsed time per iteration (ms): 37647.4 | learning rate: 1.190E-04 | global batch size:  1024 | lm loss: 1.845641E+00 | loss scale: 1.0 | grad norm: 0.094 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25366/   51900 | consumed samples:     25974784 | elapsed time per iteration (ms): 37645.1 | learning rate: 1.190E-04 | global batch size:  1024 | lm loss: 1.862404E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25367/   51900 | consumed samples:     25975808 | elapsed time per iteration (ms): 37615.0 | learning rate: 1.190E-04 | global batch size:  1024 | lm loss: 1.839635E+00 | loss scale: 1.0 | grad norm: 0.087 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25368/   51900 | consumed samples:     25976832 | elapsed time per iteration (ms): 37613.2 | learning rate: 1.189E-04 | global batch size:  1024 | lm loss: 1.852221E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25369/   51900 | consumed samples:     25977856 | elapsed time per iteration (ms): 37545.2 | learning rate: 1.189E-04 | global batch size:  1024 | lm loss: 1.859771E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25370/   51900 | consumed samples:     25978880 | elapsed time per iteration (ms): 37649.2 | learning rate: 1.189E-04 | global batch size:  1024 | lm loss: 1.842547E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25371/   51900 | consumed samples:     25979904 | elapsed time per iteration (ms): 37613.0 | learning rate: 1.189E-04 | global batch size:  1024 | lm loss: 1.852771E+00 | loss scale: 1.0 | grad norm: 0.090 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25372/   51900 | consumed samples:     25980928 | elapsed time per iteration (ms): 37623.2 | learning rate: 1.189E-04 | global batch size:  1024 | lm loss: 1.872539E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25373/   51900 | consumed samples:     25981952 | elapsed time per iteration (ms): 37664.4 | learning rate: 1.189E-04 | global batch size:  1024 | lm loss: 1.847560E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25374/   51900 | consumed samples:     25982976 | elapsed time per iteration (ms): 37680.4 | learning rate: 1.189E-04 | global batch size:  1024 | lm loss: 1.871084E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25375/   51900 | consumed samples:     25984000 | elapsed time per iteration (ms): 37763.5 | learning rate: 1.189E-04 | global batch size:  1024 | lm loss: 1.842007E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25376/   51900 | consumed samples:     25985024 | elapsed time per iteration (ms): 37646.0 | learning rate: 1.189E-04 | global batch size:  1024 | lm loss: 1.870211E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25377/   51900 | consumed samples:     25986048 | elapsed time per iteration (ms): 37569.7 | learning rate: 1.189E-04 | global batch size:  1024 | lm loss: 1.864749E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25378/   51900 | consumed samples:     25987072 | elapsed time per iteration (ms): 37728.2 | learning rate: 1.189E-04 | global batch size:  1024 | lm loss: 1.833401E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25379/   51900 | consumed samples:     25988096 | elapsed time per iteration (ms): 37620.4 | learning rate: 1.189E-04 | global batch size:  1024 | lm loss: 1.857528E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25380/   51900 | consumed samples:     25989120 | elapsed time per iteration (ms): 37640.9 | learning rate: 1.189E-04 | global batch size:  1024 | lm loss: 1.873659E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25381/   51900 | consumed samples:     25990144 | elapsed time per iteration (ms): 37672.4 | learning rate: 1.189E-04 | global batch size:  1024 | lm loss: 1.854751E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25382/   51900 | consumed samples:     25991168 | elapsed time per iteration (ms): 37615.1 | learning rate: 1.189E-04 | global batch size:  1024 | lm loss: 1.840598E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25383/   51900 | consumed samples:     25992192 | elapsed time per iteration (ms): 37536.6 | learning rate: 1.189E-04 | global batch size:  1024 | lm loss: 1.854732E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25384/   51900 | consumed samples:     25993216 | elapsed time per iteration (ms): 37688.9 | learning rate: 1.189E-04 | global batch size:  1024 | lm loss: 1.847787E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25385/   51900 | consumed samples:     25994240 | elapsed time per iteration (ms): 37564.1 | learning rate: 1.189E-04 | global batch size:  1024 | lm loss: 1.852989E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25386/   51900 | consumed samples:     25995264 | elapsed time per iteration (ms): 37454.4 | learning rate: 1.188E-04 | global batch size:  1024 | lm loss: 1.856542E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25387/   51900 | consumed samples:     25996288 | elapsed time per iteration (ms): 37727.8 | learning rate: 1.188E-04 | global batch size:  1024 | lm loss: 1.867465E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25388/   51900 | consumed samples:     25997312 | elapsed time per iteration (ms): 37642.1 | learning rate: 1.188E-04 | global batch size:  1024 | lm loss: 1.877972E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25389/   51900 | consumed samples:     25998336 | elapsed time per iteration (ms): 37665.9 | learning rate: 1.188E-04 | global batch size:  1024 | lm loss: 1.874212E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25390/   51900 | consumed samples:     25999360 | elapsed time per iteration (ms): 37568.9 | learning rate: 1.188E-04 | global batch size:  1024 | lm loss: 1.850791E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25391/   51900 | consumed samples:     26000384 | elapsed time per iteration (ms): 37631.4 | learning rate: 1.188E-04 | global batch size:  1024 | lm loss: 1.848207E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25392/   51900 | consumed samples:     26001408 | elapsed time per iteration (ms): 37617.6 | learning rate: 1.188E-04 | global batch size:  1024 | lm loss: 1.852417E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25393/   51900 | consumed samples:     26002432 | elapsed time per iteration (ms): 37625.3 | learning rate: 1.188E-04 | global batch size:  1024 | lm loss: 1.851202E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25394/   51900 | consumed samples:     26003456 | elapsed time per iteration (ms): 37665.5 | learning rate: 1.188E-04 | global batch size:  1024 | lm loss: 1.835351E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25395/   51900 | consumed samples:     26004480 | elapsed time per iteration (ms): 37637.5 | learning rate: 1.188E-04 | global batch size:  1024 | lm loss: 1.849895E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25396/   51900 | consumed samples:     26005504 | elapsed time per iteration (ms): 37630.2 | learning rate: 1.188E-04 | global batch size:  1024 | lm loss: 1.840943E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25397/   51900 | consumed samples:     26006528 | elapsed time per iteration (ms): 37661.9 | learning rate: 1.188E-04 | global batch size:  1024 | lm loss: 1.859612E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25398/   51900 | consumed samples:     26007552 | elapsed time per iteration (ms): 37742.8 | learning rate: 1.188E-04 | global batch size:  1024 | lm loss: 1.861827E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25399/   51900 | consumed samples:     26008576 | elapsed time per iteration (ms): 37495.9 | learning rate: 1.188E-04 | global batch size:  1024 | lm loss: 1.844141E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25400/   51900 | consumed samples:     26009600 | elapsed time per iteration (ms): 37631.6 | learning rate: 1.188E-04 | global batch size:  1024 | lm loss: 1.850693E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25401/   51900 | consumed samples:     26010624 | elapsed time per iteration (ms): 37620.2 | learning rate: 1.188E-04 | global batch size:  1024 | lm loss: 1.862777E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25402/   51900 | consumed samples:     26011648 | elapsed time per iteration (ms): 37655.0 | learning rate: 1.188E-04 | global batch size:  1024 | lm loss: 1.854584E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25403/   51900 | consumed samples:     26012672 | elapsed time per iteration (ms): 37598.2 | learning rate: 1.188E-04 | global batch size:  1024 | lm loss: 1.853024E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25404/   51900 | consumed samples:     26013696 | elapsed time per iteration (ms): 37585.8 | learning rate: 1.187E-04 | global batch size:  1024 | lm loss: 1.855912E+00 | loss scale: 1.0 | grad norm: 0.090 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25405/   51900 | consumed samples:     26014720 | elapsed time per iteration (ms): 37562.1 | learning rate: 1.187E-04 | global batch size:  1024 | lm loss: 1.859583E+00 | loss scale: 1.0 | grad norm: 0.090 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25406/   51900 | consumed samples:     26015744 | elapsed time per iteration (ms): 37708.3 | learning rate: 1.187E-04 | global batch size:  1024 | lm loss: 1.862875E+00 | loss scale: 1.0 | grad norm: 0.095 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25407/   51900 | consumed samples:     26016768 | elapsed time per iteration (ms): 37680.3 | learning rate: 1.187E-04 | global batch size:  1024 | lm loss: 1.841051E+00 | loss scale: 1.0 | grad norm: 0.092 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25408/   51900 | consumed samples:     26017792 | elapsed time per iteration (ms): 37673.7 | learning rate: 1.187E-04 | global batch size:  1024 | lm loss: 1.846651E+00 | loss scale: 1.0 | grad norm: 0.088 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25409/   51900 | consumed samples:     26018816 | elapsed time per iteration (ms): 37677.5 | learning rate: 1.187E-04 | global batch size:  1024 | lm loss: 1.849475E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25410/   51900 | consumed samples:     26019840 | elapsed time per iteration (ms): 37660.2 | learning rate: 1.187E-04 | global batch size:  1024 | lm loss: 1.863118E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25411/   51900 | consumed samples:     26020864 | elapsed time per iteration (ms): 37618.4 | learning rate: 1.187E-04 | global batch size:  1024 | lm loss: 1.862001E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25412/   51900 | consumed samples:     26021888 | elapsed time per iteration (ms): 37635.1 | learning rate: 1.187E-04 | global batch size:  1024 | lm loss: 1.867847E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25413/   51900 | consumed samples:     26022912 | elapsed time per iteration (ms): 37655.2 | learning rate: 1.187E-04 | global batch size:  1024 | lm loss: 1.857606E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25414/   51900 | consumed samples:     26023936 | elapsed time per iteration (ms): 37563.8 | learning rate: 1.187E-04 | global batch size:  1024 | lm loss: 1.834278E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25415/   51900 | consumed samples:     26024960 | elapsed time per iteration (ms): 37839.6 | learning rate: 1.187E-04 | global batch size:  1024 | lm loss: 1.859228E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25416/   51900 | consumed samples:     26025984 | elapsed time per iteration (ms): 37728.0 | learning rate: 1.187E-04 | global batch size:  1024 | lm loss: 1.848178E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25417/   51900 | consumed samples:     26027008 | elapsed time per iteration (ms): 37628.5 | learning rate: 1.187E-04 | global batch size:  1024 | lm loss: 1.874538E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25418/   51900 | consumed samples:     26028032 | elapsed time per iteration (ms): 37632.3 | learning rate: 1.187E-04 | global batch size:  1024 | lm loss: 1.864136E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25419/   51900 | consumed samples:     26029056 | elapsed time per iteration (ms): 37637.0 | learning rate: 1.187E-04 | global batch size:  1024 | lm loss: 1.848665E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25420/   51900 | consumed samples:     26030080 | elapsed time per iteration (ms): 37669.3 | learning rate: 1.187E-04 | global batch size:  1024 | lm loss: 1.852444E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25421/   51900 | consumed samples:     26031104 | elapsed time per iteration (ms): 37665.2 | learning rate: 1.187E-04 | global batch size:  1024 | lm loss: 1.867315E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25422/   51900 | consumed samples:     26032128 | elapsed time per iteration (ms): 37640.5 | learning rate: 1.186E-04 | global batch size:  1024 | lm loss: 1.876704E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25423/   51900 | consumed samples:     26033152 | elapsed time per iteration (ms): 37698.3 | learning rate: 1.186E-04 | global batch size:  1024 | lm loss: 1.855577E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25424/   51900 | consumed samples:     26034176 | elapsed time per iteration (ms): 37587.5 | learning rate: 1.186E-04 | global batch size:  1024 | lm loss: 1.858874E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25425/   51900 | consumed samples:     26035200 | elapsed time per iteration (ms): 37840.8 | learning rate: 1.186E-04 | global batch size:  1024 | lm loss: 1.860816E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25426/   51900 | consumed samples:     26036224 | elapsed time per iteration (ms): 37500.0 | learning rate: 1.186E-04 | global batch size:  1024 | lm loss: 1.877983E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25427/   51900 | consumed samples:     26037248 | elapsed time per iteration (ms): 37675.7 | learning rate: 1.186E-04 | global batch size:  1024 | lm loss: 1.852558E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25428/   51900 | consumed samples:     26038272 | elapsed time per iteration (ms): 37628.3 | learning rate: 1.186E-04 | global batch size:  1024 | lm loss: 1.875652E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25429/   51900 | consumed samples:     26039296 | elapsed time per iteration (ms): 37695.2 | learning rate: 1.186E-04 | global batch size:  1024 | lm loss: 1.861633E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25430/   51900 | consumed samples:     26040320 | elapsed time per iteration (ms): 37692.3 | learning rate: 1.186E-04 | global batch size:  1024 | lm loss: 1.876874E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25431/   51900 | consumed samples:     26041344 | elapsed time per iteration (ms): 37666.6 | learning rate: 1.186E-04 | global batch size:  1024 | lm loss: 1.848282E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25432/   51900 | consumed samples:     26042368 | elapsed time per iteration (ms): 37621.2 | learning rate: 1.186E-04 | global batch size:  1024 | lm loss: 1.870910E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25433/   51900 | consumed samples:     26043392 | elapsed time per iteration (ms): 37669.7 | learning rate: 1.186E-04 | global batch size:  1024 | lm loss: 1.838263E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25434/   51900 | consumed samples:     26044416 | elapsed time per iteration (ms): 37671.5 | learning rate: 1.186E-04 | global batch size:  1024 | lm loss: 1.843632E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25435/   51900 | consumed samples:     26045440 | elapsed time per iteration (ms): 37664.1 | learning rate: 1.186E-04 | global batch size:  1024 | lm loss: 1.860323E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25436/   51900 | consumed samples:     26046464 | elapsed time per iteration (ms): 37589.8 | learning rate: 1.186E-04 | global batch size:  1024 | lm loss: 1.863685E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25437/   51900 | consumed samples:     26047488 | elapsed time per iteration (ms): 37557.4 | learning rate: 1.186E-04 | global batch size:  1024 | lm loss: 1.854229E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25438/   51900 | consumed samples:     26048512 | elapsed time per iteration (ms): 37592.1 | learning rate: 1.186E-04 | global batch size:  1024 | lm loss: 1.848451E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25439/   51900 | consumed samples:     26049536 | elapsed time per iteration (ms): 37617.9 | learning rate: 1.185E-04 | global batch size:  1024 | lm loss: 1.839819E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25440/   51900 | consumed samples:     26050560 | elapsed time per iteration (ms): 37626.2 | learning rate: 1.185E-04 | global batch size:  1024 | lm loss: 1.855327E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25441/   51900 | consumed samples:     26051584 | elapsed time per iteration (ms): 37570.4 | learning rate: 1.185E-04 | global batch size:  1024 | lm loss: 1.871349E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25442/   51900 | consumed samples:     26052608 | elapsed time per iteration (ms): 37721.7 | learning rate: 1.185E-04 | global batch size:  1024 | lm loss: 1.845227E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25443/   51900 | consumed samples:     26053632 | elapsed time per iteration (ms): 37615.4 | learning rate: 1.185E-04 | global batch size:  1024 | lm loss: 1.854893E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25444/   51900 | consumed samples:     26054656 | elapsed time per iteration (ms): 37646.4 | learning rate: 1.185E-04 | global batch size:  1024 | lm loss: 1.863798E+00 | loss scale: 1.0 | grad norm: 0.091 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25445/   51900 | consumed samples:     26055680 | elapsed time per iteration (ms): 37620.7 | learning rate: 1.185E-04 | global batch size:  1024 | lm loss: 1.879690E+00 | loss scale: 1.0 | grad norm: 0.088 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25446/   51900 | consumed samples:     26056704 | elapsed time per iteration (ms): 37590.8 | learning rate: 1.185E-04 | global batch size:  1024 | lm loss: 1.847612E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25447/   51900 | consumed samples:     26057728 | elapsed time per iteration (ms): 37608.8 | learning rate: 1.185E-04 | global batch size:  1024 | lm loss: 1.854059E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25448/   51900 | consumed samples:     26058752 | elapsed time per iteration (ms): 37735.5 | learning rate: 1.185E-04 | global batch size:  1024 | lm loss: 1.863824E+00 | loss scale: 1.0 | grad norm: 0.088 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25449/   51900 | consumed samples:     26059776 | elapsed time per iteration (ms): 37608.9 | learning rate: 1.185E-04 | global batch size:  1024 | lm loss: 1.847334E+00 | loss scale: 1.0 | grad norm: 0.092 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25450/   51900 | consumed samples:     26060800 | elapsed time per iteration (ms): 37582.2 | learning rate: 1.185E-04 | global batch size:  1024 | lm loss: 1.862916E+00 | loss scale: 1.0 | grad norm: 0.087 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25451/   51900 | consumed samples:     26061824 | elapsed time per iteration (ms): 37642.3 | learning rate: 1.185E-04 | global batch size:  1024 | lm loss: 1.853889E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25452/   51900 | consumed samples:     26062848 | elapsed time per iteration (ms): 37659.2 | learning rate: 1.185E-04 | global batch size:  1024 | lm loss: 1.877438E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25453/   51900 | consumed samples:     26063872 | elapsed time per iteration (ms): 37655.6 | learning rate: 1.185E-04 | global batch size:  1024 | lm loss: 1.842682E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25454/   51900 | consumed samples:     26064896 | elapsed time per iteration (ms): 37618.0 | learning rate: 1.185E-04 | global batch size:  1024 | lm loss: 1.870771E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25455/   51900 | consumed samples:     26065920 | elapsed time per iteration (ms): 37683.2 | learning rate: 1.185E-04 | global batch size:  1024 | lm loss: 1.835985E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25456/   51900 | consumed samples:     26066944 | elapsed time per iteration (ms): 37770.3 | learning rate: 1.185E-04 | global batch size:  1024 | lm loss: 1.858075E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25457/   51900 | consumed samples:     26067968 | elapsed time per iteration (ms): 37694.0 | learning rate: 1.184E-04 | global batch size:  1024 | lm loss: 1.843388E+00 | loss scale: 1.0 | grad norm: 0.090 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25458/   51900 | consumed samples:     26068992 | elapsed time per iteration (ms): 37572.6 | learning rate: 1.184E-04 | global batch size:  1024 | lm loss: 1.861266E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25459/   51900 | consumed samples:     26070016 | elapsed time per iteration (ms): 37597.6 | learning rate: 1.184E-04 | global batch size:  1024 | lm loss: 1.865230E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25460/   51900 | consumed samples:     26071040 | elapsed time per iteration (ms): 37602.8 | learning rate: 1.184E-04 | global batch size:  1024 | lm loss: 1.854414E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25461/   51900 | consumed samples:     26072064 | elapsed time per iteration (ms): 37641.2 | learning rate: 1.184E-04 | global batch size:  1024 | lm loss: 1.846923E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25462/   51900 | consumed samples:     26073088 | elapsed time per iteration (ms): 37729.8 | learning rate: 1.184E-04 | global batch size:  1024 | lm loss: 1.837065E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25463/   51900 | consumed samples:     26074112 | elapsed time per iteration (ms): 37816.7 | learning rate: 1.184E-04 | global batch size:  1024 | lm loss: 1.834385E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25464/   51900 | consumed samples:     26075136 | elapsed time per iteration (ms): 37608.3 | learning rate: 1.184E-04 | global batch size:  1024 | lm loss: 1.847911E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25465/   51900 | consumed samples:     26076160 | elapsed time per iteration (ms): 37689.7 | learning rate: 1.184E-04 | global batch size:  1024 | lm loss: 1.846378E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25466/   51900 | consumed samples:     26077184 | elapsed time per iteration (ms): 37709.5 | learning rate: 1.184E-04 | global batch size:  1024 | lm loss: 1.860477E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25467/   51900 | consumed samples:     26078208 | elapsed time per iteration (ms): 37681.8 | learning rate: 1.184E-04 | global batch size:  1024 | lm loss: 1.867141E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25468/   51900 | consumed samples:     26079232 | elapsed time per iteration (ms): 37626.8 | learning rate: 1.184E-04 | global batch size:  1024 | lm loss: 1.850281E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25469/   51900 | consumed samples:     26080256 | elapsed time per iteration (ms): 37650.6 | learning rate: 1.184E-04 | global batch size:  1024 | lm loss: 1.848087E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25470/   51900 | consumed samples:     26081280 | elapsed time per iteration (ms): 37597.0 | learning rate: 1.184E-04 | global batch size:  1024 | lm loss: 1.838532E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25471/   51900 | consumed samples:     26082304 | elapsed time per iteration (ms): 37650.0 | learning rate: 1.184E-04 | global batch size:  1024 | lm loss: 1.849113E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25472/   51900 | consumed samples:     26083328 | elapsed time per iteration (ms): 37675.1 | learning rate: 1.184E-04 | global batch size:  1024 | lm loss: 1.863236E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25473/   51900 | consumed samples:     26084352 | elapsed time per iteration (ms): 37630.9 | learning rate: 1.184E-04 | global batch size:  1024 | lm loss: 1.849196E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25474/   51900 | consumed samples:     26085376 | elapsed time per iteration (ms): 37675.8 | learning rate: 1.184E-04 | global batch size:  1024 | lm loss: 1.855276E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25475/   51900 | consumed samples:     26086400 | elapsed time per iteration (ms): 37704.6 | learning rate: 1.183E-04 | global batch size:  1024 | lm loss: 1.864633E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25476/   51900 | consumed samples:     26087424 | elapsed time per iteration (ms): 37756.3 | learning rate: 1.183E-04 | global batch size:  1024 | lm loss: 1.863170E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25477/   51900 | consumed samples:     26088448 | elapsed time per iteration (ms): 37541.4 | learning rate: 1.183E-04 | global batch size:  1024 | lm loss: 1.878154E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25478/   51900 | consumed samples:     26089472 | elapsed time per iteration (ms): 37578.3 | learning rate: 1.183E-04 | global batch size:  1024 | lm loss: 1.876181E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25479/   51900 | consumed samples:     26090496 | elapsed time per iteration (ms): 37654.1 | learning rate: 1.183E-04 | global batch size:  1024 | lm loss: 1.839131E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25480/   51900 | consumed samples:     26091520 | elapsed time per iteration (ms): 37668.9 | learning rate: 1.183E-04 | global batch size:  1024 | lm loss: 1.839874E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25481/   51900 | consumed samples:     26092544 | elapsed time per iteration (ms): 37635.7 | learning rate: 1.183E-04 | global batch size:  1024 | lm loss: 1.868904E+00 | loss scale: 1.0 | grad norm: 0.089 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25482/   51900 | consumed samples:     26093568 | elapsed time per iteration (ms): 37693.8 | learning rate: 1.183E-04 | global batch size:  1024 | lm loss: 1.831427E+00 | loss scale: 1.0 | grad norm: 0.088 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25483/   51900 | consumed samples:     26094592 | elapsed time per iteration (ms): 37619.8 | learning rate: 1.183E-04 | global batch size:  1024 | lm loss: 1.859328E+00 | loss scale: 1.0 | grad norm: 0.088 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25484/   51900 | consumed samples:     26095616 | elapsed time per iteration (ms): 37758.3 | learning rate: 1.183E-04 | global batch size:  1024 | lm loss: 1.862757E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25485/   51900 | consumed samples:     26096640 | elapsed time per iteration (ms): 37649.6 | learning rate: 1.183E-04 | global batch size:  1024 | lm loss: 1.856294E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25486/   51900 | consumed samples:     26097664 | elapsed time per iteration (ms): 37613.6 | learning rate: 1.183E-04 | global batch size:  1024 | lm loss: 1.842553E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25487/   51900 | consumed samples:     26098688 | elapsed time per iteration (ms): 37656.8 | learning rate: 1.183E-04 | global batch size:  1024 | lm loss: 1.859167E+00 | loss scale: 1.0 | grad norm: 0.092 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25488/   51900 | consumed samples:     26099712 | elapsed time per iteration (ms): 37662.1 | learning rate: 1.183E-04 | global batch size:  1024 | lm loss: 1.844720E+00 | loss scale: 1.0 | grad norm: 0.090 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25489/   51900 | consumed samples:     26100736 | elapsed time per iteration (ms): 37697.1 | learning rate: 1.183E-04 | global batch size:  1024 | lm loss: 1.852745E+00 | loss scale: 1.0 | grad norm: 0.092 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25490/   51900 | consumed samples:     26101760 | elapsed time per iteration (ms): 37672.8 | learning rate: 1.183E-04 | global batch size:  1024 | lm loss: 1.854566E+00 | loss scale: 1.0 | grad norm: 0.097 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25491/   51900 | consumed samples:     26102784 | elapsed time per iteration (ms): 37727.9 | learning rate: 1.183E-04 | global batch size:  1024 | lm loss: 1.861807E+00 | loss scale: 1.0 | grad norm: 0.089 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25492/   51900 | consumed samples:     26103808 | elapsed time per iteration (ms): 37650.3 | learning rate: 1.182E-04 | global batch size:  1024 | lm loss: 1.854703E+00 | loss scale: 1.0 | grad norm: 0.091 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25493/   51900 | consumed samples:     26104832 | elapsed time per iteration (ms): 37645.4 | learning rate: 1.182E-04 | global batch size:  1024 | lm loss: 1.845003E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25494/   51900 | consumed samples:     26105856 | elapsed time per iteration (ms): 37595.0 | learning rate: 1.182E-04 | global batch size:  1024 | lm loss: 1.869970E+00 | loss scale: 1.0 | grad norm: 0.094 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25495/   51900 | consumed samples:     26106880 | elapsed time per iteration (ms): 37532.8 | learning rate: 1.182E-04 | global batch size:  1024 | lm loss: 1.853927E+00 | loss scale: 1.0 | grad norm: 0.087 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25496/   51900 | consumed samples:     26107904 | elapsed time per iteration (ms): 37647.0 | learning rate: 1.182E-04 | global batch size:  1024 | lm loss: 1.867373E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25497/   51900 | consumed samples:     26108928 | elapsed time per iteration (ms): 37749.6 | learning rate: 1.182E-04 | global batch size:  1024 | lm loss: 1.867440E+00 | loss scale: 1.0 | grad norm: 0.092 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25498/   51900 | consumed samples:     26109952 | elapsed time per iteration (ms): 37618.5 | learning rate: 1.182E-04 | global batch size:  1024 | lm loss: 1.862530E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25499/   51900 | consumed samples:     26110976 | elapsed time per iteration (ms): 37666.6 | learning rate: 1.182E-04 | global batch size:  1024 | lm loss: 1.843321E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25500/   51900 | consumed samples:     26112000 | elapsed time per iteration (ms): 37670.7 | learning rate: 1.182E-04 | global batch size:  1024 | lm loss: 1.860644E+00 | loss scale: 1.0 | grad norm: 0.092 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    save-checkpoint ................................: (170019.78, 170019.88)
 iteration    25501/   51900 | consumed samples:     26113024 | elapsed time per iteration (ms): 37202.6 | learning rate: 1.182E-04 | global batch size:  1024 | lm loss: 1.849161E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25502/   51900 | consumed samples:     26114048 | elapsed time per iteration (ms): 37551.5 | learning rate: 1.182E-04 | global batch size:  1024 | lm loss: 1.869349E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25503/   51900 | consumed samples:     26115072 | elapsed time per iteration (ms): 37626.5 | learning rate: 1.182E-04 | global batch size:  1024 | lm loss: 1.863043E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25504/   51900 | consumed samples:     26116096 | elapsed time per iteration (ms): 37683.6 | learning rate: 1.182E-04 | global batch size:  1024 | lm loss: 1.845654E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25505/   51900 | consumed samples:     26117120 | elapsed time per iteration (ms): 37644.0 | learning rate: 1.182E-04 | global batch size:  1024 | lm loss: 1.849729E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25506/   51900 | consumed samples:     26118144 | elapsed time per iteration (ms): 37573.6 | learning rate: 1.182E-04 | global batch size:  1024 | lm loss: 1.883573E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25507/   51900 | consumed samples:     26119168 | elapsed time per iteration (ms): 37600.4 | learning rate: 1.182E-04 | global batch size:  1024 | lm loss: 1.834672E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25508/   51900 | consumed samples:     26120192 | elapsed time per iteration (ms): 37599.7 | learning rate: 1.182E-04 | global batch size:  1024 | lm loss: 1.860622E+00 | loss scale: 1.0 | grad norm: 0.088 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25509/   51900 | consumed samples:     26121216 | elapsed time per iteration (ms): 37621.9 | learning rate: 1.182E-04 | global batch size:  1024 | lm loss: 1.862977E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25510/   51900 | consumed samples:     26122240 | elapsed time per iteration (ms): 37659.3 | learning rate: 1.181E-04 | global batch size:  1024 | lm loss: 1.883380E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25511/   51900 | consumed samples:     26123264 | elapsed time per iteration (ms): 37738.6 | learning rate: 1.181E-04 | global batch size:  1024 | lm loss: 1.865492E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25512/   51900 | consumed samples:     26124288 | elapsed time per iteration (ms): 37653.9 | learning rate: 1.181E-04 | global batch size:  1024 | lm loss: 1.853528E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25513/   51900 | consumed samples:     26125312 | elapsed time per iteration (ms): 37719.4 | learning rate: 1.181E-04 | global batch size:  1024 | lm loss: 1.852310E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25514/   51900 | consumed samples:     26126336 | elapsed time per iteration (ms): 37636.0 | learning rate: 1.181E-04 | global batch size:  1024 | lm loss: 1.842234E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25515/   51900 | consumed samples:     26127360 | elapsed time per iteration (ms): 37641.6 | learning rate: 1.181E-04 | global batch size:  1024 | lm loss: 1.880951E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25516/   51900 | consumed samples:     26128384 | elapsed time per iteration (ms): 37663.2 | learning rate: 1.181E-04 | global batch size:  1024 | lm loss: 1.862371E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25517/   51900 | consumed samples:     26129408 | elapsed time per iteration (ms): 37547.0 | learning rate: 1.181E-04 | global batch size:  1024 | lm loss: 1.869805E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25518/   51900 | consumed samples:     26130432 | elapsed time per iteration (ms): 37675.4 | learning rate: 1.181E-04 | global batch size:  1024 | lm loss: 1.877189E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25519/   51900 | consumed samples:     26131456 | elapsed time per iteration (ms): 37681.9 | learning rate: 1.181E-04 | global batch size:  1024 | lm loss: 1.845120E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25520/   51900 | consumed samples:     26132480 | elapsed time per iteration (ms): 37597.6 | learning rate: 1.181E-04 | global batch size:  1024 | lm loss: 1.859093E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25521/   51900 | consumed samples:     26133504 | elapsed time per iteration (ms): 37587.0 | learning rate: 1.181E-04 | global batch size:  1024 | lm loss: 1.851580E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25522/   51900 | consumed samples:     26134528 | elapsed time per iteration (ms): 37666.3 | learning rate: 1.181E-04 | global batch size:  1024 | lm loss: 1.860336E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25523/   51900 | consumed samples:     26135552 | elapsed time per iteration (ms): 37675.9 | learning rate: 1.181E-04 | global batch size:  1024 | lm loss: 1.861733E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25524/   51900 | consumed samples:     26136576 | elapsed time per iteration (ms): 37650.0 | learning rate: 1.181E-04 | global batch size:  1024 | lm loss: 1.841374E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25525/   51900 | consumed samples:     26137600 | elapsed time per iteration (ms): 37690.1 | learning rate: 1.181E-04 | global batch size:  1024 | lm loss: 1.864483E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25526/   51900 | consumed samples:     26138624 | elapsed time per iteration (ms): 37670.5 | learning rate: 1.181E-04 | global batch size:  1024 | lm loss: 1.829345E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25527/   51900 | consumed samples:     26139648 | elapsed time per iteration (ms): 37642.0 | learning rate: 1.181E-04 | global batch size:  1024 | lm loss: 1.861784E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25528/   51900 | consumed samples:     26140672 | elapsed time per iteration (ms): 37518.1 | learning rate: 1.180E-04 | global batch size:  1024 | lm loss: 1.837698E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25529/   51900 | consumed samples:     26141696 | elapsed time per iteration (ms): 37649.4 | learning rate: 1.180E-04 | global batch size:  1024 | lm loss: 1.863778E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25530/   51900 | consumed samples:     26142720 | elapsed time per iteration (ms): 37538.6 | learning rate: 1.180E-04 | global batch size:  1024 | lm loss: 1.859908E+00 | loss scale: 1.0 | grad norm: 0.246 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25531/   51900 | consumed samples:     26143744 | elapsed time per iteration (ms): 37615.6 | learning rate: 1.180E-04 | global batch size:  1024 | lm loss: 1.842024E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25532/   51900 | consumed samples:     26144768 | elapsed time per iteration (ms): 37632.1 | learning rate: 1.180E-04 | global batch size:  1024 | lm loss: 1.857821E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25533/   51900 | consumed samples:     26145792 | elapsed time per iteration (ms): 37691.1 | learning rate: 1.180E-04 | global batch size:  1024 | lm loss: 1.848624E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25534/   51900 | consumed samples:     26146816 | elapsed time per iteration (ms): 37636.9 | learning rate: 1.180E-04 | global batch size:  1024 | lm loss: 1.852803E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25535/   51900 | consumed samples:     26147840 | elapsed time per iteration (ms): 37702.5 | learning rate: 1.180E-04 | global batch size:  1024 | lm loss: 1.846890E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25536/   51900 | consumed samples:     26148864 | elapsed time per iteration (ms): 37739.9 | learning rate: 1.180E-04 | global batch size:  1024 | lm loss: 1.861955E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25537/   51900 | consumed samples:     26149888 | elapsed time per iteration (ms): 37690.7 | learning rate: 1.180E-04 | global batch size:  1024 | lm loss: 1.859303E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25538/   51900 | consumed samples:     26150912 | elapsed time per iteration (ms): 37563.3 | learning rate: 1.180E-04 | global batch size:  1024 | lm loss: 1.832146E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25539/   51900 | consumed samples:     26151936 | elapsed time per iteration (ms): 37538.2 | learning rate: 1.180E-04 | global batch size:  1024 | lm loss: 1.875969E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25540/   51900 | consumed samples:     26152960 | elapsed time per iteration (ms): 37550.7 | learning rate: 1.180E-04 | global batch size:  1024 | lm loss: 1.856208E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25541/   51900 | consumed samples:     26153984 | elapsed time per iteration (ms): 37682.0 | learning rate: 1.180E-04 | global batch size:  1024 | lm loss: 1.865165E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25542/   51900 | consumed samples:     26155008 | elapsed time per iteration (ms): 37761.9 | learning rate: 1.180E-04 | global batch size:  1024 | lm loss: 1.831406E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25543/   51900 | consumed samples:     26156032 | elapsed time per iteration (ms): 37766.8 | learning rate: 1.180E-04 | global batch size:  1024 | lm loss: 1.851156E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25544/   51900 | consumed samples:     26157056 | elapsed time per iteration (ms): 37675.4 | learning rate: 1.180E-04 | global batch size:  1024 | lm loss: 1.853119E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25545/   51900 | consumed samples:     26158080 | elapsed time per iteration (ms): 37716.9 | learning rate: 1.180E-04 | global batch size:  1024 | lm loss: 1.864719E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25546/   51900 | consumed samples:     26159104 | elapsed time per iteration (ms): 37668.3 | learning rate: 1.179E-04 | global batch size:  1024 | lm loss: 1.853379E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25547/   51900 | consumed samples:     26160128 | elapsed time per iteration (ms): 37650.3 | learning rate: 1.179E-04 | global batch size:  1024 | lm loss: 1.852741E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25548/   51900 | consumed samples:     26161152 | elapsed time per iteration (ms): 37628.6 | learning rate: 1.179E-04 | global batch size:  1024 | lm loss: 1.852508E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25549/   51900 | consumed samples:     26162176 | elapsed time per iteration (ms): 37708.6 | learning rate: 1.179E-04 | global batch size:  1024 | lm loss: 1.854206E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25550/   51900 | consumed samples:     26163200 | elapsed time per iteration (ms): 37612.4 | learning rate: 1.179E-04 | global batch size:  1024 | lm loss: 1.853398E+00 | loss scale: 1.0 | grad norm: 0.087 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25551/   51900 | consumed samples:     26164224 | elapsed time per iteration (ms): 37717.7 | learning rate: 1.179E-04 | global batch size:  1024 | lm loss: 1.857003E+00 | loss scale: 1.0 | grad norm: 0.093 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25552/   51900 | consumed samples:     26165248 | elapsed time per iteration (ms): 37559.4 | learning rate: 1.179E-04 | global batch size:  1024 | lm loss: 1.854413E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25553/   51900 | consumed samples:     26166272 | elapsed time per iteration (ms): 37597.4 | learning rate: 1.179E-04 | global batch size:  1024 | lm loss: 1.864055E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25554/   51900 | consumed samples:     26167296 | elapsed time per iteration (ms): 37577.1 | learning rate: 1.179E-04 | global batch size:  1024 | lm loss: 1.853378E+00 | loss scale: 1.0 | grad norm: 0.103 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25555/   51900 | consumed samples:     26168320 | elapsed time per iteration (ms): 37527.1 | learning rate: 1.179E-04 | global batch size:  1024 | lm loss: 1.841671E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25556/   51900 | consumed samples:     26169344 | elapsed time per iteration (ms): 37604.4 | learning rate: 1.179E-04 | global batch size:  1024 | lm loss: 1.845218E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25557/   51900 | consumed samples:     26170368 | elapsed time per iteration (ms): 37728.9 | learning rate: 1.179E-04 | global batch size:  1024 | lm loss: 1.867922E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25558/   51900 | consumed samples:     26171392 | elapsed time per iteration (ms): 37673.4 | learning rate: 1.179E-04 | global batch size:  1024 | lm loss: 1.848436E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25559/   51900 | consumed samples:     26172416 | elapsed time per iteration (ms): 37643.4 | learning rate: 1.179E-04 | global batch size:  1024 | lm loss: 1.855561E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25560/   51900 | consumed samples:     26173440 | elapsed time per iteration (ms): 37592.2 | learning rate: 1.179E-04 | global batch size:  1024 | lm loss: 1.867379E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25561/   51900 | consumed samples:     26174464 | elapsed time per iteration (ms): 37583.4 | learning rate: 1.179E-04 | global batch size:  1024 | lm loss: 1.847966E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25562/   51900 | consumed samples:     26175488 | elapsed time per iteration (ms): 37569.4 | learning rate: 1.179E-04 | global batch size:  1024 | lm loss: 1.848924E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25563/   51900 | consumed samples:     26176512 | elapsed time per iteration (ms): 37644.7 | learning rate: 1.178E-04 | global batch size:  1024 | lm loss: 1.866384E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25564/   51900 | consumed samples:     26177536 | elapsed time per iteration (ms): 37642.2 | learning rate: 1.178E-04 | global batch size:  1024 | lm loss: 1.851064E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25565/   51900 | consumed samples:     26178560 | elapsed time per iteration (ms): 37671.2 | learning rate: 1.178E-04 | global batch size:  1024 | lm loss: 1.849972E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25566/   51900 | consumed samples:     26179584 | elapsed time per iteration (ms): 37640.0 | learning rate: 1.178E-04 | global batch size:  1024 | lm loss: 1.854517E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25567/   51900 | consumed samples:     26180608 | elapsed time per iteration (ms): 37728.9 | learning rate: 1.178E-04 | global batch size:  1024 | lm loss: 1.868477E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25568/   51900 | consumed samples:     26181632 | elapsed time per iteration (ms): 37622.4 | learning rate: 1.178E-04 | global batch size:  1024 | lm loss: 1.842735E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25569/   51900 | consumed samples:     26182656 | elapsed time per iteration (ms): 37778.1 | learning rate: 1.178E-04 | global batch size:  1024 | lm loss: 1.850404E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25570/   51900 | consumed samples:     26183680 | elapsed time per iteration (ms): 37671.8 | learning rate: 1.178E-04 | global batch size:  1024 | lm loss: 1.864431E+00 | loss scale: 1.0 | grad norm: 0.089 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25571/   51900 | consumed samples:     26184704 | elapsed time per iteration (ms): 37640.4 | learning rate: 1.178E-04 | global batch size:  1024 | lm loss: 1.863159E+00 | loss scale: 1.0 | grad norm: 0.090 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25572/   51900 | consumed samples:     26185728 | elapsed time per iteration (ms): 37639.4 | learning rate: 1.178E-04 | global batch size:  1024 | lm loss: 1.841535E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25573/   51900 | consumed samples:     26186752 | elapsed time per iteration (ms): 37676.9 | learning rate: 1.178E-04 | global batch size:  1024 | lm loss: 1.859376E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25574/   51900 | consumed samples:     26187776 | elapsed time per iteration (ms): 37660.3 | learning rate: 1.178E-04 | global batch size:  1024 | lm loss: 1.855064E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25575/   51900 | consumed samples:     26188800 | elapsed time per iteration (ms): 37699.4 | learning rate: 1.178E-04 | global batch size:  1024 | lm loss: 1.844265E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25576/   51900 | consumed samples:     26189824 | elapsed time per iteration (ms): 37627.1 | learning rate: 1.178E-04 | global batch size:  1024 | lm loss: 1.854379E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25577/   51900 | consumed samples:     26190848 | elapsed time per iteration (ms): 37599.2 | learning rate: 1.178E-04 | global batch size:  1024 | lm loss: 1.846403E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25578/   51900 | consumed samples:     26191872 | elapsed time per iteration (ms): 37680.7 | learning rate: 1.178E-04 | global batch size:  1024 | lm loss: 1.866852E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25579/   51900 | consumed samples:     26192896 | elapsed time per iteration (ms): 37652.4 | learning rate: 1.178E-04 | global batch size:  1024 | lm loss: 1.862317E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25580/   51900 | consumed samples:     26193920 | elapsed time per iteration (ms): 37561.8 | learning rate: 1.178E-04 | global batch size:  1024 | lm loss: 1.872553E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25581/   51900 | consumed samples:     26194944 | elapsed time per iteration (ms): 37556.0 | learning rate: 1.177E-04 | global batch size:  1024 | lm loss: 1.859489E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25582/   51900 | consumed samples:     26195968 | elapsed time per iteration (ms): 37552.7 | learning rate: 1.177E-04 | global batch size:  1024 | lm loss: 1.849837E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25583/   51900 | consumed samples:     26196992 | elapsed time per iteration (ms): 37626.5 | learning rate: 1.177E-04 | global batch size:  1024 | lm loss: 1.854930E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25584/   51900 | consumed samples:     26198016 | elapsed time per iteration (ms): 37650.1 | learning rate: 1.177E-04 | global batch size:  1024 | lm loss: 1.856579E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25585/   51900 | consumed samples:     26199040 | elapsed time per iteration (ms): 37695.6 | learning rate: 1.177E-04 | global batch size:  1024 | lm loss: 1.844420E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25586/   51900 | consumed samples:     26200064 | elapsed time per iteration (ms): 37666.0 | learning rate: 1.177E-04 | global batch size:  1024 | lm loss: 1.860576E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25587/   51900 | consumed samples:     26201088 | elapsed time per iteration (ms): 37615.1 | learning rate: 1.177E-04 | global batch size:  1024 | lm loss: 1.871946E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25588/   51900 | consumed samples:     26202112 | elapsed time per iteration (ms): 37682.2 | learning rate: 1.177E-04 | global batch size:  1024 | lm loss: 1.864826E+00 | loss scale: 1.0 | grad norm: 0.088 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25589/   51900 | consumed samples:     26203136 | elapsed time per iteration (ms): 37550.0 | learning rate: 1.177E-04 | global batch size:  1024 | lm loss: 1.858041E+00 | loss scale: 1.0 | grad norm: 0.087 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25590/   51900 | consumed samples:     26204160 | elapsed time per iteration (ms): 37649.2 | learning rate: 1.177E-04 | global batch size:  1024 | lm loss: 1.855320E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25591/   51900 | consumed samples:     26205184 | elapsed time per iteration (ms): 37642.4 | learning rate: 1.177E-04 | global batch size:  1024 | lm loss: 1.866309E+00 | loss scale: 1.0 | grad norm: 0.096 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25592/   51900 | consumed samples:     26206208 | elapsed time per iteration (ms): 37601.6 | learning rate: 1.177E-04 | global batch size:  1024 | lm loss: 1.864025E+00 | loss scale: 1.0 | grad norm: 0.093 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25593/   51900 | consumed samples:     26207232 | elapsed time per iteration (ms): 37545.3 | learning rate: 1.177E-04 | global batch size:  1024 | lm loss: 1.838884E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25594/   51900 | consumed samples:     26208256 | elapsed time per iteration (ms): 37611.0 | learning rate: 1.177E-04 | global batch size:  1024 | lm loss: 1.863267E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25595/   51900 | consumed samples:     26209280 | elapsed time per iteration (ms): 37587.7 | learning rate: 1.177E-04 | global batch size:  1024 | lm loss: 1.849974E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25596/   51900 | consumed samples:     26210304 | elapsed time per iteration (ms): 37664.8 | learning rate: 1.177E-04 | global batch size:  1024 | lm loss: 1.862715E+00 | loss scale: 1.0 | grad norm: 0.090 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25597/   51900 | consumed samples:     26211328 | elapsed time per iteration (ms): 37633.2 | learning rate: 1.177E-04 | global batch size:  1024 | lm loss: 1.861102E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25598/   51900 | consumed samples:     26212352 | elapsed time per iteration (ms): 37570.6 | learning rate: 1.177E-04 | global batch size:  1024 | lm loss: 1.852426E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25599/   51900 | consumed samples:     26213376 | elapsed time per iteration (ms): 37696.6 | learning rate: 1.176E-04 | global batch size:  1024 | lm loss: 1.856022E+00 | loss scale: 1.0 | grad norm: 0.089 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25600/   51900 | consumed samples:     26214400 | elapsed time per iteration (ms): 37611.0 | learning rate: 1.176E-04 | global batch size:  1024 | lm loss: 1.843720E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25601/   51900 | consumed samples:     26215424 | elapsed time per iteration (ms): 37588.9 | learning rate: 1.176E-04 | global batch size:  1024 | lm loss: 1.858723E+00 | loss scale: 1.0 | grad norm: 0.090 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25602/   51900 | consumed samples:     26216448 | elapsed time per iteration (ms): 37644.4 | learning rate: 1.176E-04 | global batch size:  1024 | lm loss: 1.838675E+00 | loss scale: 1.0 | grad norm: 0.094 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25603/   51900 | consumed samples:     26217472 | elapsed time per iteration (ms): 37601.7 | learning rate: 1.176E-04 | global batch size:  1024 | lm loss: 1.855161E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25604/   51900 | consumed samples:     26218496 | elapsed time per iteration (ms): 37733.9 | learning rate: 1.176E-04 | global batch size:  1024 | lm loss: 1.871477E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25605/   51900 | consumed samples:     26219520 | elapsed time per iteration (ms): 37661.6 | learning rate: 1.176E-04 | global batch size:  1024 | lm loss: 1.837313E+00 | loss scale: 1.0 | grad norm: 0.090 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25606/   51900 | consumed samples:     26220544 | elapsed time per iteration (ms): 37581.6 | learning rate: 1.176E-04 | global batch size:  1024 | lm loss: 1.847312E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25607/   51900 | consumed samples:     26221568 | elapsed time per iteration (ms): 37607.2 | learning rate: 1.176E-04 | global batch size:  1024 | lm loss: 1.866164E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25608/   51900 | consumed samples:     26222592 | elapsed time per iteration (ms): 37575.9 | learning rate: 1.176E-04 | global batch size:  1024 | lm loss: 1.872125E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25609/   51900 | consumed samples:     26223616 | elapsed time per iteration (ms): 37587.1 | learning rate: 1.176E-04 | global batch size:  1024 | lm loss: 1.859394E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25610/   51900 | consumed samples:     26224640 | elapsed time per iteration (ms): 37609.0 | learning rate: 1.176E-04 | global batch size:  1024 | lm loss: 1.848320E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25611/   51900 | consumed samples:     26225664 | elapsed time per iteration (ms): 37634.9 | learning rate: 1.176E-04 | global batch size:  1024 | lm loss: 1.837195E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25612/   51900 | consumed samples:     26226688 | elapsed time per iteration (ms): 37697.7 | learning rate: 1.176E-04 | global batch size:  1024 | lm loss: 1.844600E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25613/   51900 | consumed samples:     26227712 | elapsed time per iteration (ms): 37588.9 | learning rate: 1.176E-04 | global batch size:  1024 | lm loss: 1.840626E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25614/   51900 | consumed samples:     26228736 | elapsed time per iteration (ms): 37615.9 | learning rate: 1.176E-04 | global batch size:  1024 | lm loss: 1.849491E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25615/   51900 | consumed samples:     26229760 | elapsed time per iteration (ms): 37653.3 | learning rate: 1.176E-04 | global batch size:  1024 | lm loss: 1.856620E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25616/   51900 | consumed samples:     26230784 | elapsed time per iteration (ms): 37591.2 | learning rate: 1.175E-04 | global batch size:  1024 | lm loss: 1.855263E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25617/   51900 | consumed samples:     26231808 | elapsed time per iteration (ms): 37674.2 | learning rate: 1.175E-04 | global batch size:  1024 | lm loss: 1.853553E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25618/   51900 | consumed samples:     26232832 | elapsed time per iteration (ms): 37605.2 | learning rate: 1.175E-04 | global batch size:  1024 | lm loss: 1.852869E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25619/   51900 | consumed samples:     26233856 | elapsed time per iteration (ms): 37568.5 | learning rate: 1.175E-04 | global batch size:  1024 | lm loss: 1.853081E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25620/   51900 | consumed samples:     26234880 | elapsed time per iteration (ms): 37653.5 | learning rate: 1.175E-04 | global batch size:  1024 | lm loss: 1.857425E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25621/   51900 | consumed samples:     26235904 | elapsed time per iteration (ms): 37639.8 | learning rate: 1.175E-04 | global batch size:  1024 | lm loss: 1.867104E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25622/   51900 | consumed samples:     26236928 | elapsed time per iteration (ms): 37626.9 | learning rate: 1.175E-04 | global batch size:  1024 | lm loss: 1.863641E+00 | loss scale: 1.0 | grad norm: 0.091 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25623/   51900 | consumed samples:     26237952 | elapsed time per iteration (ms): 37557.9 | learning rate: 1.175E-04 | global batch size:  1024 | lm loss: 1.865016E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25624/   51900 | consumed samples:     26238976 | elapsed time per iteration (ms): 37637.0 | learning rate: 1.175E-04 | global batch size:  1024 | lm loss: 1.839164E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25625/   51900 | consumed samples:     26240000 | elapsed time per iteration (ms): 37680.8 | learning rate: 1.175E-04 | global batch size:  1024 | lm loss: 1.864424E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25626/   51900 | consumed samples:     26241024 | elapsed time per iteration (ms): 37752.7 | learning rate: 1.175E-04 | global batch size:  1024 | lm loss: 1.859226E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25627/   51900 | consumed samples:     26242048 | elapsed time per iteration (ms): 37703.8 | learning rate: 1.175E-04 | global batch size:  1024 | lm loss: 1.863830E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25628/   51900 | consumed samples:     26243072 | elapsed time per iteration (ms): 37516.6 | learning rate: 1.175E-04 | global batch size:  1024 | lm loss: 1.856270E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25629/   51900 | consumed samples:     26244096 | elapsed time per iteration (ms): 37619.3 | learning rate: 1.175E-04 | global batch size:  1024 | lm loss: 1.850786E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25630/   51900 | consumed samples:     26245120 | elapsed time per iteration (ms): 37620.0 | learning rate: 1.175E-04 | global batch size:  1024 | lm loss: 1.842028E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25631/   51900 | consumed samples:     26246144 | elapsed time per iteration (ms): 37686.0 | learning rate: 1.175E-04 | global batch size:  1024 | lm loss: 1.861165E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25632/   51900 | consumed samples:     26247168 | elapsed time per iteration (ms): 37673.3 | learning rate: 1.175E-04 | global batch size:  1024 | lm loss: 1.852122E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25633/   51900 | consumed samples:     26248192 | elapsed time per iteration (ms): 37677.0 | learning rate: 1.175E-04 | global batch size:  1024 | lm loss: 1.838198E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25634/   51900 | consumed samples:     26249216 | elapsed time per iteration (ms): 37712.4 | learning rate: 1.174E-04 | global batch size:  1024 | lm loss: 1.862591E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25635/   51900 | consumed samples:     26250240 | elapsed time per iteration (ms): 37748.4 | learning rate: 1.174E-04 | global batch size:  1024 | lm loss: 1.850657E+00 | loss scale: 1.0 | grad norm: 0.088 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25636/   51900 | consumed samples:     26251264 | elapsed time per iteration (ms): 37711.0 | learning rate: 1.174E-04 | global batch size:  1024 | lm loss: 1.862137E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25637/   51900 | consumed samples:     26252288 | elapsed time per iteration (ms): 37695.9 | learning rate: 1.174E-04 | global batch size:  1024 | lm loss: 1.856908E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25638/   51900 | consumed samples:     26253312 | elapsed time per iteration (ms): 37596.4 | learning rate: 1.174E-04 | global batch size:  1024 | lm loss: 1.865787E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25639/   51900 | consumed samples:     26254336 | elapsed time per iteration (ms): 37794.5 | learning rate: 1.174E-04 | global batch size:  1024 | lm loss: 1.860215E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25640/   51900 | consumed samples:     26255360 | elapsed time per iteration (ms): 37806.7 | learning rate: 1.174E-04 | global batch size:  1024 | lm loss: 1.852224E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25641/   51900 | consumed samples:     26256384 | elapsed time per iteration (ms): 37743.9 | learning rate: 1.174E-04 | global batch size:  1024 | lm loss: 1.867398E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25642/   51900 | consumed samples:     26257408 | elapsed time per iteration (ms): 37642.0 | learning rate: 1.174E-04 | global batch size:  1024 | lm loss: 1.857918E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25643/   51900 | consumed samples:     26258432 | elapsed time per iteration (ms): 37751.1 | learning rate: 1.174E-04 | global batch size:  1024 | lm loss: 1.849935E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25644/   51900 | consumed samples:     26259456 | elapsed time per iteration (ms): 37670.5 | learning rate: 1.174E-04 | global batch size:  1024 | lm loss: 1.848688E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25645/   51900 | consumed samples:     26260480 | elapsed time per iteration (ms): 37739.1 | learning rate: 1.174E-04 | global batch size:  1024 | lm loss: 1.853006E+00 | loss scale: 1.0 | grad norm: 0.088 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25646/   51900 | consumed samples:     26261504 | elapsed time per iteration (ms): 37704.3 | learning rate: 1.174E-04 | global batch size:  1024 | lm loss: 1.853574E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25647/   51900 | consumed samples:     26262528 | elapsed time per iteration (ms): 37608.8 | learning rate: 1.174E-04 | global batch size:  1024 | lm loss: 1.865025E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25648/   51900 | consumed samples:     26263552 | elapsed time per iteration (ms): 37636.2 | learning rate: 1.174E-04 | global batch size:  1024 | lm loss: 1.862681E+00 | loss scale: 1.0 | grad norm: 0.090 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25649/   51900 | consumed samples:     26264576 | elapsed time per iteration (ms): 37730.7 | learning rate: 1.174E-04 | global batch size:  1024 | lm loss: 1.853758E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25650/   51900 | consumed samples:     26265600 | elapsed time per iteration (ms): 37573.6 | learning rate: 1.174E-04 | global batch size:  1024 | lm loss: 1.851403E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25651/   51900 | consumed samples:     26266624 | elapsed time per iteration (ms): 37687.4 | learning rate: 1.174E-04 | global batch size:  1024 | lm loss: 1.860644E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25652/   51900 | consumed samples:     26267648 | elapsed time per iteration (ms): 37623.9 | learning rate: 1.173E-04 | global batch size:  1024 | lm loss: 1.840660E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25653/   51900 | consumed samples:     26268672 | elapsed time per iteration (ms): 37632.4 | learning rate: 1.173E-04 | global batch size:  1024 | lm loss: 1.856344E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25654/   51900 | consumed samples:     26269696 | elapsed time per iteration (ms): 37704.9 | learning rate: 1.173E-04 | global batch size:  1024 | lm loss: 1.856475E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25655/   51900 | consumed samples:     26270720 | elapsed time per iteration (ms): 37685.0 | learning rate: 1.173E-04 | global batch size:  1024 | lm loss: 1.866634E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25656/   51900 | consumed samples:     26271744 | elapsed time per iteration (ms): 37644.4 | learning rate: 1.173E-04 | global batch size:  1024 | lm loss: 1.877894E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25657/   51900 | consumed samples:     26272768 | elapsed time per iteration (ms): 37610.1 | learning rate: 1.173E-04 | global batch size:  1024 | lm loss: 1.853633E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25658/   51900 | consumed samples:     26273792 | elapsed time per iteration (ms): 37681.5 | learning rate: 1.173E-04 | global batch size:  1024 | lm loss: 1.866329E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25659/   51900 | consumed samples:     26274816 | elapsed time per iteration (ms): 37801.8 | learning rate: 1.173E-04 | global batch size:  1024 | lm loss: 1.850687E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25660/   51900 | consumed samples:     26275840 | elapsed time per iteration (ms): 37639.0 | learning rate: 1.173E-04 | global batch size:  1024 | lm loss: 1.876539E+00 | loss scale: 1.0 | grad norm: 0.097 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25661/   51900 | consumed samples:     26276864 | elapsed time per iteration (ms): 37677.1 | learning rate: 1.173E-04 | global batch size:  1024 | lm loss: 1.833050E+00 | loss scale: 1.0 | grad norm: 0.092 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25662/   51900 | consumed samples:     26277888 | elapsed time per iteration (ms): 37712.4 | learning rate: 1.173E-04 | global batch size:  1024 | lm loss: 1.846548E+00 | loss scale: 1.0 | grad norm: 0.096 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25663/   51900 | consumed samples:     26278912 | elapsed time per iteration (ms): 37703.5 | learning rate: 1.173E-04 | global batch size:  1024 | lm loss: 1.866868E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25664/   51900 | consumed samples:     26279936 | elapsed time per iteration (ms): 37662.3 | learning rate: 1.173E-04 | global batch size:  1024 | lm loss: 1.853319E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25665/   51900 | consumed samples:     26280960 | elapsed time per iteration (ms): 37579.2 | learning rate: 1.173E-04 | global batch size:  1024 | lm loss: 1.852014E+00 | loss scale: 1.0 | grad norm: 0.087 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25666/   51900 | consumed samples:     26281984 | elapsed time per iteration (ms): 37667.5 | learning rate: 1.173E-04 | global batch size:  1024 | lm loss: 1.864206E+00 | loss scale: 1.0 | grad norm: 0.098 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25667/   51900 | consumed samples:     26283008 | elapsed time per iteration (ms): 37742.1 | learning rate: 1.173E-04 | global batch size:  1024 | lm loss: 1.825994E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25668/   51900 | consumed samples:     26284032 | elapsed time per iteration (ms): 37612.2 | learning rate: 1.173E-04 | global batch size:  1024 | lm loss: 1.845266E+00 | loss scale: 1.0 | grad norm: 0.154 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25669/   51900 | consumed samples:     26285056 | elapsed time per iteration (ms): 37628.4 | learning rate: 1.173E-04 | global batch size:  1024 | lm loss: 1.848968E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25670/   51900 | consumed samples:     26286080 | elapsed time per iteration (ms): 37656.4 | learning rate: 1.172E-04 | global batch size:  1024 | lm loss: 1.844950E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25671/   51900 | consumed samples:     26287104 | elapsed time per iteration (ms): 37714.7 | learning rate: 1.172E-04 | global batch size:  1024 | lm loss: 1.846593E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25672/   51900 | consumed samples:     26288128 | elapsed time per iteration (ms): 37513.7 | learning rate: 1.172E-04 | global batch size:  1024 | lm loss: 1.860810E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25673/   51900 | consumed samples:     26289152 | elapsed time per iteration (ms): 37617.8 | learning rate: 1.172E-04 | global batch size:  1024 | lm loss: 1.861845E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25674/   51900 | consumed samples:     26290176 | elapsed time per iteration (ms): 37592.0 | learning rate: 1.172E-04 | global batch size:  1024 | lm loss: 1.854391E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25675/   51900 | consumed samples:     26291200 | elapsed time per iteration (ms): 37605.4 | learning rate: 1.172E-04 | global batch size:  1024 | lm loss: 1.854401E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25676/   51900 | consumed samples:     26292224 | elapsed time per iteration (ms): 37622.4 | learning rate: 1.172E-04 | global batch size:  1024 | lm loss: 1.860295E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25677/   51900 | consumed samples:     26293248 | elapsed time per iteration (ms): 37598.3 | learning rate: 1.172E-04 | global batch size:  1024 | lm loss: 1.860294E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25678/   51900 | consumed samples:     26294272 | elapsed time per iteration (ms): 37544.1 | learning rate: 1.172E-04 | global batch size:  1024 | lm loss: 1.852847E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25679/   51900 | consumed samples:     26295296 | elapsed time per iteration (ms): 37695.8 | learning rate: 1.172E-04 | global batch size:  1024 | lm loss: 1.860518E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25680/   51900 | consumed samples:     26296320 | elapsed time per iteration (ms): 37694.8 | learning rate: 1.172E-04 | global batch size:  1024 | lm loss: 1.855858E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25681/   51900 | consumed samples:     26297344 | elapsed time per iteration (ms): 37722.2 | learning rate: 1.172E-04 | global batch size:  1024 | lm loss: 1.862831E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25682/   51900 | consumed samples:     26298368 | elapsed time per iteration (ms): 37774.0 | learning rate: 1.172E-04 | global batch size:  1024 | lm loss: 1.851238E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25683/   51900 | consumed samples:     26299392 | elapsed time per iteration (ms): 37780.6 | learning rate: 1.172E-04 | global batch size:  1024 | lm loss: 1.844210E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25684/   51900 | consumed samples:     26300416 | elapsed time per iteration (ms): 37574.9 | learning rate: 1.172E-04 | global batch size:  1024 | lm loss: 1.856595E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25685/   51900 | consumed samples:     26301440 | elapsed time per iteration (ms): 37642.5 | learning rate: 1.172E-04 | global batch size:  1024 | lm loss: 1.843163E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25686/   51900 | consumed samples:     26302464 | elapsed time per iteration (ms): 37764.4 | learning rate: 1.172E-04 | global batch size:  1024 | lm loss: 1.842098E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25687/   51900 | consumed samples:     26303488 | elapsed time per iteration (ms): 37740.2 | learning rate: 1.171E-04 | global batch size:  1024 | lm loss: 1.854451E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25688/   51900 | consumed samples:     26304512 | elapsed time per iteration (ms): 37682.4 | learning rate: 1.171E-04 | global batch size:  1024 | lm loss: 1.840590E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25689/   51900 | consumed samples:     26305536 | elapsed time per iteration (ms): 37717.0 | learning rate: 1.171E-04 | global batch size:  1024 | lm loss: 1.846565E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25690/   51900 | consumed samples:     26306560 | elapsed time per iteration (ms): 37734.6 | learning rate: 1.171E-04 | global batch size:  1024 | lm loss: 1.833151E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25691/   51900 | consumed samples:     26307584 | elapsed time per iteration (ms): 37680.0 | learning rate: 1.171E-04 | global batch size:  1024 | lm loss: 1.854761E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25692/   51900 | consumed samples:     26308608 | elapsed time per iteration (ms): 37589.8 | learning rate: 1.171E-04 | global batch size:  1024 | lm loss: 1.885073E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25693/   51900 | consumed samples:     26309632 | elapsed time per iteration (ms): 37592.9 | learning rate: 1.171E-04 | global batch size:  1024 | lm loss: 1.882486E+00 | loss scale: 1.0 | grad norm: 0.088 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25694/   51900 | consumed samples:     26310656 | elapsed time per iteration (ms): 37691.7 | learning rate: 1.171E-04 | global batch size:  1024 | lm loss: 1.849877E+00 | loss scale: 1.0 | grad norm: 0.090 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25695/   51900 | consumed samples:     26311680 | elapsed time per iteration (ms): 37603.0 | learning rate: 1.171E-04 | global batch size:  1024 | lm loss: 1.850030E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25696/   51900 | consumed samples:     26312704 | elapsed time per iteration (ms): 37646.5 | learning rate: 1.171E-04 | global batch size:  1024 | lm loss: 1.838214E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25697/   51900 | consumed samples:     26313728 | elapsed time per iteration (ms): 37698.1 | learning rate: 1.171E-04 | global batch size:  1024 | lm loss: 1.846222E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25698/   51900 | consumed samples:     26314752 | elapsed time per iteration (ms): 37683.9 | learning rate: 1.171E-04 | global batch size:  1024 | lm loss: 1.855523E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25699/   51900 | consumed samples:     26315776 | elapsed time per iteration (ms): 37747.9 | learning rate: 1.171E-04 | global batch size:  1024 | lm loss: 1.853426E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25700/   51900 | consumed samples:     26316800 | elapsed time per iteration (ms): 37572.8 | learning rate: 1.171E-04 | global batch size:  1024 | lm loss: 1.870029E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25701/   51900 | consumed samples:     26317824 | elapsed time per iteration (ms): 37613.1 | learning rate: 1.171E-04 | global batch size:  1024 | lm loss: 1.850165E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25702/   51900 | consumed samples:     26318848 | elapsed time per iteration (ms): 37565.4 | learning rate: 1.171E-04 | global batch size:  1024 | lm loss: 1.873777E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25703/   51900 | consumed samples:     26319872 | elapsed time per iteration (ms): 37615.4 | learning rate: 1.171E-04 | global batch size:  1024 | lm loss: 1.850835E+00 | loss scale: 1.0 | grad norm: 0.088 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25704/   51900 | consumed samples:     26320896 | elapsed time per iteration (ms): 37589.2 | learning rate: 1.171E-04 | global batch size:  1024 | lm loss: 1.863430E+00 | loss scale: 1.0 | grad norm: 0.097 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25705/   51900 | consumed samples:     26321920 | elapsed time per iteration (ms): 37600.3 | learning rate: 1.170E-04 | global batch size:  1024 | lm loss: 1.861910E+00 | loss scale: 1.0 | grad norm: 0.087 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25706/   51900 | consumed samples:     26322944 | elapsed time per iteration (ms): 37612.8 | learning rate: 1.170E-04 | global batch size:  1024 | lm loss: 1.861148E+00 | loss scale: 1.0 | grad norm: 0.088 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25707/   51900 | consumed samples:     26323968 | elapsed time per iteration (ms): 37616.8 | learning rate: 1.170E-04 | global batch size:  1024 | lm loss: 1.860624E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25708/   51900 | consumed samples:     26324992 | elapsed time per iteration (ms): 37635.7 | learning rate: 1.170E-04 | global batch size:  1024 | lm loss: 1.873439E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25709/   51900 | consumed samples:     26326016 | elapsed time per iteration (ms): 37679.9 | learning rate: 1.170E-04 | global batch size:  1024 | lm loss: 1.862204E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25710/   51900 | consumed samples:     26327040 | elapsed time per iteration (ms): 37682.1 | learning rate: 1.170E-04 | global batch size:  1024 | lm loss: 1.862651E+00 | loss scale: 1.0 | grad norm: 0.088 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25711/   51900 | consumed samples:     26328064 | elapsed time per iteration (ms): 37683.1 | learning rate: 1.170E-04 | global batch size:  1024 | lm loss: 1.846980E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25712/   51900 | consumed samples:     26329088 | elapsed time per iteration (ms): 37554.8 | learning rate: 1.170E-04 | global batch size:  1024 | lm loss: 1.863328E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25713/   51900 | consumed samples:     26330112 | elapsed time per iteration (ms): 37639.8 | learning rate: 1.170E-04 | global batch size:  1024 | lm loss: 1.854041E+00 | loss scale: 1.0 | grad norm: 0.134 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25714/   51900 | consumed samples:     26331136 | elapsed time per iteration (ms): 37623.0 | learning rate: 1.170E-04 | global batch size:  1024 | lm loss: 1.849166E+00 | loss scale: 1.0 | grad norm: 0.089 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25715/   51900 | consumed samples:     26332160 | elapsed time per iteration (ms): 37621.5 | learning rate: 1.170E-04 | global batch size:  1024 | lm loss: 1.858273E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25716/   51900 | consumed samples:     26333184 | elapsed time per iteration (ms): 37700.3 | learning rate: 1.170E-04 | global batch size:  1024 | lm loss: 1.875636E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25717/   51900 | consumed samples:     26334208 | elapsed time per iteration (ms): 37607.3 | learning rate: 1.170E-04 | global batch size:  1024 | lm loss: 1.848353E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25718/   51900 | consumed samples:     26335232 | elapsed time per iteration (ms): 37673.2 | learning rate: 1.170E-04 | global batch size:  1024 | lm loss: 1.841687E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25719/   51900 | consumed samples:     26336256 | elapsed time per iteration (ms): 37653.4 | learning rate: 1.170E-04 | global batch size:  1024 | lm loss: 1.874582E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25720/   51900 | consumed samples:     26337280 | elapsed time per iteration (ms): 37739.2 | learning rate: 1.170E-04 | global batch size:  1024 | lm loss: 1.849403E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25721/   51900 | consumed samples:     26338304 | elapsed time per iteration (ms): 37758.5 | learning rate: 1.170E-04 | global batch size:  1024 | lm loss: 1.861182E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25722/   51900 | consumed samples:     26339328 | elapsed time per iteration (ms): 37637.4 | learning rate: 1.170E-04 | global batch size:  1024 | lm loss: 1.856685E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25723/   51900 | consumed samples:     26340352 | elapsed time per iteration (ms): 37710.4 | learning rate: 1.169E-04 | global batch size:  1024 | lm loss: 1.835062E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25724/   51900 | consumed samples:     26341376 | elapsed time per iteration (ms): 37738.1 | learning rate: 1.169E-04 | global batch size:  1024 | lm loss: 1.871312E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25725/   51900 | consumed samples:     26342400 | elapsed time per iteration (ms): 37553.5 | learning rate: 1.169E-04 | global batch size:  1024 | lm loss: 1.862137E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25726/   51900 | consumed samples:     26343424 | elapsed time per iteration (ms): 37649.1 | learning rate: 1.169E-04 | global batch size:  1024 | lm loss: 1.846586E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25727/   51900 | consumed samples:     26344448 | elapsed time per iteration (ms): 37627.0 | learning rate: 1.169E-04 | global batch size:  1024 | lm loss: 1.864253E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25728/   51900 | consumed samples:     26345472 | elapsed time per iteration (ms): 37746.9 | learning rate: 1.169E-04 | global batch size:  1024 | lm loss: 1.841705E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25729/   51900 | consumed samples:     26346496 | elapsed time per iteration (ms): 37620.5 | learning rate: 1.169E-04 | global batch size:  1024 | lm loss: 1.856808E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25730/   51900 | consumed samples:     26347520 | elapsed time per iteration (ms): 37663.4 | learning rate: 1.169E-04 | global batch size:  1024 | lm loss: 1.839758E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25731/   51900 | consumed samples:     26348544 | elapsed time per iteration (ms): 37567.8 | learning rate: 1.169E-04 | global batch size:  1024 | lm loss: 1.844592E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25732/   51900 | consumed samples:     26349568 | elapsed time per iteration (ms): 37669.7 | learning rate: 1.169E-04 | global batch size:  1024 | lm loss: 1.856027E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25733/   51900 | consumed samples:     26350592 | elapsed time per iteration (ms): 37488.1 | learning rate: 1.169E-04 | global batch size:  1024 | lm loss: 1.849370E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25734/   51900 | consumed samples:     26351616 | elapsed time per iteration (ms): 37684.2 | learning rate: 1.169E-04 | global batch size:  1024 | lm loss: 1.849630E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25735/   51900 | consumed samples:     26352640 | elapsed time per iteration (ms): 37592.1 | learning rate: 1.169E-04 | global batch size:  1024 | lm loss: 1.856991E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25736/   51900 | consumed samples:     26353664 | elapsed time per iteration (ms): 37622.3 | learning rate: 1.169E-04 | global batch size:  1024 | lm loss: 1.843426E+00 | loss scale: 1.0 | grad norm: 0.090 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25737/   51900 | consumed samples:     26354688 | elapsed time per iteration (ms): 37703.3 | learning rate: 1.169E-04 | global batch size:  1024 | lm loss: 1.851379E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25738/   51900 | consumed samples:     26355712 | elapsed time per iteration (ms): 37545.3 | learning rate: 1.169E-04 | global batch size:  1024 | lm loss: 1.848600E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25739/   51900 | consumed samples:     26356736 | elapsed time per iteration (ms): 37598.8 | learning rate: 1.169E-04 | global batch size:  1024 | lm loss: 1.862845E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25740/   51900 | consumed samples:     26357760 | elapsed time per iteration (ms): 37600.1 | learning rate: 1.168E-04 | global batch size:  1024 | lm loss: 1.860245E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25741/   51900 | consumed samples:     26358784 | elapsed time per iteration (ms): 37716.0 | learning rate: 1.168E-04 | global batch size:  1024 | lm loss: 1.833690E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25742/   51900 | consumed samples:     26359808 | elapsed time per iteration (ms): 37644.1 | learning rate: 1.168E-04 | global batch size:  1024 | lm loss: 1.842189E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25743/   51900 | consumed samples:     26360832 | elapsed time per iteration (ms): 37591.2 | learning rate: 1.168E-04 | global batch size:  1024 | lm loss: 1.839596E+00 | loss scale: 1.0 | grad norm: 0.097 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25744/   51900 | consumed samples:     26361856 | elapsed time per iteration (ms): 37621.1 | learning rate: 1.168E-04 | global batch size:  1024 | lm loss: 1.865340E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25745/   51900 | consumed samples:     26362880 | elapsed time per iteration (ms): 37636.6 | learning rate: 1.168E-04 | global batch size:  1024 | lm loss: 1.841026E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25746/   51900 | consumed samples:     26363904 | elapsed time per iteration (ms): 37544.7 | learning rate: 1.168E-04 | global batch size:  1024 | lm loss: 1.842473E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25747/   51900 | consumed samples:     26364928 | elapsed time per iteration (ms): 37642.6 | learning rate: 1.168E-04 | global batch size:  1024 | lm loss: 1.852314E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25748/   51900 | consumed samples:     26365952 | elapsed time per iteration (ms): 37742.0 | learning rate: 1.168E-04 | global batch size:  1024 | lm loss: 1.843938E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25749/   51900 | consumed samples:     26366976 | elapsed time per iteration (ms): 37711.5 | learning rate: 1.168E-04 | global batch size:  1024 | lm loss: 1.864897E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25750/   51900 | consumed samples:     26368000 | elapsed time per iteration (ms): 37717.4 | learning rate: 1.168E-04 | global batch size:  1024 | lm loss: 1.842168E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25751/   51900 | consumed samples:     26369024 | elapsed time per iteration (ms): 37670.6 | learning rate: 1.168E-04 | global batch size:  1024 | lm loss: 1.855852E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25752/   51900 | consumed samples:     26370048 | elapsed time per iteration (ms): 37710.4 | learning rate: 1.168E-04 | global batch size:  1024 | lm loss: 1.857193E+00 | loss scale: 1.0 | grad norm: 0.091 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25753/   51900 | consumed samples:     26371072 | elapsed time per iteration (ms): 37571.9 | learning rate: 1.168E-04 | global batch size:  1024 | lm loss: 1.855753E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25754/   51900 | consumed samples:     26372096 | elapsed time per iteration (ms): 37701.7 | learning rate: 1.168E-04 | global batch size:  1024 | lm loss: 1.851542E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25755/   51900 | consumed samples:     26373120 | elapsed time per iteration (ms): 37665.5 | learning rate: 1.168E-04 | global batch size:  1024 | lm loss: 1.845049E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25756/   51900 | consumed samples:     26374144 | elapsed time per iteration (ms): 37664.6 | learning rate: 1.168E-04 | global batch size:  1024 | lm loss: 1.839796E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25757/   51900 | consumed samples:     26375168 | elapsed time per iteration (ms): 37849.4 | learning rate: 1.168E-04 | global batch size:  1024 | lm loss: 1.863365E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25758/   51900 | consumed samples:     26376192 | elapsed time per iteration (ms): 37694.8 | learning rate: 1.167E-04 | global batch size:  1024 | lm loss: 1.843628E+00 | loss scale: 1.0 | grad norm: 0.089 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25759/   51900 | consumed samples:     26377216 | elapsed time per iteration (ms): 37702.1 | learning rate: 1.167E-04 | global batch size:  1024 | lm loss: 1.845427E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25760/   51900 | consumed samples:     26378240 | elapsed time per iteration (ms): 37534.9 | learning rate: 1.167E-04 | global batch size:  1024 | lm loss: 1.849167E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25761/   51900 | consumed samples:     26379264 | elapsed time per iteration (ms): 37666.3 | learning rate: 1.167E-04 | global batch size:  1024 | lm loss: 1.849621E+00 | loss scale: 1.0 | grad norm: 0.090 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25762/   51900 | consumed samples:     26380288 | elapsed time per iteration (ms): 37739.9 | learning rate: 1.167E-04 | global batch size:  1024 | lm loss: 1.859427E+00 | loss scale: 1.0 | grad norm: 0.091 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25763/   51900 | consumed samples:     26381312 | elapsed time per iteration (ms): 37689.7 | learning rate: 1.167E-04 | global batch size:  1024 | lm loss: 1.850533E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25764/   51900 | consumed samples:     26382336 | elapsed time per iteration (ms): 37505.6 | learning rate: 1.167E-04 | global batch size:  1024 | lm loss: 1.868467E+00 | loss scale: 1.0 | grad norm: 0.087 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25765/   51900 | consumed samples:     26383360 | elapsed time per iteration (ms): 37687.2 | learning rate: 1.167E-04 | global batch size:  1024 | lm loss: 1.862423E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25766/   51900 | consumed samples:     26384384 | elapsed time per iteration (ms): 37681.1 | learning rate: 1.167E-04 | global batch size:  1024 | lm loss: 1.854201E+00 | loss scale: 1.0 | grad norm: 0.089 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25767/   51900 | consumed samples:     26385408 | elapsed time per iteration (ms): 37709.5 | learning rate: 1.167E-04 | global batch size:  1024 | lm loss: 1.845191E+00 | loss scale: 1.0 | grad norm: 0.094 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25768/   51900 | consumed samples:     26386432 | elapsed time per iteration (ms): 37621.2 | learning rate: 1.167E-04 | global batch size:  1024 | lm loss: 1.860974E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25769/   51900 | consumed samples:     26387456 | elapsed time per iteration (ms): 37581.8 | learning rate: 1.167E-04 | global batch size:  1024 | lm loss: 1.839945E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25770/   51900 | consumed samples:     26388480 | elapsed time per iteration (ms): 37674.5 | learning rate: 1.167E-04 | global batch size:  1024 | lm loss: 1.856281E+00 | loss scale: 1.0 | grad norm: 0.089 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25771/   51900 | consumed samples:     26389504 | elapsed time per iteration (ms): 37701.8 | learning rate: 1.167E-04 | global batch size:  1024 | lm loss: 1.866893E+00 | loss scale: 1.0 | grad norm: 0.088 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25772/   51900 | consumed samples:     26390528 | elapsed time per iteration (ms): 37643.7 | learning rate: 1.167E-04 | global batch size:  1024 | lm loss: 1.869655E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25773/   51900 | consumed samples:     26391552 | elapsed time per iteration (ms): 37580.2 | learning rate: 1.167E-04 | global batch size:  1024 | lm loss: 1.869080E+00 | loss scale: 1.0 | grad norm: 0.092 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25774/   51900 | consumed samples:     26392576 | elapsed time per iteration (ms): 37679.3 | learning rate: 1.167E-04 | global batch size:  1024 | lm loss: 1.858408E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25775/   51900 | consumed samples:     26393600 | elapsed time per iteration (ms): 37654.6 | learning rate: 1.167E-04 | global batch size:  1024 | lm loss: 1.854047E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25776/   51900 | consumed samples:     26394624 | elapsed time per iteration (ms): 37680.6 | learning rate: 1.166E-04 | global batch size:  1024 | lm loss: 1.852319E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25777/   51900 | consumed samples:     26395648 | elapsed time per iteration (ms): 37802.9 | learning rate: 1.166E-04 | global batch size:  1024 | lm loss: 1.862193E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25778/   51900 | consumed samples:     26396672 | elapsed time per iteration (ms): 37626.3 | learning rate: 1.166E-04 | global batch size:  1024 | lm loss: 1.856576E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25779/   51900 | consumed samples:     26397696 | elapsed time per iteration (ms): 37687.9 | learning rate: 1.166E-04 | global batch size:  1024 | lm loss: 1.876225E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25780/   51900 | consumed samples:     26398720 | elapsed time per iteration (ms): 37681.4 | learning rate: 1.166E-04 | global batch size:  1024 | lm loss: 1.859605E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25781/   51900 | consumed samples:     26399744 | elapsed time per iteration (ms): 37590.5 | learning rate: 1.166E-04 | global batch size:  1024 | lm loss: 1.840995E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25782/   51900 | consumed samples:     26400768 | elapsed time per iteration (ms): 37526.3 | learning rate: 1.166E-04 | global batch size:  1024 | lm loss: 1.861842E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25783/   51900 | consumed samples:     26401792 | elapsed time per iteration (ms): 37639.7 | learning rate: 1.166E-04 | global batch size:  1024 | lm loss: 1.845339E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25784/   51900 | consumed samples:     26402816 | elapsed time per iteration (ms): 37692.7 | learning rate: 1.166E-04 | global batch size:  1024 | lm loss: 1.845682E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25785/   51900 | consumed samples:     26403840 | elapsed time per iteration (ms): 37599.4 | learning rate: 1.166E-04 | global batch size:  1024 | lm loss: 1.869691E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25786/   51900 | consumed samples:     26404864 | elapsed time per iteration (ms): 37566.3 | learning rate: 1.166E-04 | global batch size:  1024 | lm loss: 1.852148E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25787/   51900 | consumed samples:     26405888 | elapsed time per iteration (ms): 37614.8 | learning rate: 1.166E-04 | global batch size:  1024 | lm loss: 1.848056E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25788/   51900 | consumed samples:     26406912 | elapsed time per iteration (ms): 37693.4 | learning rate: 1.166E-04 | global batch size:  1024 | lm loss: 1.860208E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25789/   51900 | consumed samples:     26407936 | elapsed time per iteration (ms): 37614.1 | learning rate: 1.166E-04 | global batch size:  1024 | lm loss: 1.862884E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25790/   51900 | consumed samples:     26408960 | elapsed time per iteration (ms): 37690.4 | learning rate: 1.166E-04 | global batch size:  1024 | lm loss: 1.852098E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25791/   51900 | consumed samples:     26409984 | elapsed time per iteration (ms): 37657.1 | learning rate: 1.166E-04 | global batch size:  1024 | lm loss: 1.844795E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25792/   51900 | consumed samples:     26411008 | elapsed time per iteration (ms): 37623.4 | learning rate: 1.166E-04 | global batch size:  1024 | lm loss: 1.857805E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25793/   51900 | consumed samples:     26412032 | elapsed time per iteration (ms): 37643.3 | learning rate: 1.165E-04 | global batch size:  1024 | lm loss: 1.844828E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25794/   51900 | consumed samples:     26413056 | elapsed time per iteration (ms): 37591.6 | learning rate: 1.165E-04 | global batch size:  1024 | lm loss: 1.868805E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25795/   51900 | consumed samples:     26414080 | elapsed time per iteration (ms): 37640.8 | learning rate: 1.165E-04 | global batch size:  1024 | lm loss: 1.836681E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25796/   51900 | consumed samples:     26415104 | elapsed time per iteration (ms): 37525.3 | learning rate: 1.165E-04 | global batch size:  1024 | lm loss: 1.862965E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25797/   51900 | consumed samples:     26416128 | elapsed time per iteration (ms): 37663.5 | learning rate: 1.165E-04 | global batch size:  1024 | lm loss: 1.835424E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25798/   51900 | consumed samples:     26417152 | elapsed time per iteration (ms): 37658.1 | learning rate: 1.165E-04 | global batch size:  1024 | lm loss: 1.865586E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25799/   51900 | consumed samples:     26418176 | elapsed time per iteration (ms): 37716.8 | learning rate: 1.165E-04 | global batch size:  1024 | lm loss: 1.865721E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25800/   51900 | consumed samples:     26419200 | elapsed time per iteration (ms): 37524.2 | learning rate: 1.165E-04 | global batch size:  1024 | lm loss: 1.869104E+00 | loss scale: 1.0 | grad norm: 0.087 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25801/   51900 | consumed samples:     26420224 | elapsed time per iteration (ms): 37724.1 | learning rate: 1.165E-04 | global batch size:  1024 | lm loss: 1.842744E+00 | loss scale: 1.0 | grad norm: 0.089 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25802/   51900 | consumed samples:     26421248 | elapsed time per iteration (ms): 37693.3 | learning rate: 1.165E-04 | global batch size:  1024 | lm loss: 1.848504E+00 | loss scale: 1.0 | grad norm: 0.090 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25803/   51900 | consumed samples:     26422272 | elapsed time per iteration (ms): 37622.9 | learning rate: 1.165E-04 | global batch size:  1024 | lm loss: 1.857273E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25804/   51900 | consumed samples:     26423296 | elapsed time per iteration (ms): 37628.1 | learning rate: 1.165E-04 | global batch size:  1024 | lm loss: 1.855772E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25805/   51900 | consumed samples:     26424320 | elapsed time per iteration (ms): 37620.3 | learning rate: 1.165E-04 | global batch size:  1024 | lm loss: 1.853169E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25806/   51900 | consumed samples:     26425344 | elapsed time per iteration (ms): 37506.8 | learning rate: 1.165E-04 | global batch size:  1024 | lm loss: 1.848118E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25807/   51900 | consumed samples:     26426368 | elapsed time per iteration (ms): 37789.5 | learning rate: 1.165E-04 | global batch size:  1024 | lm loss: 1.865266E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25808/   51900 | consumed samples:     26427392 | elapsed time per iteration (ms): 37723.0 | learning rate: 1.165E-04 | global batch size:  1024 | lm loss: 1.855934E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25809/   51900 | consumed samples:     26428416 | elapsed time per iteration (ms): 37636.7 | learning rate: 1.165E-04 | global batch size:  1024 | lm loss: 1.850202E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25810/   51900 | consumed samples:     26429440 | elapsed time per iteration (ms): 37607.0 | learning rate: 1.165E-04 | global batch size:  1024 | lm loss: 1.851518E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25811/   51900 | consumed samples:     26430464 | elapsed time per iteration (ms): 37718.6 | learning rate: 1.164E-04 | global batch size:  1024 | lm loss: 1.860042E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25812/   51900 | consumed samples:     26431488 | elapsed time per iteration (ms): 37677.5 | learning rate: 1.164E-04 | global batch size:  1024 | lm loss: 1.859452E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25813/   51900 | consumed samples:     26432512 | elapsed time per iteration (ms): 37640.1 | learning rate: 1.164E-04 | global batch size:  1024 | lm loss: 1.865177E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25814/   51900 | consumed samples:     26433536 | elapsed time per iteration (ms): 37577.9 | learning rate: 1.164E-04 | global batch size:  1024 | lm loss: 1.834517E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25815/   51900 | consumed samples:     26434560 | elapsed time per iteration (ms): 37805.8 | learning rate: 1.164E-04 | global batch size:  1024 | lm loss: 1.857356E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25816/   51900 | consumed samples:     26435584 | elapsed time per iteration (ms): 37608.7 | learning rate: 1.164E-04 | global batch size:  1024 | lm loss: 1.851905E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25817/   51900 | consumed samples:     26436608 | elapsed time per iteration (ms): 37683.5 | learning rate: 1.164E-04 | global batch size:  1024 | lm loss: 1.850888E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25818/   51900 | consumed samples:     26437632 | elapsed time per iteration (ms): 37648.5 | learning rate: 1.164E-04 | global batch size:  1024 | lm loss: 1.872701E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25819/   51900 | consumed samples:     26438656 | elapsed time per iteration (ms): 37627.2 | learning rate: 1.164E-04 | global batch size:  1024 | lm loss: 1.863554E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25820/   51900 | consumed samples:     26439680 | elapsed time per iteration (ms): 37565.0 | learning rate: 1.164E-04 | global batch size:  1024 | lm loss: 1.865607E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25821/   51900 | consumed samples:     26440704 | elapsed time per iteration (ms): 37646.3 | learning rate: 1.164E-04 | global batch size:  1024 | lm loss: 1.849359E+00 | loss scale: 1.0 | grad norm: 0.087 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25822/   51900 | consumed samples:     26441728 | elapsed time per iteration (ms): 37745.8 | learning rate: 1.164E-04 | global batch size:  1024 | lm loss: 1.868206E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25823/   51900 | consumed samples:     26442752 | elapsed time per iteration (ms): 37646.9 | learning rate: 1.164E-04 | global batch size:  1024 | lm loss: 1.862854E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25824/   51900 | consumed samples:     26443776 | elapsed time per iteration (ms): 37650.5 | learning rate: 1.164E-04 | global batch size:  1024 | lm loss: 1.837478E+00 | loss scale: 1.0 | grad norm: 0.099 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25825/   51900 | consumed samples:     26444800 | elapsed time per iteration (ms): 37611.1 | learning rate: 1.164E-04 | global batch size:  1024 | lm loss: 1.854764E+00 | loss scale: 1.0 | grad norm: 0.091 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25826/   51900 | consumed samples:     26445824 | elapsed time per iteration (ms): 37610.8 | learning rate: 1.164E-04 | global batch size:  1024 | lm loss: 1.844131E+00 | loss scale: 1.0 | grad norm: 0.093 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25827/   51900 | consumed samples:     26446848 | elapsed time per iteration (ms): 37600.9 | learning rate: 1.164E-04 | global batch size:  1024 | lm loss: 1.869389E+00 | loss scale: 1.0 | grad norm: 0.089 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25828/   51900 | consumed samples:     26447872 | elapsed time per iteration (ms): 37569.9 | learning rate: 1.164E-04 | global batch size:  1024 | lm loss: 1.847509E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25829/   51900 | consumed samples:     26448896 | elapsed time per iteration (ms): 37587.2 | learning rate: 1.163E-04 | global batch size:  1024 | lm loss: 1.865235E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25830/   51900 | consumed samples:     26449920 | elapsed time per iteration (ms): 37640.6 | learning rate: 1.163E-04 | global batch size:  1024 | lm loss: 1.852804E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25831/   51900 | consumed samples:     26450944 | elapsed time per iteration (ms): 37592.5 | learning rate: 1.163E-04 | global batch size:  1024 | lm loss: 1.860655E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25832/   51900 | consumed samples:     26451968 | elapsed time per iteration (ms): 37623.5 | learning rate: 1.163E-04 | global batch size:  1024 | lm loss: 1.841418E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25833/   51900 | consumed samples:     26452992 | elapsed time per iteration (ms): 37624.1 | learning rate: 1.163E-04 | global batch size:  1024 | lm loss: 1.858640E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25834/   51900 | consumed samples:     26454016 | elapsed time per iteration (ms): 37599.3 | learning rate: 1.163E-04 | global batch size:  1024 | lm loss: 1.866088E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25835/   51900 | consumed samples:     26455040 | elapsed time per iteration (ms): 37674.9 | learning rate: 1.163E-04 | global batch size:  1024 | lm loss: 1.876710E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25836/   51900 | consumed samples:     26456064 | elapsed time per iteration (ms): 37659.6 | learning rate: 1.163E-04 | global batch size:  1024 | lm loss: 1.851452E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25837/   51900 | consumed samples:     26457088 | elapsed time per iteration (ms): 37566.0 | learning rate: 1.163E-04 | global batch size:  1024 | lm loss: 1.841610E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25838/   51900 | consumed samples:     26458112 | elapsed time per iteration (ms): 37705.8 | learning rate: 1.163E-04 | global batch size:  1024 | lm loss: 1.839343E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25839/   51900 | consumed samples:     26459136 | elapsed time per iteration (ms): 37528.9 | learning rate: 1.163E-04 | global batch size:  1024 | lm loss: 1.867814E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25840/   51900 | consumed samples:     26460160 | elapsed time per iteration (ms): 37639.4 | learning rate: 1.163E-04 | global batch size:  1024 | lm loss: 1.853291E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25841/   51900 | consumed samples:     26461184 | elapsed time per iteration (ms): 37708.6 | learning rate: 1.163E-04 | global batch size:  1024 | lm loss: 1.837117E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25842/   51900 | consumed samples:     26462208 | elapsed time per iteration (ms): 37644.0 | learning rate: 1.163E-04 | global batch size:  1024 | lm loss: 1.856594E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25843/   51900 | consumed samples:     26463232 | elapsed time per iteration (ms): 37716.3 | learning rate: 1.163E-04 | global batch size:  1024 | lm loss: 1.858047E+00 | loss scale: 1.0 | grad norm: 0.088 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25844/   51900 | consumed samples:     26464256 | elapsed time per iteration (ms): 37700.6 | learning rate: 1.163E-04 | global batch size:  1024 | lm loss: 1.853006E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25845/   51900 | consumed samples:     26465280 | elapsed time per iteration (ms): 37671.0 | learning rate: 1.163E-04 | global batch size:  1024 | lm loss: 1.841719E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25846/   51900 | consumed samples:     26466304 | elapsed time per iteration (ms): 37675.7 | learning rate: 1.163E-04 | global batch size:  1024 | lm loss: 1.871252E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25847/   51900 | consumed samples:     26467328 | elapsed time per iteration (ms): 37669.5 | learning rate: 1.162E-04 | global batch size:  1024 | lm loss: 1.838618E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25848/   51900 | consumed samples:     26468352 | elapsed time per iteration (ms): 37629.9 | learning rate: 1.162E-04 | global batch size:  1024 | lm loss: 1.866275E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25849/   51900 | consumed samples:     26469376 | elapsed time per iteration (ms): 37644.4 | learning rate: 1.162E-04 | global batch size:  1024 | lm loss: 1.858587E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25850/   51900 | consumed samples:     26470400 | elapsed time per iteration (ms): 37646.8 | learning rate: 1.162E-04 | global batch size:  1024 | lm loss: 1.836318E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25851/   51900 | consumed samples:     26471424 | elapsed time per iteration (ms): 37557.1 | learning rate: 1.162E-04 | global batch size:  1024 | lm loss: 1.860574E+00 | loss scale: 1.0 | grad norm: 0.123 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25852/   51900 | consumed samples:     26472448 | elapsed time per iteration (ms): 37585.6 | learning rate: 1.162E-04 | global batch size:  1024 | lm loss: 1.855059E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25853/   51900 | consumed samples:     26473472 | elapsed time per iteration (ms): 37600.6 | learning rate: 1.162E-04 | global batch size:  1024 | lm loss: 1.859540E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25854/   51900 | consumed samples:     26474496 | elapsed time per iteration (ms): 37592.7 | learning rate: 1.162E-04 | global batch size:  1024 | lm loss: 1.842943E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25855/   51900 | consumed samples:     26475520 | elapsed time per iteration (ms): 37694.5 | learning rate: 1.162E-04 | global batch size:  1024 | lm loss: 1.873361E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25856/   51900 | consumed samples:     26476544 | elapsed time per iteration (ms): 37558.5 | learning rate: 1.162E-04 | global batch size:  1024 | lm loss: 1.851033E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25857/   51900 | consumed samples:     26477568 | elapsed time per iteration (ms): 37668.6 | learning rate: 1.162E-04 | global batch size:  1024 | lm loss: 1.856786E+00 | loss scale: 1.0 | grad norm: 0.092 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25858/   51900 | consumed samples:     26478592 | elapsed time per iteration (ms): 37615.1 | learning rate: 1.162E-04 | global batch size:  1024 | lm loss: 1.849941E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25859/   51900 | consumed samples:     26479616 | elapsed time per iteration (ms): 37711.6 | learning rate: 1.162E-04 | global batch size:  1024 | lm loss: 1.855564E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25860/   51900 | consumed samples:     26480640 | elapsed time per iteration (ms): 37688.8 | learning rate: 1.162E-04 | global batch size:  1024 | lm loss: 1.842404E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25861/   51900 | consumed samples:     26481664 | elapsed time per iteration (ms): 37692.4 | learning rate: 1.162E-04 | global batch size:  1024 | lm loss: 1.864395E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25862/   51900 | consumed samples:     26482688 | elapsed time per iteration (ms): 37629.8 | learning rate: 1.162E-04 | global batch size:  1024 | lm loss: 1.848057E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25863/   51900 | consumed samples:     26483712 | elapsed time per iteration (ms): 37675.5 | learning rate: 1.162E-04 | global batch size:  1024 | lm loss: 1.851849E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25864/   51900 | consumed samples:     26484736 | elapsed time per iteration (ms): 37709.4 | learning rate: 1.161E-04 | global batch size:  1024 | lm loss: 1.838834E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25865/   51900 | consumed samples:     26485760 | elapsed time per iteration (ms): 37606.4 | learning rate: 1.161E-04 | global batch size:  1024 | lm loss: 1.844282E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25866/   51900 | consumed samples:     26486784 | elapsed time per iteration (ms): 37690.0 | learning rate: 1.161E-04 | global batch size:  1024 | lm loss: 1.835858E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25867/   51900 | consumed samples:     26487808 | elapsed time per iteration (ms): 37686.6 | learning rate: 1.161E-04 | global batch size:  1024 | lm loss: 1.855117E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25868/   51900 | consumed samples:     26488832 | elapsed time per iteration (ms): 37705.5 | learning rate: 1.161E-04 | global batch size:  1024 | lm loss: 1.845004E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25869/   51900 | consumed samples:     26489856 | elapsed time per iteration (ms): 37766.4 | learning rate: 1.161E-04 | global batch size:  1024 | lm loss: 1.846972E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25870/   51900 | consumed samples:     26490880 | elapsed time per iteration (ms): 37578.3 | learning rate: 1.161E-04 | global batch size:  1024 | lm loss: 1.859358E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25871/   51900 | consumed samples:     26491904 | elapsed time per iteration (ms): 37638.7 | learning rate: 1.161E-04 | global batch size:  1024 | lm loss: 1.848591E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25872/   51900 | consumed samples:     26492928 | elapsed time per iteration (ms): 37660.6 | learning rate: 1.161E-04 | global batch size:  1024 | lm loss: 1.853685E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25873/   51900 | consumed samples:     26493952 | elapsed time per iteration (ms): 37671.0 | learning rate: 1.161E-04 | global batch size:  1024 | lm loss: 1.842789E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25874/   51900 | consumed samples:     26494976 | elapsed time per iteration (ms): 37584.6 | learning rate: 1.161E-04 | global batch size:  1024 | lm loss: 1.844014E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25875/   51900 | consumed samples:     26496000 | elapsed time per iteration (ms): 37685.2 | learning rate: 1.161E-04 | global batch size:  1024 | lm loss: 1.848554E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25876/   51900 | consumed samples:     26497024 | elapsed time per iteration (ms): 37602.9 | learning rate: 1.161E-04 | global batch size:  1024 | lm loss: 1.864602E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25877/   51900 | consumed samples:     26498048 | elapsed time per iteration (ms): 37595.7 | learning rate: 1.161E-04 | global batch size:  1024 | lm loss: 1.845726E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25878/   51900 | consumed samples:     26499072 | elapsed time per iteration (ms): 37823.7 | learning rate: 1.161E-04 | global batch size:  1024 | lm loss: 1.853920E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25879/   51900 | consumed samples:     26500096 | elapsed time per iteration (ms): 37594.4 | learning rate: 1.161E-04 | global batch size:  1024 | lm loss: 1.864146E+00 | loss scale: 1.0 | grad norm: 0.089 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25880/   51900 | consumed samples:     26501120 | elapsed time per iteration (ms): 37687.5 | learning rate: 1.161E-04 | global batch size:  1024 | lm loss: 1.856586E+00 | loss scale: 1.0 | grad norm: 0.087 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25881/   51900 | consumed samples:     26502144 | elapsed time per iteration (ms): 37644.6 | learning rate: 1.161E-04 | global batch size:  1024 | lm loss: 1.849600E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25882/   51900 | consumed samples:     26503168 | elapsed time per iteration (ms): 37688.0 | learning rate: 1.160E-04 | global batch size:  1024 | lm loss: 1.861445E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25883/   51900 | consumed samples:     26504192 | elapsed time per iteration (ms): 37739.9 | learning rate: 1.160E-04 | global batch size:  1024 | lm loss: 1.868170E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25884/   51900 | consumed samples:     26505216 | elapsed time per iteration (ms): 37669.0 | learning rate: 1.160E-04 | global batch size:  1024 | lm loss: 1.867041E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25885/   51900 | consumed samples:     26506240 | elapsed time per iteration (ms): 37577.6 | learning rate: 1.160E-04 | global batch size:  1024 | lm loss: 1.849576E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25886/   51900 | consumed samples:     26507264 | elapsed time per iteration (ms): 37612.5 | learning rate: 1.160E-04 | global batch size:  1024 | lm loss: 1.849972E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25887/   51900 | consumed samples:     26508288 | elapsed time per iteration (ms): 37666.1 | learning rate: 1.160E-04 | global batch size:  1024 | lm loss: 1.845782E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25888/   51900 | consumed samples:     26509312 | elapsed time per iteration (ms): 37671.1 | learning rate: 1.160E-04 | global batch size:  1024 | lm loss: 1.841168E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25889/   51900 | consumed samples:     26510336 | elapsed time per iteration (ms): 37650.6 | learning rate: 1.160E-04 | global batch size:  1024 | lm loss: 1.846547E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25890/   51900 | consumed samples:     26511360 | elapsed time per iteration (ms): 37689.7 | learning rate: 1.160E-04 | global batch size:  1024 | lm loss: 1.848425E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25891/   51900 | consumed samples:     26512384 | elapsed time per iteration (ms): 37641.2 | learning rate: 1.160E-04 | global batch size:  1024 | lm loss: 1.858902E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25892/   51900 | consumed samples:     26513408 | elapsed time per iteration (ms): 37633.1 | learning rate: 1.160E-04 | global batch size:  1024 | lm loss: 1.844198E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25893/   51900 | consumed samples:     26514432 | elapsed time per iteration (ms): 37671.0 | learning rate: 1.160E-04 | global batch size:  1024 | lm loss: 1.845322E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25894/   51900 | consumed samples:     26515456 | elapsed time per iteration (ms): 37567.4 | learning rate: 1.160E-04 | global batch size:  1024 | lm loss: 1.855454E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25895/   51900 | consumed samples:     26516480 | elapsed time per iteration (ms): 37627.5 | learning rate: 1.160E-04 | global batch size:  1024 | lm loss: 1.869045E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25896/   51900 | consumed samples:     26517504 | elapsed time per iteration (ms): 37604.8 | learning rate: 1.160E-04 | global batch size:  1024 | lm loss: 1.875358E+00 | loss scale: 1.0 | grad norm: 0.088 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25897/   51900 | consumed samples:     26518528 | elapsed time per iteration (ms): 37709.4 | learning rate: 1.160E-04 | global batch size:  1024 | lm loss: 1.854375E+00 | loss scale: 1.0 | grad norm: 0.087 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25898/   51900 | consumed samples:     26519552 | elapsed time per iteration (ms): 37570.8 | learning rate: 1.160E-04 | global batch size:  1024 | lm loss: 1.854553E+00 | loss scale: 1.0 | grad norm: 0.091 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25899/   51900 | consumed samples:     26520576 | elapsed time per iteration (ms): 37608.8 | learning rate: 1.160E-04 | global batch size:  1024 | lm loss: 1.849033E+00 | loss scale: 1.0 | grad norm: 0.096 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25900/   51900 | consumed samples:     26521600 | elapsed time per iteration (ms): 37655.6 | learning rate: 1.159E-04 | global batch size:  1024 | lm loss: 1.845475E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25901/   51900 | consumed samples:     26522624 | elapsed time per iteration (ms): 37554.8 | learning rate: 1.159E-04 | global batch size:  1024 | lm loss: 1.847236E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25902/   51900 | consumed samples:     26523648 | elapsed time per iteration (ms): 37658.7 | learning rate: 1.159E-04 | global batch size:  1024 | lm loss: 1.866595E+00 | loss scale: 1.0 | grad norm: 0.092 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25903/   51900 | consumed samples:     26524672 | elapsed time per iteration (ms): 37682.2 | learning rate: 1.159E-04 | global batch size:  1024 | lm loss: 1.852580E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25904/   51900 | consumed samples:     26525696 | elapsed time per iteration (ms): 37674.3 | learning rate: 1.159E-04 | global batch size:  1024 | lm loss: 1.858165E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25905/   51900 | consumed samples:     26526720 | elapsed time per iteration (ms): 37632.8 | learning rate: 1.159E-04 | global batch size:  1024 | lm loss: 1.853272E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25906/   51900 | consumed samples:     26527744 | elapsed time per iteration (ms): 37700.3 | learning rate: 1.159E-04 | global batch size:  1024 | lm loss: 1.848925E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25907/   51900 | consumed samples:     26528768 | elapsed time per iteration (ms): 37775.2 | learning rate: 1.159E-04 | global batch size:  1024 | lm loss: 1.851643E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25908/   51900 | consumed samples:     26529792 | elapsed time per iteration (ms): 37820.4 | learning rate: 1.159E-04 | global batch size:  1024 | lm loss: 1.858556E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25909/   51900 | consumed samples:     26530816 | elapsed time per iteration (ms): 37689.8 | learning rate: 1.159E-04 | global batch size:  1024 | lm loss: 1.864634E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25910/   51900 | consumed samples:     26531840 | elapsed time per iteration (ms): 37743.3 | learning rate: 1.159E-04 | global batch size:  1024 | lm loss: 1.836045E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25911/   51900 | consumed samples:     26532864 | elapsed time per iteration (ms): 37672.6 | learning rate: 1.159E-04 | global batch size:  1024 | lm loss: 1.840774E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25912/   51900 | consumed samples:     26533888 | elapsed time per iteration (ms): 37637.5 | learning rate: 1.159E-04 | global batch size:  1024 | lm loss: 1.855900E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25913/   51900 | consumed samples:     26534912 | elapsed time per iteration (ms): 37526.2 | learning rate: 1.159E-04 | global batch size:  1024 | lm loss: 1.839770E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25914/   51900 | consumed samples:     26535936 | elapsed time per iteration (ms): 37548.3 | learning rate: 1.159E-04 | global batch size:  1024 | lm loss: 1.844895E+00 | loss scale: 1.0 | grad norm: 0.091 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25915/   51900 | consumed samples:     26536960 | elapsed time per iteration (ms): 37691.3 | learning rate: 1.159E-04 | global batch size:  1024 | lm loss: 1.853720E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25916/   51900 | consumed samples:     26537984 | elapsed time per iteration (ms): 37724.0 | learning rate: 1.159E-04 | global batch size:  1024 | lm loss: 1.858149E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25917/   51900 | consumed samples:     26539008 | elapsed time per iteration (ms): 37617.4 | learning rate: 1.158E-04 | global batch size:  1024 | lm loss: 1.871557E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25918/   51900 | consumed samples:     26540032 | elapsed time per iteration (ms): 37598.6 | learning rate: 1.158E-04 | global batch size:  1024 | lm loss: 1.854823E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25919/   51900 | consumed samples:     26541056 | elapsed time per iteration (ms): 37697.4 | learning rate: 1.158E-04 | global batch size:  1024 | lm loss: 1.848958E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25920/   51900 | consumed samples:     26542080 | elapsed time per iteration (ms): 37604.3 | learning rate: 1.158E-04 | global batch size:  1024 | lm loss: 1.842053E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25921/   51900 | consumed samples:     26543104 | elapsed time per iteration (ms): 37717.3 | learning rate: 1.158E-04 | global batch size:  1024 | lm loss: 1.842315E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25922/   51900 | consumed samples:     26544128 | elapsed time per iteration (ms): 37714.2 | learning rate: 1.158E-04 | global batch size:  1024 | lm loss: 1.847518E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25923/   51900 | consumed samples:     26545152 | elapsed time per iteration (ms): 37665.0 | learning rate: 1.158E-04 | global batch size:  1024 | lm loss: 1.854090E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25924/   51900 | consumed samples:     26546176 | elapsed time per iteration (ms): 37734.7 | learning rate: 1.158E-04 | global batch size:  1024 | lm loss: 1.851069E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25925/   51900 | consumed samples:     26547200 | elapsed time per iteration (ms): 37792.8 | learning rate: 1.158E-04 | global batch size:  1024 | lm loss: 1.836315E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25926/   51900 | consumed samples:     26548224 | elapsed time per iteration (ms): 37701.3 | learning rate: 1.158E-04 | global batch size:  1024 | lm loss: 1.836809E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25927/   51900 | consumed samples:     26549248 | elapsed time per iteration (ms): 37747.6 | learning rate: 1.158E-04 | global batch size:  1024 | lm loss: 1.863025E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25928/   51900 | consumed samples:     26550272 | elapsed time per iteration (ms): 37624.0 | learning rate: 1.158E-04 | global batch size:  1024 | lm loss: 1.836880E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25929/   51900 | consumed samples:     26551296 | elapsed time per iteration (ms): 37666.1 | learning rate: 1.158E-04 | global batch size:  1024 | lm loss: 1.835728E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25930/   51900 | consumed samples:     26552320 | elapsed time per iteration (ms): 37660.8 | learning rate: 1.158E-04 | global batch size:  1024 | lm loss: 1.860386E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25931/   51900 | consumed samples:     26553344 | elapsed time per iteration (ms): 37753.4 | learning rate: 1.158E-04 | global batch size:  1024 | lm loss: 1.863486E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25932/   51900 | consumed samples:     26554368 | elapsed time per iteration (ms): 37793.6 | learning rate: 1.158E-04 | global batch size:  1024 | lm loss: 1.848512E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25933/   51900 | consumed samples:     26555392 | elapsed time per iteration (ms): 37668.3 | learning rate: 1.158E-04 | global batch size:  1024 | lm loss: 1.850340E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25934/   51900 | consumed samples:     26556416 | elapsed time per iteration (ms): 37744.8 | learning rate: 1.158E-04 | global batch size:  1024 | lm loss: 1.843158E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25935/   51900 | consumed samples:     26557440 | elapsed time per iteration (ms): 37677.9 | learning rate: 1.157E-04 | global batch size:  1024 | lm loss: 1.848056E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25936/   51900 | consumed samples:     26558464 | elapsed time per iteration (ms): 37686.8 | learning rate: 1.157E-04 | global batch size:  1024 | lm loss: 1.855476E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25937/   51900 | consumed samples:     26559488 | elapsed time per iteration (ms): 37537.7 | learning rate: 1.157E-04 | global batch size:  1024 | lm loss: 1.849658E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25938/   51900 | consumed samples:     26560512 | elapsed time per iteration (ms): 37654.3 | learning rate: 1.157E-04 | global batch size:  1024 | lm loss: 1.851964E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25939/   51900 | consumed samples:     26561536 | elapsed time per iteration (ms): 37682.2 | learning rate: 1.157E-04 | global batch size:  1024 | lm loss: 1.854129E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25940/   51900 | consumed samples:     26562560 | elapsed time per iteration (ms): 37729.1 | learning rate: 1.157E-04 | global batch size:  1024 | lm loss: 1.865802E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25941/   51900 | consumed samples:     26563584 | elapsed time per iteration (ms): 37659.4 | learning rate: 1.157E-04 | global batch size:  1024 | lm loss: 1.854352E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25942/   51900 | consumed samples:     26564608 | elapsed time per iteration (ms): 37673.7 | learning rate: 1.157E-04 | global batch size:  1024 | lm loss: 1.846869E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25943/   51900 | consumed samples:     26565632 | elapsed time per iteration (ms): 37715.7 | learning rate: 1.157E-04 | global batch size:  1024 | lm loss: 1.850725E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25944/   51900 | consumed samples:     26566656 | elapsed time per iteration (ms): 37683.1 | learning rate: 1.157E-04 | global batch size:  1024 | lm loss: 1.847104E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25945/   51900 | consumed samples:     26567680 | elapsed time per iteration (ms): 37619.8 | learning rate: 1.157E-04 | global batch size:  1024 | lm loss: 1.864911E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25946/   51900 | consumed samples:     26568704 | elapsed time per iteration (ms): 37721.5 | learning rate: 1.157E-04 | global batch size:  1024 | lm loss: 1.849650E+00 | loss scale: 1.0 | grad norm: 0.156 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25947/   51900 | consumed samples:     26569728 | elapsed time per iteration (ms): 37659.6 | learning rate: 1.157E-04 | global batch size:  1024 | lm loss: 1.867268E+00 | loss scale: 1.0 | grad norm: 0.087 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25948/   51900 | consumed samples:     26570752 | elapsed time per iteration (ms): 37549.4 | learning rate: 1.157E-04 | global batch size:  1024 | lm loss: 1.864441E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25949/   51900 | consumed samples:     26571776 | elapsed time per iteration (ms): 37695.5 | learning rate: 1.157E-04 | global batch size:  1024 | lm loss: 1.863603E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25950/   51900 | consumed samples:     26572800 | elapsed time per iteration (ms): 37507.2 | learning rate: 1.157E-04 | global batch size:  1024 | lm loss: 1.852901E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25951/   51900 | consumed samples:     26573824 | elapsed time per iteration (ms): 37510.2 | learning rate: 1.157E-04 | global batch size:  1024 | lm loss: 1.856528E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25952/   51900 | consumed samples:     26574848 | elapsed time per iteration (ms): 37553.7 | learning rate: 1.157E-04 | global batch size:  1024 | lm loss: 1.859209E+00 | loss scale: 1.0 | grad norm: 0.123 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25953/   51900 | consumed samples:     26575872 | elapsed time per iteration (ms): 37676.7 | learning rate: 1.156E-04 | global batch size:  1024 | lm loss: 1.836352E+00 | loss scale: 1.0 | grad norm: 0.089 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25954/   51900 | consumed samples:     26576896 | elapsed time per iteration (ms): 37644.0 | learning rate: 1.156E-04 | global batch size:  1024 | lm loss: 1.866958E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25955/   51900 | consumed samples:     26577920 | elapsed time per iteration (ms): 37610.1 | learning rate: 1.156E-04 | global batch size:  1024 | lm loss: 1.856778E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25956/   51900 | consumed samples:     26578944 | elapsed time per iteration (ms): 37651.3 | learning rate: 1.156E-04 | global batch size:  1024 | lm loss: 1.865239E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25957/   51900 | consumed samples:     26579968 | elapsed time per iteration (ms): 37697.2 | learning rate: 1.156E-04 | global batch size:  1024 | lm loss: 1.839833E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25958/   51900 | consumed samples:     26580992 | elapsed time per iteration (ms): 37686.2 | learning rate: 1.156E-04 | global batch size:  1024 | lm loss: 1.853263E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25959/   51900 | consumed samples:     26582016 | elapsed time per iteration (ms): 37607.4 | learning rate: 1.156E-04 | global batch size:  1024 | lm loss: 1.858503E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25960/   51900 | consumed samples:     26583040 | elapsed time per iteration (ms): 37591.2 | learning rate: 1.156E-04 | global batch size:  1024 | lm loss: 1.858819E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25961/   51900 | consumed samples:     26584064 | elapsed time per iteration (ms): 37627.1 | learning rate: 1.156E-04 | global batch size:  1024 | lm loss: 1.856944E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25962/   51900 | consumed samples:     26585088 | elapsed time per iteration (ms): 37538.1 | learning rate: 1.156E-04 | global batch size:  1024 | lm loss: 1.833767E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25963/   51900 | consumed samples:     26586112 | elapsed time per iteration (ms): 37580.7 | learning rate: 1.156E-04 | global batch size:  1024 | lm loss: 1.855101E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25964/   51900 | consumed samples:     26587136 | elapsed time per iteration (ms): 37644.8 | learning rate: 1.156E-04 | global batch size:  1024 | lm loss: 1.850324E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25965/   51900 | consumed samples:     26588160 | elapsed time per iteration (ms): 37722.7 | learning rate: 1.156E-04 | global batch size:  1024 | lm loss: 1.854603E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25966/   51900 | consumed samples:     26589184 | elapsed time per iteration (ms): 37719.3 | learning rate: 1.156E-04 | global batch size:  1024 | lm loss: 1.849367E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25967/   51900 | consumed samples:     26590208 | elapsed time per iteration (ms): 37625.4 | learning rate: 1.156E-04 | global batch size:  1024 | lm loss: 1.847783E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25968/   51900 | consumed samples:     26591232 | elapsed time per iteration (ms): 37636.5 | learning rate: 1.156E-04 | global batch size:  1024 | lm loss: 1.862409E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25969/   51900 | consumed samples:     26592256 | elapsed time per iteration (ms): 37643.9 | learning rate: 1.156E-04 | global batch size:  1024 | lm loss: 1.833658E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25970/   51900 | consumed samples:     26593280 | elapsed time per iteration (ms): 37683.4 | learning rate: 1.155E-04 | global batch size:  1024 | lm loss: 1.857325E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25971/   51900 | consumed samples:     26594304 | elapsed time per iteration (ms): 37570.5 | learning rate: 1.155E-04 | global batch size:  1024 | lm loss: 1.850431E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25972/   51900 | consumed samples:     26595328 | elapsed time per iteration (ms): 37594.4 | learning rate: 1.155E-04 | global batch size:  1024 | lm loss: 1.852359E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25973/   51900 | consumed samples:     26596352 | elapsed time per iteration (ms): 37645.0 | learning rate: 1.155E-04 | global batch size:  1024 | lm loss: 1.867430E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25974/   51900 | consumed samples:     26597376 | elapsed time per iteration (ms): 37661.5 | learning rate: 1.155E-04 | global batch size:  1024 | lm loss: 1.851578E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25975/   51900 | consumed samples:     26598400 | elapsed time per iteration (ms): 37703.3 | learning rate: 1.155E-04 | global batch size:  1024 | lm loss: 1.853956E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25976/   51900 | consumed samples:     26599424 | elapsed time per iteration (ms): 37685.5 | learning rate: 1.155E-04 | global batch size:  1024 | lm loss: 1.843802E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25977/   51900 | consumed samples:     26600448 | elapsed time per iteration (ms): 37664.2 | learning rate: 1.155E-04 | global batch size:  1024 | lm loss: 1.855474E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25978/   51900 | consumed samples:     26601472 | elapsed time per iteration (ms): 37620.8 | learning rate: 1.155E-04 | global batch size:  1024 | lm loss: 1.857667E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25979/   51900 | consumed samples:     26602496 | elapsed time per iteration (ms): 37699.0 | learning rate: 1.155E-04 | global batch size:  1024 | lm loss: 1.848333E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25980/   51900 | consumed samples:     26603520 | elapsed time per iteration (ms): 37780.0 | learning rate: 1.155E-04 | global batch size:  1024 | lm loss: 1.850266E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25981/   51900 | consumed samples:     26604544 | elapsed time per iteration (ms): 37668.7 | learning rate: 1.155E-04 | global batch size:  1024 | lm loss: 1.857228E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25982/   51900 | consumed samples:     26605568 | elapsed time per iteration (ms): 37659.1 | learning rate: 1.155E-04 | global batch size:  1024 | lm loss: 1.864878E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25983/   51900 | consumed samples:     26606592 | elapsed time per iteration (ms): 37492.9 | learning rate: 1.155E-04 | global batch size:  1024 | lm loss: 1.845686E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25984/   51900 | consumed samples:     26607616 | elapsed time per iteration (ms): 37598.1 | learning rate: 1.155E-04 | global batch size:  1024 | lm loss: 1.860330E+00 | loss scale: 1.0 | grad norm: 0.089 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25985/   51900 | consumed samples:     26608640 | elapsed time per iteration (ms): 37712.2 | learning rate: 1.155E-04 | global batch size:  1024 | lm loss: 1.838634E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25986/   51900 | consumed samples:     26609664 | elapsed time per iteration (ms): 37738.8 | learning rate: 1.155E-04 | global batch size:  1024 | lm loss: 1.849838E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25987/   51900 | consumed samples:     26610688 | elapsed time per iteration (ms): 37588.0 | learning rate: 1.155E-04 | global batch size:  1024 | lm loss: 1.849450E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25988/   51900 | consumed samples:     26611712 | elapsed time per iteration (ms): 37691.1 | learning rate: 1.154E-04 | global batch size:  1024 | lm loss: 1.837385E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25989/   51900 | consumed samples:     26612736 | elapsed time per iteration (ms): 37613.9 | learning rate: 1.154E-04 | global batch size:  1024 | lm loss: 1.860887E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25990/   51900 | consumed samples:     26613760 | elapsed time per iteration (ms): 37544.1 | learning rate: 1.154E-04 | global batch size:  1024 | lm loss: 1.868754E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25991/   51900 | consumed samples:     26614784 | elapsed time per iteration (ms): 37642.8 | learning rate: 1.154E-04 | global batch size:  1024 | lm loss: 1.834745E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25992/   51900 | consumed samples:     26615808 | elapsed time per iteration (ms): 37620.9 | learning rate: 1.154E-04 | global batch size:  1024 | lm loss: 1.850585E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25993/   51900 | consumed samples:     26616832 | elapsed time per iteration (ms): 37623.1 | learning rate: 1.154E-04 | global batch size:  1024 | lm loss: 1.862432E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25994/   51900 | consumed samples:     26617856 | elapsed time per iteration (ms): 37792.9 | learning rate: 1.154E-04 | global batch size:  1024 | lm loss: 1.845190E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25995/   51900 | consumed samples:     26618880 | elapsed time per iteration (ms): 37691.2 | learning rate: 1.154E-04 | global batch size:  1024 | lm loss: 1.852856E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25996/   51900 | consumed samples:     26619904 | elapsed time per iteration (ms): 37575.2 | learning rate: 1.154E-04 | global batch size:  1024 | lm loss: 1.864752E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25997/   51900 | consumed samples:     26620928 | elapsed time per iteration (ms): 37679.3 | learning rate: 1.154E-04 | global batch size:  1024 | lm loss: 1.844630E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25998/   51900 | consumed samples:     26621952 | elapsed time per iteration (ms): 37583.0 | learning rate: 1.154E-04 | global batch size:  1024 | lm loss: 1.842635E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    25999/   51900 | consumed samples:     26622976 | elapsed time per iteration (ms): 37677.1 | learning rate: 1.154E-04 | global batch size:  1024 | lm loss: 1.853099E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26000/   51900 | consumed samples:     26624000 | elapsed time per iteration (ms): 37678.4 | learning rate: 1.154E-04 | global batch size:  1024 | lm loss: 1.840343E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    save-checkpoint ................................: (173332.28, 173332.38)
 iteration    26001/   51900 | consumed samples:     26625024 | elapsed time per iteration (ms): 37236.6 | learning rate: 1.154E-04 | global batch size:  1024 | lm loss: 1.831414E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26002/   51900 | consumed samples:     26626048 | elapsed time per iteration (ms): 37566.7 | learning rate: 1.154E-04 | global batch size:  1024 | lm loss: 1.847016E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26003/   51900 | consumed samples:     26627072 | elapsed time per iteration (ms): 37617.6 | learning rate: 1.154E-04 | global batch size:  1024 | lm loss: 1.849980E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26004/   51900 | consumed samples:     26628096 | elapsed time per iteration (ms): 37602.9 | learning rate: 1.154E-04 | global batch size:  1024 | lm loss: 1.855117E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26005/   51900 | consumed samples:     26629120 | elapsed time per iteration (ms): 37712.3 | learning rate: 1.154E-04 | global batch size:  1024 | lm loss: 1.866181E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26006/   51900 | consumed samples:     26630144 | elapsed time per iteration (ms): 37538.1 | learning rate: 1.153E-04 | global batch size:  1024 | lm loss: 1.837696E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26007/   51900 | consumed samples:     26631168 | elapsed time per iteration (ms): 37607.9 | learning rate: 1.153E-04 | global batch size:  1024 | lm loss: 1.850675E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26008/   51900 | consumed samples:     26632192 | elapsed time per iteration (ms): 37651.2 | learning rate: 1.153E-04 | global batch size:  1024 | lm loss: 1.876634E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26009/   51900 | consumed samples:     26633216 | elapsed time per iteration (ms): 37580.1 | learning rate: 1.153E-04 | global batch size:  1024 | lm loss: 1.853710E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26010/   51900 | consumed samples:     26634240 | elapsed time per iteration (ms): 37589.6 | learning rate: 1.153E-04 | global batch size:  1024 | lm loss: 1.857436E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26011/   51900 | consumed samples:     26635264 | elapsed time per iteration (ms): 37525.1 | learning rate: 1.153E-04 | global batch size:  1024 | lm loss: 1.867469E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26012/   51900 | consumed samples:     26636288 | elapsed time per iteration (ms): 37588.8 | learning rate: 1.153E-04 | global batch size:  1024 | lm loss: 1.851270E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26013/   51900 | consumed samples:     26637312 | elapsed time per iteration (ms): 37611.6 | learning rate: 1.153E-04 | global batch size:  1024 | lm loss: 1.862686E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26014/   51900 | consumed samples:     26638336 | elapsed time per iteration (ms): 37636.4 | learning rate: 1.153E-04 | global batch size:  1024 | lm loss: 1.860872E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26015/   51900 | consumed samples:     26639360 | elapsed time per iteration (ms): 37725.0 | learning rate: 1.153E-04 | global batch size:  1024 | lm loss: 1.855529E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26016/   51900 | consumed samples:     26640384 | elapsed time per iteration (ms): 37736.1 | learning rate: 1.153E-04 | global batch size:  1024 | lm loss: 1.848799E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26017/   51900 | consumed samples:     26641408 | elapsed time per iteration (ms): 37663.0 | learning rate: 1.153E-04 | global batch size:  1024 | lm loss: 1.862472E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26018/   51900 | consumed samples:     26642432 | elapsed time per iteration (ms): 37590.4 | learning rate: 1.153E-04 | global batch size:  1024 | lm loss: 1.852851E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26019/   51900 | consumed samples:     26643456 | elapsed time per iteration (ms): 37635.0 | learning rate: 1.153E-04 | global batch size:  1024 | lm loss: 1.860072E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26020/   51900 | consumed samples:     26644480 | elapsed time per iteration (ms): 37539.8 | learning rate: 1.153E-04 | global batch size:  1024 | lm loss: 1.857261E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26021/   51900 | consumed samples:     26645504 | elapsed time per iteration (ms): 37661.2 | learning rate: 1.153E-04 | global batch size:  1024 | lm loss: 1.854170E+00 | loss scale: 1.0 | grad norm: 0.089 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26022/   51900 | consumed samples:     26646528 | elapsed time per iteration (ms): 37670.5 | learning rate: 1.153E-04 | global batch size:  1024 | lm loss: 1.835898E+00 | loss scale: 1.0 | grad norm: 0.094 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26023/   51900 | consumed samples:     26647552 | elapsed time per iteration (ms): 37601.0 | learning rate: 1.152E-04 | global batch size:  1024 | lm loss: 1.849241E+00 | loss scale: 1.0 | grad norm: 0.100 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26024/   51900 | consumed samples:     26648576 | elapsed time per iteration (ms): 37685.1 | learning rate: 1.152E-04 | global batch size:  1024 | lm loss: 1.853415E+00 | loss scale: 1.0 | grad norm: 0.097 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26025/   51900 | consumed samples:     26649600 | elapsed time per iteration (ms): 37735.9 | learning rate: 1.152E-04 | global batch size:  1024 | lm loss: 1.852640E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26026/   51900 | consumed samples:     26650624 | elapsed time per iteration (ms): 37582.1 | learning rate: 1.152E-04 | global batch size:  1024 | lm loss: 1.868012E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26027/   51900 | consumed samples:     26651648 | elapsed time per iteration (ms): 37650.9 | learning rate: 1.152E-04 | global batch size:  1024 | lm loss: 1.848834E+00 | loss scale: 1.0 | grad norm: 0.090 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26028/   51900 | consumed samples:     26652672 | elapsed time per iteration (ms): 37612.1 | learning rate: 1.152E-04 | global batch size:  1024 | lm loss: 1.858157E+00 | loss scale: 1.0 | grad norm: 0.087 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26029/   51900 | consumed samples:     26653696 | elapsed time per iteration (ms): 37670.9 | learning rate: 1.152E-04 | global batch size:  1024 | lm loss: 1.860105E+00 | loss scale: 1.0 | grad norm: 0.088 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26030/   51900 | consumed samples:     26654720 | elapsed time per iteration (ms): 37626.5 | learning rate: 1.152E-04 | global batch size:  1024 | lm loss: 1.847278E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26031/   51900 | consumed samples:     26655744 | elapsed time per iteration (ms): 37631.4 | learning rate: 1.152E-04 | global batch size:  1024 | lm loss: 1.852167E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26032/   51900 | consumed samples:     26656768 | elapsed time per iteration (ms): 37601.0 | learning rate: 1.152E-04 | global batch size:  1024 | lm loss: 1.873668E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26033/   51900 | consumed samples:     26657792 | elapsed time per iteration (ms): 37669.6 | learning rate: 1.152E-04 | global batch size:  1024 | lm loss: 1.855919E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26034/   51900 | consumed samples:     26658816 | elapsed time per iteration (ms): 37691.4 | learning rate: 1.152E-04 | global batch size:  1024 | lm loss: 1.851892E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26035/   51900 | consumed samples:     26659840 | elapsed time per iteration (ms): 37601.0 | learning rate: 1.152E-04 | global batch size:  1024 | lm loss: 1.838852E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26036/   51900 | consumed samples:     26660864 | elapsed time per iteration (ms): 37645.8 | learning rate: 1.152E-04 | global batch size:  1024 | lm loss: 1.852391E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26037/   51900 | consumed samples:     26661888 | elapsed time per iteration (ms): 37656.3 | learning rate: 1.152E-04 | global batch size:  1024 | lm loss: 1.846737E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26038/   51900 | consumed samples:     26662912 | elapsed time per iteration (ms): 37658.0 | learning rate: 1.152E-04 | global batch size:  1024 | lm loss: 1.829171E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26039/   51900 | consumed samples:     26663936 | elapsed time per iteration (ms): 37571.8 | learning rate: 1.152E-04 | global batch size:  1024 | lm loss: 1.865480E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26040/   51900 | consumed samples:     26664960 | elapsed time per iteration (ms): 37623.1 | learning rate: 1.152E-04 | global batch size:  1024 | lm loss: 1.860410E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26041/   51900 | consumed samples:     26665984 | elapsed time per iteration (ms): 37593.6 | learning rate: 1.151E-04 | global batch size:  1024 | lm loss: 1.856896E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26042/   51900 | consumed samples:     26667008 | elapsed time per iteration (ms): 37741.5 | learning rate: 1.151E-04 | global batch size:  1024 | lm loss: 1.851357E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26043/   51900 | consumed samples:     26668032 | elapsed time per iteration (ms): 37666.2 | learning rate: 1.151E-04 | global batch size:  1024 | lm loss: 1.856242E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26044/   51900 | consumed samples:     26669056 | elapsed time per iteration (ms): 37699.8 | learning rate: 1.151E-04 | global batch size:  1024 | lm loss: 1.859388E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26045/   51900 | consumed samples:     26670080 | elapsed time per iteration (ms): 37562.8 | learning rate: 1.151E-04 | global batch size:  1024 | lm loss: 1.875308E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26046/   51900 | consumed samples:     26671104 | elapsed time per iteration (ms): 37621.9 | learning rate: 1.151E-04 | global batch size:  1024 | lm loss: 1.863867E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26047/   51900 | consumed samples:     26672128 | elapsed time per iteration (ms): 37616.9 | learning rate: 1.151E-04 | global batch size:  1024 | lm loss: 1.841680E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26048/   51900 | consumed samples:     26673152 | elapsed time per iteration (ms): 37726.9 | learning rate: 1.151E-04 | global batch size:  1024 | lm loss: 1.858739E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26049/   51900 | consumed samples:     26674176 | elapsed time per iteration (ms): 37524.8 | learning rate: 1.151E-04 | global batch size:  1024 | lm loss: 1.866632E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26050/   51900 | consumed samples:     26675200 | elapsed time per iteration (ms): 37655.4 | learning rate: 1.151E-04 | global batch size:  1024 | lm loss: 1.854179E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26051/   51900 | consumed samples:     26676224 | elapsed time per iteration (ms): 37591.7 | learning rate: 1.151E-04 | global batch size:  1024 | lm loss: 1.851567E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26052/   51900 | consumed samples:     26677248 | elapsed time per iteration (ms): 37697.1 | learning rate: 1.151E-04 | global batch size:  1024 | lm loss: 1.831176E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26053/   51900 | consumed samples:     26678272 | elapsed time per iteration (ms): 37760.6 | learning rate: 1.151E-04 | global batch size:  1024 | lm loss: 1.851821E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26054/   51900 | consumed samples:     26679296 | elapsed time per iteration (ms): 37553.8 | learning rate: 1.151E-04 | global batch size:  1024 | lm loss: 1.870885E+00 | loss scale: 1.0 | grad norm: 0.088 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26055/   51900 | consumed samples:     26680320 | elapsed time per iteration (ms): 37625.4 | learning rate: 1.151E-04 | global batch size:  1024 | lm loss: 1.855442E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26056/   51900 | consumed samples:     26681344 | elapsed time per iteration (ms): 37706.1 | learning rate: 1.151E-04 | global batch size:  1024 | lm loss: 1.852088E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26057/   51900 | consumed samples:     26682368 | elapsed time per iteration (ms): 37791.4 | learning rate: 1.151E-04 | global batch size:  1024 | lm loss: 1.864380E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26058/   51900 | consumed samples:     26683392 | elapsed time per iteration (ms): 37638.5 | learning rate: 1.151E-04 | global batch size:  1024 | lm loss: 1.848886E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26059/   51900 | consumed samples:     26684416 | elapsed time per iteration (ms): 37561.1 | learning rate: 1.150E-04 | global batch size:  1024 | lm loss: 1.851324E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26060/   51900 | consumed samples:     26685440 | elapsed time per iteration (ms): 37677.3 | learning rate: 1.150E-04 | global batch size:  1024 | lm loss: 1.858783E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26061/   51900 | consumed samples:     26686464 | elapsed time per iteration (ms): 37632.7 | learning rate: 1.150E-04 | global batch size:  1024 | lm loss: 1.872243E+00 | loss scale: 1.0 | grad norm: 0.087 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26062/   51900 | consumed samples:     26687488 | elapsed time per iteration (ms): 37763.2 | learning rate: 1.150E-04 | global batch size:  1024 | lm loss: 1.854322E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26063/   51900 | consumed samples:     26688512 | elapsed time per iteration (ms): 37651.1 | learning rate: 1.150E-04 | global batch size:  1024 | lm loss: 1.848260E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26064/   51900 | consumed samples:     26689536 | elapsed time per iteration (ms): 37649.0 | learning rate: 1.150E-04 | global batch size:  1024 | lm loss: 1.846004E+00 | loss scale: 1.0 | grad norm: 0.087 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26065/   51900 | consumed samples:     26690560 | elapsed time per iteration (ms): 37622.1 | learning rate: 1.150E-04 | global batch size:  1024 | lm loss: 1.835631E+00 | loss scale: 1.0 | grad norm: 0.090 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26066/   51900 | consumed samples:     26691584 | elapsed time per iteration (ms): 37781.8 | learning rate: 1.150E-04 | global batch size:  1024 | lm loss: 1.854967E+00 | loss scale: 1.0 | grad norm: 0.094 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26067/   51900 | consumed samples:     26692608 | elapsed time per iteration (ms): 37671.6 | learning rate: 1.150E-04 | global batch size:  1024 | lm loss: 1.859210E+00 | loss scale: 1.0 | grad norm: 0.087 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26068/   51900 | consumed samples:     26693632 | elapsed time per iteration (ms): 37689.2 | learning rate: 1.150E-04 | global batch size:  1024 | lm loss: 1.837416E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26069/   51900 | consumed samples:     26694656 | elapsed time per iteration (ms): 37599.4 | learning rate: 1.150E-04 | global batch size:  1024 | lm loss: 1.835733E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26070/   51900 | consumed samples:     26695680 | elapsed time per iteration (ms): 37747.1 | learning rate: 1.150E-04 | global batch size:  1024 | lm loss: 1.868572E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26071/   51900 | consumed samples:     26696704 | elapsed time per iteration (ms): 37655.2 | learning rate: 1.150E-04 | global batch size:  1024 | lm loss: 1.851620E+00 | loss scale: 1.0 | grad norm: 0.089 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26072/   51900 | consumed samples:     26697728 | elapsed time per iteration (ms): 37509.9 | learning rate: 1.150E-04 | global batch size:  1024 | lm loss: 1.844020E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26073/   51900 | consumed samples:     26698752 | elapsed time per iteration (ms): 37585.4 | learning rate: 1.150E-04 | global batch size:  1024 | lm loss: 1.860038E+00 | loss scale: 1.0 | grad norm: 0.095 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26074/   51900 | consumed samples:     26699776 | elapsed time per iteration (ms): 37624.2 | learning rate: 1.150E-04 | global batch size:  1024 | lm loss: 1.842541E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26075/   51900 | consumed samples:     26700800 | elapsed time per iteration (ms): 37610.9 | learning rate: 1.150E-04 | global batch size:  1024 | lm loss: 1.863984E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26076/   51900 | consumed samples:     26701824 | elapsed time per iteration (ms): 37545.0 | learning rate: 1.149E-04 | global batch size:  1024 | lm loss: 1.840555E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26077/   51900 | consumed samples:     26702848 | elapsed time per iteration (ms): 37711.4 | learning rate: 1.149E-04 | global batch size:  1024 | lm loss: 1.833543E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26078/   51900 | consumed samples:     26703872 | elapsed time per iteration (ms): 37725.0 | learning rate: 1.149E-04 | global batch size:  1024 | lm loss: 1.838675E+00 | loss scale: 1.0 | grad norm: 0.106 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26079/   51900 | consumed samples:     26704896 | elapsed time per iteration (ms): 37581.7 | learning rate: 1.149E-04 | global batch size:  1024 | lm loss: 1.843660E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26080/   51900 | consumed samples:     26705920 | elapsed time per iteration (ms): 37652.6 | learning rate: 1.149E-04 | global batch size:  1024 | lm loss: 1.859634E+00 | loss scale: 1.0 | grad norm: 0.089 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26081/   51900 | consumed samples:     26706944 | elapsed time per iteration (ms): 37641.6 | learning rate: 1.149E-04 | global batch size:  1024 | lm loss: 1.869542E+00 | loss scale: 1.0 | grad norm: 0.087 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26082/   51900 | consumed samples:     26707968 | elapsed time per iteration (ms): 37566.8 | learning rate: 1.149E-04 | global batch size:  1024 | lm loss: 1.843019E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26083/   51900 | consumed samples:     26708992 | elapsed time per iteration (ms): 37556.3 | learning rate: 1.149E-04 | global batch size:  1024 | lm loss: 1.844646E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26084/   51900 | consumed samples:     26710016 | elapsed time per iteration (ms): 37583.8 | learning rate: 1.149E-04 | global batch size:  1024 | lm loss: 1.859206E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26085/   51900 | consumed samples:     26711040 | elapsed time per iteration (ms): 37547.3 | learning rate: 1.149E-04 | global batch size:  1024 | lm loss: 1.859203E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26086/   51900 | consumed samples:     26712064 | elapsed time per iteration (ms): 37696.0 | learning rate: 1.149E-04 | global batch size:  1024 | lm loss: 1.862960E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26087/   51900 | consumed samples:     26713088 | elapsed time per iteration (ms): 37612.7 | learning rate: 1.149E-04 | global batch size:  1024 | lm loss: 1.860112E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26088/   51900 | consumed samples:     26714112 | elapsed time per iteration (ms): 37697.0 | learning rate: 1.149E-04 | global batch size:  1024 | lm loss: 1.854069E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26089/   51900 | consumed samples:     26715136 | elapsed time per iteration (ms): 37545.8 | learning rate: 1.149E-04 | global batch size:  1024 | lm loss: 1.858904E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26090/   51900 | consumed samples:     26716160 | elapsed time per iteration (ms): 37695.5 | learning rate: 1.149E-04 | global batch size:  1024 | lm loss: 1.855365E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26091/   51900 | consumed samples:     26717184 | elapsed time per iteration (ms): 37591.0 | learning rate: 1.149E-04 | global batch size:  1024 | lm loss: 1.855556E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26092/   51900 | consumed samples:     26718208 | elapsed time per iteration (ms): 37647.8 | learning rate: 1.149E-04 | global batch size:  1024 | lm loss: 1.854848E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26093/   51900 | consumed samples:     26719232 | elapsed time per iteration (ms): 37674.0 | learning rate: 1.149E-04 | global batch size:  1024 | lm loss: 1.837416E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26094/   51900 | consumed samples:     26720256 | elapsed time per iteration (ms): 37679.2 | learning rate: 1.148E-04 | global batch size:  1024 | lm loss: 1.850016E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26095/   51900 | consumed samples:     26721280 | elapsed time per iteration (ms): 37612.5 | learning rate: 1.148E-04 | global batch size:  1024 | lm loss: 1.856010E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26096/   51900 | consumed samples:     26722304 | elapsed time per iteration (ms): 37700.7 | learning rate: 1.148E-04 | global batch size:  1024 | lm loss: 1.841056E+00 | loss scale: 1.0 | grad norm: 0.087 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26097/   51900 | consumed samples:     26723328 | elapsed time per iteration (ms): 37620.9 | learning rate: 1.148E-04 | global batch size:  1024 | lm loss: 1.857595E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26098/   51900 | consumed samples:     26724352 | elapsed time per iteration (ms): 37703.2 | learning rate: 1.148E-04 | global batch size:  1024 | lm loss: 1.843846E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26099/   51900 | consumed samples:     26725376 | elapsed time per iteration (ms): 37711.9 | learning rate: 1.148E-04 | global batch size:  1024 | lm loss: 1.857349E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26100/   51900 | consumed samples:     26726400 | elapsed time per iteration (ms): 37598.6 | learning rate: 1.148E-04 | global batch size:  1024 | lm loss: 1.834790E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26101/   51900 | consumed samples:     26727424 | elapsed time per iteration (ms): 37576.1 | learning rate: 1.148E-04 | global batch size:  1024 | lm loss: 1.877264E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26102/   51900 | consumed samples:     26728448 | elapsed time per iteration (ms): 37627.5 | learning rate: 1.148E-04 | global batch size:  1024 | lm loss: 1.864871E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26103/   51900 | consumed samples:     26729472 | elapsed time per iteration (ms): 37747.4 | learning rate: 1.148E-04 | global batch size:  1024 | lm loss: 1.858816E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26104/   51900 | consumed samples:     26730496 | elapsed time per iteration (ms): 37749.9 | learning rate: 1.148E-04 | global batch size:  1024 | lm loss: 1.863676E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26105/   51900 | consumed samples:     26731520 | elapsed time per iteration (ms): 37569.0 | learning rate: 1.148E-04 | global batch size:  1024 | lm loss: 1.860020E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26106/   51900 | consumed samples:     26732544 | elapsed time per iteration (ms): 37566.7 | learning rate: 1.148E-04 | global batch size:  1024 | lm loss: 1.856751E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26107/   51900 | consumed samples:     26733568 | elapsed time per iteration (ms): 37650.5 | learning rate: 1.148E-04 | global batch size:  1024 | lm loss: 1.859865E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26108/   51900 | consumed samples:     26734592 | elapsed time per iteration (ms): 37639.7 | learning rate: 1.148E-04 | global batch size:  1024 | lm loss: 1.874822E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26109/   51900 | consumed samples:     26735616 | elapsed time per iteration (ms): 37513.9 | learning rate: 1.148E-04 | global batch size:  1024 | lm loss: 1.827941E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26110/   51900 | consumed samples:     26736640 | elapsed time per iteration (ms): 37587.4 | learning rate: 1.148E-04 | global batch size:  1024 | lm loss: 1.842773E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26111/   51900 | consumed samples:     26737664 | elapsed time per iteration (ms): 37638.8 | learning rate: 1.148E-04 | global batch size:  1024 | lm loss: 1.860202E+00 | loss scale: 1.0 | grad norm: 0.091 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26112/   51900 | consumed samples:     26738688 | elapsed time per iteration (ms): 37599.3 | learning rate: 1.147E-04 | global batch size:  1024 | lm loss: 1.859202E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26113/   51900 | consumed samples:     26739712 | elapsed time per iteration (ms): 37689.6 | learning rate: 1.147E-04 | global batch size:  1024 | lm loss: 1.857877E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26114/   51900 | consumed samples:     26740736 | elapsed time per iteration (ms): 37672.9 | learning rate: 1.147E-04 | global batch size:  1024 | lm loss: 1.853846E+00 | loss scale: 1.0 | grad norm: 0.096 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26115/   51900 | consumed samples:     26741760 | elapsed time per iteration (ms): 37646.5 | learning rate: 1.147E-04 | global batch size:  1024 | lm loss: 1.854375E+00 | loss scale: 1.0 | grad norm: 0.088 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26116/   51900 | consumed samples:     26742784 | elapsed time per iteration (ms): 37600.1 | learning rate: 1.147E-04 | global batch size:  1024 | lm loss: 1.847198E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26117/   51900 | consumed samples:     26743808 | elapsed time per iteration (ms): 37697.8 | learning rate: 1.147E-04 | global batch size:  1024 | lm loss: 1.843181E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26118/   51900 | consumed samples:     26744832 | elapsed time per iteration (ms): 37665.9 | learning rate: 1.147E-04 | global batch size:  1024 | lm loss: 1.873185E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26119/   51900 | consumed samples:     26745856 | elapsed time per iteration (ms): 37721.9 | learning rate: 1.147E-04 | global batch size:  1024 | lm loss: 1.846679E+00 | loss scale: 1.0 | grad norm: 0.088 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26120/   51900 | consumed samples:     26746880 | elapsed time per iteration (ms): 37708.4 | learning rate: 1.147E-04 | global batch size:  1024 | lm loss: 1.854413E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26121/   51900 | consumed samples:     26747904 | elapsed time per iteration (ms): 37655.6 | learning rate: 1.147E-04 | global batch size:  1024 | lm loss: 1.841095E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26122/   51900 | consumed samples:     26748928 | elapsed time per iteration (ms): 37737.7 | learning rate: 1.147E-04 | global batch size:  1024 | lm loss: 1.847946E+00 | loss scale: 1.0 | grad norm: 0.088 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26123/   51900 | consumed samples:     26749952 | elapsed time per iteration (ms): 37584.6 | learning rate: 1.147E-04 | global batch size:  1024 | lm loss: 1.844351E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26124/   51900 | consumed samples:     26750976 | elapsed time per iteration (ms): 37620.9 | learning rate: 1.147E-04 | global batch size:  1024 | lm loss: 1.854764E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26125/   51900 | consumed samples:     26752000 | elapsed time per iteration (ms): 37593.7 | learning rate: 1.147E-04 | global batch size:  1024 | lm loss: 1.850810E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26126/   51900 | consumed samples:     26753024 | elapsed time per iteration (ms): 37704.4 | learning rate: 1.147E-04 | global batch size:  1024 | lm loss: 1.856170E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26127/   51900 | consumed samples:     26754048 | elapsed time per iteration (ms): 37664.2 | learning rate: 1.147E-04 | global batch size:  1024 | lm loss: 1.846007E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26128/   51900 | consumed samples:     26755072 | elapsed time per iteration (ms): 37705.4 | learning rate: 1.147E-04 | global batch size:  1024 | lm loss: 1.833953E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26129/   51900 | consumed samples:     26756096 | elapsed time per iteration (ms): 37618.8 | learning rate: 1.146E-04 | global batch size:  1024 | lm loss: 1.864101E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26130/   51900 | consumed samples:     26757120 | elapsed time per iteration (ms): 37720.8 | learning rate: 1.146E-04 | global batch size:  1024 | lm loss: 1.870903E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26131/   51900 | consumed samples:     26758144 | elapsed time per iteration (ms): 37636.9 | learning rate: 1.146E-04 | global batch size:  1024 | lm loss: 1.847544E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26132/   51900 | consumed samples:     26759168 | elapsed time per iteration (ms): 37632.3 | learning rate: 1.146E-04 | global batch size:  1024 | lm loss: 1.838279E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26133/   51900 | consumed samples:     26760192 | elapsed time per iteration (ms): 37702.1 | learning rate: 1.146E-04 | global batch size:  1024 | lm loss: 1.833410E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26134/   51900 | consumed samples:     26761216 | elapsed time per iteration (ms): 37562.9 | learning rate: 1.146E-04 | global batch size:  1024 | lm loss: 1.847713E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26135/   51900 | consumed samples:     26762240 | elapsed time per iteration (ms): 37639.0 | learning rate: 1.146E-04 | global batch size:  1024 | lm loss: 1.857085E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26136/   51900 | consumed samples:     26763264 | elapsed time per iteration (ms): 37672.1 | learning rate: 1.146E-04 | global batch size:  1024 | lm loss: 1.837167E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26137/   51900 | consumed samples:     26764288 | elapsed time per iteration (ms): 37702.0 | learning rate: 1.146E-04 | global batch size:  1024 | lm loss: 1.833569E+00 | loss scale: 1.0 | grad norm: 0.184 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26138/   51900 | consumed samples:     26765312 | elapsed time per iteration (ms): 37684.1 | learning rate: 1.146E-04 | global batch size:  1024 | lm loss: 1.850055E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26139/   51900 | consumed samples:     26766336 | elapsed time per iteration (ms): 37632.7 | learning rate: 1.146E-04 | global batch size:  1024 | lm loss: 1.849197E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26140/   51900 | consumed samples:     26767360 | elapsed time per iteration (ms): 37651.9 | learning rate: 1.146E-04 | global batch size:  1024 | lm loss: 1.857850E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26141/   51900 | consumed samples:     26768384 | elapsed time per iteration (ms): 37661.0 | learning rate: 1.146E-04 | global batch size:  1024 | lm loss: 1.865926E+00 | loss scale: 1.0 | grad norm: 0.090 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26142/   51900 | consumed samples:     26769408 | elapsed time per iteration (ms): 37647.7 | learning rate: 1.146E-04 | global batch size:  1024 | lm loss: 1.850064E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26143/   51900 | consumed samples:     26770432 | elapsed time per iteration (ms): 37643.7 | learning rate: 1.146E-04 | global batch size:  1024 | lm loss: 1.831166E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26144/   51900 | consumed samples:     26771456 | elapsed time per iteration (ms): 37635.0 | learning rate: 1.146E-04 | global batch size:  1024 | lm loss: 1.859110E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26145/   51900 | consumed samples:     26772480 | elapsed time per iteration (ms): 37669.4 | learning rate: 1.146E-04 | global batch size:  1024 | lm loss: 1.832117E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26146/   51900 | consumed samples:     26773504 | elapsed time per iteration (ms): 37671.7 | learning rate: 1.146E-04 | global batch size:  1024 | lm loss: 1.855408E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26147/   51900 | consumed samples:     26774528 | elapsed time per iteration (ms): 37704.9 | learning rate: 1.145E-04 | global batch size:  1024 | lm loss: 1.852839E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26148/   51900 | consumed samples:     26775552 | elapsed time per iteration (ms): 37720.1 | learning rate: 1.145E-04 | global batch size:  1024 | lm loss: 1.863238E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26149/   51900 | consumed samples:     26776576 | elapsed time per iteration (ms): 37665.8 | learning rate: 1.145E-04 | global batch size:  1024 | lm loss: 1.854009E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26150/   51900 | consumed samples:     26777600 | elapsed time per iteration (ms): 37590.3 | learning rate: 1.145E-04 | global batch size:  1024 | lm loss: 1.849338E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26151/   51900 | consumed samples:     26778624 | elapsed time per iteration (ms): 37599.2 | learning rate: 1.145E-04 | global batch size:  1024 | lm loss: 1.853404E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26152/   51900 | consumed samples:     26779648 | elapsed time per iteration (ms): 37704.8 | learning rate: 1.145E-04 | global batch size:  1024 | lm loss: 1.854801E+00 | loss scale: 1.0 | grad norm: 0.097 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26153/   51900 | consumed samples:     26780672 | elapsed time per iteration (ms): 37700.9 | learning rate: 1.145E-04 | global batch size:  1024 | lm loss: 1.859742E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26154/   51900 | consumed samples:     26781696 | elapsed time per iteration (ms): 37669.3 | learning rate: 1.145E-04 | global batch size:  1024 | lm loss: 1.840150E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26155/   51900 | consumed samples:     26782720 | elapsed time per iteration (ms): 37571.3 | learning rate: 1.145E-04 | global batch size:  1024 | lm loss: 1.855903E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26156/   51900 | consumed samples:     26783744 | elapsed time per iteration (ms): 37784.0 | learning rate: 1.145E-04 | global batch size:  1024 | lm loss: 1.873512E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26157/   51900 | consumed samples:     26784768 | elapsed time per iteration (ms): 37656.9 | learning rate: 1.145E-04 | global batch size:  1024 | lm loss: 1.836635E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26158/   51900 | consumed samples:     26785792 | elapsed time per iteration (ms): 37660.7 | learning rate: 1.145E-04 | global batch size:  1024 | lm loss: 1.848443E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26159/   51900 | consumed samples:     26786816 | elapsed time per iteration (ms): 37600.8 | learning rate: 1.145E-04 | global batch size:  1024 | lm loss: 1.844001E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26160/   51900 | consumed samples:     26787840 | elapsed time per iteration (ms): 37591.8 | learning rate: 1.145E-04 | global batch size:  1024 | lm loss: 1.846686E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26161/   51900 | consumed samples:     26788864 | elapsed time per iteration (ms): 37636.8 | learning rate: 1.145E-04 | global batch size:  1024 | lm loss: 1.846620E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26162/   51900 | consumed samples:     26789888 | elapsed time per iteration (ms): 37551.8 | learning rate: 1.145E-04 | global batch size:  1024 | lm loss: 1.858149E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26163/   51900 | consumed samples:     26790912 | elapsed time per iteration (ms): 37652.1 | learning rate: 1.145E-04 | global batch size:  1024 | lm loss: 1.855974E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26164/   51900 | consumed samples:     26791936 | elapsed time per iteration (ms): 37632.3 | learning rate: 1.145E-04 | global batch size:  1024 | lm loss: 1.842569E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26165/   51900 | consumed samples:     26792960 | elapsed time per iteration (ms): 37663.5 | learning rate: 1.144E-04 | global batch size:  1024 | lm loss: 1.840086E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26166/   51900 | consumed samples:     26793984 | elapsed time per iteration (ms): 37607.0 | learning rate: 1.144E-04 | global batch size:  1024 | lm loss: 1.847422E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26167/   51900 | consumed samples:     26795008 | elapsed time per iteration (ms): 37756.8 | learning rate: 1.144E-04 | global batch size:  1024 | lm loss: 1.848388E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26168/   51900 | consumed samples:     26796032 | elapsed time per iteration (ms): 37620.6 | learning rate: 1.144E-04 | global batch size:  1024 | lm loss: 1.865222E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26169/   51900 | consumed samples:     26797056 | elapsed time per iteration (ms): 37653.5 | learning rate: 1.144E-04 | global batch size:  1024 | lm loss: 1.858051E+00 | loss scale: 1.0 | grad norm: 0.088 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26170/   51900 | consumed samples:     26798080 | elapsed time per iteration (ms): 37552.2 | learning rate: 1.144E-04 | global batch size:  1024 | lm loss: 1.862821E+00 | loss scale: 1.0 | grad norm: 0.101 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26171/   51900 | consumed samples:     26799104 | elapsed time per iteration (ms): 37570.6 | learning rate: 1.144E-04 | global batch size:  1024 | lm loss: 1.854841E+00 | loss scale: 1.0 | grad norm: 0.108 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26172/   51900 | consumed samples:     26800128 | elapsed time per iteration (ms): 37597.2 | learning rate: 1.144E-04 | global batch size:  1024 | lm loss: 1.835287E+00 | loss scale: 1.0 | grad norm: 0.090 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26173/   51900 | consumed samples:     26801152 | elapsed time per iteration (ms): 37670.0 | learning rate: 1.144E-04 | global batch size:  1024 | lm loss: 1.849250E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26174/   51900 | consumed samples:     26802176 | elapsed time per iteration (ms): 37657.0 | learning rate: 1.144E-04 | global batch size:  1024 | lm loss: 1.846747E+00 | loss scale: 1.0 | grad norm: 0.087 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26175/   51900 | consumed samples:     26803200 | elapsed time per iteration (ms): 37610.9 | learning rate: 1.144E-04 | global batch size:  1024 | lm loss: 1.869013E+00 | loss scale: 1.0 | grad norm: 0.088 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26176/   51900 | consumed samples:     26804224 | elapsed time per iteration (ms): 37663.6 | learning rate: 1.144E-04 | global batch size:  1024 | lm loss: 1.860367E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26177/   51900 | consumed samples:     26805248 | elapsed time per iteration (ms): 37641.3 | learning rate: 1.144E-04 | global batch size:  1024 | lm loss: 1.849332E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26178/   51900 | consumed samples:     26806272 | elapsed time per iteration (ms): 37502.8 | learning rate: 1.144E-04 | global batch size:  1024 | lm loss: 1.839444E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26179/   51900 | consumed samples:     26807296 | elapsed time per iteration (ms): 37699.6 | learning rate: 1.144E-04 | global batch size:  1024 | lm loss: 1.879025E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26180/   51900 | consumed samples:     26808320 | elapsed time per iteration (ms): 37628.8 | learning rate: 1.144E-04 | global batch size:  1024 | lm loss: 1.864511E+00 | loss scale: 1.0 | grad norm: 0.141 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26181/   51900 | consumed samples:     26809344 | elapsed time per iteration (ms): 37621.5 | learning rate: 1.144E-04 | global batch size:  1024 | lm loss: 1.864815E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26182/   51900 | consumed samples:     26810368 | elapsed time per iteration (ms): 37477.9 | learning rate: 1.143E-04 | global batch size:  1024 | lm loss: 1.855309E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26183/   51900 | consumed samples:     26811392 | elapsed time per iteration (ms): 37632.4 | learning rate: 1.143E-04 | global batch size:  1024 | lm loss: 1.843938E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26184/   51900 | consumed samples:     26812416 | elapsed time per iteration (ms): 37678.5 | learning rate: 1.143E-04 | global batch size:  1024 | lm loss: 1.854230E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26185/   51900 | consumed samples:     26813440 | elapsed time per iteration (ms): 37650.5 | learning rate: 1.143E-04 | global batch size:  1024 | lm loss: 1.872298E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26186/   51900 | consumed samples:     26814464 | elapsed time per iteration (ms): 37781.5 | learning rate: 1.143E-04 | global batch size:  1024 | lm loss: 1.872909E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26187/   51900 | consumed samples:     26815488 | elapsed time per iteration (ms): 37648.3 | learning rate: 1.143E-04 | global batch size:  1024 | lm loss: 1.851350E+00 | loss scale: 1.0 | grad norm: 0.088 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26188/   51900 | consumed samples:     26816512 | elapsed time per iteration (ms): 37764.2 | learning rate: 1.143E-04 | global batch size:  1024 | lm loss: 1.851464E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26189/   51900 | consumed samples:     26817536 | elapsed time per iteration (ms): 37604.4 | learning rate: 1.143E-04 | global batch size:  1024 | lm loss: 1.864892E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26190/   51900 | consumed samples:     26818560 | elapsed time per iteration (ms): 37636.5 | learning rate: 1.143E-04 | global batch size:  1024 | lm loss: 1.875672E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26191/   51900 | consumed samples:     26819584 | elapsed time per iteration (ms): 37621.6 | learning rate: 1.143E-04 | global batch size:  1024 | lm loss: 1.847970E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26192/   51900 | consumed samples:     26820608 | elapsed time per iteration (ms): 37600.3 | learning rate: 1.143E-04 | global batch size:  1024 | lm loss: 1.849196E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26193/   51900 | consumed samples:     26821632 | elapsed time per iteration (ms): 37633.4 | learning rate: 1.143E-04 | global batch size:  1024 | lm loss: 1.854216E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26194/   51900 | consumed samples:     26822656 | elapsed time per iteration (ms): 37721.6 | learning rate: 1.143E-04 | global batch size:  1024 | lm loss: 1.848154E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26195/   51900 | consumed samples:     26823680 | elapsed time per iteration (ms): 37546.2 | learning rate: 1.143E-04 | global batch size:  1024 | lm loss: 1.864491E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26196/   51900 | consumed samples:     26824704 | elapsed time per iteration (ms): 37614.6 | learning rate: 1.143E-04 | global batch size:  1024 | lm loss: 1.856663E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26197/   51900 | consumed samples:     26825728 | elapsed time per iteration (ms): 37768.7 | learning rate: 1.143E-04 | global batch size:  1024 | lm loss: 1.862865E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26198/   51900 | consumed samples:     26826752 | elapsed time per iteration (ms): 37740.8 | learning rate: 1.143E-04 | global batch size:  1024 | lm loss: 1.854537E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26199/   51900 | consumed samples:     26827776 | elapsed time per iteration (ms): 37670.6 | learning rate: 1.143E-04 | global batch size:  1024 | lm loss: 1.862890E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26200/   51900 | consumed samples:     26828800 | elapsed time per iteration (ms): 37546.4 | learning rate: 1.142E-04 | global batch size:  1024 | lm loss: 1.851975E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26201/   51900 | consumed samples:     26829824 | elapsed time per iteration (ms): 37655.7 | learning rate: 1.142E-04 | global batch size:  1024 | lm loss: 1.863466E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26202/   51900 | consumed samples:     26830848 | elapsed time per iteration (ms): 37661.4 | learning rate: 1.142E-04 | global batch size:  1024 | lm loss: 1.838830E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26203/   51900 | consumed samples:     26831872 | elapsed time per iteration (ms): 37759.9 | learning rate: 1.142E-04 | global batch size:  1024 | lm loss: 1.845268E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26204/   51900 | consumed samples:     26832896 | elapsed time per iteration (ms): 37715.6 | learning rate: 1.142E-04 | global batch size:  1024 | lm loss: 1.863064E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26205/   51900 | consumed samples:     26833920 | elapsed time per iteration (ms): 37651.4 | learning rate: 1.142E-04 | global batch size:  1024 | lm loss: 1.851055E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26206/   51900 | consumed samples:     26834944 | elapsed time per iteration (ms): 37714.5 | learning rate: 1.142E-04 | global batch size:  1024 | lm loss: 1.866097E+00 | loss scale: 1.0 | grad norm: 0.087 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26207/   51900 | consumed samples:     26835968 | elapsed time per iteration (ms): 37565.3 | learning rate: 1.142E-04 | global batch size:  1024 | lm loss: 1.851281E+00 | loss scale: 1.0 | grad norm: 0.089 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26208/   51900 | consumed samples:     26836992 | elapsed time per iteration (ms): 37695.8 | learning rate: 1.142E-04 | global batch size:  1024 | lm loss: 1.858479E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26209/   51900 | consumed samples:     26838016 | elapsed time per iteration (ms): 37780.9 | learning rate: 1.142E-04 | global batch size:  1024 | lm loss: 1.858529E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26210/   51900 | consumed samples:     26839040 | elapsed time per iteration (ms): 37719.8 | learning rate: 1.142E-04 | global batch size:  1024 | lm loss: 1.847409E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26211/   51900 | consumed samples:     26840064 | elapsed time per iteration (ms): 37597.1 | learning rate: 1.142E-04 | global batch size:  1024 | lm loss: 1.861858E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26212/   51900 | consumed samples:     26841088 | elapsed time per iteration (ms): 37640.1 | learning rate: 1.142E-04 | global batch size:  1024 | lm loss: 1.863224E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26213/   51900 | consumed samples:     26842112 | elapsed time per iteration (ms): 37698.5 | learning rate: 1.142E-04 | global batch size:  1024 | lm loss: 1.867112E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26214/   51900 | consumed samples:     26843136 | elapsed time per iteration (ms): 37643.3 | learning rate: 1.142E-04 | global batch size:  1024 | lm loss: 1.858522E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26215/   51900 | consumed samples:     26844160 | elapsed time per iteration (ms): 37618.3 | learning rate: 1.142E-04 | global batch size:  1024 | lm loss: 1.826703E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26216/   51900 | consumed samples:     26845184 | elapsed time per iteration (ms): 37661.0 | learning rate: 1.142E-04 | global batch size:  1024 | lm loss: 1.843144E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26217/   51900 | consumed samples:     26846208 | elapsed time per iteration (ms): 37502.3 | learning rate: 1.142E-04 | global batch size:  1024 | lm loss: 1.863834E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26218/   51900 | consumed samples:     26847232 | elapsed time per iteration (ms): 37752.8 | learning rate: 1.141E-04 | global batch size:  1024 | lm loss: 1.843702E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26219/   51900 | consumed samples:     26848256 | elapsed time per iteration (ms): 37657.6 | learning rate: 1.141E-04 | global batch size:  1024 | lm loss: 1.843506E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26220/   51900 | consumed samples:     26849280 | elapsed time per iteration (ms): 37766.5 | learning rate: 1.141E-04 | global batch size:  1024 | lm loss: 1.852452E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26221/   51900 | consumed samples:     26850304 | elapsed time per iteration (ms): 37533.3 | learning rate: 1.141E-04 | global batch size:  1024 | lm loss: 1.850609E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26222/   51900 | consumed samples:     26851328 | elapsed time per iteration (ms): 37651.0 | learning rate: 1.141E-04 | global batch size:  1024 | lm loss: 1.868560E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26223/   51900 | consumed samples:     26852352 | elapsed time per iteration (ms): 37649.8 | learning rate: 1.141E-04 | global batch size:  1024 | lm loss: 1.872059E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26224/   51900 | consumed samples:     26853376 | elapsed time per iteration (ms): 37568.2 | learning rate: 1.141E-04 | global batch size:  1024 | lm loss: 1.840672E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26225/   51900 | consumed samples:     26854400 | elapsed time per iteration (ms): 37652.3 | learning rate: 1.141E-04 | global batch size:  1024 | lm loss: 1.847888E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26226/   51900 | consumed samples:     26855424 | elapsed time per iteration (ms): 37661.9 | learning rate: 1.141E-04 | global batch size:  1024 | lm loss: 1.856482E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26227/   51900 | consumed samples:     26856448 | elapsed time per iteration (ms): 37707.7 | learning rate: 1.141E-04 | global batch size:  1024 | lm loss: 1.846992E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26228/   51900 | consumed samples:     26857472 | elapsed time per iteration (ms): 37653.9 | learning rate: 1.141E-04 | global batch size:  1024 | lm loss: 1.850334E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26229/   51900 | consumed samples:     26858496 | elapsed time per iteration (ms): 37616.2 | learning rate: 1.141E-04 | global batch size:  1024 | lm loss: 1.866833E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26230/   51900 | consumed samples:     26859520 | elapsed time per iteration (ms): 37597.2 | learning rate: 1.141E-04 | global batch size:  1024 | lm loss: 1.845037E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26231/   51900 | consumed samples:     26860544 | elapsed time per iteration (ms): 37644.4 | learning rate: 1.141E-04 | global batch size:  1024 | lm loss: 1.845894E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26232/   51900 | consumed samples:     26861568 | elapsed time per iteration (ms): 37642.7 | learning rate: 1.141E-04 | global batch size:  1024 | lm loss: 1.863708E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26233/   51900 | consumed samples:     26862592 | elapsed time per iteration (ms): 37486.6 | learning rate: 1.141E-04 | global batch size:  1024 | lm loss: 1.834852E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26234/   51900 | consumed samples:     26863616 | elapsed time per iteration (ms): 37593.3 | learning rate: 1.141E-04 | global batch size:  1024 | lm loss: 1.864826E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26235/   51900 | consumed samples:     26864640 | elapsed time per iteration (ms): 37592.8 | learning rate: 1.140E-04 | global batch size:  1024 | lm loss: 1.860005E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26236/   51900 | consumed samples:     26865664 | elapsed time per iteration (ms): 37572.6 | learning rate: 1.140E-04 | global batch size:  1024 | lm loss: 1.862778E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26237/   51900 | consumed samples:     26866688 | elapsed time per iteration (ms): 37594.3 | learning rate: 1.140E-04 | global batch size:  1024 | lm loss: 1.844271E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26238/   51900 | consumed samples:     26867712 | elapsed time per iteration (ms): 37623.1 | learning rate: 1.140E-04 | global batch size:  1024 | lm loss: 1.834494E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26239/   51900 | consumed samples:     26868736 | elapsed time per iteration (ms): 37642.4 | learning rate: 1.140E-04 | global batch size:  1024 | lm loss: 1.852068E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26240/   51900 | consumed samples:     26869760 | elapsed time per iteration (ms): 37670.0 | learning rate: 1.140E-04 | global batch size:  1024 | lm loss: 1.852874E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26241/   51900 | consumed samples:     26870784 | elapsed time per iteration (ms): 37654.0 | learning rate: 1.140E-04 | global batch size:  1024 | lm loss: 1.841624E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26242/   51900 | consumed samples:     26871808 | elapsed time per iteration (ms): 37645.1 | learning rate: 1.140E-04 | global batch size:  1024 | lm loss: 1.858210E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26243/   51900 | consumed samples:     26872832 | elapsed time per iteration (ms): 37605.8 | learning rate: 1.140E-04 | global batch size:  1024 | lm loss: 1.862763E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26244/   51900 | consumed samples:     26873856 | elapsed time per iteration (ms): 37636.9 | learning rate: 1.140E-04 | global batch size:  1024 | lm loss: 1.850605E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26245/   51900 | consumed samples:     26874880 | elapsed time per iteration (ms): 37522.9 | learning rate: 1.140E-04 | global batch size:  1024 | lm loss: 1.847715E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26246/   51900 | consumed samples:     26875904 | elapsed time per iteration (ms): 37613.7 | learning rate: 1.140E-04 | global batch size:  1024 | lm loss: 1.843809E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26247/   51900 | consumed samples:     26876928 | elapsed time per iteration (ms): 37637.3 | learning rate: 1.140E-04 | global batch size:  1024 | lm loss: 1.868018E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26248/   51900 | consumed samples:     26877952 | elapsed time per iteration (ms): 37767.8 | learning rate: 1.140E-04 | global batch size:  1024 | lm loss: 1.853644E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26249/   51900 | consumed samples:     26878976 | elapsed time per iteration (ms): 37617.8 | learning rate: 1.140E-04 | global batch size:  1024 | lm loss: 1.867727E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26250/   51900 | consumed samples:     26880000 | elapsed time per iteration (ms): 37648.0 | learning rate: 1.140E-04 | global batch size:  1024 | lm loss: 1.846425E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26251/   51900 | consumed samples:     26881024 | elapsed time per iteration (ms): 37544.6 | learning rate: 1.140E-04 | global batch size:  1024 | lm loss: 1.852821E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26252/   51900 | consumed samples:     26882048 | elapsed time per iteration (ms): 37660.0 | learning rate: 1.140E-04 | global batch size:  1024 | lm loss: 1.856085E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26253/   51900 | consumed samples:     26883072 | elapsed time per iteration (ms): 37638.6 | learning rate: 1.139E-04 | global batch size:  1024 | lm loss: 1.853643E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26254/   51900 | consumed samples:     26884096 | elapsed time per iteration (ms): 37642.7 | learning rate: 1.139E-04 | global batch size:  1024 | lm loss: 1.848945E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26255/   51900 | consumed samples:     26885120 | elapsed time per iteration (ms): 37648.4 | learning rate: 1.139E-04 | global batch size:  1024 | lm loss: 1.862243E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26256/   51900 | consumed samples:     26886144 | elapsed time per iteration (ms): 37571.9 | learning rate: 1.139E-04 | global batch size:  1024 | lm loss: 1.857790E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26257/   51900 | consumed samples:     26887168 | elapsed time per iteration (ms): 37662.7 | learning rate: 1.139E-04 | global batch size:  1024 | lm loss: 1.850659E+00 | loss scale: 1.0 | grad norm: 0.087 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26258/   51900 | consumed samples:     26888192 | elapsed time per iteration (ms): 37557.6 | learning rate: 1.139E-04 | global batch size:  1024 | lm loss: 1.851091E+00 | loss scale: 1.0 | grad norm: 0.093 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26259/   51900 | consumed samples:     26889216 | elapsed time per iteration (ms): 37569.2 | learning rate: 1.139E-04 | global batch size:  1024 | lm loss: 1.844981E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26260/   51900 | consumed samples:     26890240 | elapsed time per iteration (ms): 37631.2 | learning rate: 1.139E-04 | global batch size:  1024 | lm loss: 1.857454E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26261/   51900 | consumed samples:     26891264 | elapsed time per iteration (ms): 37589.6 | learning rate: 1.139E-04 | global batch size:  1024 | lm loss: 1.878970E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26262/   51900 | consumed samples:     26892288 | elapsed time per iteration (ms): 37655.1 | learning rate: 1.139E-04 | global batch size:  1024 | lm loss: 1.865792E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26263/   51900 | consumed samples:     26893312 | elapsed time per iteration (ms): 37697.8 | learning rate: 1.139E-04 | global batch size:  1024 | lm loss: 1.846770E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26264/   51900 | consumed samples:     26894336 | elapsed time per iteration (ms): 37645.9 | learning rate: 1.139E-04 | global batch size:  1024 | lm loss: 1.852738E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26265/   51900 | consumed samples:     26895360 | elapsed time per iteration (ms): 37712.5 | learning rate: 1.139E-04 | global batch size:  1024 | lm loss: 1.850081E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26266/   51900 | consumed samples:     26896384 | elapsed time per iteration (ms): 37665.1 | learning rate: 1.139E-04 | global batch size:  1024 | lm loss: 1.851650E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26267/   51900 | consumed samples:     26897408 | elapsed time per iteration (ms): 37685.6 | learning rate: 1.139E-04 | global batch size:  1024 | lm loss: 1.848072E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26268/   51900 | consumed samples:     26898432 | elapsed time per iteration (ms): 37622.7 | learning rate: 1.139E-04 | global batch size:  1024 | lm loss: 1.849085E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26269/   51900 | consumed samples:     26899456 | elapsed time per iteration (ms): 37709.6 | learning rate: 1.139E-04 | global batch size:  1024 | lm loss: 1.857258E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26270/   51900 | consumed samples:     26900480 | elapsed time per iteration (ms): 37714.5 | learning rate: 1.139E-04 | global batch size:  1024 | lm loss: 1.847852E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26271/   51900 | consumed samples:     26901504 | elapsed time per iteration (ms): 37624.2 | learning rate: 1.138E-04 | global batch size:  1024 | lm loss: 1.872631E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26272/   51900 | consumed samples:     26902528 | elapsed time per iteration (ms): 37622.7 | learning rate: 1.138E-04 | global batch size:  1024 | lm loss: 1.859455E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26273/   51900 | consumed samples:     26903552 | elapsed time per iteration (ms): 37714.5 | learning rate: 1.138E-04 | global batch size:  1024 | lm loss: 1.849769E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26274/   51900 | consumed samples:     26904576 | elapsed time per iteration (ms): 37636.3 | learning rate: 1.138E-04 | global batch size:  1024 | lm loss: 1.871709E+00 | loss scale: 1.0 | grad norm: 0.090 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26275/   51900 | consumed samples:     26905600 | elapsed time per iteration (ms): 37691.9 | learning rate: 1.138E-04 | global batch size:  1024 | lm loss: 1.832124E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26276/   51900 | consumed samples:     26906624 | elapsed time per iteration (ms): 37532.9 | learning rate: 1.138E-04 | global batch size:  1024 | lm loss: 1.856855E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26277/   51900 | consumed samples:     26907648 | elapsed time per iteration (ms): 37617.3 | learning rate: 1.138E-04 | global batch size:  1024 | lm loss: 1.852003E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26278/   51900 | consumed samples:     26908672 | elapsed time per iteration (ms): 37507.7 | learning rate: 1.138E-04 | global batch size:  1024 | lm loss: 1.840301E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26279/   51900 | consumed samples:     26909696 | elapsed time per iteration (ms): 37646.9 | learning rate: 1.138E-04 | global batch size:  1024 | lm loss: 1.849660E+00 | loss scale: 1.0 | grad norm: 0.087 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26280/   51900 | consumed samples:     26910720 | elapsed time per iteration (ms): 37569.2 | learning rate: 1.138E-04 | global batch size:  1024 | lm loss: 1.850324E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26281/   51900 | consumed samples:     26911744 | elapsed time per iteration (ms): 37690.4 | learning rate: 1.138E-04 | global batch size:  1024 | lm loss: 1.859972E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26282/   51900 | consumed samples:     26912768 | elapsed time per iteration (ms): 37728.3 | learning rate: 1.138E-04 | global batch size:  1024 | lm loss: 1.858036E+00 | loss scale: 1.0 | grad norm: 0.091 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26283/   51900 | consumed samples:     26913792 | elapsed time per iteration (ms): 37575.6 | learning rate: 1.138E-04 | global batch size:  1024 | lm loss: 1.863408E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26284/   51900 | consumed samples:     26914816 | elapsed time per iteration (ms): 37571.7 | learning rate: 1.138E-04 | global batch size:  1024 | lm loss: 1.832154E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26285/   51900 | consumed samples:     26915840 | elapsed time per iteration (ms): 37651.3 | learning rate: 1.138E-04 | global batch size:  1024 | lm loss: 1.856827E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26286/   51900 | consumed samples:     26916864 | elapsed time per iteration (ms): 37591.3 | learning rate: 1.138E-04 | global batch size:  1024 | lm loss: 1.843186E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26287/   51900 | consumed samples:     26917888 | elapsed time per iteration (ms): 37711.5 | learning rate: 1.138E-04 | global batch size:  1024 | lm loss: 1.844829E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26288/   51900 | consumed samples:     26918912 | elapsed time per iteration (ms): 37669.2 | learning rate: 1.137E-04 | global batch size:  1024 | lm loss: 1.840219E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26289/   51900 | consumed samples:     26919936 | elapsed time per iteration (ms): 37676.9 | learning rate: 1.137E-04 | global batch size:  1024 | lm loss: 1.856899E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26290/   51900 | consumed samples:     26920960 | elapsed time per iteration (ms): 37673.1 | learning rate: 1.137E-04 | global batch size:  1024 | lm loss: 1.849702E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26291/   51900 | consumed samples:     26921984 | elapsed time per iteration (ms): 37618.2 | learning rate: 1.137E-04 | global batch size:  1024 | lm loss: 1.846677E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26292/   51900 | consumed samples:     26923008 | elapsed time per iteration (ms): 37586.2 | learning rate: 1.137E-04 | global batch size:  1024 | lm loss: 1.867516E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26293/   51900 | consumed samples:     26924032 | elapsed time per iteration (ms): 37574.5 | learning rate: 1.137E-04 | global batch size:  1024 | lm loss: 1.856582E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26294/   51900 | consumed samples:     26925056 | elapsed time per iteration (ms): 37666.0 | learning rate: 1.137E-04 | global batch size:  1024 | lm loss: 1.846225E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26295/   51900 | consumed samples:     26926080 | elapsed time per iteration (ms): 37665.2 | learning rate: 1.137E-04 | global batch size:  1024 | lm loss: 1.854796E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26296/   51900 | consumed samples:     26927104 | elapsed time per iteration (ms): 37738.0 | learning rate: 1.137E-04 | global batch size:  1024 | lm loss: 1.848784E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26297/   51900 | consumed samples:     26928128 | elapsed time per iteration (ms): 37677.1 | learning rate: 1.137E-04 | global batch size:  1024 | lm loss: 1.847563E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26298/   51900 | consumed samples:     26929152 | elapsed time per iteration (ms): 37619.1 | learning rate: 1.137E-04 | global batch size:  1024 | lm loss: 1.848800E+00 | loss scale: 1.0 | grad norm: 0.065 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26299/   51900 | consumed samples:     26930176 | elapsed time per iteration (ms): 37631.0 | learning rate: 1.137E-04 | global batch size:  1024 | lm loss: 1.856720E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26300/   51900 | consumed samples:     26931200 | elapsed time per iteration (ms): 37592.4 | learning rate: 1.137E-04 | global batch size:  1024 | lm loss: 1.842261E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26301/   51900 | consumed samples:     26932224 | elapsed time per iteration (ms): 37578.3 | learning rate: 1.137E-04 | global batch size:  1024 | lm loss: 1.858258E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26302/   51900 | consumed samples:     26933248 | elapsed time per iteration (ms): 37635.7 | learning rate: 1.137E-04 | global batch size:  1024 | lm loss: 1.848462E+00 | loss scale: 1.0 | grad norm: 0.087 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26303/   51900 | consumed samples:     26934272 | elapsed time per iteration (ms): 37628.2 | learning rate: 1.137E-04 | global batch size:  1024 | lm loss: 1.860871E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26304/   51900 | consumed samples:     26935296 | elapsed time per iteration (ms): 37670.6 | learning rate: 1.137E-04 | global batch size:  1024 | lm loss: 1.857450E+00 | loss scale: 1.0 | grad norm: 0.097 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26305/   51900 | consumed samples:     26936320 | elapsed time per iteration (ms): 37670.8 | learning rate: 1.137E-04 | global batch size:  1024 | lm loss: 1.856066E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26306/   51900 | consumed samples:     26937344 | elapsed time per iteration (ms): 37619.2 | learning rate: 1.136E-04 | global batch size:  1024 | lm loss: 1.851280E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26307/   51900 | consumed samples:     26938368 | elapsed time per iteration (ms): 37726.3 | learning rate: 1.136E-04 | global batch size:  1024 | lm loss: 1.844064E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26308/   51900 | consumed samples:     26939392 | elapsed time per iteration (ms): 37633.8 | learning rate: 1.136E-04 | global batch size:  1024 | lm loss: 1.854175E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26309/   51900 | consumed samples:     26940416 | elapsed time per iteration (ms): 37598.6 | learning rate: 1.136E-04 | global batch size:  1024 | lm loss: 1.847386E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26310/   51900 | consumed samples:     26941440 | elapsed time per iteration (ms): 37556.9 | learning rate: 1.136E-04 | global batch size:  1024 | lm loss: 1.865203E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26311/   51900 | consumed samples:     26942464 | elapsed time per iteration (ms): 37634.0 | learning rate: 1.136E-04 | global batch size:  1024 | lm loss: 1.845020E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26312/   51900 | consumed samples:     26943488 | elapsed time per iteration (ms): 37530.7 | learning rate: 1.136E-04 | global batch size:  1024 | lm loss: 1.842828E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26313/   51900 | consumed samples:     26944512 | elapsed time per iteration (ms): 37570.1 | learning rate: 1.136E-04 | global batch size:  1024 | lm loss: 1.853027E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26314/   51900 | consumed samples:     26945536 | elapsed time per iteration (ms): 37581.2 | learning rate: 1.136E-04 | global batch size:  1024 | lm loss: 1.851019E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26315/   51900 | consumed samples:     26946560 | elapsed time per iteration (ms): 37612.3 | learning rate: 1.136E-04 | global batch size:  1024 | lm loss: 1.844162E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26316/   51900 | consumed samples:     26947584 | elapsed time per iteration (ms): 37596.5 | learning rate: 1.136E-04 | global batch size:  1024 | lm loss: 1.852285E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26317/   51900 | consumed samples:     26948608 | elapsed time per iteration (ms): 37672.1 | learning rate: 1.136E-04 | global batch size:  1024 | lm loss: 1.842053E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26318/   51900 | consumed samples:     26949632 | elapsed time per iteration (ms): 37652.0 | learning rate: 1.136E-04 | global batch size:  1024 | lm loss: 1.854725E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26319/   51900 | consumed samples:     26950656 | elapsed time per iteration (ms): 37697.8 | learning rate: 1.136E-04 | global batch size:  1024 | lm loss: 1.852571E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26320/   51900 | consumed samples:     26951680 | elapsed time per iteration (ms): 37549.6 | learning rate: 1.136E-04 | global batch size:  1024 | lm loss: 1.859433E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26321/   51900 | consumed samples:     26952704 | elapsed time per iteration (ms): 37639.4 | learning rate: 1.136E-04 | global batch size:  1024 | lm loss: 1.849965E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26322/   51900 | consumed samples:     26953728 | elapsed time per iteration (ms): 37656.7 | learning rate: 1.136E-04 | global batch size:  1024 | lm loss: 1.848191E+00 | loss scale: 1.0 | grad norm: 0.106 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26323/   51900 | consumed samples:     26954752 | elapsed time per iteration (ms): 37586.4 | learning rate: 1.136E-04 | global batch size:  1024 | lm loss: 1.850149E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26324/   51900 | consumed samples:     26955776 | elapsed time per iteration (ms): 37657.4 | learning rate: 1.135E-04 | global batch size:  1024 | lm loss: 1.857706E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26325/   51900 | consumed samples:     26956800 | elapsed time per iteration (ms): 37691.7 | learning rate: 1.135E-04 | global batch size:  1024 | lm loss: 1.844692E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26326/   51900 | consumed samples:     26957824 | elapsed time per iteration (ms): 37730.7 | learning rate: 1.135E-04 | global batch size:  1024 | lm loss: 1.864619E+00 | loss scale: 1.0 | grad norm: 0.088 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26327/   51900 | consumed samples:     26958848 | elapsed time per iteration (ms): 37640.5 | learning rate: 1.135E-04 | global batch size:  1024 | lm loss: 1.863649E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26328/   51900 | consumed samples:     26959872 | elapsed time per iteration (ms): 37647.5 | learning rate: 1.135E-04 | global batch size:  1024 | lm loss: 1.853820E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26329/   51900 | consumed samples:     26960896 | elapsed time per iteration (ms): 37633.6 | learning rate: 1.135E-04 | global batch size:  1024 | lm loss: 1.841104E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26330/   51900 | consumed samples:     26961920 | elapsed time per iteration (ms): 37592.8 | learning rate: 1.135E-04 | global batch size:  1024 | lm loss: 1.855528E+00 | loss scale: 1.0 | grad norm: 0.087 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26331/   51900 | consumed samples:     26962944 | elapsed time per iteration (ms): 37640.4 | learning rate: 1.135E-04 | global batch size:  1024 | lm loss: 1.856279E+00 | loss scale: 1.0 | grad norm: 0.095 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26332/   51900 | consumed samples:     26963968 | elapsed time per iteration (ms): 37651.8 | learning rate: 1.135E-04 | global batch size:  1024 | lm loss: 1.872437E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26333/   51900 | consumed samples:     26964992 | elapsed time per iteration (ms): 37672.4 | learning rate: 1.135E-04 | global batch size:  1024 | lm loss: 1.836669E+00 | loss scale: 1.0 | grad norm: 0.088 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26334/   51900 | consumed samples:     26966016 | elapsed time per iteration (ms): 37580.8 | learning rate: 1.135E-04 | global batch size:  1024 | lm loss: 1.852568E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26335/   51900 | consumed samples:     26967040 | elapsed time per iteration (ms): 37690.6 | learning rate: 1.135E-04 | global batch size:  1024 | lm loss: 1.859630E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26336/   51900 | consumed samples:     26968064 | elapsed time per iteration (ms): 37691.0 | learning rate: 1.135E-04 | global batch size:  1024 | lm loss: 1.844549E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26337/   51900 | consumed samples:     26969088 | elapsed time per iteration (ms): 37577.3 | learning rate: 1.135E-04 | global batch size:  1024 | lm loss: 1.865794E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26338/   51900 | consumed samples:     26970112 | elapsed time per iteration (ms): 37629.7 | learning rate: 1.135E-04 | global batch size:  1024 | lm loss: 1.863322E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26339/   51900 | consumed samples:     26971136 | elapsed time per iteration (ms): 37558.0 | learning rate: 1.135E-04 | global batch size:  1024 | lm loss: 1.847950E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26340/   51900 | consumed samples:     26972160 | elapsed time per iteration (ms): 37700.3 | learning rate: 1.135E-04 | global batch size:  1024 | lm loss: 1.842348E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26341/   51900 | consumed samples:     26973184 | elapsed time per iteration (ms): 37685.9 | learning rate: 1.134E-04 | global batch size:  1024 | lm loss: 1.828477E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26342/   51900 | consumed samples:     26974208 | elapsed time per iteration (ms): 37681.9 | learning rate: 1.134E-04 | global batch size:  1024 | lm loss: 1.845165E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26343/   51900 | consumed samples:     26975232 | elapsed time per iteration (ms): 37699.6 | learning rate: 1.134E-04 | global batch size:  1024 | lm loss: 1.855793E+00 | loss scale: 1.0 | grad norm: 0.097 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26344/   51900 | consumed samples:     26976256 | elapsed time per iteration (ms): 37687.1 | learning rate: 1.134E-04 | global batch size:  1024 | lm loss: 1.828214E+00 | loss scale: 1.0 | grad norm: 0.088 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26345/   51900 | consumed samples:     26977280 | elapsed time per iteration (ms): 37648.4 | learning rate: 1.134E-04 | global batch size:  1024 | lm loss: 1.848771E+00 | loss scale: 1.0 | grad norm: 0.168 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26346/   51900 | consumed samples:     26978304 | elapsed time per iteration (ms): 37810.2 | learning rate: 1.134E-04 | global batch size:  1024 | lm loss: 1.850731E+00 | loss scale: 1.0 | grad norm: 0.118 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26347/   51900 | consumed samples:     26979328 | elapsed time per iteration (ms): 37668.8 | learning rate: 1.134E-04 | global batch size:  1024 | lm loss: 1.854593E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26348/   51900 | consumed samples:     26980352 | elapsed time per iteration (ms): 37627.8 | learning rate: 1.134E-04 | global batch size:  1024 | lm loss: 1.839122E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26349/   51900 | consumed samples:     26981376 | elapsed time per iteration (ms): 37695.5 | learning rate: 1.134E-04 | global batch size:  1024 | lm loss: 1.848778E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26350/   51900 | consumed samples:     26982400 | elapsed time per iteration (ms): 37542.1 | learning rate: 1.134E-04 | global batch size:  1024 | lm loss: 1.841191E+00 | loss scale: 1.0 | grad norm: 0.088 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26351/   51900 | consumed samples:     26983424 | elapsed time per iteration (ms): 37684.7 | learning rate: 1.134E-04 | global batch size:  1024 | lm loss: 1.832413E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26352/   51900 | consumed samples:     26984448 | elapsed time per iteration (ms): 37667.6 | learning rate: 1.134E-04 | global batch size:  1024 | lm loss: 1.861266E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26353/   51900 | consumed samples:     26985472 | elapsed time per iteration (ms): 37628.6 | learning rate: 1.134E-04 | global batch size:  1024 | lm loss: 1.852832E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26354/   51900 | consumed samples:     26986496 | elapsed time per iteration (ms): 37669.4 | learning rate: 1.134E-04 | global batch size:  1024 | lm loss: 1.860254E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26355/   51900 | consumed samples:     26987520 | elapsed time per iteration (ms): 37719.4 | learning rate: 1.134E-04 | global batch size:  1024 | lm loss: 1.837264E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26356/   51900 | consumed samples:     26988544 | elapsed time per iteration (ms): 37587.0 | learning rate: 1.134E-04 | global batch size:  1024 | lm loss: 1.853596E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26357/   51900 | consumed samples:     26989568 | elapsed time per iteration (ms): 37638.0 | learning rate: 1.134E-04 | global batch size:  1024 | lm loss: 1.864152E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26358/   51900 | consumed samples:     26990592 | elapsed time per iteration (ms): 37609.1 | learning rate: 1.134E-04 | global batch size:  1024 | lm loss: 1.833406E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26359/   51900 | consumed samples:     26991616 | elapsed time per iteration (ms): 37736.6 | learning rate: 1.133E-04 | global batch size:  1024 | lm loss: 1.859196E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26360/   51900 | consumed samples:     26992640 | elapsed time per iteration (ms): 37643.1 | learning rate: 1.133E-04 | global batch size:  1024 | lm loss: 1.842288E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26361/   51900 | consumed samples:     26993664 | elapsed time per iteration (ms): 37656.9 | learning rate: 1.133E-04 | global batch size:  1024 | lm loss: 1.844612E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26362/   51900 | consumed samples:     26994688 | elapsed time per iteration (ms): 37643.2 | learning rate: 1.133E-04 | global batch size:  1024 | lm loss: 1.855928E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26363/   51900 | consumed samples:     26995712 | elapsed time per iteration (ms): 37651.5 | learning rate: 1.133E-04 | global batch size:  1024 | lm loss: 1.850276E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26364/   51900 | consumed samples:     26996736 | elapsed time per iteration (ms): 37593.3 | learning rate: 1.133E-04 | global batch size:  1024 | lm loss: 1.847880E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26365/   51900 | consumed samples:     26997760 | elapsed time per iteration (ms): 37710.3 | learning rate: 1.133E-04 | global batch size:  1024 | lm loss: 1.849626E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26366/   51900 | consumed samples:     26998784 | elapsed time per iteration (ms): 37688.6 | learning rate: 1.133E-04 | global batch size:  1024 | lm loss: 1.838214E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26367/   51900 | consumed samples:     26999808 | elapsed time per iteration (ms): 37756.6 | learning rate: 1.133E-04 | global batch size:  1024 | lm loss: 1.853385E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26368/   51900 | consumed samples:     27000832 | elapsed time per iteration (ms): 37823.9 | learning rate: 1.133E-04 | global batch size:  1024 | lm loss: 1.840862E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26369/   51900 | consumed samples:     27001856 | elapsed time per iteration (ms): 37650.5 | learning rate: 1.133E-04 | global batch size:  1024 | lm loss: 1.843704E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26370/   51900 | consumed samples:     27002880 | elapsed time per iteration (ms): 37561.4 | learning rate: 1.133E-04 | global batch size:  1024 | lm loss: 1.848974E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26371/   51900 | consumed samples:     27003904 | elapsed time per iteration (ms): 37580.4 | learning rate: 1.133E-04 | global batch size:  1024 | lm loss: 1.848345E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26372/   51900 | consumed samples:     27004928 | elapsed time per iteration (ms): 37551.2 | learning rate: 1.133E-04 | global batch size:  1024 | lm loss: 1.859581E+00 | loss scale: 1.0 | grad norm: 0.097 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26373/   51900 | consumed samples:     27005952 | elapsed time per iteration (ms): 37654.1 | learning rate: 1.133E-04 | global batch size:  1024 | lm loss: 1.842165E+00 | loss scale: 1.0 | grad norm: 0.089 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26374/   51900 | consumed samples:     27006976 | elapsed time per iteration (ms): 37649.3 | learning rate: 1.133E-04 | global batch size:  1024 | lm loss: 1.845829E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26375/   51900 | consumed samples:     27008000 | elapsed time per iteration (ms): 37543.1 | learning rate: 1.133E-04 | global batch size:  1024 | lm loss: 1.833470E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26376/   51900 | consumed samples:     27009024 | elapsed time per iteration (ms): 37648.8 | learning rate: 1.133E-04 | global batch size:  1024 | lm loss: 1.833362E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26377/   51900 | consumed samples:     27010048 | elapsed time per iteration (ms): 37657.2 | learning rate: 1.132E-04 | global batch size:  1024 | lm loss: 1.854194E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26378/   51900 | consumed samples:     27011072 | elapsed time per iteration (ms): 37669.4 | learning rate: 1.132E-04 | global batch size:  1024 | lm loss: 1.851666E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26379/   51900 | consumed samples:     27012096 | elapsed time per iteration (ms): 37611.5 | learning rate: 1.132E-04 | global batch size:  1024 | lm loss: 1.847849E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26380/   51900 | consumed samples:     27013120 | elapsed time per iteration (ms): 37629.0 | learning rate: 1.132E-04 | global batch size:  1024 | lm loss: 1.846372E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26381/   51900 | consumed samples:     27014144 | elapsed time per iteration (ms): 37567.0 | learning rate: 1.132E-04 | global batch size:  1024 | lm loss: 1.835664E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26382/   51900 | consumed samples:     27015168 | elapsed time per iteration (ms): 37636.6 | learning rate: 1.132E-04 | global batch size:  1024 | lm loss: 1.852115E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26383/   51900 | consumed samples:     27016192 | elapsed time per iteration (ms): 37568.1 | learning rate: 1.132E-04 | global batch size:  1024 | lm loss: 1.845720E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26384/   51900 | consumed samples:     27017216 | elapsed time per iteration (ms): 37570.0 | learning rate: 1.132E-04 | global batch size:  1024 | lm loss: 1.865162E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26385/   51900 | consumed samples:     27018240 | elapsed time per iteration (ms): 37683.5 | learning rate: 1.132E-04 | global batch size:  1024 | lm loss: 1.835530E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26386/   51900 | consumed samples:     27019264 | elapsed time per iteration (ms): 37651.5 | learning rate: 1.132E-04 | global batch size:  1024 | lm loss: 1.864311E+00 | loss scale: 1.0 | grad norm: 0.091 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26387/   51900 | consumed samples:     27020288 | elapsed time per iteration (ms): 37594.7 | learning rate: 1.132E-04 | global batch size:  1024 | lm loss: 1.847126E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26388/   51900 | consumed samples:     27021312 | elapsed time per iteration (ms): 37683.2 | learning rate: 1.132E-04 | global batch size:  1024 | lm loss: 1.850278E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26389/   51900 | consumed samples:     27022336 | elapsed time per iteration (ms): 37594.9 | learning rate: 1.132E-04 | global batch size:  1024 | lm loss: 1.861193E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26390/   51900 | consumed samples:     27023360 | elapsed time per iteration (ms): 37616.2 | learning rate: 1.132E-04 | global batch size:  1024 | lm loss: 1.867083E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26391/   51900 | consumed samples:     27024384 | elapsed time per iteration (ms): 37564.7 | learning rate: 1.132E-04 | global batch size:  1024 | lm loss: 1.857245E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26392/   51900 | consumed samples:     27025408 | elapsed time per iteration (ms): 37664.4 | learning rate: 1.132E-04 | global batch size:  1024 | lm loss: 1.873492E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26393/   51900 | consumed samples:     27026432 | elapsed time per iteration (ms): 37717.0 | learning rate: 1.132E-04 | global batch size:  1024 | lm loss: 1.847951E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26394/   51900 | consumed samples:     27027456 | elapsed time per iteration (ms): 37675.5 | learning rate: 1.131E-04 | global batch size:  1024 | lm loss: 1.844572E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26395/   51900 | consumed samples:     27028480 | elapsed time per iteration (ms): 37586.4 | learning rate: 1.131E-04 | global batch size:  1024 | lm loss: 1.867135E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26396/   51900 | consumed samples:     27029504 | elapsed time per iteration (ms): 37640.2 | learning rate: 1.131E-04 | global batch size:  1024 | lm loss: 1.858003E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26397/   51900 | consumed samples:     27030528 | elapsed time per iteration (ms): 37593.5 | learning rate: 1.131E-04 | global batch size:  1024 | lm loss: 1.835129E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26398/   51900 | consumed samples:     27031552 | elapsed time per iteration (ms): 37616.0 | learning rate: 1.131E-04 | global batch size:  1024 | lm loss: 1.832528E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26399/   51900 | consumed samples:     27032576 | elapsed time per iteration (ms): 37556.7 | learning rate: 1.131E-04 | global batch size:  1024 | lm loss: 1.866312E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26400/   51900 | consumed samples:     27033600 | elapsed time per iteration (ms): 37646.9 | learning rate: 1.131E-04 | global batch size:  1024 | lm loss: 1.844663E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26401/   51900 | consumed samples:     27034624 | elapsed time per iteration (ms): 37787.4 | learning rate: 1.131E-04 | global batch size:  1024 | lm loss: 1.873000E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26402/   51900 | consumed samples:     27035648 | elapsed time per iteration (ms): 37685.3 | learning rate: 1.131E-04 | global batch size:  1024 | lm loss: 1.861595E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26403/   51900 | consumed samples:     27036672 | elapsed time per iteration (ms): 37558.8 | learning rate: 1.131E-04 | global batch size:  1024 | lm loss: 1.860421E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26404/   51900 | consumed samples:     27037696 | elapsed time per iteration (ms): 37735.5 | learning rate: 1.131E-04 | global batch size:  1024 | lm loss: 1.860149E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26405/   51900 | consumed samples:     27038720 | elapsed time per iteration (ms): 37687.8 | learning rate: 1.131E-04 | global batch size:  1024 | lm loss: 1.852107E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26406/   51900 | consumed samples:     27039744 | elapsed time per iteration (ms): 37623.1 | learning rate: 1.131E-04 | global batch size:  1024 | lm loss: 1.851740E+00 | loss scale: 1.0 | grad norm: 0.090 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26407/   51900 | consumed samples:     27040768 | elapsed time per iteration (ms): 37629.1 | learning rate: 1.131E-04 | global batch size:  1024 | lm loss: 1.832205E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26408/   51900 | consumed samples:     27041792 | elapsed time per iteration (ms): 37648.2 | learning rate: 1.131E-04 | global batch size:  1024 | lm loss: 1.848888E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26409/   51900 | consumed samples:     27042816 | elapsed time per iteration (ms): 37680.2 | learning rate: 1.131E-04 | global batch size:  1024 | lm loss: 1.860726E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26410/   51900 | consumed samples:     27043840 | elapsed time per iteration (ms): 37706.3 | learning rate: 1.131E-04 | global batch size:  1024 | lm loss: 1.850921E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26411/   51900 | consumed samples:     27044864 | elapsed time per iteration (ms): 37637.0 | learning rate: 1.131E-04 | global batch size:  1024 | lm loss: 1.857107E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26412/   51900 | consumed samples:     27045888 | elapsed time per iteration (ms): 37696.1 | learning rate: 1.130E-04 | global batch size:  1024 | lm loss: 1.839223E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26413/   51900 | consumed samples:     27046912 | elapsed time per iteration (ms): 37608.2 | learning rate: 1.130E-04 | global batch size:  1024 | lm loss: 1.850382E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26414/   51900 | consumed samples:     27047936 | elapsed time per iteration (ms): 37624.8 | learning rate: 1.130E-04 | global batch size:  1024 | lm loss: 1.885774E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26415/   51900 | consumed samples:     27048960 | elapsed time per iteration (ms): 37598.3 | learning rate: 1.130E-04 | global batch size:  1024 | lm loss: 1.848698E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26416/   51900 | consumed samples:     27049984 | elapsed time per iteration (ms): 37562.6 | learning rate: 1.130E-04 | global batch size:  1024 | lm loss: 1.860716E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26417/   51900 | consumed samples:     27051008 | elapsed time per iteration (ms): 37618.9 | learning rate: 1.130E-04 | global batch size:  1024 | lm loss: 1.845635E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26418/   51900 | consumed samples:     27052032 | elapsed time per iteration (ms): 37537.3 | learning rate: 1.130E-04 | global batch size:  1024 | lm loss: 1.842150E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26419/   51900 | consumed samples:     27053056 | elapsed time per iteration (ms): 37664.3 | learning rate: 1.130E-04 | global batch size:  1024 | lm loss: 1.835752E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26420/   51900 | consumed samples:     27054080 | elapsed time per iteration (ms): 37610.2 | learning rate: 1.130E-04 | global batch size:  1024 | lm loss: 1.857898E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26421/   51900 | consumed samples:     27055104 | elapsed time per iteration (ms): 37648.4 | learning rate: 1.130E-04 | global batch size:  1024 | lm loss: 1.845716E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26422/   51900 | consumed samples:     27056128 | elapsed time per iteration (ms): 37658.3 | learning rate: 1.130E-04 | global batch size:  1024 | lm loss: 1.847399E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26423/   51900 | consumed samples:     27057152 | elapsed time per iteration (ms): 37704.6 | learning rate: 1.130E-04 | global batch size:  1024 | lm loss: 1.857404E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26424/   51900 | consumed samples:     27058176 | elapsed time per iteration (ms): 37700.2 | learning rate: 1.130E-04 | global batch size:  1024 | lm loss: 1.843778E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26425/   51900 | consumed samples:     27059200 | elapsed time per iteration (ms): 37638.4 | learning rate: 1.130E-04 | global batch size:  1024 | lm loss: 1.881956E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26426/   51900 | consumed samples:     27060224 | elapsed time per iteration (ms): 37750.2 | learning rate: 1.130E-04 | global batch size:  1024 | lm loss: 1.844946E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26427/   51900 | consumed samples:     27061248 | elapsed time per iteration (ms): 37675.6 | learning rate: 1.130E-04 | global batch size:  1024 | lm loss: 1.852347E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26428/   51900 | consumed samples:     27062272 | elapsed time per iteration (ms): 37666.1 | learning rate: 1.130E-04 | global batch size:  1024 | lm loss: 1.852333E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26429/   51900 | consumed samples:     27063296 | elapsed time per iteration (ms): 37751.7 | learning rate: 1.130E-04 | global batch size:  1024 | lm loss: 1.848275E+00 | loss scale: 1.0 | grad norm: 0.090 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26430/   51900 | consumed samples:     27064320 | elapsed time per iteration (ms): 37617.6 | learning rate: 1.129E-04 | global batch size:  1024 | lm loss: 1.848467E+00 | loss scale: 1.0 | grad norm: 0.100 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26431/   51900 | consumed samples:     27065344 | elapsed time per iteration (ms): 37800.6 | learning rate: 1.129E-04 | global batch size:  1024 | lm loss: 1.848771E+00 | loss scale: 1.0 | grad norm: 0.089 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26432/   51900 | consumed samples:     27066368 | elapsed time per iteration (ms): 37700.3 | learning rate: 1.129E-04 | global batch size:  1024 | lm loss: 1.852154E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26433/   51900 | consumed samples:     27067392 | elapsed time per iteration (ms): 37659.3 | learning rate: 1.129E-04 | global batch size:  1024 | lm loss: 1.846673E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26434/   51900 | consumed samples:     27068416 | elapsed time per iteration (ms): 37648.9 | learning rate: 1.129E-04 | global batch size:  1024 | lm loss: 1.844476E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26435/   51900 | consumed samples:     27069440 | elapsed time per iteration (ms): 37685.3 | learning rate: 1.129E-04 | global batch size:  1024 | lm loss: 1.840047E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26436/   51900 | consumed samples:     27070464 | elapsed time per iteration (ms): 37692.0 | learning rate: 1.129E-04 | global batch size:  1024 | lm loss: 1.849462E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26437/   51900 | consumed samples:     27071488 | elapsed time per iteration (ms): 37543.7 | learning rate: 1.129E-04 | global batch size:  1024 | lm loss: 1.853713E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26438/   51900 | consumed samples:     27072512 | elapsed time per iteration (ms): 37681.4 | learning rate: 1.129E-04 | global batch size:  1024 | lm loss: 1.853051E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26439/   51900 | consumed samples:     27073536 | elapsed time per iteration (ms): 37633.1 | learning rate: 1.129E-04 | global batch size:  1024 | lm loss: 1.858446E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26440/   51900 | consumed samples:     27074560 | elapsed time per iteration (ms): 37744.7 | learning rate: 1.129E-04 | global batch size:  1024 | lm loss: 1.862138E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26441/   51900 | consumed samples:     27075584 | elapsed time per iteration (ms): 37581.9 | learning rate: 1.129E-04 | global batch size:  1024 | lm loss: 1.858496E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26442/   51900 | consumed samples:     27076608 | elapsed time per iteration (ms): 37662.8 | learning rate: 1.129E-04 | global batch size:  1024 | lm loss: 1.858552E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26443/   51900 | consumed samples:     27077632 | elapsed time per iteration (ms): 37651.0 | learning rate: 1.129E-04 | global batch size:  1024 | lm loss: 1.849037E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26444/   51900 | consumed samples:     27078656 | elapsed time per iteration (ms): 37748.9 | learning rate: 1.129E-04 | global batch size:  1024 | lm loss: 1.855495E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26445/   51900 | consumed samples:     27079680 | elapsed time per iteration (ms): 37690.4 | learning rate: 1.129E-04 | global batch size:  1024 | lm loss: 1.860883E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26446/   51900 | consumed samples:     27080704 | elapsed time per iteration (ms): 37739.4 | learning rate: 1.129E-04 | global batch size:  1024 | lm loss: 1.845228E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26447/   51900 | consumed samples:     27081728 | elapsed time per iteration (ms): 37691.7 | learning rate: 1.128E-04 | global batch size:  1024 | lm loss: 1.829088E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26448/   51900 | consumed samples:     27082752 | elapsed time per iteration (ms): 37706.7 | learning rate: 1.128E-04 | global batch size:  1024 | lm loss: 1.849836E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26449/   51900 | consumed samples:     27083776 | elapsed time per iteration (ms): 37667.9 | learning rate: 1.128E-04 | global batch size:  1024 | lm loss: 1.875288E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26450/   51900 | consumed samples:     27084800 | elapsed time per iteration (ms): 37669.9 | learning rate: 1.128E-04 | global batch size:  1024 | lm loss: 1.841792E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26451/   51900 | consumed samples:     27085824 | elapsed time per iteration (ms): 37691.4 | learning rate: 1.128E-04 | global batch size:  1024 | lm loss: 1.848633E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26452/   51900 | consumed samples:     27086848 | elapsed time per iteration (ms): 37573.7 | learning rate: 1.128E-04 | global batch size:  1024 | lm loss: 1.867238E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26453/   51900 | consumed samples:     27087872 | elapsed time per iteration (ms): 37712.1 | learning rate: 1.128E-04 | global batch size:  1024 | lm loss: 1.851991E+00 | loss scale: 1.0 | grad norm: 0.087 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26454/   51900 | consumed samples:     27088896 | elapsed time per iteration (ms): 37607.4 | learning rate: 1.128E-04 | global batch size:  1024 | lm loss: 1.855252E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26455/   51900 | consumed samples:     27089920 | elapsed time per iteration (ms): 37687.6 | learning rate: 1.128E-04 | global batch size:  1024 | lm loss: 1.871681E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26456/   51900 | consumed samples:     27090944 | elapsed time per iteration (ms): 37711.6 | learning rate: 1.128E-04 | global batch size:  1024 | lm loss: 1.846547E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26457/   51900 | consumed samples:     27091968 | elapsed time per iteration (ms): 37622.2 | learning rate: 1.128E-04 | global batch size:  1024 | lm loss: 1.841686E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26458/   51900 | consumed samples:     27092992 | elapsed time per iteration (ms): 37628.1 | learning rate: 1.128E-04 | global batch size:  1024 | lm loss: 1.853226E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26459/   51900 | consumed samples:     27094016 | elapsed time per iteration (ms): 37707.6 | learning rate: 1.128E-04 | global batch size:  1024 | lm loss: 1.871926E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26460/   51900 | consumed samples:     27095040 | elapsed time per iteration (ms): 37755.7 | learning rate: 1.128E-04 | global batch size:  1024 | lm loss: 1.854058E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26461/   51900 | consumed samples:     27096064 | elapsed time per iteration (ms): 37572.2 | learning rate: 1.128E-04 | global batch size:  1024 | lm loss: 1.860401E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26462/   51900 | consumed samples:     27097088 | elapsed time per iteration (ms): 37590.4 | learning rate: 1.128E-04 | global batch size:  1024 | lm loss: 1.848627E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26463/   51900 | consumed samples:     27098112 | elapsed time per iteration (ms): 37651.2 | learning rate: 1.128E-04 | global batch size:  1024 | lm loss: 1.864592E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26464/   51900 | consumed samples:     27099136 | elapsed time per iteration (ms): 37597.2 | learning rate: 1.128E-04 | global batch size:  1024 | lm loss: 1.847629E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26465/   51900 | consumed samples:     27100160 | elapsed time per iteration (ms): 37522.7 | learning rate: 1.127E-04 | global batch size:  1024 | lm loss: 1.824844E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26466/   51900 | consumed samples:     27101184 | elapsed time per iteration (ms): 37686.4 | learning rate: 1.127E-04 | global batch size:  1024 | lm loss: 1.853876E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26467/   51900 | consumed samples:     27102208 | elapsed time per iteration (ms): 37589.1 | learning rate: 1.127E-04 | global batch size:  1024 | lm loss: 1.852003E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26468/   51900 | consumed samples:     27103232 | elapsed time per iteration (ms): 37739.7 | learning rate: 1.127E-04 | global batch size:  1024 | lm loss: 1.838025E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26469/   51900 | consumed samples:     27104256 | elapsed time per iteration (ms): 37640.3 | learning rate: 1.127E-04 | global batch size:  1024 | lm loss: 1.871737E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26470/   51900 | consumed samples:     27105280 | elapsed time per iteration (ms): 37600.9 | learning rate: 1.127E-04 | global batch size:  1024 | lm loss: 1.871761E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26471/   51900 | consumed samples:     27106304 | elapsed time per iteration (ms): 37602.1 | learning rate: 1.127E-04 | global batch size:  1024 | lm loss: 1.859448E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26472/   51900 | consumed samples:     27107328 | elapsed time per iteration (ms): 37655.1 | learning rate: 1.127E-04 | global batch size:  1024 | lm loss: 1.840976E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26473/   51900 | consumed samples:     27108352 | elapsed time per iteration (ms): 37612.8 | learning rate: 1.127E-04 | global batch size:  1024 | lm loss: 1.847627E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26474/   51900 | consumed samples:     27109376 | elapsed time per iteration (ms): 37606.0 | learning rate: 1.127E-04 | global batch size:  1024 | lm loss: 1.837068E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26475/   51900 | consumed samples:     27110400 | elapsed time per iteration (ms): 37675.1 | learning rate: 1.127E-04 | global batch size:  1024 | lm loss: 1.854262E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26476/   51900 | consumed samples:     27111424 | elapsed time per iteration (ms): 37604.6 | learning rate: 1.127E-04 | global batch size:  1024 | lm loss: 1.849013E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26477/   51900 | consumed samples:     27112448 | elapsed time per iteration (ms): 37665.2 | learning rate: 1.127E-04 | global batch size:  1024 | lm loss: 1.852279E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26478/   51900 | consumed samples:     27113472 | elapsed time per iteration (ms): 37587.3 | learning rate: 1.127E-04 | global batch size:  1024 | lm loss: 1.852429E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26479/   51900 | consumed samples:     27114496 | elapsed time per iteration (ms): 37772.4 | learning rate: 1.127E-04 | global batch size:  1024 | lm loss: 1.856177E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26480/   51900 | consumed samples:     27115520 | elapsed time per iteration (ms): 37637.0 | learning rate: 1.127E-04 | global batch size:  1024 | lm loss: 1.858146E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26481/   51900 | consumed samples:     27116544 | elapsed time per iteration (ms): 37613.6 | learning rate: 1.127E-04 | global batch size:  1024 | lm loss: 1.856250E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26482/   51900 | consumed samples:     27117568 | elapsed time per iteration (ms): 37605.7 | learning rate: 1.127E-04 | global batch size:  1024 | lm loss: 1.846976E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26483/   51900 | consumed samples:     27118592 | elapsed time per iteration (ms): 37631.0 | learning rate: 1.126E-04 | global batch size:  1024 | lm loss: 1.873732E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26484/   51900 | consumed samples:     27119616 | elapsed time per iteration (ms): 37756.4 | learning rate: 1.126E-04 | global batch size:  1024 | lm loss: 1.854304E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26485/   51900 | consumed samples:     27120640 | elapsed time per iteration (ms): 37693.1 | learning rate: 1.126E-04 | global batch size:  1024 | lm loss: 1.856424E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26486/   51900 | consumed samples:     27121664 | elapsed time per iteration (ms): 37636.5 | learning rate: 1.126E-04 | global batch size:  1024 | lm loss: 1.858760E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26487/   51900 | consumed samples:     27122688 | elapsed time per iteration (ms): 37623.5 | learning rate: 1.126E-04 | global batch size:  1024 | lm loss: 1.835559E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26488/   51900 | consumed samples:     27123712 | elapsed time per iteration (ms): 37649.1 | learning rate: 1.126E-04 | global batch size:  1024 | lm loss: 1.848379E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26489/   51900 | consumed samples:     27124736 | elapsed time per iteration (ms): 37642.7 | learning rate: 1.126E-04 | global batch size:  1024 | lm loss: 1.845081E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26490/   51900 | consumed samples:     27125760 | elapsed time per iteration (ms): 37750.5 | learning rate: 1.126E-04 | global batch size:  1024 | lm loss: 1.865065E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26491/   51900 | consumed samples:     27126784 | elapsed time per iteration (ms): 37632.3 | learning rate: 1.126E-04 | global batch size:  1024 | lm loss: 1.847061E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26492/   51900 | consumed samples:     27127808 | elapsed time per iteration (ms): 37694.7 | learning rate: 1.126E-04 | global batch size:  1024 | lm loss: 1.854265E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26493/   51900 | consumed samples:     27128832 | elapsed time per iteration (ms): 37604.0 | learning rate: 1.126E-04 | global batch size:  1024 | lm loss: 1.840258E+00 | loss scale: 1.0 | grad norm: 0.101 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26494/   51900 | consumed samples:     27129856 | elapsed time per iteration (ms): 37703.4 | learning rate: 1.126E-04 | global batch size:  1024 | lm loss: 1.840499E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26495/   51900 | consumed samples:     27130880 | elapsed time per iteration (ms): 37695.6 | learning rate: 1.126E-04 | global batch size:  1024 | lm loss: 1.847082E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26496/   51900 | consumed samples:     27131904 | elapsed time per iteration (ms): 37577.9 | learning rate: 1.126E-04 | global batch size:  1024 | lm loss: 1.855014E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26497/   51900 | consumed samples:     27132928 | elapsed time per iteration (ms): 37592.1 | learning rate: 1.126E-04 | global batch size:  1024 | lm loss: 1.850728E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26498/   51900 | consumed samples:     27133952 | elapsed time per iteration (ms): 37644.4 | learning rate: 1.126E-04 | global batch size:  1024 | lm loss: 1.848960E+00 | loss scale: 1.0 | grad norm: 0.089 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26499/   51900 | consumed samples:     27134976 | elapsed time per iteration (ms): 37560.6 | learning rate: 1.126E-04 | global batch size:  1024 | lm loss: 1.864021E+00 | loss scale: 1.0 | grad norm: 0.090 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26500/   51900 | consumed samples:     27136000 | elapsed time per iteration (ms): 37739.3 | learning rate: 1.125E-04 | global batch size:  1024 | lm loss: 1.862124E+00 | loss scale: 1.0 | grad norm: 0.089 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    save-checkpoint ................................: (173361.30, 173361.37)
 iteration    26501/   51900 | consumed samples:     27137024 | elapsed time per iteration (ms): 37331.8 | learning rate: 1.125E-04 | global batch size:  1024 | lm loss: 1.855406E+00 | loss scale: 1.0 | grad norm: 0.093 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26502/   51900 | consumed samples:     27138048 | elapsed time per iteration (ms): 37708.7 | learning rate: 1.125E-04 | global batch size:  1024 | lm loss: 1.847348E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26503/   51900 | consumed samples:     27139072 | elapsed time per iteration (ms): 37648.5 | learning rate: 1.125E-04 | global batch size:  1024 | lm loss: 1.852980E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26504/   51900 | consumed samples:     27140096 | elapsed time per iteration (ms): 37577.7 | learning rate: 1.125E-04 | global batch size:  1024 | lm loss: 1.856031E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26505/   51900 | consumed samples:     27141120 | elapsed time per iteration (ms): 37705.7 | learning rate: 1.125E-04 | global batch size:  1024 | lm loss: 1.844980E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26506/   51900 | consumed samples:     27142144 | elapsed time per iteration (ms): 37712.4 | learning rate: 1.125E-04 | global batch size:  1024 | lm loss: 1.860726E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26507/   51900 | consumed samples:     27143168 | elapsed time per iteration (ms): 37647.4 | learning rate: 1.125E-04 | global batch size:  1024 | lm loss: 1.856454E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26508/   51900 | consumed samples:     27144192 | elapsed time per iteration (ms): 37681.8 | learning rate: 1.125E-04 | global batch size:  1024 | lm loss: 1.851079E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26509/   51900 | consumed samples:     27145216 | elapsed time per iteration (ms): 37589.4 | learning rate: 1.125E-04 | global batch size:  1024 | lm loss: 1.848227E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26510/   51900 | consumed samples:     27146240 | elapsed time per iteration (ms): 37572.5 | learning rate: 1.125E-04 | global batch size:  1024 | lm loss: 1.844004E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26511/   51900 | consumed samples:     27147264 | elapsed time per iteration (ms): 37744.8 | learning rate: 1.125E-04 | global batch size:  1024 | lm loss: 1.861064E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26512/   51900 | consumed samples:     27148288 | elapsed time per iteration (ms): 37754.7 | learning rate: 1.125E-04 | global batch size:  1024 | lm loss: 1.838221E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26513/   51900 | consumed samples:     27149312 | elapsed time per iteration (ms): 37631.4 | learning rate: 1.125E-04 | global batch size:  1024 | lm loss: 1.866312E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26514/   51900 | consumed samples:     27150336 | elapsed time per iteration (ms): 37623.0 | learning rate: 1.125E-04 | global batch size:  1024 | lm loss: 1.870859E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26515/   51900 | consumed samples:     27151360 | elapsed time per iteration (ms): 37654.7 | learning rate: 1.125E-04 | global batch size:  1024 | lm loss: 1.852170E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26516/   51900 | consumed samples:     27152384 | elapsed time per iteration (ms): 37552.7 | learning rate: 1.125E-04 | global batch size:  1024 | lm loss: 1.851790E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26517/   51900 | consumed samples:     27153408 | elapsed time per iteration (ms): 37595.1 | learning rate: 1.125E-04 | global batch size:  1024 | lm loss: 1.860256E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26518/   51900 | consumed samples:     27154432 | elapsed time per iteration (ms): 37721.5 | learning rate: 1.124E-04 | global batch size:  1024 | lm loss: 1.845202E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26519/   51900 | consumed samples:     27155456 | elapsed time per iteration (ms): 37606.8 | learning rate: 1.124E-04 | global batch size:  1024 | lm loss: 1.849483E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26520/   51900 | consumed samples:     27156480 | elapsed time per iteration (ms): 37576.5 | learning rate: 1.124E-04 | global batch size:  1024 | lm loss: 1.834375E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26521/   51900 | consumed samples:     27157504 | elapsed time per iteration (ms): 37621.8 | learning rate: 1.124E-04 | global batch size:  1024 | lm loss: 1.861585E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26522/   51900 | consumed samples:     27158528 | elapsed time per iteration (ms): 37681.3 | learning rate: 1.124E-04 | global batch size:  1024 | lm loss: 1.842932E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26523/   51900 | consumed samples:     27159552 | elapsed time per iteration (ms): 37648.2 | learning rate: 1.124E-04 | global batch size:  1024 | lm loss: 1.848091E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26524/   51900 | consumed samples:     27160576 | elapsed time per iteration (ms): 37708.0 | learning rate: 1.124E-04 | global batch size:  1024 | lm loss: 1.862609E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26525/   51900 | consumed samples:     27161600 | elapsed time per iteration (ms): 37641.4 | learning rate: 1.124E-04 | global batch size:  1024 | lm loss: 1.851111E+00 | loss scale: 1.0 | grad norm: 0.088 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26526/   51900 | consumed samples:     27162624 | elapsed time per iteration (ms): 37609.1 | learning rate: 1.124E-04 | global batch size:  1024 | lm loss: 1.846433E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26527/   51900 | consumed samples:     27163648 | elapsed time per iteration (ms): 37670.7 | learning rate: 1.124E-04 | global batch size:  1024 | lm loss: 1.834788E+00 | loss scale: 1.0 | grad norm: 0.065 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26528/   51900 | consumed samples:     27164672 | elapsed time per iteration (ms): 37671.4 | learning rate: 1.124E-04 | global batch size:  1024 | lm loss: 1.850813E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26529/   51900 | consumed samples:     27165696 | elapsed time per iteration (ms): 37645.8 | learning rate: 1.124E-04 | global batch size:  1024 | lm loss: 1.853662E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26530/   51900 | consumed samples:     27166720 | elapsed time per iteration (ms): 37583.4 | learning rate: 1.124E-04 | global batch size:  1024 | lm loss: 1.847304E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26531/   51900 | consumed samples:     27167744 | elapsed time per iteration (ms): 37789.6 | learning rate: 1.124E-04 | global batch size:  1024 | lm loss: 1.846923E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26532/   51900 | consumed samples:     27168768 | elapsed time per iteration (ms): 37626.2 | learning rate: 1.124E-04 | global batch size:  1024 | lm loss: 1.830320E+00 | loss scale: 1.0 | grad norm: 0.095 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26533/   51900 | consumed samples:     27169792 | elapsed time per iteration (ms): 37631.5 | learning rate: 1.124E-04 | global batch size:  1024 | lm loss: 1.845899E+00 | loss scale: 1.0 | grad norm: 0.100 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26534/   51900 | consumed samples:     27170816 | elapsed time per iteration (ms): 37744.4 | learning rate: 1.124E-04 | global batch size:  1024 | lm loss: 1.859654E+00 | loss scale: 1.0 | grad norm: 0.091 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26535/   51900 | consumed samples:     27171840 | elapsed time per iteration (ms): 37568.9 | learning rate: 1.124E-04 | global batch size:  1024 | lm loss: 1.848017E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26536/   51900 | consumed samples:     27172864 | elapsed time per iteration (ms): 37647.9 | learning rate: 1.123E-04 | global batch size:  1024 | lm loss: 1.853651E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26537/   51900 | consumed samples:     27173888 | elapsed time per iteration (ms): 37691.3 | learning rate: 1.123E-04 | global batch size:  1024 | lm loss: 1.850658E+00 | loss scale: 1.0 | grad norm: 0.092 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26538/   51900 | consumed samples:     27174912 | elapsed time per iteration (ms): 37643.9 | learning rate: 1.123E-04 | global batch size:  1024 | lm loss: 1.847906E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26539/   51900 | consumed samples:     27175936 | elapsed time per iteration (ms): 37617.4 | learning rate: 1.123E-04 | global batch size:  1024 | lm loss: 1.843814E+00 | loss scale: 1.0 | grad norm: 0.087 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26540/   51900 | consumed samples:     27176960 | elapsed time per iteration (ms): 37610.3 | learning rate: 1.123E-04 | global batch size:  1024 | lm loss: 1.857374E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26541/   51900 | consumed samples:     27177984 | elapsed time per iteration (ms): 37568.9 | learning rate: 1.123E-04 | global batch size:  1024 | lm loss: 1.837239E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26542/   51900 | consumed samples:     27179008 | elapsed time per iteration (ms): 37515.6 | learning rate: 1.123E-04 | global batch size:  1024 | lm loss: 1.833774E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26543/   51900 | consumed samples:     27180032 | elapsed time per iteration (ms): 37597.8 | learning rate: 1.123E-04 | global batch size:  1024 | lm loss: 1.860069E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26544/   51900 | consumed samples:     27181056 | elapsed time per iteration (ms): 37637.8 | learning rate: 1.123E-04 | global batch size:  1024 | lm loss: 1.851370E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26545/   51900 | consumed samples:     27182080 | elapsed time per iteration (ms): 37691.0 | learning rate: 1.123E-04 | global batch size:  1024 | lm loss: 1.865545E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26546/   51900 | consumed samples:     27183104 | elapsed time per iteration (ms): 37604.3 | learning rate: 1.123E-04 | global batch size:  1024 | lm loss: 1.843120E+00 | loss scale: 1.0 | grad norm: 0.108 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26547/   51900 | consumed samples:     27184128 | elapsed time per iteration (ms): 37721.6 | learning rate: 1.123E-04 | global batch size:  1024 | lm loss: 1.852090E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26548/   51900 | consumed samples:     27185152 | elapsed time per iteration (ms): 37743.2 | learning rate: 1.123E-04 | global batch size:  1024 | lm loss: 1.850877E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26549/   51900 | consumed samples:     27186176 | elapsed time per iteration (ms): 37611.2 | learning rate: 1.123E-04 | global batch size:  1024 | lm loss: 1.843254E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26550/   51900 | consumed samples:     27187200 | elapsed time per iteration (ms): 37678.3 | learning rate: 1.123E-04 | global batch size:  1024 | lm loss: 1.826143E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26551/   51900 | consumed samples:     27188224 | elapsed time per iteration (ms): 37652.2 | learning rate: 1.123E-04 | global batch size:  1024 | lm loss: 1.830653E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26552/   51900 | consumed samples:     27189248 | elapsed time per iteration (ms): 37585.2 | learning rate: 1.123E-04 | global batch size:  1024 | lm loss: 1.845969E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26553/   51900 | consumed samples:     27190272 | elapsed time per iteration (ms): 37668.9 | learning rate: 1.122E-04 | global batch size:  1024 | lm loss: 1.856109E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26554/   51900 | consumed samples:     27191296 | elapsed time per iteration (ms): 37646.0 | learning rate: 1.122E-04 | global batch size:  1024 | lm loss: 1.856088E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26555/   51900 | consumed samples:     27192320 | elapsed time per iteration (ms): 37662.8 | learning rate: 1.122E-04 | global batch size:  1024 | lm loss: 1.852901E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26556/   51900 | consumed samples:     27193344 | elapsed time per iteration (ms): 37565.0 | learning rate: 1.122E-04 | global batch size:  1024 | lm loss: 1.854470E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26557/   51900 | consumed samples:     27194368 | elapsed time per iteration (ms): 37792.0 | learning rate: 1.122E-04 | global batch size:  1024 | lm loss: 1.849168E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26558/   51900 | consumed samples:     27195392 | elapsed time per iteration (ms): 37566.4 | learning rate: 1.122E-04 | global batch size:  1024 | lm loss: 1.841596E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26559/   51900 | consumed samples:     27196416 | elapsed time per iteration (ms): 37567.0 | learning rate: 1.122E-04 | global batch size:  1024 | lm loss: 1.863613E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26560/   51900 | consumed samples:     27197440 | elapsed time per iteration (ms): 37706.6 | learning rate: 1.122E-04 | global batch size:  1024 | lm loss: 1.850679E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26561/   51900 | consumed samples:     27198464 | elapsed time per iteration (ms): 37720.7 | learning rate: 1.122E-04 | global batch size:  1024 | lm loss: 1.858737E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26562/   51900 | consumed samples:     27199488 | elapsed time per iteration (ms): 37582.3 | learning rate: 1.122E-04 | global batch size:  1024 | lm loss: 1.875616E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26563/   51900 | consumed samples:     27200512 | elapsed time per iteration (ms): 37692.6 | learning rate: 1.122E-04 | global batch size:  1024 | lm loss: 1.862950E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26564/   51900 | consumed samples:     27201536 | elapsed time per iteration (ms): 37599.2 | learning rate: 1.122E-04 | global batch size:  1024 | lm loss: 1.833975E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26565/   51900 | consumed samples:     27202560 | elapsed time per iteration (ms): 37628.4 | learning rate: 1.122E-04 | global batch size:  1024 | lm loss: 1.850497E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26566/   51900 | consumed samples:     27203584 | elapsed time per iteration (ms): 37658.4 | learning rate: 1.122E-04 | global batch size:  1024 | lm loss: 1.855897E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26567/   51900 | consumed samples:     27204608 | elapsed time per iteration (ms): 37657.4 | learning rate: 1.122E-04 | global batch size:  1024 | lm loss: 1.848699E+00 | loss scale: 1.0 | grad norm: 0.175 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26568/   51900 | consumed samples:     27205632 | elapsed time per iteration (ms): 37649.0 | learning rate: 1.122E-04 | global batch size:  1024 | lm loss: 1.837861E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26569/   51900 | consumed samples:     27206656 | elapsed time per iteration (ms): 37593.3 | learning rate: 1.122E-04 | global batch size:  1024 | lm loss: 1.863743E+00 | loss scale: 1.0 | grad norm: 0.091 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26570/   51900 | consumed samples:     27207680 | elapsed time per iteration (ms): 37689.0 | learning rate: 1.122E-04 | global batch size:  1024 | lm loss: 1.858648E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26571/   51900 | consumed samples:     27208704 | elapsed time per iteration (ms): 37623.9 | learning rate: 1.121E-04 | global batch size:  1024 | lm loss: 1.856472E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26572/   51900 | consumed samples:     27209728 | elapsed time per iteration (ms): 37606.4 | learning rate: 1.121E-04 | global batch size:  1024 | lm loss: 1.836479E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26573/   51900 | consumed samples:     27210752 | elapsed time per iteration (ms): 37733.8 | learning rate: 1.121E-04 | global batch size:  1024 | lm loss: 1.858019E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26574/   51900 | consumed samples:     27211776 | elapsed time per iteration (ms): 37718.0 | learning rate: 1.121E-04 | global batch size:  1024 | lm loss: 1.848916E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26575/   51900 | consumed samples:     27212800 | elapsed time per iteration (ms): 37598.2 | learning rate: 1.121E-04 | global batch size:  1024 | lm loss: 1.841069E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26576/   51900 | consumed samples:     27213824 | elapsed time per iteration (ms): 37641.4 | learning rate: 1.121E-04 | global batch size:  1024 | lm loss: 1.839894E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26577/   51900 | consumed samples:     27214848 | elapsed time per iteration (ms): 37665.1 | learning rate: 1.121E-04 | global batch size:  1024 | lm loss: 1.855193E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26578/   51900 | consumed samples:     27215872 | elapsed time per iteration (ms): 37613.9 | learning rate: 1.121E-04 | global batch size:  1024 | lm loss: 1.848461E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26579/   51900 | consumed samples:     27216896 | elapsed time per iteration (ms): 37596.7 | learning rate: 1.121E-04 | global batch size:  1024 | lm loss: 1.861859E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26580/   51900 | consumed samples:     27217920 | elapsed time per iteration (ms): 37628.4 | learning rate: 1.121E-04 | global batch size:  1024 | lm loss: 1.829977E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26581/   51900 | consumed samples:     27218944 | elapsed time per iteration (ms): 37672.8 | learning rate: 1.121E-04 | global batch size:  1024 | lm loss: 1.846562E+00 | loss scale: 1.0 | grad norm: 0.090 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26582/   51900 | consumed samples:     27219968 | elapsed time per iteration (ms): 37702.7 | learning rate: 1.121E-04 | global batch size:  1024 | lm loss: 1.843719E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26583/   51900 | consumed samples:     27220992 | elapsed time per iteration (ms): 37644.3 | learning rate: 1.121E-04 | global batch size:  1024 | lm loss: 1.853582E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26584/   51900 | consumed samples:     27222016 | elapsed time per iteration (ms): 37646.3 | learning rate: 1.121E-04 | global batch size:  1024 | lm loss: 1.844437E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26585/   51900 | consumed samples:     27223040 | elapsed time per iteration (ms): 37615.8 | learning rate: 1.121E-04 | global batch size:  1024 | lm loss: 1.847608E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26586/   51900 | consumed samples:     27224064 | elapsed time per iteration (ms): 37597.6 | learning rate: 1.121E-04 | global batch size:  1024 | lm loss: 1.831288E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26587/   51900 | consumed samples:     27225088 | elapsed time per iteration (ms): 37709.2 | learning rate: 1.121E-04 | global batch size:  1024 | lm loss: 1.843504E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26588/   51900 | consumed samples:     27226112 | elapsed time per iteration (ms): 37536.4 | learning rate: 1.121E-04 | global batch size:  1024 | lm loss: 1.842792E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26589/   51900 | consumed samples:     27227136 | elapsed time per iteration (ms): 37601.4 | learning rate: 1.120E-04 | global batch size:  1024 | lm loss: 1.851359E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26590/   51900 | consumed samples:     27228160 | elapsed time per iteration (ms): 37651.6 | learning rate: 1.120E-04 | global batch size:  1024 | lm loss: 1.842142E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26591/   51900 | consumed samples:     27229184 | elapsed time per iteration (ms): 37729.1 | learning rate: 1.120E-04 | global batch size:  1024 | lm loss: 1.858205E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26592/   51900 | consumed samples:     27230208 | elapsed time per iteration (ms): 37704.3 | learning rate: 1.120E-04 | global batch size:  1024 | lm loss: 1.851789E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26593/   51900 | consumed samples:     27231232 | elapsed time per iteration (ms): 37660.1 | learning rate: 1.120E-04 | global batch size:  1024 | lm loss: 1.842041E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26594/   51900 | consumed samples:     27232256 | elapsed time per iteration (ms): 37656.3 | learning rate: 1.120E-04 | global batch size:  1024 | lm loss: 1.842685E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26595/   51900 | consumed samples:     27233280 | elapsed time per iteration (ms): 37564.3 | learning rate: 1.120E-04 | global batch size:  1024 | lm loss: 1.858635E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26596/   51900 | consumed samples:     27234304 | elapsed time per iteration (ms): 37711.5 | learning rate: 1.120E-04 | global batch size:  1024 | lm loss: 1.854514E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26597/   51900 | consumed samples:     27235328 | elapsed time per iteration (ms): 37599.3 | learning rate: 1.120E-04 | global batch size:  1024 | lm loss: 1.841251E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26598/   51900 | consumed samples:     27236352 | elapsed time per iteration (ms): 37507.1 | learning rate: 1.120E-04 | global batch size:  1024 | lm loss: 1.861457E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26599/   51900 | consumed samples:     27237376 | elapsed time per iteration (ms): 37744.3 | learning rate: 1.120E-04 | global batch size:  1024 | lm loss: 1.860730E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26600/   51900 | consumed samples:     27238400 | elapsed time per iteration (ms): 37691.1 | learning rate: 1.120E-04 | global batch size:  1024 | lm loss: 1.844216E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26601/   51900 | consumed samples:     27239424 | elapsed time per iteration (ms): 37650.9 | learning rate: 1.120E-04 | global batch size:  1024 | lm loss: 1.865353E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26602/   51900 | consumed samples:     27240448 | elapsed time per iteration (ms): 37467.0 | learning rate: 1.120E-04 | global batch size:  1024 | lm loss: 1.850652E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26603/   51900 | consumed samples:     27241472 | elapsed time per iteration (ms): 37515.8 | learning rate: 1.120E-04 | global batch size:  1024 | lm loss: 1.832732E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26604/   51900 | consumed samples:     27242496 | elapsed time per iteration (ms): 37712.2 | learning rate: 1.120E-04 | global batch size:  1024 | lm loss: 1.840817E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26605/   51900 | consumed samples:     27243520 | elapsed time per iteration (ms): 37631.6 | learning rate: 1.120E-04 | global batch size:  1024 | lm loss: 1.840265E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26606/   51900 | consumed samples:     27244544 | elapsed time per iteration (ms): 37615.1 | learning rate: 1.119E-04 | global batch size:  1024 | lm loss: 1.828766E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26607/   51900 | consumed samples:     27245568 | elapsed time per iteration (ms): 37608.3 | learning rate: 1.119E-04 | global batch size:  1024 | lm loss: 1.832126E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26608/   51900 | consumed samples:     27246592 | elapsed time per iteration (ms): 37628.7 | learning rate: 1.119E-04 | global batch size:  1024 | lm loss: 1.845664E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26609/   51900 | consumed samples:     27247616 | elapsed time per iteration (ms): 37644.9 | learning rate: 1.119E-04 | global batch size:  1024 | lm loss: 1.863818E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26610/   51900 | consumed samples:     27248640 | elapsed time per iteration (ms): 37683.6 | learning rate: 1.119E-04 | global batch size:  1024 | lm loss: 1.842558E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26611/   51900 | consumed samples:     27249664 | elapsed time per iteration (ms): 37694.4 | learning rate: 1.119E-04 | global batch size:  1024 | lm loss: 1.875318E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26612/   51900 | consumed samples:     27250688 | elapsed time per iteration (ms): 37679.6 | learning rate: 1.119E-04 | global batch size:  1024 | lm loss: 1.844308E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26613/   51900 | consumed samples:     27251712 | elapsed time per iteration (ms): 37576.2 | learning rate: 1.119E-04 | global batch size:  1024 | lm loss: 1.841674E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26614/   51900 | consumed samples:     27252736 | elapsed time per iteration (ms): 37709.7 | learning rate: 1.119E-04 | global batch size:  1024 | lm loss: 1.846294E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26615/   51900 | consumed samples:     27253760 | elapsed time per iteration (ms): 37638.5 | learning rate: 1.119E-04 | global batch size:  1024 | lm loss: 1.850905E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26616/   51900 | consumed samples:     27254784 | elapsed time per iteration (ms): 37526.4 | learning rate: 1.119E-04 | global batch size:  1024 | lm loss: 1.847322E+00 | loss scale: 1.0 | grad norm: 0.087 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26617/   51900 | consumed samples:     27255808 | elapsed time per iteration (ms): 37619.5 | learning rate: 1.119E-04 | global batch size:  1024 | lm loss: 1.836248E+00 | loss scale: 1.0 | grad norm: 0.091 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26618/   51900 | consumed samples:     27256832 | elapsed time per iteration (ms): 37613.8 | learning rate: 1.119E-04 | global batch size:  1024 | lm loss: 1.850481E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26619/   51900 | consumed samples:     27257856 | elapsed time per iteration (ms): 37661.4 | learning rate: 1.119E-04 | global batch size:  1024 | lm loss: 1.849279E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26620/   51900 | consumed samples:     27258880 | elapsed time per iteration (ms): 37654.5 | learning rate: 1.119E-04 | global batch size:  1024 | lm loss: 1.851817E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26621/   51900 | consumed samples:     27259904 | elapsed time per iteration (ms): 37642.2 | learning rate: 1.119E-04 | global batch size:  1024 | lm loss: 1.844680E+00 | loss scale: 1.0 | grad norm: 0.093 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26622/   51900 | consumed samples:     27260928 | elapsed time per iteration (ms): 37620.5 | learning rate: 1.119E-04 | global batch size:  1024 | lm loss: 1.847559E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26623/   51900 | consumed samples:     27261952 | elapsed time per iteration (ms): 37666.7 | learning rate: 1.119E-04 | global batch size:  1024 | lm loss: 1.840687E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26624/   51900 | consumed samples:     27262976 | elapsed time per iteration (ms): 37693.3 | learning rate: 1.118E-04 | global batch size:  1024 | lm loss: 1.856179E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26625/   51900 | consumed samples:     27264000 | elapsed time per iteration (ms): 37585.4 | learning rate: 1.118E-04 | global batch size:  1024 | lm loss: 1.863501E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26626/   51900 | consumed samples:     27265024 | elapsed time per iteration (ms): 37741.7 | learning rate: 1.118E-04 | global batch size:  1024 | lm loss: 1.841434E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26627/   51900 | consumed samples:     27266048 | elapsed time per iteration (ms): 37613.4 | learning rate: 1.118E-04 | global batch size:  1024 | lm loss: 1.864160E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26628/   51900 | consumed samples:     27267072 | elapsed time per iteration (ms): 37596.5 | learning rate: 1.118E-04 | global batch size:  1024 | lm loss: 1.838353E+00 | loss scale: 1.0 | grad norm: 0.088 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26629/   51900 | consumed samples:     27268096 | elapsed time per iteration (ms): 37707.3 | learning rate: 1.118E-04 | global batch size:  1024 | lm loss: 1.833060E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26630/   51900 | consumed samples:     27269120 | elapsed time per iteration (ms): 37582.4 | learning rate: 1.118E-04 | global batch size:  1024 | lm loss: 1.855538E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26631/   51900 | consumed samples:     27270144 | elapsed time per iteration (ms): 37680.4 | learning rate: 1.118E-04 | global batch size:  1024 | lm loss: 1.840846E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26632/   51900 | consumed samples:     27271168 | elapsed time per iteration (ms): 37666.1 | learning rate: 1.118E-04 | global batch size:  1024 | lm loss: 1.849141E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26633/   51900 | consumed samples:     27272192 | elapsed time per iteration (ms): 37616.5 | learning rate: 1.118E-04 | global batch size:  1024 | lm loss: 1.864399E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26634/   51900 | consumed samples:     27273216 | elapsed time per iteration (ms): 37575.2 | learning rate: 1.118E-04 | global batch size:  1024 | lm loss: 1.848189E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26635/   51900 | consumed samples:     27274240 | elapsed time per iteration (ms): 37572.9 | learning rate: 1.118E-04 | global batch size:  1024 | lm loss: 1.859174E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26636/   51900 | consumed samples:     27275264 | elapsed time per iteration (ms): 37650.0 | learning rate: 1.118E-04 | global batch size:  1024 | lm loss: 1.850318E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26637/   51900 | consumed samples:     27276288 | elapsed time per iteration (ms): 37694.1 | learning rate: 1.118E-04 | global batch size:  1024 | lm loss: 1.832381E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26638/   51900 | consumed samples:     27277312 | elapsed time per iteration (ms): 37739.6 | learning rate: 1.118E-04 | global batch size:  1024 | lm loss: 1.843237E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26639/   51900 | consumed samples:     27278336 | elapsed time per iteration (ms): 37721.4 | learning rate: 1.118E-04 | global batch size:  1024 | lm loss: 1.853892E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26640/   51900 | consumed samples:     27279360 | elapsed time per iteration (ms): 37641.0 | learning rate: 1.118E-04 | global batch size:  1024 | lm loss: 1.853104E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26641/   51900 | consumed samples:     27280384 | elapsed time per iteration (ms): 37589.7 | learning rate: 1.118E-04 | global batch size:  1024 | lm loss: 1.845980E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26642/   51900 | consumed samples:     27281408 | elapsed time per iteration (ms): 37583.5 | learning rate: 1.117E-04 | global batch size:  1024 | lm loss: 1.841257E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26643/   51900 | consumed samples:     27282432 | elapsed time per iteration (ms): 37580.5 | learning rate: 1.117E-04 | global batch size:  1024 | lm loss: 1.846622E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26644/   51900 | consumed samples:     27283456 | elapsed time per iteration (ms): 37659.5 | learning rate: 1.117E-04 | global batch size:  1024 | lm loss: 1.856147E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26645/   51900 | consumed samples:     27284480 | elapsed time per iteration (ms): 37635.7 | learning rate: 1.117E-04 | global batch size:  1024 | lm loss: 1.842895E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26646/   51900 | consumed samples:     27285504 | elapsed time per iteration (ms): 37615.5 | learning rate: 1.117E-04 | global batch size:  1024 | lm loss: 1.860285E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26647/   51900 | consumed samples:     27286528 | elapsed time per iteration (ms): 37669.5 | learning rate: 1.117E-04 | global batch size:  1024 | lm loss: 1.846750E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26648/   51900 | consumed samples:     27287552 | elapsed time per iteration (ms): 37608.6 | learning rate: 1.117E-04 | global batch size:  1024 | lm loss: 1.849941E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26649/   51900 | consumed samples:     27288576 | elapsed time per iteration (ms): 37710.1 | learning rate: 1.117E-04 | global batch size:  1024 | lm loss: 1.864763E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26650/   51900 | consumed samples:     27289600 | elapsed time per iteration (ms): 37612.7 | learning rate: 1.117E-04 | global batch size:  1024 | lm loss: 1.854053E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26651/   51900 | consumed samples:     27290624 | elapsed time per iteration (ms): 37698.6 | learning rate: 1.117E-04 | global batch size:  1024 | lm loss: 1.847288E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26652/   51900 | consumed samples:     27291648 | elapsed time per iteration (ms): 37560.9 | learning rate: 1.117E-04 | global batch size:  1024 | lm loss: 1.840481E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26653/   51900 | consumed samples:     27292672 | elapsed time per iteration (ms): 37646.9 | learning rate: 1.117E-04 | global batch size:  1024 | lm loss: 1.855043E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26654/   51900 | consumed samples:     27293696 | elapsed time per iteration (ms): 37717.0 | learning rate: 1.117E-04 | global batch size:  1024 | lm loss: 1.847805E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26655/   51900 | consumed samples:     27294720 | elapsed time per iteration (ms): 37601.8 | learning rate: 1.117E-04 | global batch size:  1024 | lm loss: 1.855759E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26656/   51900 | consumed samples:     27295744 | elapsed time per iteration (ms): 37601.4 | learning rate: 1.117E-04 | global batch size:  1024 | lm loss: 1.836542E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26657/   51900 | consumed samples:     27296768 | elapsed time per iteration (ms): 37641.2 | learning rate: 1.117E-04 | global batch size:  1024 | lm loss: 1.862091E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26658/   51900 | consumed samples:     27297792 | elapsed time per iteration (ms): 37660.0 | learning rate: 1.117E-04 | global batch size:  1024 | lm loss: 1.860674E+00 | loss scale: 1.0 | grad norm: 0.088 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26659/   51900 | consumed samples:     27298816 | elapsed time per iteration (ms): 37724.2 | learning rate: 1.116E-04 | global batch size:  1024 | lm loss: 1.840882E+00 | loss scale: 1.0 | grad norm: 0.102 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26660/   51900 | consumed samples:     27299840 | elapsed time per iteration (ms): 37660.3 | learning rate: 1.116E-04 | global batch size:  1024 | lm loss: 1.841967E+00 | loss scale: 1.0 | grad norm: 0.090 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26661/   51900 | consumed samples:     27300864 | elapsed time per iteration (ms): 37696.3 | learning rate: 1.116E-04 | global batch size:  1024 | lm loss: 1.836317E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26662/   51900 | consumed samples:     27301888 | elapsed time per iteration (ms): 37658.3 | learning rate: 1.116E-04 | global batch size:  1024 | lm loss: 1.847644E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26663/   51900 | consumed samples:     27302912 | elapsed time per iteration (ms): 37703.6 | learning rate: 1.116E-04 | global batch size:  1024 | lm loss: 1.849443E+00 | loss scale: 1.0 | grad norm: 0.091 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26664/   51900 | consumed samples:     27303936 | elapsed time per iteration (ms): 37683.2 | learning rate: 1.116E-04 | global batch size:  1024 | lm loss: 1.843251E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26665/   51900 | consumed samples:     27304960 | elapsed time per iteration (ms): 37734.0 | learning rate: 1.116E-04 | global batch size:  1024 | lm loss: 1.850307E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26666/   51900 | consumed samples:     27305984 | elapsed time per iteration (ms): 37591.9 | learning rate: 1.116E-04 | global batch size:  1024 | lm loss: 1.844885E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26667/   51900 | consumed samples:     27307008 | elapsed time per iteration (ms): 37650.8 | learning rate: 1.116E-04 | global batch size:  1024 | lm loss: 1.823214E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26668/   51900 | consumed samples:     27308032 | elapsed time per iteration (ms): 37666.7 | learning rate: 1.116E-04 | global batch size:  1024 | lm loss: 1.851505E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26669/   51900 | consumed samples:     27309056 | elapsed time per iteration (ms): 37766.1 | learning rate: 1.116E-04 | global batch size:  1024 | lm loss: 1.854893E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26670/   51900 | consumed samples:     27310080 | elapsed time per iteration (ms): 37566.1 | learning rate: 1.116E-04 | global batch size:  1024 | lm loss: 1.861831E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26671/   51900 | consumed samples:     27311104 | elapsed time per iteration (ms): 37549.5 | learning rate: 1.116E-04 | global batch size:  1024 | lm loss: 1.861471E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26672/   51900 | consumed samples:     27312128 | elapsed time per iteration (ms): 37643.9 | learning rate: 1.116E-04 | global batch size:  1024 | lm loss: 1.846590E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26673/   51900 | consumed samples:     27313152 | elapsed time per iteration (ms): 37683.3 | learning rate: 1.116E-04 | global batch size:  1024 | lm loss: 1.848286E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26674/   51900 | consumed samples:     27314176 | elapsed time per iteration (ms): 37650.8 | learning rate: 1.116E-04 | global batch size:  1024 | lm loss: 1.843289E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26675/   51900 | consumed samples:     27315200 | elapsed time per iteration (ms): 37626.1 | learning rate: 1.116E-04 | global batch size:  1024 | lm loss: 1.855519E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26676/   51900 | consumed samples:     27316224 | elapsed time per iteration (ms): 37584.4 | learning rate: 1.116E-04 | global batch size:  1024 | lm loss: 1.847951E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26677/   51900 | consumed samples:     27317248 | elapsed time per iteration (ms): 37700.3 | learning rate: 1.115E-04 | global batch size:  1024 | lm loss: 1.862951E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26678/   51900 | consumed samples:     27318272 | elapsed time per iteration (ms): 37574.9 | learning rate: 1.115E-04 | global batch size:  1024 | lm loss: 1.855475E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26679/   51900 | consumed samples:     27319296 | elapsed time per iteration (ms): 37580.7 | learning rate: 1.115E-04 | global batch size:  1024 | lm loss: 1.847363E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26680/   51900 | consumed samples:     27320320 | elapsed time per iteration (ms): 37657.6 | learning rate: 1.115E-04 | global batch size:  1024 | lm loss: 1.833773E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26681/   51900 | consumed samples:     27321344 | elapsed time per iteration (ms): 37700.9 | learning rate: 1.115E-04 | global batch size:  1024 | lm loss: 1.850909E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26682/   51900 | consumed samples:     27322368 | elapsed time per iteration (ms): 37786.8 | learning rate: 1.115E-04 | global batch size:  1024 | lm loss: 1.869611E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26683/   51900 | consumed samples:     27323392 | elapsed time per iteration (ms): 37714.7 | learning rate: 1.115E-04 | global batch size:  1024 | lm loss: 1.839554E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26684/   51900 | consumed samples:     27324416 | elapsed time per iteration (ms): 37651.7 | learning rate: 1.115E-04 | global batch size:  1024 | lm loss: 1.854034E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26685/   51900 | consumed samples:     27325440 | elapsed time per iteration (ms): 37583.7 | learning rate: 1.115E-04 | global batch size:  1024 | lm loss: 1.863836E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26686/   51900 | consumed samples:     27326464 | elapsed time per iteration (ms): 37690.6 | learning rate: 1.115E-04 | global batch size:  1024 | lm loss: 1.854880E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26687/   51900 | consumed samples:     27327488 | elapsed time per iteration (ms): 37641.8 | learning rate: 1.115E-04 | global batch size:  1024 | lm loss: 1.836338E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26688/   51900 | consumed samples:     27328512 | elapsed time per iteration (ms): 37663.0 | learning rate: 1.115E-04 | global batch size:  1024 | lm loss: 1.847345E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26689/   51900 | consumed samples:     27329536 | elapsed time per iteration (ms): 37615.5 | learning rate: 1.115E-04 | global batch size:  1024 | lm loss: 1.860245E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26690/   51900 | consumed samples:     27330560 | elapsed time per iteration (ms): 37680.0 | learning rate: 1.115E-04 | global batch size:  1024 | lm loss: 1.853691E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26691/   51900 | consumed samples:     27331584 | elapsed time per iteration (ms): 37590.9 | learning rate: 1.115E-04 | global batch size:  1024 | lm loss: 1.843860E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26692/   51900 | consumed samples:     27332608 | elapsed time per iteration (ms): 37730.7 | learning rate: 1.115E-04 | global batch size:  1024 | lm loss: 1.866121E+00 | loss scale: 1.0 | grad norm: 0.088 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26693/   51900 | consumed samples:     27333632 | elapsed time per iteration (ms): 37612.7 | learning rate: 1.115E-04 | global batch size:  1024 | lm loss: 1.849779E+00 | loss scale: 1.0 | grad norm: 0.091 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26694/   51900 | consumed samples:     27334656 | elapsed time per iteration (ms): 37641.5 | learning rate: 1.115E-04 | global batch size:  1024 | lm loss: 1.817710E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26695/   51900 | consumed samples:     27335680 | elapsed time per iteration (ms): 37667.7 | learning rate: 1.114E-04 | global batch size:  1024 | lm loss: 1.842333E+00 | loss scale: 1.0 | grad norm: 0.100 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26696/   51900 | consumed samples:     27336704 | elapsed time per iteration (ms): 37513.8 | learning rate: 1.114E-04 | global batch size:  1024 | lm loss: 1.842427E+00 | loss scale: 1.0 | grad norm: 0.094 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26697/   51900 | consumed samples:     27337728 | elapsed time per iteration (ms): 37757.5 | learning rate: 1.114E-04 | global batch size:  1024 | lm loss: 1.837662E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26698/   51900 | consumed samples:     27338752 | elapsed time per iteration (ms): 37647.6 | learning rate: 1.114E-04 | global batch size:  1024 | lm loss: 1.857264E+00 | loss scale: 1.0 | grad norm: 0.091 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26699/   51900 | consumed samples:     27339776 | elapsed time per iteration (ms): 37714.2 | learning rate: 1.114E-04 | global batch size:  1024 | lm loss: 1.849540E+00 | loss scale: 1.0 | grad norm: 0.093 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26700/   51900 | consumed samples:     27340800 | elapsed time per iteration (ms): 37721.4 | learning rate: 1.114E-04 | global batch size:  1024 | lm loss: 1.856827E+00 | loss scale: 1.0 | grad norm: 0.088 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26701/   51900 | consumed samples:     27341824 | elapsed time per iteration (ms): 37691.2 | learning rate: 1.114E-04 | global batch size:  1024 | lm loss: 1.862895E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26702/   51900 | consumed samples:     27342848 | elapsed time per iteration (ms): 37632.6 | learning rate: 1.114E-04 | global batch size:  1024 | lm loss: 1.843826E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26703/   51900 | consumed samples:     27343872 | elapsed time per iteration (ms): 37675.8 | learning rate: 1.114E-04 | global batch size:  1024 | lm loss: 1.855389E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26704/   51900 | consumed samples:     27344896 | elapsed time per iteration (ms): 37616.3 | learning rate: 1.114E-04 | global batch size:  1024 | lm loss: 1.831946E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26705/   51900 | consumed samples:     27345920 | elapsed time per iteration (ms): 37636.5 | learning rate: 1.114E-04 | global batch size:  1024 | lm loss: 1.838854E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26706/   51900 | consumed samples:     27346944 | elapsed time per iteration (ms): 37721.6 | learning rate: 1.114E-04 | global batch size:  1024 | lm loss: 1.860087E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26707/   51900 | consumed samples:     27347968 | elapsed time per iteration (ms): 37687.7 | learning rate: 1.114E-04 | global batch size:  1024 | lm loss: 1.858109E+00 | loss scale: 1.0 | grad norm: 0.089 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26708/   51900 | consumed samples:     27348992 | elapsed time per iteration (ms): 37630.5 | learning rate: 1.114E-04 | global batch size:  1024 | lm loss: 1.834824E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26709/   51900 | consumed samples:     27350016 | elapsed time per iteration (ms): 37567.8 | learning rate: 1.114E-04 | global batch size:  1024 | lm loss: 1.856680E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26710/   51900 | consumed samples:     27351040 | elapsed time per iteration (ms): 37728.3 | learning rate: 1.114E-04 | global batch size:  1024 | lm loss: 1.853385E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26711/   51900 | consumed samples:     27352064 | elapsed time per iteration (ms): 37631.8 | learning rate: 1.114E-04 | global batch size:  1024 | lm loss: 1.847646E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26712/   51900 | consumed samples:     27353088 | elapsed time per iteration (ms): 37597.9 | learning rate: 1.113E-04 | global batch size:  1024 | lm loss: 1.866416E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26713/   51900 | consumed samples:     27354112 | elapsed time per iteration (ms): 37665.5 | learning rate: 1.113E-04 | global batch size:  1024 | lm loss: 1.838579E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26714/   51900 | consumed samples:     27355136 | elapsed time per iteration (ms): 37644.9 | learning rate: 1.113E-04 | global batch size:  1024 | lm loss: 1.845024E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26715/   51900 | consumed samples:     27356160 | elapsed time per iteration (ms): 37663.0 | learning rate: 1.113E-04 | global batch size:  1024 | lm loss: 1.865635E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26716/   51900 | consumed samples:     27357184 | elapsed time per iteration (ms): 37703.9 | learning rate: 1.113E-04 | global batch size:  1024 | lm loss: 1.850899E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26717/   51900 | consumed samples:     27358208 | elapsed time per iteration (ms): 37700.5 | learning rate: 1.113E-04 | global batch size:  1024 | lm loss: 1.861309E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26718/   51900 | consumed samples:     27359232 | elapsed time per iteration (ms): 37605.1 | learning rate: 1.113E-04 | global batch size:  1024 | lm loss: 1.840181E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26719/   51900 | consumed samples:     27360256 | elapsed time per iteration (ms): 37709.3 | learning rate: 1.113E-04 | global batch size:  1024 | lm loss: 1.861708E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26720/   51900 | consumed samples:     27361280 | elapsed time per iteration (ms): 37624.3 | learning rate: 1.113E-04 | global batch size:  1024 | lm loss: 1.846807E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26721/   51900 | consumed samples:     27362304 | elapsed time per iteration (ms): 37624.5 | learning rate: 1.113E-04 | global batch size:  1024 | lm loss: 1.858864E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26722/   51900 | consumed samples:     27363328 | elapsed time per iteration (ms): 37674.0 | learning rate: 1.113E-04 | global batch size:  1024 | lm loss: 1.847904E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26723/   51900 | consumed samples:     27364352 | elapsed time per iteration (ms): 37564.9 | learning rate: 1.113E-04 | global batch size:  1024 | lm loss: 1.850604E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26724/   51900 | consumed samples:     27365376 | elapsed time per iteration (ms): 37647.5 | learning rate: 1.113E-04 | global batch size:  1024 | lm loss: 1.854067E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26725/   51900 | consumed samples:     27366400 | elapsed time per iteration (ms): 37670.2 | learning rate: 1.113E-04 | global batch size:  1024 | lm loss: 1.850436E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26726/   51900 | consumed samples:     27367424 | elapsed time per iteration (ms): 37743.8 | learning rate: 1.113E-04 | global batch size:  1024 | lm loss: 1.828224E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26727/   51900 | consumed samples:     27368448 | elapsed time per iteration (ms): 37770.1 | learning rate: 1.113E-04 | global batch size:  1024 | lm loss: 1.830601E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26728/   51900 | consumed samples:     27369472 | elapsed time per iteration (ms): 37626.6 | learning rate: 1.113E-04 | global batch size:  1024 | lm loss: 1.860636E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26729/   51900 | consumed samples:     27370496 | elapsed time per iteration (ms): 37650.8 | learning rate: 1.113E-04 | global batch size:  1024 | lm loss: 1.863452E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26730/   51900 | consumed samples:     27371520 | elapsed time per iteration (ms): 37740.0 | learning rate: 1.112E-04 | global batch size:  1024 | lm loss: 1.852790E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26731/   51900 | consumed samples:     27372544 | elapsed time per iteration (ms): 37635.4 | learning rate: 1.112E-04 | global batch size:  1024 | lm loss: 1.836761E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26732/   51900 | consumed samples:     27373568 | elapsed time per iteration (ms): 37568.1 | learning rate: 1.112E-04 | global batch size:  1024 | lm loss: 1.860028E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26733/   51900 | consumed samples:     27374592 | elapsed time per iteration (ms): 37618.7 | learning rate: 1.112E-04 | global batch size:  1024 | lm loss: 1.849517E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26734/   51900 | consumed samples:     27375616 | elapsed time per iteration (ms): 37680.1 | learning rate: 1.112E-04 | global batch size:  1024 | lm loss: 1.858215E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26735/   51900 | consumed samples:     27376640 | elapsed time per iteration (ms): 37653.9 | learning rate: 1.112E-04 | global batch size:  1024 | lm loss: 1.853826E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26736/   51900 | consumed samples:     27377664 | elapsed time per iteration (ms): 37640.6 | learning rate: 1.112E-04 | global batch size:  1024 | lm loss: 1.854112E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26737/   51900 | consumed samples:     27378688 | elapsed time per iteration (ms): 37644.1 | learning rate: 1.112E-04 | global batch size:  1024 | lm loss: 1.864148E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26738/   51900 | consumed samples:     27379712 | elapsed time per iteration (ms): 37663.1 | learning rate: 1.112E-04 | global batch size:  1024 | lm loss: 1.852238E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26739/   51900 | consumed samples:     27380736 | elapsed time per iteration (ms): 37700.5 | learning rate: 1.112E-04 | global batch size:  1024 | lm loss: 1.849555E+00 | loss scale: 1.0 | grad norm: 0.092 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26740/   51900 | consumed samples:     27381760 | elapsed time per iteration (ms): 37712.9 | learning rate: 1.112E-04 | global batch size:  1024 | lm loss: 1.846040E+00 | loss scale: 1.0 | grad norm: 0.091 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26741/   51900 | consumed samples:     27382784 | elapsed time per iteration (ms): 37742.2 | learning rate: 1.112E-04 | global batch size:  1024 | lm loss: 1.855480E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26742/   51900 | consumed samples:     27383808 | elapsed time per iteration (ms): 37748.2 | learning rate: 1.112E-04 | global batch size:  1024 | lm loss: 1.847075E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26743/   51900 | consumed samples:     27384832 | elapsed time per iteration (ms): 37649.3 | learning rate: 1.112E-04 | global batch size:  1024 | lm loss: 1.850580E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26744/   51900 | consumed samples:     27385856 | elapsed time per iteration (ms): 37635.0 | learning rate: 1.112E-04 | global batch size:  1024 | lm loss: 1.854565E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26745/   51900 | consumed samples:     27386880 | elapsed time per iteration (ms): 37588.2 | learning rate: 1.112E-04 | global batch size:  1024 | lm loss: 1.858798E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26746/   51900 | consumed samples:     27387904 | elapsed time per iteration (ms): 37719.9 | learning rate: 1.112E-04 | global batch size:  1024 | lm loss: 1.863979E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26747/   51900 | consumed samples:     27388928 | elapsed time per iteration (ms): 37764.4 | learning rate: 1.112E-04 | global batch size:  1024 | lm loss: 1.861579E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26748/   51900 | consumed samples:     27389952 | elapsed time per iteration (ms): 37693.7 | learning rate: 1.111E-04 | global batch size:  1024 | lm loss: 1.860045E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26749/   51900 | consumed samples:     27390976 | elapsed time per iteration (ms): 37621.0 | learning rate: 1.111E-04 | global batch size:  1024 | lm loss: 1.871325E+00 | loss scale: 1.0 | grad norm: 0.131 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26750/   51900 | consumed samples:     27392000 | elapsed time per iteration (ms): 37603.6 | learning rate: 1.111E-04 | global batch size:  1024 | lm loss: 1.843906E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26751/   51900 | consumed samples:     27393024 | elapsed time per iteration (ms): 37636.3 | learning rate: 1.111E-04 | global batch size:  1024 | lm loss: 1.823711E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26752/   51900 | consumed samples:     27394048 | elapsed time per iteration (ms): 37600.7 | learning rate: 1.111E-04 | global batch size:  1024 | lm loss: 1.855522E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26753/   51900 | consumed samples:     27395072 | elapsed time per iteration (ms): 37781.8 | learning rate: 1.111E-04 | global batch size:  1024 | lm loss: 1.853959E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26754/   51900 | consumed samples:     27396096 | elapsed time per iteration (ms): 37753.2 | learning rate: 1.111E-04 | global batch size:  1024 | lm loss: 1.843007E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26755/   51900 | consumed samples:     27397120 | elapsed time per iteration (ms): 37607.5 | learning rate: 1.111E-04 | global batch size:  1024 | lm loss: 1.842393E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26756/   51900 | consumed samples:     27398144 | elapsed time per iteration (ms): 37661.0 | learning rate: 1.111E-04 | global batch size:  1024 | lm loss: 1.849614E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26757/   51900 | consumed samples:     27399168 | elapsed time per iteration (ms): 37660.8 | learning rate: 1.111E-04 | global batch size:  1024 | lm loss: 1.854334E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26758/   51900 | consumed samples:     27400192 | elapsed time per iteration (ms): 37657.7 | learning rate: 1.111E-04 | global batch size:  1024 | lm loss: 1.847132E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26759/   51900 | consumed samples:     27401216 | elapsed time per iteration (ms): 37736.4 | learning rate: 1.111E-04 | global batch size:  1024 | lm loss: 1.834563E+00 | loss scale: 1.0 | grad norm: 0.087 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26760/   51900 | consumed samples:     27402240 | elapsed time per iteration (ms): 37693.6 | learning rate: 1.111E-04 | global batch size:  1024 | lm loss: 1.856555E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26761/   51900 | consumed samples:     27403264 | elapsed time per iteration (ms): 37574.9 | learning rate: 1.111E-04 | global batch size:  1024 | lm loss: 1.853929E+00 | loss scale: 1.0 | grad norm: 0.087 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26762/   51900 | consumed samples:     27404288 | elapsed time per iteration (ms): 37761.9 | learning rate: 1.111E-04 | global batch size:  1024 | lm loss: 1.856949E+00 | loss scale: 1.0 | grad norm: 0.087 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26763/   51900 | consumed samples:     27405312 | elapsed time per iteration (ms): 37619.8 | learning rate: 1.111E-04 | global batch size:  1024 | lm loss: 1.846808E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26764/   51900 | consumed samples:     27406336 | elapsed time per iteration (ms): 37616.8 | learning rate: 1.111E-04 | global batch size:  1024 | lm loss: 1.832021E+00 | loss scale: 1.0 | grad norm: 0.095 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26765/   51900 | consumed samples:     27407360 | elapsed time per iteration (ms): 37596.8 | learning rate: 1.110E-04 | global batch size:  1024 | lm loss: 1.871520E+00 | loss scale: 1.0 | grad norm: 0.089 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26766/   51900 | consumed samples:     27408384 | elapsed time per iteration (ms): 37694.8 | learning rate: 1.110E-04 | global batch size:  1024 | lm loss: 1.855476E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26767/   51900 | consumed samples:     27409408 | elapsed time per iteration (ms): 37643.5 | learning rate: 1.110E-04 | global batch size:  1024 | lm loss: 1.843163E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26768/   51900 | consumed samples:     27410432 | elapsed time per iteration (ms): 37690.3 | learning rate: 1.110E-04 | global batch size:  1024 | lm loss: 1.848691E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26769/   51900 | consumed samples:     27411456 | elapsed time per iteration (ms): 37751.3 | learning rate: 1.110E-04 | global batch size:  1024 | lm loss: 1.865816E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26770/   51900 | consumed samples:     27412480 | elapsed time per iteration (ms): 37709.9 | learning rate: 1.110E-04 | global batch size:  1024 | lm loss: 1.856707E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26771/   51900 | consumed samples:     27413504 | elapsed time per iteration (ms): 37669.3 | learning rate: 1.110E-04 | global batch size:  1024 | lm loss: 1.834469E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26772/   51900 | consumed samples:     27414528 | elapsed time per iteration (ms): 37657.6 | learning rate: 1.110E-04 | global batch size:  1024 | lm loss: 1.853420E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26773/   51900 | consumed samples:     27415552 | elapsed time per iteration (ms): 37628.8 | learning rate: 1.110E-04 | global batch size:  1024 | lm loss: 1.853195E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26774/   51900 | consumed samples:     27416576 | elapsed time per iteration (ms): 37607.6 | learning rate: 1.110E-04 | global batch size:  1024 | lm loss: 1.838214E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26775/   51900 | consumed samples:     27417600 | elapsed time per iteration (ms): 37649.2 | learning rate: 1.110E-04 | global batch size:  1024 | lm loss: 1.829083E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26776/   51900 | consumed samples:     27418624 | elapsed time per iteration (ms): 37602.6 | learning rate: 1.110E-04 | global batch size:  1024 | lm loss: 1.862689E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26777/   51900 | consumed samples:     27419648 | elapsed time per iteration (ms): 37607.3 | learning rate: 1.110E-04 | global batch size:  1024 | lm loss: 1.854003E+00 | loss scale: 1.0 | grad norm: 0.114 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26778/   51900 | consumed samples:     27420672 | elapsed time per iteration (ms): 37652.9 | learning rate: 1.110E-04 | global batch size:  1024 | lm loss: 1.828344E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26779/   51900 | consumed samples:     27421696 | elapsed time per iteration (ms): 37671.8 | learning rate: 1.110E-04 | global batch size:  1024 | lm loss: 1.869105E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26780/   51900 | consumed samples:     27422720 | elapsed time per iteration (ms): 37619.2 | learning rate: 1.110E-04 | global batch size:  1024 | lm loss: 1.872958E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26781/   51900 | consumed samples:     27423744 | elapsed time per iteration (ms): 37702.1 | learning rate: 1.110E-04 | global batch size:  1024 | lm loss: 1.858249E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26782/   51900 | consumed samples:     27424768 | elapsed time per iteration (ms): 37595.8 | learning rate: 1.110E-04 | global batch size:  1024 | lm loss: 1.843918E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26783/   51900 | consumed samples:     27425792 | elapsed time per iteration (ms): 37636.5 | learning rate: 1.109E-04 | global batch size:  1024 | lm loss: 1.852310E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26784/   51900 | consumed samples:     27426816 | elapsed time per iteration (ms): 37746.0 | learning rate: 1.109E-04 | global batch size:  1024 | lm loss: 1.856019E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26785/   51900 | consumed samples:     27427840 | elapsed time per iteration (ms): 37535.3 | learning rate: 1.109E-04 | global batch size:  1024 | lm loss: 1.830412E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26786/   51900 | consumed samples:     27428864 | elapsed time per iteration (ms): 37652.6 | learning rate: 1.109E-04 | global batch size:  1024 | lm loss: 1.831251E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26787/   51900 | consumed samples:     27429888 | elapsed time per iteration (ms): 37602.4 | learning rate: 1.109E-04 | global batch size:  1024 | lm loss: 1.847463E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26788/   51900 | consumed samples:     27430912 | elapsed time per iteration (ms): 37744.5 | learning rate: 1.109E-04 | global batch size:  1024 | lm loss: 1.860916E+00 | loss scale: 1.0 | grad norm: 0.088 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26789/   51900 | consumed samples:     27431936 | elapsed time per iteration (ms): 37638.5 | learning rate: 1.109E-04 | global batch size:  1024 | lm loss: 1.844230E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26790/   51900 | consumed samples:     27432960 | elapsed time per iteration (ms): 37604.3 | learning rate: 1.109E-04 | global batch size:  1024 | lm loss: 1.850071E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26791/   51900 | consumed samples:     27433984 | elapsed time per iteration (ms): 37631.4 | learning rate: 1.109E-04 | global batch size:  1024 | lm loss: 1.849973E+00 | loss scale: 1.0 | grad norm: 0.088 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26792/   51900 | consumed samples:     27435008 | elapsed time per iteration (ms): 37832.1 | learning rate: 1.109E-04 | global batch size:  1024 | lm loss: 1.858455E+00 | loss scale: 1.0 | grad norm: 0.089 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26793/   51900 | consumed samples:     27436032 | elapsed time per iteration (ms): 37609.9 | learning rate: 1.109E-04 | global batch size:  1024 | lm loss: 1.847062E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26794/   51900 | consumed samples:     27437056 | elapsed time per iteration (ms): 37691.2 | learning rate: 1.109E-04 | global batch size:  1024 | lm loss: 1.844617E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26795/   51900 | consumed samples:     27438080 | elapsed time per iteration (ms): 37639.9 | learning rate: 1.109E-04 | global batch size:  1024 | lm loss: 1.860102E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26796/   51900 | consumed samples:     27439104 | elapsed time per iteration (ms): 37713.1 | learning rate: 1.109E-04 | global batch size:  1024 | lm loss: 1.852782E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26797/   51900 | consumed samples:     27440128 | elapsed time per iteration (ms): 37718.4 | learning rate: 1.109E-04 | global batch size:  1024 | lm loss: 1.859973E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26798/   51900 | consumed samples:     27441152 | elapsed time per iteration (ms): 37602.8 | learning rate: 1.109E-04 | global batch size:  1024 | lm loss: 1.860078E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26799/   51900 | consumed samples:     27442176 | elapsed time per iteration (ms): 37573.6 | learning rate: 1.109E-04 | global batch size:  1024 | lm loss: 1.853455E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26800/   51900 | consumed samples:     27443200 | elapsed time per iteration (ms): 37678.0 | learning rate: 1.108E-04 | global batch size:  1024 | lm loss: 1.834789E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26801/   51900 | consumed samples:     27444224 | elapsed time per iteration (ms): 37585.0 | learning rate: 1.108E-04 | global batch size:  1024 | lm loss: 1.848434E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26802/   51900 | consumed samples:     27445248 | elapsed time per iteration (ms): 37587.6 | learning rate: 1.108E-04 | global batch size:  1024 | lm loss: 1.843343E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26803/   51900 | consumed samples:     27446272 | elapsed time per iteration (ms): 37645.9 | learning rate: 1.108E-04 | global batch size:  1024 | lm loss: 1.852288E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26804/   51900 | consumed samples:     27447296 | elapsed time per iteration (ms): 37652.2 | learning rate: 1.108E-04 | global batch size:  1024 | lm loss: 1.855900E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26805/   51900 | consumed samples:     27448320 | elapsed time per iteration (ms): 37722.9 | learning rate: 1.108E-04 | global batch size:  1024 | lm loss: 1.838389E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26806/   51900 | consumed samples:     27449344 | elapsed time per iteration (ms): 37653.3 | learning rate: 1.108E-04 | global batch size:  1024 | lm loss: 1.858227E+00 | loss scale: 1.0 | grad norm: 0.097 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26807/   51900 | consumed samples:     27450368 | elapsed time per iteration (ms): 37644.2 | learning rate: 1.108E-04 | global batch size:  1024 | lm loss: 1.848950E+00 | loss scale: 1.0 | grad norm: 0.090 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26808/   51900 | consumed samples:     27451392 | elapsed time per iteration (ms): 37609.9 | learning rate: 1.108E-04 | global batch size:  1024 | lm loss: 1.850528E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26809/   51900 | consumed samples:     27452416 | elapsed time per iteration (ms): 37580.4 | learning rate: 1.108E-04 | global batch size:  1024 | lm loss: 1.844729E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26810/   51900 | consumed samples:     27453440 | elapsed time per iteration (ms): 37653.8 | learning rate: 1.108E-04 | global batch size:  1024 | lm loss: 1.827922E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26811/   51900 | consumed samples:     27454464 | elapsed time per iteration (ms): 37708.0 | learning rate: 1.108E-04 | global batch size:  1024 | lm loss: 1.851144E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26812/   51900 | consumed samples:     27455488 | elapsed time per iteration (ms): 37585.2 | learning rate: 1.108E-04 | global batch size:  1024 | lm loss: 1.835446E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26813/   51900 | consumed samples:     27456512 | elapsed time per iteration (ms): 37630.0 | learning rate: 1.108E-04 | global batch size:  1024 | lm loss: 1.827944E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26814/   51900 | consumed samples:     27457536 | elapsed time per iteration (ms): 37732.7 | learning rate: 1.108E-04 | global batch size:  1024 | lm loss: 1.842952E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26815/   51900 | consumed samples:     27458560 | elapsed time per iteration (ms): 37799.1 | learning rate: 1.108E-04 | global batch size:  1024 | lm loss: 1.858642E+00 | loss scale: 1.0 | grad norm: 0.088 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26816/   51900 | consumed samples:     27459584 | elapsed time per iteration (ms): 37627.0 | learning rate: 1.108E-04 | global batch size:  1024 | lm loss: 1.857568E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26817/   51900 | consumed samples:     27460608 | elapsed time per iteration (ms): 37668.7 | learning rate: 1.108E-04 | global batch size:  1024 | lm loss: 1.843880E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26818/   51900 | consumed samples:     27461632 | elapsed time per iteration (ms): 37637.4 | learning rate: 1.107E-04 | global batch size:  1024 | lm loss: 1.864661E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26819/   51900 | consumed samples:     27462656 | elapsed time per iteration (ms): 37658.9 | learning rate: 1.107E-04 | global batch size:  1024 | lm loss: 1.856549E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26820/   51900 | consumed samples:     27463680 | elapsed time per iteration (ms): 37661.2 | learning rate: 1.107E-04 | global batch size:  1024 | lm loss: 1.845530E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26821/   51900 | consumed samples:     27464704 | elapsed time per iteration (ms): 37689.4 | learning rate: 1.107E-04 | global batch size:  1024 | lm loss: 1.861986E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26822/   51900 | consumed samples:     27465728 | elapsed time per iteration (ms): 37700.3 | learning rate: 1.107E-04 | global batch size:  1024 | lm loss: 1.823031E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26823/   51900 | consumed samples:     27466752 | elapsed time per iteration (ms): 37786.6 | learning rate: 1.107E-04 | global batch size:  1024 | lm loss: 1.853410E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26824/   51900 | consumed samples:     27467776 | elapsed time per iteration (ms): 37653.3 | learning rate: 1.107E-04 | global batch size:  1024 | lm loss: 1.851908E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26825/   51900 | consumed samples:     27468800 | elapsed time per iteration (ms): 37688.6 | learning rate: 1.107E-04 | global batch size:  1024 | lm loss: 1.835892E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26826/   51900 | consumed samples:     27469824 | elapsed time per iteration (ms): 37641.6 | learning rate: 1.107E-04 | global batch size:  1024 | lm loss: 1.858355E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26827/   51900 | consumed samples:     27470848 | elapsed time per iteration (ms): 37671.7 | learning rate: 1.107E-04 | global batch size:  1024 | lm loss: 1.868555E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26828/   51900 | consumed samples:     27471872 | elapsed time per iteration (ms): 37622.8 | learning rate: 1.107E-04 | global batch size:  1024 | lm loss: 1.840631E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26829/   51900 | consumed samples:     27472896 | elapsed time per iteration (ms): 37640.6 | learning rate: 1.107E-04 | global batch size:  1024 | lm loss: 1.844131E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26830/   51900 | consumed samples:     27473920 | elapsed time per iteration (ms): 37661.6 | learning rate: 1.107E-04 | global batch size:  1024 | lm loss: 1.866824E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26831/   51900 | consumed samples:     27474944 | elapsed time per iteration (ms): 37703.4 | learning rate: 1.107E-04 | global batch size:  1024 | lm loss: 1.859966E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26832/   51900 | consumed samples:     27475968 | elapsed time per iteration (ms): 37624.4 | learning rate: 1.107E-04 | global batch size:  1024 | lm loss: 1.859110E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26833/   51900 | consumed samples:     27476992 | elapsed time per iteration (ms): 37670.8 | learning rate: 1.107E-04 | global batch size:  1024 | lm loss: 1.874872E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26834/   51900 | consumed samples:     27478016 | elapsed time per iteration (ms): 37694.1 | learning rate: 1.107E-04 | global batch size:  1024 | lm loss: 1.844509E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26835/   51900 | consumed samples:     27479040 | elapsed time per iteration (ms): 37721.2 | learning rate: 1.107E-04 | global batch size:  1024 | lm loss: 1.853961E+00 | loss scale: 1.0 | grad norm: 0.088 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26836/   51900 | consumed samples:     27480064 | elapsed time per iteration (ms): 37820.1 | learning rate: 1.106E-04 | global batch size:  1024 | lm loss: 1.853292E+00 | loss scale: 1.0 | grad norm: 0.103 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26837/   51900 | consumed samples:     27481088 | elapsed time per iteration (ms): 37745.4 | learning rate: 1.106E-04 | global batch size:  1024 | lm loss: 1.835000E+00 | loss scale: 1.0 | grad norm: 0.093 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26838/   51900 | consumed samples:     27482112 | elapsed time per iteration (ms): 37654.0 | learning rate: 1.106E-04 | global batch size:  1024 | lm loss: 1.853328E+00 | loss scale: 1.0 | grad norm: 0.128 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26839/   51900 | consumed samples:     27483136 | elapsed time per iteration (ms): 37595.5 | learning rate: 1.106E-04 | global batch size:  1024 | lm loss: 1.824375E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26840/   51900 | consumed samples:     27484160 | elapsed time per iteration (ms): 37686.2 | learning rate: 1.106E-04 | global batch size:  1024 | lm loss: 1.852119E+00 | loss scale: 1.0 | grad norm: 0.087 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26841/   51900 | consumed samples:     27485184 | elapsed time per iteration (ms): 37600.1 | learning rate: 1.106E-04 | global batch size:  1024 | lm loss: 1.860453E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26842/   51900 | consumed samples:     27486208 | elapsed time per iteration (ms): 37625.1 | learning rate: 1.106E-04 | global batch size:  1024 | lm loss: 1.816861E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26843/   51900 | consumed samples:     27487232 | elapsed time per iteration (ms): 37721.0 | learning rate: 1.106E-04 | global batch size:  1024 | lm loss: 1.849082E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26844/   51900 | consumed samples:     27488256 | elapsed time per iteration (ms): 37746.9 | learning rate: 1.106E-04 | global batch size:  1024 | lm loss: 1.858443E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26845/   51900 | consumed samples:     27489280 | elapsed time per iteration (ms): 37511.3 | learning rate: 1.106E-04 | global batch size:  1024 | lm loss: 1.856459E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26846/   51900 | consumed samples:     27490304 | elapsed time per iteration (ms): 37653.9 | learning rate: 1.106E-04 | global batch size:  1024 | lm loss: 1.863628E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26847/   51900 | consumed samples:     27491328 | elapsed time per iteration (ms): 37653.0 | learning rate: 1.106E-04 | global batch size:  1024 | lm loss: 1.847260E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26848/   51900 | consumed samples:     27492352 | elapsed time per iteration (ms): 37476.9 | learning rate: 1.106E-04 | global batch size:  1024 | lm loss: 1.843268E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26849/   51900 | consumed samples:     27493376 | elapsed time per iteration (ms): 37604.9 | learning rate: 1.106E-04 | global batch size:  1024 | lm loss: 1.845310E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26850/   51900 | consumed samples:     27494400 | elapsed time per iteration (ms): 37669.7 | learning rate: 1.106E-04 | global batch size:  1024 | lm loss: 1.848196E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26851/   51900 | consumed samples:     27495424 | elapsed time per iteration (ms): 37677.1 | learning rate: 1.106E-04 | global batch size:  1024 | lm loss: 1.842848E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26852/   51900 | consumed samples:     27496448 | elapsed time per iteration (ms): 37666.4 | learning rate: 1.106E-04 | global batch size:  1024 | lm loss: 1.871575E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26853/   51900 | consumed samples:     27497472 | elapsed time per iteration (ms): 37638.7 | learning rate: 1.105E-04 | global batch size:  1024 | lm loss: 1.847543E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26854/   51900 | consumed samples:     27498496 | elapsed time per iteration (ms): 37562.9 | learning rate: 1.105E-04 | global batch size:  1024 | lm loss: 1.871753E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26855/   51900 | consumed samples:     27499520 | elapsed time per iteration (ms): 37652.0 | learning rate: 1.105E-04 | global batch size:  1024 | lm loss: 1.852397E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26856/   51900 | consumed samples:     27500544 | elapsed time per iteration (ms): 37677.7 | learning rate: 1.105E-04 | global batch size:  1024 | lm loss: 1.852677E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26857/   51900 | consumed samples:     27501568 | elapsed time per iteration (ms): 37638.2 | learning rate: 1.105E-04 | global batch size:  1024 | lm loss: 1.862721E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26858/   51900 | consumed samples:     27502592 | elapsed time per iteration (ms): 37600.2 | learning rate: 1.105E-04 | global batch size:  1024 | lm loss: 1.846771E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26859/   51900 | consumed samples:     27503616 | elapsed time per iteration (ms): 37647.1 | learning rate: 1.105E-04 | global batch size:  1024 | lm loss: 1.840571E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26860/   51900 | consumed samples:     27504640 | elapsed time per iteration (ms): 37733.3 | learning rate: 1.105E-04 | global batch size:  1024 | lm loss: 1.844950E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26861/   51900 | consumed samples:     27505664 | elapsed time per iteration (ms): 37690.1 | learning rate: 1.105E-04 | global batch size:  1024 | lm loss: 1.862028E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26862/   51900 | consumed samples:     27506688 | elapsed time per iteration (ms): 37627.1 | learning rate: 1.105E-04 | global batch size:  1024 | lm loss: 1.846403E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26863/   51900 | consumed samples:     27507712 | elapsed time per iteration (ms): 37700.6 | learning rate: 1.105E-04 | global batch size:  1024 | lm loss: 1.867967E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26864/   51900 | consumed samples:     27508736 | elapsed time per iteration (ms): 37716.3 | learning rate: 1.105E-04 | global batch size:  1024 | lm loss: 1.833481E+00 | loss scale: 1.0 | grad norm: 0.090 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26865/   51900 | consumed samples:     27509760 | elapsed time per iteration (ms): 37732.6 | learning rate: 1.105E-04 | global batch size:  1024 | lm loss: 1.857425E+00 | loss scale: 1.0 | grad norm: 0.113 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26866/   51900 | consumed samples:     27510784 | elapsed time per iteration (ms): 37603.5 | learning rate: 1.105E-04 | global batch size:  1024 | lm loss: 1.850824E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26867/   51900 | consumed samples:     27511808 | elapsed time per iteration (ms): 37823.9 | learning rate: 1.105E-04 | global batch size:  1024 | lm loss: 1.843153E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26868/   51900 | consumed samples:     27512832 | elapsed time per iteration (ms): 37721.1 | learning rate: 1.105E-04 | global batch size:  1024 | lm loss: 1.843386E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26869/   51900 | consumed samples:     27513856 | elapsed time per iteration (ms): 37706.0 | learning rate: 1.105E-04 | global batch size:  1024 | lm loss: 1.823025E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26870/   51900 | consumed samples:     27514880 | elapsed time per iteration (ms): 37562.1 | learning rate: 1.105E-04 | global batch size:  1024 | lm loss: 1.831548E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26871/   51900 | consumed samples:     27515904 | elapsed time per iteration (ms): 37653.6 | learning rate: 1.104E-04 | global batch size:  1024 | lm loss: 1.851984E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26872/   51900 | consumed samples:     27516928 | elapsed time per iteration (ms): 37577.4 | learning rate: 1.104E-04 | global batch size:  1024 | lm loss: 1.842470E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26873/   51900 | consumed samples:     27517952 | elapsed time per iteration (ms): 37665.9 | learning rate: 1.104E-04 | global batch size:  1024 | lm loss: 1.850658E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26874/   51900 | consumed samples:     27518976 | elapsed time per iteration (ms): 37721.3 | learning rate: 1.104E-04 | global batch size:  1024 | lm loss: 1.846334E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26875/   51900 | consumed samples:     27520000 | elapsed time per iteration (ms): 37704.3 | learning rate: 1.104E-04 | global batch size:  1024 | lm loss: 1.850208E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26876/   51900 | consumed samples:     27521024 | elapsed time per iteration (ms): 37606.1 | learning rate: 1.104E-04 | global batch size:  1024 | lm loss: 1.848503E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26877/   51900 | consumed samples:     27522048 | elapsed time per iteration (ms): 37704.4 | learning rate: 1.104E-04 | global batch size:  1024 | lm loss: 1.847474E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26878/   51900 | consumed samples:     27523072 | elapsed time per iteration (ms): 37650.6 | learning rate: 1.104E-04 | global batch size:  1024 | lm loss: 1.851590E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26879/   51900 | consumed samples:     27524096 | elapsed time per iteration (ms): 37607.2 | learning rate: 1.104E-04 | global batch size:  1024 | lm loss: 1.851194E+00 | loss scale: 1.0 | grad norm: 0.087 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26880/   51900 | consumed samples:     27525120 | elapsed time per iteration (ms): 37659.7 | learning rate: 1.104E-04 | global batch size:  1024 | lm loss: 1.867859E+00 | loss scale: 1.0 | grad norm: 0.096 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26881/   51900 | consumed samples:     27526144 | elapsed time per iteration (ms): 37624.4 | learning rate: 1.104E-04 | global batch size:  1024 | lm loss: 1.830362E+00 | loss scale: 1.0 | grad norm: 0.099 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26882/   51900 | consumed samples:     27527168 | elapsed time per iteration (ms): 37670.0 | learning rate: 1.104E-04 | global batch size:  1024 | lm loss: 1.853674E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26883/   51900 | consumed samples:     27528192 | elapsed time per iteration (ms): 37704.3 | learning rate: 1.104E-04 | global batch size:  1024 | lm loss: 1.850549E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26884/   51900 | consumed samples:     27529216 | elapsed time per iteration (ms): 37639.5 | learning rate: 1.104E-04 | global batch size:  1024 | lm loss: 1.841914E+00 | loss scale: 1.0 | grad norm: 0.088 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26885/   51900 | consumed samples:     27530240 | elapsed time per iteration (ms): 37719.8 | learning rate: 1.104E-04 | global batch size:  1024 | lm loss: 1.846498E+00 | loss scale: 1.0 | grad norm: 0.088 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26886/   51900 | consumed samples:     27531264 | elapsed time per iteration (ms): 37709.2 | learning rate: 1.104E-04 | global batch size:  1024 | lm loss: 1.850004E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26887/   51900 | consumed samples:     27532288 | elapsed time per iteration (ms): 37694.7 | learning rate: 1.104E-04 | global batch size:  1024 | lm loss: 1.868907E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26888/   51900 | consumed samples:     27533312 | elapsed time per iteration (ms): 37700.7 | learning rate: 1.104E-04 | global batch size:  1024 | lm loss: 1.854037E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26889/   51900 | consumed samples:     27534336 | elapsed time per iteration (ms): 37694.3 | learning rate: 1.103E-04 | global batch size:  1024 | lm loss: 1.869271E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26890/   51900 | consumed samples:     27535360 | elapsed time per iteration (ms): 37706.9 | learning rate: 1.103E-04 | global batch size:  1024 | lm loss: 1.849319E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26891/   51900 | consumed samples:     27536384 | elapsed time per iteration (ms): 37697.0 | learning rate: 1.103E-04 | global batch size:  1024 | lm loss: 1.864579E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26892/   51900 | consumed samples:     27537408 | elapsed time per iteration (ms): 37614.5 | learning rate: 1.103E-04 | global batch size:  1024 | lm loss: 1.840175E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26893/   51900 | consumed samples:     27538432 | elapsed time per iteration (ms): 37487.3 | learning rate: 1.103E-04 | global batch size:  1024 | lm loss: 1.854141E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26894/   51900 | consumed samples:     27539456 | elapsed time per iteration (ms): 37683.6 | learning rate: 1.103E-04 | global batch size:  1024 | lm loss: 1.839918E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26895/   51900 | consumed samples:     27540480 | elapsed time per iteration (ms): 37703.1 | learning rate: 1.103E-04 | global batch size:  1024 | lm loss: 1.854979E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26896/   51900 | consumed samples:     27541504 | elapsed time per iteration (ms): 37595.2 | learning rate: 1.103E-04 | global batch size:  1024 | lm loss: 1.841955E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26897/   51900 | consumed samples:     27542528 | elapsed time per iteration (ms): 37633.0 | learning rate: 1.103E-04 | global batch size:  1024 | lm loss: 1.844229E+00 | loss scale: 1.0 | grad norm: 0.064 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26898/   51900 | consumed samples:     27543552 | elapsed time per iteration (ms): 37661.5 | learning rate: 1.103E-04 | global batch size:  1024 | lm loss: 1.847125E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26899/   51900 | consumed samples:     27544576 | elapsed time per iteration (ms): 37756.9 | learning rate: 1.103E-04 | global batch size:  1024 | lm loss: 1.849179E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26900/   51900 | consumed samples:     27545600 | elapsed time per iteration (ms): 37657.7 | learning rate: 1.103E-04 | global batch size:  1024 | lm loss: 1.852571E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26901/   51900 | consumed samples:     27546624 | elapsed time per iteration (ms): 37703.9 | learning rate: 1.103E-04 | global batch size:  1024 | lm loss: 1.843603E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26902/   51900 | consumed samples:     27547648 | elapsed time per iteration (ms): 37562.2 | learning rate: 1.103E-04 | global batch size:  1024 | lm loss: 1.839124E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26903/   51900 | consumed samples:     27548672 | elapsed time per iteration (ms): 37598.1 | learning rate: 1.103E-04 | global batch size:  1024 | lm loss: 1.853065E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26904/   51900 | consumed samples:     27549696 | elapsed time per iteration (ms): 37748.1 | learning rate: 1.103E-04 | global batch size:  1024 | lm loss: 1.830334E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26905/   51900 | consumed samples:     27550720 | elapsed time per iteration (ms): 37609.8 | learning rate: 1.103E-04 | global batch size:  1024 | lm loss: 1.850019E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26906/   51900 | consumed samples:     27551744 | elapsed time per iteration (ms): 37752.6 | learning rate: 1.102E-04 | global batch size:  1024 | lm loss: 1.856088E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26907/   51900 | consumed samples:     27552768 | elapsed time per iteration (ms): 37637.9 | learning rate: 1.102E-04 | global batch size:  1024 | lm loss: 1.839439E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26908/   51900 | consumed samples:     27553792 | elapsed time per iteration (ms): 37553.1 | learning rate: 1.102E-04 | global batch size:  1024 | lm loss: 1.861013E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26909/   51900 | consumed samples:     27554816 | elapsed time per iteration (ms): 37684.3 | learning rate: 1.102E-04 | global batch size:  1024 | lm loss: 1.846368E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26910/   51900 | consumed samples:     27555840 | elapsed time per iteration (ms): 37691.3 | learning rate: 1.102E-04 | global batch size:  1024 | lm loss: 1.850702E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26911/   51900 | consumed samples:     27556864 | elapsed time per iteration (ms): 37579.0 | learning rate: 1.102E-04 | global batch size:  1024 | lm loss: 1.853204E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26912/   51900 | consumed samples:     27557888 | elapsed time per iteration (ms): 37636.6 | learning rate: 1.102E-04 | global batch size:  1024 | lm loss: 1.857359E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26913/   51900 | consumed samples:     27558912 | elapsed time per iteration (ms): 37580.4 | learning rate: 1.102E-04 | global batch size:  1024 | lm loss: 1.845998E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26914/   51900 | consumed samples:     27559936 | elapsed time per iteration (ms): 37661.9 | learning rate: 1.102E-04 | global batch size:  1024 | lm loss: 1.850168E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26915/   51900 | consumed samples:     27560960 | elapsed time per iteration (ms): 37654.0 | learning rate: 1.102E-04 | global batch size:  1024 | lm loss: 1.860337E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26916/   51900 | consumed samples:     27561984 | elapsed time per iteration (ms): 37628.9 | learning rate: 1.102E-04 | global batch size:  1024 | lm loss: 1.839483E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26917/   51900 | consumed samples:     27563008 | elapsed time per iteration (ms): 37735.9 | learning rate: 1.102E-04 | global batch size:  1024 | lm loss: 1.855881E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26918/   51900 | consumed samples:     27564032 | elapsed time per iteration (ms): 37659.6 | learning rate: 1.102E-04 | global batch size:  1024 | lm loss: 1.835706E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26919/   51900 | consumed samples:     27565056 | elapsed time per iteration (ms): 37629.9 | learning rate: 1.102E-04 | global batch size:  1024 | lm loss: 1.848981E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26920/   51900 | consumed samples:     27566080 | elapsed time per iteration (ms): 37631.9 | learning rate: 1.102E-04 | global batch size:  1024 | lm loss: 1.840922E+00 | loss scale: 1.0 | grad norm: 0.089 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26921/   51900 | consumed samples:     27567104 | elapsed time per iteration (ms): 37828.3 | learning rate: 1.102E-04 | global batch size:  1024 | lm loss: 1.853312E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26922/   51900 | consumed samples:     27568128 | elapsed time per iteration (ms): 37645.2 | learning rate: 1.102E-04 | global batch size:  1024 | lm loss: 1.832523E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26923/   51900 | consumed samples:     27569152 | elapsed time per iteration (ms): 37711.8 | learning rate: 1.102E-04 | global batch size:  1024 | lm loss: 1.833533E+00 | loss scale: 1.0 | grad norm: 0.110 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26924/   51900 | consumed samples:     27570176 | elapsed time per iteration (ms): 37638.9 | learning rate: 1.101E-04 | global batch size:  1024 | lm loss: 1.845962E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26925/   51900 | consumed samples:     27571200 | elapsed time per iteration (ms): 37682.7 | learning rate: 1.101E-04 | global batch size:  1024 | lm loss: 1.860967E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26926/   51900 | consumed samples:     27572224 | elapsed time per iteration (ms): 37612.4 | learning rate: 1.101E-04 | global batch size:  1024 | lm loss: 1.842110E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26927/   51900 | consumed samples:     27573248 | elapsed time per iteration (ms): 37638.7 | learning rate: 1.101E-04 | global batch size:  1024 | lm loss: 1.859525E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26928/   51900 | consumed samples:     27574272 | elapsed time per iteration (ms): 37635.7 | learning rate: 1.101E-04 | global batch size:  1024 | lm loss: 1.849570E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26929/   51900 | consumed samples:     27575296 | elapsed time per iteration (ms): 37584.5 | learning rate: 1.101E-04 | global batch size:  1024 | lm loss: 1.843843E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26930/   51900 | consumed samples:     27576320 | elapsed time per iteration (ms): 37741.2 | learning rate: 1.101E-04 | global batch size:  1024 | lm loss: 1.870883E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26931/   51900 | consumed samples:     27577344 | elapsed time per iteration (ms): 37710.1 | learning rate: 1.101E-04 | global batch size:  1024 | lm loss: 1.849710E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26932/   51900 | consumed samples:     27578368 | elapsed time per iteration (ms): 37613.8 | learning rate: 1.101E-04 | global batch size:  1024 | lm loss: 1.825846E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26933/   51900 | consumed samples:     27579392 | elapsed time per iteration (ms): 37608.0 | learning rate: 1.101E-04 | global batch size:  1024 | lm loss: 1.837932E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26934/   51900 | consumed samples:     27580416 | elapsed time per iteration (ms): 37614.4 | learning rate: 1.101E-04 | global batch size:  1024 | lm loss: 1.841739E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26935/   51900 | consumed samples:     27581440 | elapsed time per iteration (ms): 37711.6 | learning rate: 1.101E-04 | global batch size:  1024 | lm loss: 1.853087E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26936/   51900 | consumed samples:     27582464 | elapsed time per iteration (ms): 37790.5 | learning rate: 1.101E-04 | global batch size:  1024 | lm loss: 1.844434E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26937/   51900 | consumed samples:     27583488 | elapsed time per iteration (ms): 37718.0 | learning rate: 1.101E-04 | global batch size:  1024 | lm loss: 1.836887E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26938/   51900 | consumed samples:     27584512 | elapsed time per iteration (ms): 37625.2 | learning rate: 1.101E-04 | global batch size:  1024 | lm loss: 1.861857E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26939/   51900 | consumed samples:     27585536 | elapsed time per iteration (ms): 37699.2 | learning rate: 1.101E-04 | global batch size:  1024 | lm loss: 1.840898E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26940/   51900 | consumed samples:     27586560 | elapsed time per iteration (ms): 37756.3 | learning rate: 1.101E-04 | global batch size:  1024 | lm loss: 1.865073E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26941/   51900 | consumed samples:     27587584 | elapsed time per iteration (ms): 37659.0 | learning rate: 1.101E-04 | global batch size:  1024 | lm loss: 1.841079E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26942/   51900 | consumed samples:     27588608 | elapsed time per iteration (ms): 37598.0 | learning rate: 1.100E-04 | global batch size:  1024 | lm loss: 1.852075E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26943/   51900 | consumed samples:     27589632 | elapsed time per iteration (ms): 37650.9 | learning rate: 1.100E-04 | global batch size:  1024 | lm loss: 1.833905E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26944/   51900 | consumed samples:     27590656 | elapsed time per iteration (ms): 37645.9 | learning rate: 1.100E-04 | global batch size:  1024 | lm loss: 1.860136E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26945/   51900 | consumed samples:     27591680 | elapsed time per iteration (ms): 37604.7 | learning rate: 1.100E-04 | global batch size:  1024 | lm loss: 1.828175E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26946/   51900 | consumed samples:     27592704 | elapsed time per iteration (ms): 37669.3 | learning rate: 1.100E-04 | global batch size:  1024 | lm loss: 1.857845E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26947/   51900 | consumed samples:     27593728 | elapsed time per iteration (ms): 37665.0 | learning rate: 1.100E-04 | global batch size:  1024 | lm loss: 1.834956E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26948/   51900 | consumed samples:     27594752 | elapsed time per iteration (ms): 37623.8 | learning rate: 1.100E-04 | global batch size:  1024 | lm loss: 1.853823E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26949/   51900 | consumed samples:     27595776 | elapsed time per iteration (ms): 37696.0 | learning rate: 1.100E-04 | global batch size:  1024 | lm loss: 1.872131E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26950/   51900 | consumed samples:     27596800 | elapsed time per iteration (ms): 37729.1 | learning rate: 1.100E-04 | global batch size:  1024 | lm loss: 1.846250E+00 | loss scale: 1.0 | grad norm: 0.087 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26951/   51900 | consumed samples:     27597824 | elapsed time per iteration (ms): 37582.2 | learning rate: 1.100E-04 | global batch size:  1024 | lm loss: 1.854421E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26952/   51900 | consumed samples:     27598848 | elapsed time per iteration (ms): 37549.6 | learning rate: 1.100E-04 | global batch size:  1024 | lm loss: 1.854864E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26953/   51900 | consumed samples:     27599872 | elapsed time per iteration (ms): 37670.3 | learning rate: 1.100E-04 | global batch size:  1024 | lm loss: 1.849139E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26954/   51900 | consumed samples:     27600896 | elapsed time per iteration (ms): 37690.3 | learning rate: 1.100E-04 | global batch size:  1024 | lm loss: 1.869098E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26955/   51900 | consumed samples:     27601920 | elapsed time per iteration (ms): 37637.8 | learning rate: 1.100E-04 | global batch size:  1024 | lm loss: 1.840720E+00 | loss scale: 1.0 | grad norm: 0.090 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26956/   51900 | consumed samples:     27602944 | elapsed time per iteration (ms): 37716.7 | learning rate: 1.100E-04 | global batch size:  1024 | lm loss: 1.847517E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26957/   51900 | consumed samples:     27603968 | elapsed time per iteration (ms): 37713.2 | learning rate: 1.100E-04 | global batch size:  1024 | lm loss: 1.848300E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26958/   51900 | consumed samples:     27604992 | elapsed time per iteration (ms): 37718.3 | learning rate: 1.100E-04 | global batch size:  1024 | lm loss: 1.861782E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26959/   51900 | consumed samples:     27606016 | elapsed time per iteration (ms): 37567.0 | learning rate: 1.099E-04 | global batch size:  1024 | lm loss: 1.848464E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26960/   51900 | consumed samples:     27607040 | elapsed time per iteration (ms): 37581.4 | learning rate: 1.099E-04 | global batch size:  1024 | lm loss: 1.860419E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26961/   51900 | consumed samples:     27608064 | elapsed time per iteration (ms): 37660.8 | learning rate: 1.099E-04 | global batch size:  1024 | lm loss: 1.858309E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26962/   51900 | consumed samples:     27609088 | elapsed time per iteration (ms): 37594.8 | learning rate: 1.099E-04 | global batch size:  1024 | lm loss: 1.847997E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26963/   51900 | consumed samples:     27610112 | elapsed time per iteration (ms): 37649.7 | learning rate: 1.099E-04 | global batch size:  1024 | lm loss: 1.851548E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26964/   51900 | consumed samples:     27611136 | elapsed time per iteration (ms): 37634.8 | learning rate: 1.099E-04 | global batch size:  1024 | lm loss: 1.850931E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26965/   51900 | consumed samples:     27612160 | elapsed time per iteration (ms): 37660.6 | learning rate: 1.099E-04 | global batch size:  1024 | lm loss: 1.849421E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26966/   51900 | consumed samples:     27613184 | elapsed time per iteration (ms): 37695.0 | learning rate: 1.099E-04 | global batch size:  1024 | lm loss: 1.849509E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26967/   51900 | consumed samples:     27614208 | elapsed time per iteration (ms): 37611.7 | learning rate: 1.099E-04 | global batch size:  1024 | lm loss: 1.838166E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26968/   51900 | consumed samples:     27615232 | elapsed time per iteration (ms): 37554.3 | learning rate: 1.099E-04 | global batch size:  1024 | lm loss: 1.859460E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26969/   51900 | consumed samples:     27616256 | elapsed time per iteration (ms): 37650.3 | learning rate: 1.099E-04 | global batch size:  1024 | lm loss: 1.844432E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26970/   51900 | consumed samples:     27617280 | elapsed time per iteration (ms): 37686.4 | learning rate: 1.099E-04 | global batch size:  1024 | lm loss: 1.847668E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26971/   51900 | consumed samples:     27618304 | elapsed time per iteration (ms): 37572.2 | learning rate: 1.099E-04 | global batch size:  1024 | lm loss: 1.854826E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26972/   51900 | consumed samples:     27619328 | elapsed time per iteration (ms): 37638.1 | learning rate: 1.099E-04 | global batch size:  1024 | lm loss: 1.845962E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26973/   51900 | consumed samples:     27620352 | elapsed time per iteration (ms): 37710.5 | learning rate: 1.099E-04 | global batch size:  1024 | lm loss: 1.846679E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26974/   51900 | consumed samples:     27621376 | elapsed time per iteration (ms): 37695.7 | learning rate: 1.099E-04 | global batch size:  1024 | lm loss: 1.852129E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26975/   51900 | consumed samples:     27622400 | elapsed time per iteration (ms): 37701.6 | learning rate: 1.099E-04 | global batch size:  1024 | lm loss: 1.833055E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26976/   51900 | consumed samples:     27623424 | elapsed time per iteration (ms): 37599.1 | learning rate: 1.099E-04 | global batch size:  1024 | lm loss: 1.868042E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26977/   51900 | consumed samples:     27624448 | elapsed time per iteration (ms): 37642.3 | learning rate: 1.098E-04 | global batch size:  1024 | lm loss: 1.863297E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26978/   51900 | consumed samples:     27625472 | elapsed time per iteration (ms): 37655.5 | learning rate: 1.098E-04 | global batch size:  1024 | lm loss: 1.844992E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26979/   51900 | consumed samples:     27626496 | elapsed time per iteration (ms): 37757.7 | learning rate: 1.098E-04 | global batch size:  1024 | lm loss: 1.858791E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26980/   51900 | consumed samples:     27627520 | elapsed time per iteration (ms): 37660.1 | learning rate: 1.098E-04 | global batch size:  1024 | lm loss: 1.860036E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26981/   51900 | consumed samples:     27628544 | elapsed time per iteration (ms): 37698.2 | learning rate: 1.098E-04 | global batch size:  1024 | lm loss: 1.837640E+00 | loss scale: 1.0 | grad norm: 0.090 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26982/   51900 | consumed samples:     27629568 | elapsed time per iteration (ms): 37610.3 | learning rate: 1.098E-04 | global batch size:  1024 | lm loss: 1.837707E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26983/   51900 | consumed samples:     27630592 | elapsed time per iteration (ms): 37782.2 | learning rate: 1.098E-04 | global batch size:  1024 | lm loss: 1.821328E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26984/   51900 | consumed samples:     27631616 | elapsed time per iteration (ms): 37686.5 | learning rate: 1.098E-04 | global batch size:  1024 | lm loss: 1.833299E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26985/   51900 | consumed samples:     27632640 | elapsed time per iteration (ms): 37642.0 | learning rate: 1.098E-04 | global batch size:  1024 | lm loss: 1.857574E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26986/   51900 | consumed samples:     27633664 | elapsed time per iteration (ms): 37836.1 | learning rate: 1.098E-04 | global batch size:  1024 | lm loss: 1.850977E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26987/   51900 | consumed samples:     27634688 | elapsed time per iteration (ms): 37574.0 | learning rate: 1.098E-04 | global batch size:  1024 | lm loss: 1.868804E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26988/   51900 | consumed samples:     27635712 | elapsed time per iteration (ms): 37632.5 | learning rate: 1.098E-04 | global batch size:  1024 | lm loss: 1.859215E+00 | loss scale: 1.0 | grad norm: 0.087 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26989/   51900 | consumed samples:     27636736 | elapsed time per iteration (ms): 37680.1 | learning rate: 1.098E-04 | global batch size:  1024 | lm loss: 1.829913E+00 | loss scale: 1.0 | grad norm: 0.087 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26990/   51900 | consumed samples:     27637760 | elapsed time per iteration (ms): 37584.0 | learning rate: 1.098E-04 | global batch size:  1024 | lm loss: 1.845857E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26991/   51900 | consumed samples:     27638784 | elapsed time per iteration (ms): 37604.1 | learning rate: 1.098E-04 | global batch size:  1024 | lm loss: 1.836922E+00 | loss scale: 1.0 | grad norm: 0.095 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26992/   51900 | consumed samples:     27639808 | elapsed time per iteration (ms): 37584.8 | learning rate: 1.098E-04 | global batch size:  1024 | lm loss: 1.829959E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26993/   51900 | consumed samples:     27640832 | elapsed time per iteration (ms): 37643.7 | learning rate: 1.098E-04 | global batch size:  1024 | lm loss: 1.816093E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26994/   51900 | consumed samples:     27641856 | elapsed time per iteration (ms): 37637.1 | learning rate: 1.098E-04 | global batch size:  1024 | lm loss: 1.826850E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26995/   51900 | consumed samples:     27642880 | elapsed time per iteration (ms): 37611.7 | learning rate: 1.097E-04 | global batch size:  1024 | lm loss: 1.837992E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26996/   51900 | consumed samples:     27643904 | elapsed time per iteration (ms): 37690.8 | learning rate: 1.097E-04 | global batch size:  1024 | lm loss: 1.856376E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26997/   51900 | consumed samples:     27644928 | elapsed time per iteration (ms): 37629.2 | learning rate: 1.097E-04 | global batch size:  1024 | lm loss: 1.860422E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26998/   51900 | consumed samples:     27645952 | elapsed time per iteration (ms): 37610.9 | learning rate: 1.097E-04 | global batch size:  1024 | lm loss: 1.850997E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    26999/   51900 | consumed samples:     27646976 | elapsed time per iteration (ms): 37747.5 | learning rate: 1.097E-04 | global batch size:  1024 | lm loss: 1.841440E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27000/   51900 | consumed samples:     27648000 | elapsed time per iteration (ms): 37724.9 | learning rate: 1.097E-04 | global batch size:  1024 | lm loss: 1.850669E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    save-checkpoint ................................: (171466.93, 171467.00)
 iteration    27001/   51900 | consumed samples:     27649024 | elapsed time per iteration (ms): 37210.9 | learning rate: 1.097E-04 | global batch size:  1024 | lm loss: 1.863317E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27002/   51900 | consumed samples:     27650048 | elapsed time per iteration (ms): 37486.3 | learning rate: 1.097E-04 | global batch size:  1024 | lm loss: 1.864855E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27003/   51900 | consumed samples:     27651072 | elapsed time per iteration (ms): 37567.5 | learning rate: 1.097E-04 | global batch size:  1024 | lm loss: 1.850666E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27004/   51900 | consumed samples:     27652096 | elapsed time per iteration (ms): 37606.4 | learning rate: 1.097E-04 | global batch size:  1024 | lm loss: 1.839453E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27005/   51900 | consumed samples:     27653120 | elapsed time per iteration (ms): 37616.2 | learning rate: 1.097E-04 | global batch size:  1024 | lm loss: 1.844641E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27006/   51900 | consumed samples:     27654144 | elapsed time per iteration (ms): 37621.0 | learning rate: 1.097E-04 | global batch size:  1024 | lm loss: 1.843611E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27007/   51900 | consumed samples:     27655168 | elapsed time per iteration (ms): 37619.9 | learning rate: 1.097E-04 | global batch size:  1024 | lm loss: 1.848752E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27008/   51900 | consumed samples:     27656192 | elapsed time per iteration (ms): 37630.4 | learning rate: 1.097E-04 | global batch size:  1024 | lm loss: 1.854411E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27009/   51900 | consumed samples:     27657216 | elapsed time per iteration (ms): 37520.7 | learning rate: 1.097E-04 | global batch size:  1024 | lm loss: 1.837776E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27010/   51900 | consumed samples:     27658240 | elapsed time per iteration (ms): 37612.7 | learning rate: 1.097E-04 | global batch size:  1024 | lm loss: 1.840638E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27011/   51900 | consumed samples:     27659264 | elapsed time per iteration (ms): 37654.0 | learning rate: 1.097E-04 | global batch size:  1024 | lm loss: 1.859715E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27012/   51900 | consumed samples:     27660288 | elapsed time per iteration (ms): 37651.8 | learning rate: 1.096E-04 | global batch size:  1024 | lm loss: 1.851739E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27013/   51900 | consumed samples:     27661312 | elapsed time per iteration (ms): 37544.3 | learning rate: 1.096E-04 | global batch size:  1024 | lm loss: 1.836050E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27014/   51900 | consumed samples:     27662336 | elapsed time per iteration (ms): 37562.1 | learning rate: 1.096E-04 | global batch size:  1024 | lm loss: 1.838416E+00 | loss scale: 1.0 | grad norm: 0.104 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27015/   51900 | consumed samples:     27663360 | elapsed time per iteration (ms): 37657.0 | learning rate: 1.096E-04 | global batch size:  1024 | lm loss: 1.864641E+00 | loss scale: 1.0 | grad norm: 0.102 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27016/   51900 | consumed samples:     27664384 | elapsed time per iteration (ms): 37693.7 | learning rate: 1.096E-04 | global batch size:  1024 | lm loss: 1.851858E+00 | loss scale: 1.0 | grad norm: 0.098 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27017/   51900 | consumed samples:     27665408 | elapsed time per iteration (ms): 37635.5 | learning rate: 1.096E-04 | global batch size:  1024 | lm loss: 1.839060E+00 | loss scale: 1.0 | grad norm: 0.091 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27018/   51900 | consumed samples:     27666432 | elapsed time per iteration (ms): 37641.0 | learning rate: 1.096E-04 | global batch size:  1024 | lm loss: 1.842792E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27019/   51900 | consumed samples:     27667456 | elapsed time per iteration (ms): 37628.7 | learning rate: 1.096E-04 | global batch size:  1024 | lm loss: 1.853538E+00 | loss scale: 1.0 | grad norm: 0.091 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27020/   51900 | consumed samples:     27668480 | elapsed time per iteration (ms): 37795.1 | learning rate: 1.096E-04 | global batch size:  1024 | lm loss: 1.848566E+00 | loss scale: 1.0 | grad norm: 0.091 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27021/   51900 | consumed samples:     27669504 | elapsed time per iteration (ms): 37611.8 | learning rate: 1.096E-04 | global batch size:  1024 | lm loss: 1.847436E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27022/   51900 | consumed samples:     27670528 | elapsed time per iteration (ms): 37688.3 | learning rate: 1.096E-04 | global batch size:  1024 | lm loss: 1.834171E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27023/   51900 | consumed samples:     27671552 | elapsed time per iteration (ms): 37610.3 | learning rate: 1.096E-04 | global batch size:  1024 | lm loss: 1.836738E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27024/   51900 | consumed samples:     27672576 | elapsed time per iteration (ms): 37761.2 | learning rate: 1.096E-04 | global batch size:  1024 | lm loss: 1.840896E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27025/   51900 | consumed samples:     27673600 | elapsed time per iteration (ms): 37603.8 | learning rate: 1.096E-04 | global batch size:  1024 | lm loss: 1.846643E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27026/   51900 | consumed samples:     27674624 | elapsed time per iteration (ms): 37667.1 | learning rate: 1.096E-04 | global batch size:  1024 | lm loss: 1.852690E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27027/   51900 | consumed samples:     27675648 | elapsed time per iteration (ms): 37638.9 | learning rate: 1.096E-04 | global batch size:  1024 | lm loss: 1.848795E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27028/   51900 | consumed samples:     27676672 | elapsed time per iteration (ms): 37677.3 | learning rate: 1.096E-04 | global batch size:  1024 | lm loss: 1.830991E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27029/   51900 | consumed samples:     27677696 | elapsed time per iteration (ms): 37653.5 | learning rate: 1.096E-04 | global batch size:  1024 | lm loss: 1.862530E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27030/   51900 | consumed samples:     27678720 | elapsed time per iteration (ms): 37566.5 | learning rate: 1.095E-04 | global batch size:  1024 | lm loss: 1.849568E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27031/   51900 | consumed samples:     27679744 | elapsed time per iteration (ms): 37645.4 | learning rate: 1.095E-04 | global batch size:  1024 | lm loss: 1.847317E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27032/   51900 | consumed samples:     27680768 | elapsed time per iteration (ms): 37674.0 | learning rate: 1.095E-04 | global batch size:  1024 | lm loss: 1.837708E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27033/   51900 | consumed samples:     27681792 | elapsed time per iteration (ms): 37580.3 | learning rate: 1.095E-04 | global batch size:  1024 | lm loss: 1.865254E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27034/   51900 | consumed samples:     27682816 | elapsed time per iteration (ms): 37616.9 | learning rate: 1.095E-04 | global batch size:  1024 | lm loss: 1.844096E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27035/   51900 | consumed samples:     27683840 | elapsed time per iteration (ms): 37669.9 | learning rate: 1.095E-04 | global batch size:  1024 | lm loss: 1.845765E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27036/   51900 | consumed samples:     27684864 | elapsed time per iteration (ms): 37619.8 | learning rate: 1.095E-04 | global batch size:  1024 | lm loss: 1.846320E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27037/   51900 | consumed samples:     27685888 | elapsed time per iteration (ms): 37587.2 | learning rate: 1.095E-04 | global batch size:  1024 | lm loss: 1.848695E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27038/   51900 | consumed samples:     27686912 | elapsed time per iteration (ms): 37697.5 | learning rate: 1.095E-04 | global batch size:  1024 | lm loss: 1.851326E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27039/   51900 | consumed samples:     27687936 | elapsed time per iteration (ms): 37661.7 | learning rate: 1.095E-04 | global batch size:  1024 | lm loss: 1.845024E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27040/   51900 | consumed samples:     27688960 | elapsed time per iteration (ms): 37587.2 | learning rate: 1.095E-04 | global batch size:  1024 | lm loss: 1.845115E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27041/   51900 | consumed samples:     27689984 | elapsed time per iteration (ms): 37704.2 | learning rate: 1.095E-04 | global batch size:  1024 | lm loss: 1.840852E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27042/   51900 | consumed samples:     27691008 | elapsed time per iteration (ms): 37605.1 | learning rate: 1.095E-04 | global batch size:  1024 | lm loss: 1.823824E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27043/   51900 | consumed samples:     27692032 | elapsed time per iteration (ms): 37642.6 | learning rate: 1.095E-04 | global batch size:  1024 | lm loss: 1.848069E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27044/   51900 | consumed samples:     27693056 | elapsed time per iteration (ms): 37636.8 | learning rate: 1.095E-04 | global batch size:  1024 | lm loss: 1.851868E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27045/   51900 | consumed samples:     27694080 | elapsed time per iteration (ms): 37793.7 | learning rate: 1.095E-04 | global batch size:  1024 | lm loss: 1.844355E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27046/   51900 | consumed samples:     27695104 | elapsed time per iteration (ms): 37633.5 | learning rate: 1.095E-04 | global batch size:  1024 | lm loss: 1.845391E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27047/   51900 | consumed samples:     27696128 | elapsed time per iteration (ms): 37663.4 | learning rate: 1.095E-04 | global batch size:  1024 | lm loss: 1.840554E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27048/   51900 | consumed samples:     27697152 | elapsed time per iteration (ms): 37606.2 | learning rate: 1.094E-04 | global batch size:  1024 | lm loss: 1.858356E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27049/   51900 | consumed samples:     27698176 | elapsed time per iteration (ms): 37724.5 | learning rate: 1.094E-04 | global batch size:  1024 | lm loss: 1.855128E+00 | loss scale: 1.0 | grad norm: 0.089 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27050/   51900 | consumed samples:     27699200 | elapsed time per iteration (ms): 37708.8 | learning rate: 1.094E-04 | global batch size:  1024 | lm loss: 1.843608E+00 | loss scale: 1.0 | grad norm: 0.089 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27051/   51900 | consumed samples:     27700224 | elapsed time per iteration (ms): 37643.6 | learning rate: 1.094E-04 | global batch size:  1024 | lm loss: 1.857929E+00 | loss scale: 1.0 | grad norm: 0.098 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27052/   51900 | consumed samples:     27701248 | elapsed time per iteration (ms): 37698.0 | learning rate: 1.094E-04 | global batch size:  1024 | lm loss: 1.848155E+00 | loss scale: 1.0 | grad norm: 0.094 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27053/   51900 | consumed samples:     27702272 | elapsed time per iteration (ms): 37644.5 | learning rate: 1.094E-04 | global batch size:  1024 | lm loss: 1.845444E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27054/   51900 | consumed samples:     27703296 | elapsed time per iteration (ms): 37738.2 | learning rate: 1.094E-04 | global batch size:  1024 | lm loss: 1.853556E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27055/   51900 | consumed samples:     27704320 | elapsed time per iteration (ms): 37675.6 | learning rate: 1.094E-04 | global batch size:  1024 | lm loss: 1.839366E+00 | loss scale: 1.0 | grad norm: 0.092 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27056/   51900 | consumed samples:     27705344 | elapsed time per iteration (ms): 37670.3 | learning rate: 1.094E-04 | global batch size:  1024 | lm loss: 1.858042E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27057/   51900 | consumed samples:     27706368 | elapsed time per iteration (ms): 37597.4 | learning rate: 1.094E-04 | global batch size:  1024 | lm loss: 1.863759E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27058/   51900 | consumed samples:     27707392 | elapsed time per iteration (ms): 37618.1 | learning rate: 1.094E-04 | global batch size:  1024 | lm loss: 1.850847E+00 | loss scale: 1.0 | grad norm: 0.091 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27059/   51900 | consumed samples:     27708416 | elapsed time per iteration (ms): 37561.9 | learning rate: 1.094E-04 | global batch size:  1024 | lm loss: 1.859102E+00 | loss scale: 1.0 | grad norm: 0.094 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27060/   51900 | consumed samples:     27709440 | elapsed time per iteration (ms): 37578.9 | learning rate: 1.094E-04 | global batch size:  1024 | lm loss: 1.856376E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27061/   51900 | consumed samples:     27710464 | elapsed time per iteration (ms): 37702.6 | learning rate: 1.094E-04 | global batch size:  1024 | lm loss: 1.860887E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27062/   51900 | consumed samples:     27711488 | elapsed time per iteration (ms): 37608.9 | learning rate: 1.094E-04 | global batch size:  1024 | lm loss: 1.821480E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27063/   51900 | consumed samples:     27712512 | elapsed time per iteration (ms): 37635.8 | learning rate: 1.094E-04 | global batch size:  1024 | lm loss: 1.848477E+00 | loss scale: 1.0 | grad norm: 0.087 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27064/   51900 | consumed samples:     27713536 | elapsed time per iteration (ms): 37724.2 | learning rate: 1.094E-04 | global batch size:  1024 | lm loss: 1.857321E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27065/   51900 | consumed samples:     27714560 | elapsed time per iteration (ms): 37657.2 | learning rate: 1.093E-04 | global batch size:  1024 | lm loss: 1.843989E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27066/   51900 | consumed samples:     27715584 | elapsed time per iteration (ms): 37646.1 | learning rate: 1.093E-04 | global batch size:  1024 | lm loss: 1.851860E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27067/   51900 | consumed samples:     27716608 | elapsed time per iteration (ms): 37554.9 | learning rate: 1.093E-04 | global batch size:  1024 | lm loss: 1.849279E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27068/   51900 | consumed samples:     27717632 | elapsed time per iteration (ms): 37675.8 | learning rate: 1.093E-04 | global batch size:  1024 | lm loss: 1.868547E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27069/   51900 | consumed samples:     27718656 | elapsed time per iteration (ms): 37601.8 | learning rate: 1.093E-04 | global batch size:  1024 | lm loss: 1.838957E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27070/   51900 | consumed samples:     27719680 | elapsed time per iteration (ms): 37729.5 | learning rate: 1.093E-04 | global batch size:  1024 | lm loss: 1.840827E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27071/   51900 | consumed samples:     27720704 | elapsed time per iteration (ms): 37565.0 | learning rate: 1.093E-04 | global batch size:  1024 | lm loss: 1.848132E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27072/   51900 | consumed samples:     27721728 | elapsed time per iteration (ms): 37702.9 | learning rate: 1.093E-04 | global batch size:  1024 | lm loss: 1.852992E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27073/   51900 | consumed samples:     27722752 | elapsed time per iteration (ms): 37523.4 | learning rate: 1.093E-04 | global batch size:  1024 | lm loss: 1.836771E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27074/   51900 | consumed samples:     27723776 | elapsed time per iteration (ms): 37718.1 | learning rate: 1.093E-04 | global batch size:  1024 | lm loss: 1.833855E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27075/   51900 | consumed samples:     27724800 | elapsed time per iteration (ms): 37695.1 | learning rate: 1.093E-04 | global batch size:  1024 | lm loss: 1.847584E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27076/   51900 | consumed samples:     27725824 | elapsed time per iteration (ms): 37753.5 | learning rate: 1.093E-04 | global batch size:  1024 | lm loss: 1.854803E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27077/   51900 | consumed samples:     27726848 | elapsed time per iteration (ms): 37647.3 | learning rate: 1.093E-04 | global batch size:  1024 | lm loss: 1.841449E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27078/   51900 | consumed samples:     27727872 | elapsed time per iteration (ms): 37747.6 | learning rate: 1.093E-04 | global batch size:  1024 | lm loss: 1.851097E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27079/   51900 | consumed samples:     27728896 | elapsed time per iteration (ms): 37646.2 | learning rate: 1.093E-04 | global batch size:  1024 | lm loss: 1.838501E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27080/   51900 | consumed samples:     27729920 | elapsed time per iteration (ms): 37699.6 | learning rate: 1.093E-04 | global batch size:  1024 | lm loss: 1.848795E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27081/   51900 | consumed samples:     27730944 | elapsed time per iteration (ms): 37559.8 | learning rate: 1.093E-04 | global batch size:  1024 | lm loss: 1.847176E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27082/   51900 | consumed samples:     27731968 | elapsed time per iteration (ms): 37548.0 | learning rate: 1.093E-04 | global batch size:  1024 | lm loss: 1.874602E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27083/   51900 | consumed samples:     27732992 | elapsed time per iteration (ms): 37681.0 | learning rate: 1.092E-04 | global batch size:  1024 | lm loss: 1.856687E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27084/   51900 | consumed samples:     27734016 | elapsed time per iteration (ms): 37727.0 | learning rate: 1.092E-04 | global batch size:  1024 | lm loss: 1.855668E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27085/   51900 | consumed samples:     27735040 | elapsed time per iteration (ms): 37663.0 | learning rate: 1.092E-04 | global batch size:  1024 | lm loss: 1.844733E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27086/   51900 | consumed samples:     27736064 | elapsed time per iteration (ms): 37720.8 | learning rate: 1.092E-04 | global batch size:  1024 | lm loss: 1.863594E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27087/   51900 | consumed samples:     27737088 | elapsed time per iteration (ms): 37616.8 | learning rate: 1.092E-04 | global batch size:  1024 | lm loss: 1.862844E+00 | loss scale: 1.0 | grad norm: 0.087 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27088/   51900 | consumed samples:     27738112 | elapsed time per iteration (ms): 37662.3 | learning rate: 1.092E-04 | global batch size:  1024 | lm loss: 1.840552E+00 | loss scale: 1.0 | grad norm: 0.088 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27089/   51900 | consumed samples:     27739136 | elapsed time per iteration (ms): 37588.5 | learning rate: 1.092E-04 | global batch size:  1024 | lm loss: 1.845852E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27090/   51900 | consumed samples:     27740160 | elapsed time per iteration (ms): 37646.8 | learning rate: 1.092E-04 | global batch size:  1024 | lm loss: 1.849849E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27091/   51900 | consumed samples:     27741184 | elapsed time per iteration (ms): 37600.1 | learning rate: 1.092E-04 | global batch size:  1024 | lm loss: 1.848815E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27092/   51900 | consumed samples:     27742208 | elapsed time per iteration (ms): 37624.8 | learning rate: 1.092E-04 | global batch size:  1024 | lm loss: 1.857994E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27093/   51900 | consumed samples:     27743232 | elapsed time per iteration (ms): 37643.0 | learning rate: 1.092E-04 | global batch size:  1024 | lm loss: 1.842939E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27094/   51900 | consumed samples:     27744256 | elapsed time per iteration (ms): 37798.3 | learning rate: 1.092E-04 | global batch size:  1024 | lm loss: 1.845200E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27095/   51900 | consumed samples:     27745280 | elapsed time per iteration (ms): 37664.8 | learning rate: 1.092E-04 | global batch size:  1024 | lm loss: 1.847731E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27096/   51900 | consumed samples:     27746304 | elapsed time per iteration (ms): 37688.0 | learning rate: 1.092E-04 | global batch size:  1024 | lm loss: 1.851315E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27097/   51900 | consumed samples:     27747328 | elapsed time per iteration (ms): 37714.7 | learning rate: 1.092E-04 | global batch size:  1024 | lm loss: 1.845124E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27098/   51900 | consumed samples:     27748352 | elapsed time per iteration (ms): 37676.0 | learning rate: 1.092E-04 | global batch size:  1024 | lm loss: 1.837979E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27099/   51900 | consumed samples:     27749376 | elapsed time per iteration (ms): 37667.2 | learning rate: 1.092E-04 | global batch size:  1024 | lm loss: 1.824870E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27100/   51900 | consumed samples:     27750400 | elapsed time per iteration (ms): 37697.7 | learning rate: 1.092E-04 | global batch size:  1024 | lm loss: 1.864605E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27101/   51900 | consumed samples:     27751424 | elapsed time per iteration (ms): 37664.6 | learning rate: 1.091E-04 | global batch size:  1024 | lm loss: 1.848170E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27102/   51900 | consumed samples:     27752448 | elapsed time per iteration (ms): 37671.9 | learning rate: 1.091E-04 | global batch size:  1024 | lm loss: 1.843152E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27103/   51900 | consumed samples:     27753472 | elapsed time per iteration (ms): 37585.1 | learning rate: 1.091E-04 | global batch size:  1024 | lm loss: 1.836382E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27104/   51900 | consumed samples:     27754496 | elapsed time per iteration (ms): 37643.1 | learning rate: 1.091E-04 | global batch size:  1024 | lm loss: 1.863087E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27105/   51900 | consumed samples:     27755520 | elapsed time per iteration (ms): 37628.3 | learning rate: 1.091E-04 | global batch size:  1024 | lm loss: 1.853005E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27106/   51900 | consumed samples:     27756544 | elapsed time per iteration (ms): 37627.4 | learning rate: 1.091E-04 | global batch size:  1024 | lm loss: 1.834321E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27107/   51900 | consumed samples:     27757568 | elapsed time per iteration (ms): 37589.7 | learning rate: 1.091E-04 | global batch size:  1024 | lm loss: 1.861117E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27108/   51900 | consumed samples:     27758592 | elapsed time per iteration (ms): 37677.7 | learning rate: 1.091E-04 | global batch size:  1024 | lm loss: 1.858263E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27109/   51900 | consumed samples:     27759616 | elapsed time per iteration (ms): 37615.3 | learning rate: 1.091E-04 | global batch size:  1024 | lm loss: 1.843474E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27110/   51900 | consumed samples:     27760640 | elapsed time per iteration (ms): 37783.3 | learning rate: 1.091E-04 | global batch size:  1024 | lm loss: 1.837926E+00 | loss scale: 1.0 | grad norm: 0.088 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27111/   51900 | consumed samples:     27761664 | elapsed time per iteration (ms): 37677.8 | learning rate: 1.091E-04 | global batch size:  1024 | lm loss: 1.870325E+00 | loss scale: 1.0 | grad norm: 0.091 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27112/   51900 | consumed samples:     27762688 | elapsed time per iteration (ms): 37706.1 | learning rate: 1.091E-04 | global batch size:  1024 | lm loss: 1.843190E+00 | loss scale: 1.0 | grad norm: 0.089 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27113/   51900 | consumed samples:     27763712 | elapsed time per iteration (ms): 37663.7 | learning rate: 1.091E-04 | global batch size:  1024 | lm loss: 1.837311E+00 | loss scale: 1.0 | grad norm: 0.088 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27114/   51900 | consumed samples:     27764736 | elapsed time per iteration (ms): 37586.5 | learning rate: 1.091E-04 | global batch size:  1024 | lm loss: 1.843787E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27115/   51900 | consumed samples:     27765760 | elapsed time per iteration (ms): 37720.6 | learning rate: 1.091E-04 | global batch size:  1024 | lm loss: 1.835859E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27116/   51900 | consumed samples:     27766784 | elapsed time per iteration (ms): 37500.1 | learning rate: 1.091E-04 | global batch size:  1024 | lm loss: 1.845557E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27117/   51900 | consumed samples:     27767808 | elapsed time per iteration (ms): 37595.2 | learning rate: 1.091E-04 | global batch size:  1024 | lm loss: 1.848199E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27118/   51900 | consumed samples:     27768832 | elapsed time per iteration (ms): 37657.1 | learning rate: 1.090E-04 | global batch size:  1024 | lm loss: 1.848906E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27119/   51900 | consumed samples:     27769856 | elapsed time per iteration (ms): 37667.4 | learning rate: 1.090E-04 | global batch size:  1024 | lm loss: 1.836319E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27120/   51900 | consumed samples:     27770880 | elapsed time per iteration (ms): 37658.4 | learning rate: 1.090E-04 | global batch size:  1024 | lm loss: 1.834395E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27121/   51900 | consumed samples:     27771904 | elapsed time per iteration (ms): 37666.8 | learning rate: 1.090E-04 | global batch size:  1024 | lm loss: 1.840898E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27122/   51900 | consumed samples:     27772928 | elapsed time per iteration (ms): 37612.4 | learning rate: 1.090E-04 | global batch size:  1024 | lm loss: 1.853255E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27123/   51900 | consumed samples:     27773952 | elapsed time per iteration (ms): 37581.8 | learning rate: 1.090E-04 | global batch size:  1024 | lm loss: 1.856693E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27124/   51900 | consumed samples:     27774976 | elapsed time per iteration (ms): 37616.8 | learning rate: 1.090E-04 | global batch size:  1024 | lm loss: 1.856726E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27125/   51900 | consumed samples:     27776000 | elapsed time per iteration (ms): 37606.8 | learning rate: 1.090E-04 | global batch size:  1024 | lm loss: 1.847283E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27126/   51900 | consumed samples:     27777024 | elapsed time per iteration (ms): 37645.3 | learning rate: 1.090E-04 | global batch size:  1024 | lm loss: 1.859537E+00 | loss scale: 1.0 | grad norm: 0.096 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27127/   51900 | consumed samples:     27778048 | elapsed time per iteration (ms): 37551.7 | learning rate: 1.090E-04 | global batch size:  1024 | lm loss: 1.836683E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27128/   51900 | consumed samples:     27779072 | elapsed time per iteration (ms): 37684.5 | learning rate: 1.090E-04 | global batch size:  1024 | lm loss: 1.850940E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27129/   51900 | consumed samples:     27780096 | elapsed time per iteration (ms): 37606.5 | learning rate: 1.090E-04 | global batch size:  1024 | lm loss: 1.841096E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27130/   51900 | consumed samples:     27781120 | elapsed time per iteration (ms): 37608.7 | learning rate: 1.090E-04 | global batch size:  1024 | lm loss: 1.849201E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27131/   51900 | consumed samples:     27782144 | elapsed time per iteration (ms): 37768.1 | learning rate: 1.090E-04 | global batch size:  1024 | lm loss: 1.838193E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27132/   51900 | consumed samples:     27783168 | elapsed time per iteration (ms): 37779.0 | learning rate: 1.090E-04 | global batch size:  1024 | lm loss: 1.847253E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27133/   51900 | consumed samples:     27784192 | elapsed time per iteration (ms): 37667.0 | learning rate: 1.090E-04 | global batch size:  1024 | lm loss: 1.850947E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27134/   51900 | consumed samples:     27785216 | elapsed time per iteration (ms): 37700.8 | learning rate: 1.090E-04 | global batch size:  1024 | lm loss: 1.865492E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27135/   51900 | consumed samples:     27786240 | elapsed time per iteration (ms): 37692.2 | learning rate: 1.090E-04 | global batch size:  1024 | lm loss: 1.868920E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27136/   51900 | consumed samples:     27787264 | elapsed time per iteration (ms): 37665.7 | learning rate: 1.089E-04 | global batch size:  1024 | lm loss: 1.850922E+00 | loss scale: 1.0 | grad norm: 0.087 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27137/   51900 | consumed samples:     27788288 | elapsed time per iteration (ms): 37700.3 | learning rate: 1.089E-04 | global batch size:  1024 | lm loss: 1.836238E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27138/   51900 | consumed samples:     27789312 | elapsed time per iteration (ms): 37756.5 | learning rate: 1.089E-04 | global batch size:  1024 | lm loss: 1.851461E+00 | loss scale: 1.0 | grad norm: 0.088 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27139/   51900 | consumed samples:     27790336 | elapsed time per iteration (ms): 37612.6 | learning rate: 1.089E-04 | global batch size:  1024 | lm loss: 1.856287E+00 | loss scale: 1.0 | grad norm: 0.095 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27140/   51900 | consumed samples:     27791360 | elapsed time per iteration (ms): 37613.7 | learning rate: 1.089E-04 | global batch size:  1024 | lm loss: 1.844105E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27141/   51900 | consumed samples:     27792384 | elapsed time per iteration (ms): 37578.5 | learning rate: 1.089E-04 | global batch size:  1024 | lm loss: 1.831866E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27142/   51900 | consumed samples:     27793408 | elapsed time per iteration (ms): 37607.6 | learning rate: 1.089E-04 | global batch size:  1024 | lm loss: 1.847693E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27143/   51900 | consumed samples:     27794432 | elapsed time per iteration (ms): 37675.5 | learning rate: 1.089E-04 | global batch size:  1024 | lm loss: 1.856546E+00 | loss scale: 1.0 | grad norm: 0.140 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27144/   51900 | consumed samples:     27795456 | elapsed time per iteration (ms): 37628.1 | learning rate: 1.089E-04 | global batch size:  1024 | lm loss: 1.856527E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27145/   51900 | consumed samples:     27796480 | elapsed time per iteration (ms): 37617.7 | learning rate: 1.089E-04 | global batch size:  1024 | lm loss: 1.853038E+00 | loss scale: 1.0 | grad norm: 0.087 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27146/   51900 | consumed samples:     27797504 | elapsed time per iteration (ms): 37574.0 | learning rate: 1.089E-04 | global batch size:  1024 | lm loss: 1.862495E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27147/   51900 | consumed samples:     27798528 | elapsed time per iteration (ms): 37603.9 | learning rate: 1.089E-04 | global batch size:  1024 | lm loss: 1.840819E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27148/   51900 | consumed samples:     27799552 | elapsed time per iteration (ms): 37701.8 | learning rate: 1.089E-04 | global batch size:  1024 | lm loss: 1.849341E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27149/   51900 | consumed samples:     27800576 | elapsed time per iteration (ms): 37675.7 | learning rate: 1.089E-04 | global batch size:  1024 | lm loss: 1.839771E+00 | loss scale: 1.0 | grad norm: 0.090 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27150/   51900 | consumed samples:     27801600 | elapsed time per iteration (ms): 37652.1 | learning rate: 1.089E-04 | global batch size:  1024 | lm loss: 1.840227E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27151/   51900 | consumed samples:     27802624 | elapsed time per iteration (ms): 37653.8 | learning rate: 1.089E-04 | global batch size:  1024 | lm loss: 1.849577E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27152/   51900 | consumed samples:     27803648 | elapsed time per iteration (ms): 37641.5 | learning rate: 1.089E-04 | global batch size:  1024 | lm loss: 1.844445E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27153/   51900 | consumed samples:     27804672 | elapsed time per iteration (ms): 37654.5 | learning rate: 1.088E-04 | global batch size:  1024 | lm loss: 1.868514E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27154/   51900 | consumed samples:     27805696 | elapsed time per iteration (ms): 37518.8 | learning rate: 1.088E-04 | global batch size:  1024 | lm loss: 1.848755E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27155/   51900 | consumed samples:     27806720 | elapsed time per iteration (ms): 37605.8 | learning rate: 1.088E-04 | global batch size:  1024 | lm loss: 1.848991E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27156/   51900 | consumed samples:     27807744 | elapsed time per iteration (ms): 37756.3 | learning rate: 1.088E-04 | global batch size:  1024 | lm loss: 1.871478E+00 | loss scale: 1.0 | grad norm: 0.395 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27157/   51900 | consumed samples:     27808768 | elapsed time per iteration (ms): 37750.4 | learning rate: 1.088E-04 | global batch size:  1024 | lm loss: 1.862972E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27158/   51900 | consumed samples:     27809792 | elapsed time per iteration (ms): 37665.3 | learning rate: 1.088E-04 | global batch size:  1024 | lm loss: 1.845237E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27159/   51900 | consumed samples:     27810816 | elapsed time per iteration (ms): 37656.8 | learning rate: 1.088E-04 | global batch size:  1024 | lm loss: 1.861504E+00 | loss scale: 1.0 | grad norm: 0.101 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27160/   51900 | consumed samples:     27811840 | elapsed time per iteration (ms): 37698.5 | learning rate: 1.088E-04 | global batch size:  1024 | lm loss: 1.869937E+00 | loss scale: 1.0 | grad norm: 0.101 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27161/   51900 | consumed samples:     27812864 | elapsed time per iteration (ms): 37673.5 | learning rate: 1.088E-04 | global batch size:  1024 | lm loss: 1.853045E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27162/   51900 | consumed samples:     27813888 | elapsed time per iteration (ms): 37590.3 | learning rate: 1.088E-04 | global batch size:  1024 | lm loss: 1.859650E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27163/   51900 | consumed samples:     27814912 | elapsed time per iteration (ms): 37718.1 | learning rate: 1.088E-04 | global batch size:  1024 | lm loss: 1.859823E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27164/   51900 | consumed samples:     27815936 | elapsed time per iteration (ms): 37698.5 | learning rate: 1.088E-04 | global batch size:  1024 | lm loss: 1.845617E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27165/   51900 | consumed samples:     27816960 | elapsed time per iteration (ms): 37615.0 | learning rate: 1.088E-04 | global batch size:  1024 | lm loss: 1.837555E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27166/   51900 | consumed samples:     27817984 | elapsed time per iteration (ms): 37617.7 | learning rate: 1.088E-04 | global batch size:  1024 | lm loss: 1.846895E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27167/   51900 | consumed samples:     27819008 | elapsed time per iteration (ms): 37633.6 | learning rate: 1.088E-04 | global batch size:  1024 | lm loss: 1.853508E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27168/   51900 | consumed samples:     27820032 | elapsed time per iteration (ms): 37715.2 | learning rate: 1.088E-04 | global batch size:  1024 | lm loss: 1.861547E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27169/   51900 | consumed samples:     27821056 | elapsed time per iteration (ms): 37611.9 | learning rate: 1.088E-04 | global batch size:  1024 | lm loss: 1.844356E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27170/   51900 | consumed samples:     27822080 | elapsed time per iteration (ms): 37613.2 | learning rate: 1.088E-04 | global batch size:  1024 | lm loss: 1.853584E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27171/   51900 | consumed samples:     27823104 | elapsed time per iteration (ms): 37684.8 | learning rate: 1.087E-04 | global batch size:  1024 | lm loss: 1.845039E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27172/   51900 | consumed samples:     27824128 | elapsed time per iteration (ms): 37638.2 | learning rate: 1.087E-04 | global batch size:  1024 | lm loss: 1.860664E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27173/   51900 | consumed samples:     27825152 | elapsed time per iteration (ms): 37522.0 | learning rate: 1.087E-04 | global batch size:  1024 | lm loss: 1.862979E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27174/   51900 | consumed samples:     27826176 | elapsed time per iteration (ms): 37657.2 | learning rate: 1.087E-04 | global batch size:  1024 | lm loss: 1.847082E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27175/   51900 | consumed samples:     27827200 | elapsed time per iteration (ms): 37604.2 | learning rate: 1.087E-04 | global batch size:  1024 | lm loss: 1.851330E+00 | loss scale: 1.0 | grad norm: 0.146 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27176/   51900 | consumed samples:     27828224 | elapsed time per iteration (ms): 37553.9 | learning rate: 1.087E-04 | global batch size:  1024 | lm loss: 1.840451E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27177/   51900 | consumed samples:     27829248 | elapsed time per iteration (ms): 37640.1 | learning rate: 1.087E-04 | global batch size:  1024 | lm loss: 1.875941E+00 | loss scale: 1.0 | grad norm: 0.096 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27178/   51900 | consumed samples:     27830272 | elapsed time per iteration (ms): 37757.8 | learning rate: 1.087E-04 | global batch size:  1024 | lm loss: 1.858264E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27179/   51900 | consumed samples:     27831296 | elapsed time per iteration (ms): 37771.5 | learning rate: 1.087E-04 | global batch size:  1024 | lm loss: 1.849793E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27180/   51900 | consumed samples:     27832320 | elapsed time per iteration (ms): 37605.7 | learning rate: 1.087E-04 | global batch size:  1024 | lm loss: 1.834794E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27181/   51900 | consumed samples:     27833344 | elapsed time per iteration (ms): 37626.7 | learning rate: 1.087E-04 | global batch size:  1024 | lm loss: 1.847780E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27182/   51900 | consumed samples:     27834368 | elapsed time per iteration (ms): 37588.3 | learning rate: 1.087E-04 | global batch size:  1024 | lm loss: 1.843057E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27183/   51900 | consumed samples:     27835392 | elapsed time per iteration (ms): 37565.3 | learning rate: 1.087E-04 | global batch size:  1024 | lm loss: 1.847253E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27184/   51900 | consumed samples:     27836416 | elapsed time per iteration (ms): 37623.2 | learning rate: 1.087E-04 | global batch size:  1024 | lm loss: 1.853672E+00 | loss scale: 1.0 | grad norm: 0.065 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27185/   51900 | consumed samples:     27837440 | elapsed time per iteration (ms): 37713.4 | learning rate: 1.087E-04 | global batch size:  1024 | lm loss: 1.874307E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27186/   51900 | consumed samples:     27838464 | elapsed time per iteration (ms): 37743.9 | learning rate: 1.087E-04 | global batch size:  1024 | lm loss: 1.852729E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27187/   51900 | consumed samples:     27839488 | elapsed time per iteration (ms): 37702.1 | learning rate: 1.087E-04 | global batch size:  1024 | lm loss: 1.831548E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27188/   51900 | consumed samples:     27840512 | elapsed time per iteration (ms): 37719.7 | learning rate: 1.087E-04 | global batch size:  1024 | lm loss: 1.833623E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27189/   51900 | consumed samples:     27841536 | elapsed time per iteration (ms): 37614.2 | learning rate: 1.086E-04 | global batch size:  1024 | lm loss: 1.847133E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27190/   51900 | consumed samples:     27842560 | elapsed time per iteration (ms): 37728.3 | learning rate: 1.086E-04 | global batch size:  1024 | lm loss: 1.830135E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27191/   51900 | consumed samples:     27843584 | elapsed time per iteration (ms): 37802.3 | learning rate: 1.086E-04 | global batch size:  1024 | lm loss: 1.830634E+00 | loss scale: 1.0 | grad norm: 0.064 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27192/   51900 | consumed samples:     27844608 | elapsed time per iteration (ms): 37624.9 | learning rate: 1.086E-04 | global batch size:  1024 | lm loss: 1.832287E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27193/   51900 | consumed samples:     27845632 | elapsed time per iteration (ms): 37717.8 | learning rate: 1.086E-04 | global batch size:  1024 | lm loss: 1.841326E+00 | loss scale: 1.0 | grad norm: 0.064 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27194/   51900 | consumed samples:     27846656 | elapsed time per iteration (ms): 37555.8 | learning rate: 1.086E-04 | global batch size:  1024 | lm loss: 1.839404E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27195/   51900 | consumed samples:     27847680 | elapsed time per iteration (ms): 37676.1 | learning rate: 1.086E-04 | global batch size:  1024 | lm loss: 1.824776E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27196/   51900 | consumed samples:     27848704 | elapsed time per iteration (ms): 37742.4 | learning rate: 1.086E-04 | global batch size:  1024 | lm loss: 1.860169E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27197/   51900 | consumed samples:     27849728 | elapsed time per iteration (ms): 37658.0 | learning rate: 1.086E-04 | global batch size:  1024 | lm loss: 1.848649E+00 | loss scale: 1.0 | grad norm: 0.063 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27198/   51900 | consumed samples:     27850752 | elapsed time per iteration (ms): 37763.2 | learning rate: 1.086E-04 | global batch size:  1024 | lm loss: 1.858648E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27199/   51900 | consumed samples:     27851776 | elapsed time per iteration (ms): 37653.3 | learning rate: 1.086E-04 | global batch size:  1024 | lm loss: 1.828992E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27200/   51900 | consumed samples:     27852800 | elapsed time per iteration (ms): 37649.7 | learning rate: 1.086E-04 | global batch size:  1024 | lm loss: 1.834850E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27201/   51900 | consumed samples:     27853824 | elapsed time per iteration (ms): 37756.3 | learning rate: 1.086E-04 | global batch size:  1024 | lm loss: 1.820873E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27202/   51900 | consumed samples:     27854848 | elapsed time per iteration (ms): 37615.0 | learning rate: 1.086E-04 | global batch size:  1024 | lm loss: 1.861043E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27203/   51900 | consumed samples:     27855872 | elapsed time per iteration (ms): 37814.8 | learning rate: 1.086E-04 | global batch size:  1024 | lm loss: 1.863101E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27204/   51900 | consumed samples:     27856896 | elapsed time per iteration (ms): 37691.8 | learning rate: 1.086E-04 | global batch size:  1024 | lm loss: 1.847040E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27205/   51900 | consumed samples:     27857920 | elapsed time per iteration (ms): 37727.0 | learning rate: 1.086E-04 | global batch size:  1024 | lm loss: 1.844721E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27206/   51900 | consumed samples:     27858944 | elapsed time per iteration (ms): 37680.2 | learning rate: 1.085E-04 | global batch size:  1024 | lm loss: 1.863623E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27207/   51900 | consumed samples:     27859968 | elapsed time per iteration (ms): 37651.6 | learning rate: 1.085E-04 | global batch size:  1024 | lm loss: 1.841585E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27208/   51900 | consumed samples:     27860992 | elapsed time per iteration (ms): 37603.5 | learning rate: 1.085E-04 | global batch size:  1024 | lm loss: 1.854395E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27209/   51900 | consumed samples:     27862016 | elapsed time per iteration (ms): 37696.4 | learning rate: 1.085E-04 | global batch size:  1024 | lm loss: 1.842772E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27210/   51900 | consumed samples:     27863040 | elapsed time per iteration (ms): 37736.6 | learning rate: 1.085E-04 | global batch size:  1024 | lm loss: 1.849654E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27211/   51900 | consumed samples:     27864064 | elapsed time per iteration (ms): 37665.7 | learning rate: 1.085E-04 | global batch size:  1024 | lm loss: 1.854372E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27212/   51900 | consumed samples:     27865088 | elapsed time per iteration (ms): 37701.9 | learning rate: 1.085E-04 | global batch size:  1024 | lm loss: 1.835535E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27213/   51900 | consumed samples:     27866112 | elapsed time per iteration (ms): 37696.6 | learning rate: 1.085E-04 | global batch size:  1024 | lm loss: 1.847258E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27214/   51900 | consumed samples:     27867136 | elapsed time per iteration (ms): 37582.6 | learning rate: 1.085E-04 | global batch size:  1024 | lm loss: 1.853652E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27215/   51900 | consumed samples:     27868160 | elapsed time per iteration (ms): 37692.6 | learning rate: 1.085E-04 | global batch size:  1024 | lm loss: 1.835399E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27216/   51900 | consumed samples:     27869184 | elapsed time per iteration (ms): 37730.2 | learning rate: 1.085E-04 | global batch size:  1024 | lm loss: 1.838863E+00 | loss scale: 1.0 | grad norm: 0.103 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27217/   51900 | consumed samples:     27870208 | elapsed time per iteration (ms): 37697.2 | learning rate: 1.085E-04 | global batch size:  1024 | lm loss: 1.843454E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27218/   51900 | consumed samples:     27871232 | elapsed time per iteration (ms): 37760.1 | learning rate: 1.085E-04 | global batch size:  1024 | lm loss: 1.860388E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27219/   51900 | consumed samples:     27872256 | elapsed time per iteration (ms): 37572.4 | learning rate: 1.085E-04 | global batch size:  1024 | lm loss: 1.860382E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27220/   51900 | consumed samples:     27873280 | elapsed time per iteration (ms): 37565.2 | learning rate: 1.085E-04 | global batch size:  1024 | lm loss: 1.853060E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27221/   51900 | consumed samples:     27874304 | elapsed time per iteration (ms): 37693.7 | learning rate: 1.085E-04 | global batch size:  1024 | lm loss: 1.835292E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27222/   51900 | consumed samples:     27875328 | elapsed time per iteration (ms): 37685.7 | learning rate: 1.085E-04 | global batch size:  1024 | lm loss: 1.830629E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27223/   51900 | consumed samples:     27876352 | elapsed time per iteration (ms): 37651.1 | learning rate: 1.085E-04 | global batch size:  1024 | lm loss: 1.848129E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27224/   51900 | consumed samples:     27877376 | elapsed time per iteration (ms): 37609.9 | learning rate: 1.084E-04 | global batch size:  1024 | lm loss: 1.867586E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27225/   51900 | consumed samples:     27878400 | elapsed time per iteration (ms): 37617.7 | learning rate: 1.084E-04 | global batch size:  1024 | lm loss: 1.845547E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27226/   51900 | consumed samples:     27879424 | elapsed time per iteration (ms): 37616.4 | learning rate: 1.084E-04 | global batch size:  1024 | lm loss: 1.842178E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27227/   51900 | consumed samples:     27880448 | elapsed time per iteration (ms): 37580.9 | learning rate: 1.084E-04 | global batch size:  1024 | lm loss: 1.831254E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27228/   51900 | consumed samples:     27881472 | elapsed time per iteration (ms): 37611.2 | learning rate: 1.084E-04 | global batch size:  1024 | lm loss: 1.845890E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27229/   51900 | consumed samples:     27882496 | elapsed time per iteration (ms): 37725.9 | learning rate: 1.084E-04 | global batch size:  1024 | lm loss: 1.864792E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27230/   51900 | consumed samples:     27883520 | elapsed time per iteration (ms): 37694.1 | learning rate: 1.084E-04 | global batch size:  1024 | lm loss: 1.823869E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27231/   51900 | consumed samples:     27884544 | elapsed time per iteration (ms): 37643.2 | learning rate: 1.084E-04 | global batch size:  1024 | lm loss: 1.842433E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27232/   51900 | consumed samples:     27885568 | elapsed time per iteration (ms): 37669.0 | learning rate: 1.084E-04 | global batch size:  1024 | lm loss: 1.831374E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27233/   51900 | consumed samples:     27886592 | elapsed time per iteration (ms): 37754.0 | learning rate: 1.084E-04 | global batch size:  1024 | lm loss: 1.839746E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27234/   51900 | consumed samples:     27887616 | elapsed time per iteration (ms): 37572.7 | learning rate: 1.084E-04 | global batch size:  1024 | lm loss: 1.854794E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27235/   51900 | consumed samples:     27888640 | elapsed time per iteration (ms): 37730.3 | learning rate: 1.084E-04 | global batch size:  1024 | lm loss: 1.860939E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27236/   51900 | consumed samples:     27889664 | elapsed time per iteration (ms): 37698.9 | learning rate: 1.084E-04 | global batch size:  1024 | lm loss: 1.847355E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27237/   51900 | consumed samples:     27890688 | elapsed time per iteration (ms): 37708.5 | learning rate: 1.084E-04 | global batch size:  1024 | lm loss: 1.849291E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27238/   51900 | consumed samples:     27891712 | elapsed time per iteration (ms): 37702.3 | learning rate: 1.084E-04 | global batch size:  1024 | lm loss: 1.848269E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27239/   51900 | consumed samples:     27892736 | elapsed time per iteration (ms): 37713.4 | learning rate: 1.084E-04 | global batch size:  1024 | lm loss: 1.856201E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27240/   51900 | consumed samples:     27893760 | elapsed time per iteration (ms): 37636.2 | learning rate: 1.084E-04 | global batch size:  1024 | lm loss: 1.837058E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27241/   51900 | consumed samples:     27894784 | elapsed time per iteration (ms): 37597.5 | learning rate: 1.084E-04 | global batch size:  1024 | lm loss: 1.856637E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27242/   51900 | consumed samples:     27895808 | elapsed time per iteration (ms): 37723.1 | learning rate: 1.083E-04 | global batch size:  1024 | lm loss: 1.856628E+00 | loss scale: 1.0 | grad norm: 0.088 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27243/   51900 | consumed samples:     27896832 | elapsed time per iteration (ms): 37674.1 | learning rate: 1.083E-04 | global batch size:  1024 | lm loss: 1.837968E+00 | loss scale: 1.0 | grad norm: 0.089 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27244/   51900 | consumed samples:     27897856 | elapsed time per iteration (ms): 37571.2 | learning rate: 1.083E-04 | global batch size:  1024 | lm loss: 1.828752E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27245/   51900 | consumed samples:     27898880 | elapsed time per iteration (ms): 37605.5 | learning rate: 1.083E-04 | global batch size:  1024 | lm loss: 1.841700E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27246/   51900 | consumed samples:     27899904 | elapsed time per iteration (ms): 37733.9 | learning rate: 1.083E-04 | global batch size:  1024 | lm loss: 1.853567E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27247/   51900 | consumed samples:     27900928 | elapsed time per iteration (ms): 37665.1 | learning rate: 1.083E-04 | global batch size:  1024 | lm loss: 1.833768E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27248/   51900 | consumed samples:     27901952 | elapsed time per iteration (ms): 37645.6 | learning rate: 1.083E-04 | global batch size:  1024 | lm loss: 1.845161E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27249/   51900 | consumed samples:     27902976 | elapsed time per iteration (ms): 37602.2 | learning rate: 1.083E-04 | global batch size:  1024 | lm loss: 1.833973E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27250/   51900 | consumed samples:     27904000 | elapsed time per iteration (ms): 37536.6 | learning rate: 1.083E-04 | global batch size:  1024 | lm loss: 1.842971E+00 | loss scale: 1.0 | grad norm: 0.092 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27251/   51900 | consumed samples:     27905024 | elapsed time per iteration (ms): 37683.5 | learning rate: 1.083E-04 | global batch size:  1024 | lm loss: 1.849759E+00 | loss scale: 1.0 | grad norm: 0.103 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27252/   51900 | consumed samples:     27906048 | elapsed time per iteration (ms): 37651.9 | learning rate: 1.083E-04 | global batch size:  1024 | lm loss: 1.841789E+00 | loss scale: 1.0 | grad norm: 0.087 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27253/   51900 | consumed samples:     27907072 | elapsed time per iteration (ms): 37577.1 | learning rate: 1.083E-04 | global batch size:  1024 | lm loss: 1.838244E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27254/   51900 | consumed samples:     27908096 | elapsed time per iteration (ms): 37666.0 | learning rate: 1.083E-04 | global batch size:  1024 | lm loss: 1.849659E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27255/   51900 | consumed samples:     27909120 | elapsed time per iteration (ms): 37600.9 | learning rate: 1.083E-04 | global batch size:  1024 | lm loss: 1.855867E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27256/   51900 | consumed samples:     27910144 | elapsed time per iteration (ms): 37602.2 | learning rate: 1.083E-04 | global batch size:  1024 | lm loss: 1.832981E+00 | loss scale: 1.0 | grad norm: 0.089 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27257/   51900 | consumed samples:     27911168 | elapsed time per iteration (ms): 37690.4 | learning rate: 1.083E-04 | global batch size:  1024 | lm loss: 1.846168E+00 | loss scale: 1.0 | grad norm: 0.088 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27258/   51900 | consumed samples:     27912192 | elapsed time per iteration (ms): 37679.4 | learning rate: 1.083E-04 | global batch size:  1024 | lm loss: 1.852333E+00 | loss scale: 1.0 | grad norm: 0.088 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27259/   51900 | consumed samples:     27913216 | elapsed time per iteration (ms): 37526.8 | learning rate: 1.082E-04 | global batch size:  1024 | lm loss: 1.824110E+00 | loss scale: 1.0 | grad norm: 0.093 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27260/   51900 | consumed samples:     27914240 | elapsed time per iteration (ms): 37631.0 | learning rate: 1.082E-04 | global batch size:  1024 | lm loss: 1.844017E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27261/   51900 | consumed samples:     27915264 | elapsed time per iteration (ms): 37594.8 | learning rate: 1.082E-04 | global batch size:  1024 | lm loss: 1.843654E+00 | loss scale: 1.0 | grad norm: 0.092 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27262/   51900 | consumed samples:     27916288 | elapsed time per iteration (ms): 37628.6 | learning rate: 1.082E-04 | global batch size:  1024 | lm loss: 1.856706E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27263/   51900 | consumed samples:     27917312 | elapsed time per iteration (ms): 37664.1 | learning rate: 1.082E-04 | global batch size:  1024 | lm loss: 1.836354E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27264/   51900 | consumed samples:     27918336 | elapsed time per iteration (ms): 37650.8 | learning rate: 1.082E-04 | global batch size:  1024 | lm loss: 1.828158E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27265/   51900 | consumed samples:     27919360 | elapsed time per iteration (ms): 37684.3 | learning rate: 1.082E-04 | global batch size:  1024 | lm loss: 1.845803E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27266/   51900 | consumed samples:     27920384 | elapsed time per iteration (ms): 37655.2 | learning rate: 1.082E-04 | global batch size:  1024 | lm loss: 1.826451E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27267/   51900 | consumed samples:     27921408 | elapsed time per iteration (ms): 37612.1 | learning rate: 1.082E-04 | global batch size:  1024 | lm loss: 1.856679E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27268/   51900 | consumed samples:     27922432 | elapsed time per iteration (ms): 37626.5 | learning rate: 1.082E-04 | global batch size:  1024 | lm loss: 1.857564E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27269/   51900 | consumed samples:     27923456 | elapsed time per iteration (ms): 37668.8 | learning rate: 1.082E-04 | global batch size:  1024 | lm loss: 1.870831E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27270/   51900 | consumed samples:     27924480 | elapsed time per iteration (ms): 37532.7 | learning rate: 1.082E-04 | global batch size:  1024 | lm loss: 1.830174E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27271/   51900 | consumed samples:     27925504 | elapsed time per iteration (ms): 37667.3 | learning rate: 1.082E-04 | global batch size:  1024 | lm loss: 1.846905E+00 | loss scale: 1.0 | grad norm: 0.090 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27272/   51900 | consumed samples:     27926528 | elapsed time per iteration (ms): 37609.2 | learning rate: 1.082E-04 | global batch size:  1024 | lm loss: 1.850091E+00 | loss scale: 1.0 | grad norm: 0.090 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27273/   51900 | consumed samples:     27927552 | elapsed time per iteration (ms): 37732.1 | learning rate: 1.082E-04 | global batch size:  1024 | lm loss: 1.849415E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27274/   51900 | consumed samples:     27928576 | elapsed time per iteration (ms): 37765.2 | learning rate: 1.082E-04 | global batch size:  1024 | lm loss: 1.856626E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27275/   51900 | consumed samples:     27929600 | elapsed time per iteration (ms): 37612.8 | learning rate: 1.082E-04 | global batch size:  1024 | lm loss: 1.847974E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27276/   51900 | consumed samples:     27930624 | elapsed time per iteration (ms): 37667.4 | learning rate: 1.082E-04 | global batch size:  1024 | lm loss: 1.865865E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27277/   51900 | consumed samples:     27931648 | elapsed time per iteration (ms): 37633.9 | learning rate: 1.081E-04 | global batch size:  1024 | lm loss: 1.860518E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27278/   51900 | consumed samples:     27932672 | elapsed time per iteration (ms): 37605.8 | learning rate: 1.081E-04 | global batch size:  1024 | lm loss: 1.835911E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27279/   51900 | consumed samples:     27933696 | elapsed time per iteration (ms): 37587.4 | learning rate: 1.081E-04 | global batch size:  1024 | lm loss: 1.845667E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27280/   51900 | consumed samples:     27934720 | elapsed time per iteration (ms): 37561.6 | learning rate: 1.081E-04 | global batch size:  1024 | lm loss: 1.830593E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27281/   51900 | consumed samples:     27935744 | elapsed time per iteration (ms): 37729.9 | learning rate: 1.081E-04 | global batch size:  1024 | lm loss: 1.849671E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27282/   51900 | consumed samples:     27936768 | elapsed time per iteration (ms): 37662.1 | learning rate: 1.081E-04 | global batch size:  1024 | lm loss: 1.837370E+00 | loss scale: 1.0 | grad norm: 0.102 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27283/   51900 | consumed samples:     27937792 | elapsed time per iteration (ms): 37590.3 | learning rate: 1.081E-04 | global batch size:  1024 | lm loss: 1.836627E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27284/   51900 | consumed samples:     27938816 | elapsed time per iteration (ms): 37713.1 | learning rate: 1.081E-04 | global batch size:  1024 | lm loss: 1.850325E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27285/   51900 | consumed samples:     27939840 | elapsed time per iteration (ms): 37745.1 | learning rate: 1.081E-04 | global batch size:  1024 | lm loss: 1.849561E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27286/   51900 | consumed samples:     27940864 | elapsed time per iteration (ms): 37622.8 | learning rate: 1.081E-04 | global batch size:  1024 | lm loss: 1.840033E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27287/   51900 | consumed samples:     27941888 | elapsed time per iteration (ms): 37690.1 | learning rate: 1.081E-04 | global batch size:  1024 | lm loss: 1.834317E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27288/   51900 | consumed samples:     27942912 | elapsed time per iteration (ms): 37728.8 | learning rate: 1.081E-04 | global batch size:  1024 | lm loss: 1.845143E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27289/   51900 | consumed samples:     27943936 | elapsed time per iteration (ms): 37686.5 | learning rate: 1.081E-04 | global batch size:  1024 | lm loss: 1.845629E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27290/   51900 | consumed samples:     27944960 | elapsed time per iteration (ms): 37629.3 | learning rate: 1.081E-04 | global batch size:  1024 | lm loss: 1.844386E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27291/   51900 | consumed samples:     27945984 | elapsed time per iteration (ms): 37757.8 | learning rate: 1.081E-04 | global batch size:  1024 | lm loss: 1.859207E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27292/   51900 | consumed samples:     27947008 | elapsed time per iteration (ms): 37548.7 | learning rate: 1.081E-04 | global batch size:  1024 | lm loss: 1.846689E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27293/   51900 | consumed samples:     27948032 | elapsed time per iteration (ms): 37647.5 | learning rate: 1.081E-04 | global batch size:  1024 | lm loss: 1.844771E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27294/   51900 | consumed samples:     27949056 | elapsed time per iteration (ms): 37617.5 | learning rate: 1.081E-04 | global batch size:  1024 | lm loss: 1.829992E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27295/   51900 | consumed samples:     27950080 | elapsed time per iteration (ms): 37741.3 | learning rate: 1.080E-04 | global batch size:  1024 | lm loss: 1.852484E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27296/   51900 | consumed samples:     27951104 | elapsed time per iteration (ms): 37626.5 | learning rate: 1.080E-04 | global batch size:  1024 | lm loss: 1.855773E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27297/   51900 | consumed samples:     27952128 | elapsed time per iteration (ms): 37502.7 | learning rate: 1.080E-04 | global batch size:  1024 | lm loss: 1.850757E+00 | loss scale: 1.0 | grad norm: 0.088 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27298/   51900 | consumed samples:     27953152 | elapsed time per iteration (ms): 37752.9 | learning rate: 1.080E-04 | global batch size:  1024 | lm loss: 1.843162E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27299/   51900 | consumed samples:     27954176 | elapsed time per iteration (ms): 37662.3 | learning rate: 1.080E-04 | global batch size:  1024 | lm loss: 1.832566E+00 | loss scale: 1.0 | grad norm: 0.087 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27300/   51900 | consumed samples:     27955200 | elapsed time per iteration (ms): 37638.9 | learning rate: 1.080E-04 | global batch size:  1024 | lm loss: 1.838416E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27301/   51900 | consumed samples:     27956224 | elapsed time per iteration (ms): 37601.2 | learning rate: 1.080E-04 | global batch size:  1024 | lm loss: 1.843966E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27302/   51900 | consumed samples:     27957248 | elapsed time per iteration (ms): 37711.6 | learning rate: 1.080E-04 | global batch size:  1024 | lm loss: 1.846939E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27303/   51900 | consumed samples:     27958272 | elapsed time per iteration (ms): 37556.1 | learning rate: 1.080E-04 | global batch size:  1024 | lm loss: 1.843319E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27304/   51900 | consumed samples:     27959296 | elapsed time per iteration (ms): 37668.2 | learning rate: 1.080E-04 | global batch size:  1024 | lm loss: 1.845052E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27305/   51900 | consumed samples:     27960320 | elapsed time per iteration (ms): 37661.2 | learning rate: 1.080E-04 | global batch size:  1024 | lm loss: 1.860271E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27306/   51900 | consumed samples:     27961344 | elapsed time per iteration (ms): 37664.6 | learning rate: 1.080E-04 | global batch size:  1024 | lm loss: 1.850649E+00 | loss scale: 1.0 | grad norm: 0.088 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27307/   51900 | consumed samples:     27962368 | elapsed time per iteration (ms): 37719.3 | learning rate: 1.080E-04 | global batch size:  1024 | lm loss: 1.818787E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27308/   51900 | consumed samples:     27963392 | elapsed time per iteration (ms): 37633.5 | learning rate: 1.080E-04 | global batch size:  1024 | lm loss: 1.853999E+00 | loss scale: 1.0 | grad norm: 0.090 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27309/   51900 | consumed samples:     27964416 | elapsed time per iteration (ms): 37655.2 | learning rate: 1.080E-04 | global batch size:  1024 | lm loss: 1.857547E+00 | loss scale: 1.0 | grad norm: 0.088 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27310/   51900 | consumed samples:     27965440 | elapsed time per iteration (ms): 37697.8 | learning rate: 1.080E-04 | global batch size:  1024 | lm loss: 1.837578E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27311/   51900 | consumed samples:     27966464 | elapsed time per iteration (ms): 37544.9 | learning rate: 1.080E-04 | global batch size:  1024 | lm loss: 1.836038E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27312/   51900 | consumed samples:     27967488 | elapsed time per iteration (ms): 37591.8 | learning rate: 1.079E-04 | global batch size:  1024 | lm loss: 1.854318E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27313/   51900 | consumed samples:     27968512 | elapsed time per iteration (ms): 37656.9 | learning rate: 1.079E-04 | global batch size:  1024 | lm loss: 1.870940E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27314/   51900 | consumed samples:     27969536 | elapsed time per iteration (ms): 37582.4 | learning rate: 1.079E-04 | global batch size:  1024 | lm loss: 1.841505E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27315/   51900 | consumed samples:     27970560 | elapsed time per iteration (ms): 37613.2 | learning rate: 1.079E-04 | global batch size:  1024 | lm loss: 1.849793E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27316/   51900 | consumed samples:     27971584 | elapsed time per iteration (ms): 37718.3 | learning rate: 1.079E-04 | global batch size:  1024 | lm loss: 1.857617E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27317/   51900 | consumed samples:     27972608 | elapsed time per iteration (ms): 37668.0 | learning rate: 1.079E-04 | global batch size:  1024 | lm loss: 1.847907E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27318/   51900 | consumed samples:     27973632 | elapsed time per iteration (ms): 37636.3 | learning rate: 1.079E-04 | global batch size:  1024 | lm loss: 1.852331E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27319/   51900 | consumed samples:     27974656 | elapsed time per iteration (ms): 37599.4 | learning rate: 1.079E-04 | global batch size:  1024 | lm loss: 1.847056E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27320/   51900 | consumed samples:     27975680 | elapsed time per iteration (ms): 37693.1 | learning rate: 1.079E-04 | global batch size:  1024 | lm loss: 1.857788E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27321/   51900 | consumed samples:     27976704 | elapsed time per iteration (ms): 37623.6 | learning rate: 1.079E-04 | global batch size:  1024 | lm loss: 1.846446E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27322/   51900 | consumed samples:     27977728 | elapsed time per iteration (ms): 37664.8 | learning rate: 1.079E-04 | global batch size:  1024 | lm loss: 1.852930E+00 | loss scale: 1.0 | grad norm: 0.090 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27323/   51900 | consumed samples:     27978752 | elapsed time per iteration (ms): 37643.3 | learning rate: 1.079E-04 | global batch size:  1024 | lm loss: 1.833322E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27324/   51900 | consumed samples:     27979776 | elapsed time per iteration (ms): 37587.0 | learning rate: 1.079E-04 | global batch size:  1024 | lm loss: 1.857541E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27325/   51900 | consumed samples:     27980800 | elapsed time per iteration (ms): 37741.4 | learning rate: 1.079E-04 | global batch size:  1024 | lm loss: 1.846455E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27326/   51900 | consumed samples:     27981824 | elapsed time per iteration (ms): 37592.9 | learning rate: 1.079E-04 | global batch size:  1024 | lm loss: 1.844899E+00 | loss scale: 1.0 | grad norm: 0.089 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27327/   51900 | consumed samples:     27982848 | elapsed time per iteration (ms): 37555.7 | learning rate: 1.079E-04 | global batch size:  1024 | lm loss: 1.848263E+00 | loss scale: 1.0 | grad norm: 0.089 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27328/   51900 | consumed samples:     27983872 | elapsed time per iteration (ms): 37708.4 | learning rate: 1.079E-04 | global batch size:  1024 | lm loss: 1.854240E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27329/   51900 | consumed samples:     27984896 | elapsed time per iteration (ms): 37582.4 | learning rate: 1.079E-04 | global batch size:  1024 | lm loss: 1.837265E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27330/   51900 | consumed samples:     27985920 | elapsed time per iteration (ms): 37604.0 | learning rate: 1.078E-04 | global batch size:  1024 | lm loss: 1.845757E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27331/   51900 | consumed samples:     27986944 | elapsed time per iteration (ms): 37645.2 | learning rate: 1.078E-04 | global batch size:  1024 | lm loss: 1.857351E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27332/   51900 | consumed samples:     27987968 | elapsed time per iteration (ms): 37703.4 | learning rate: 1.078E-04 | global batch size:  1024 | lm loss: 1.852194E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27333/   51900 | consumed samples:     27988992 | elapsed time per iteration (ms): 37698.7 | learning rate: 1.078E-04 | global batch size:  1024 | lm loss: 1.836805E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27334/   51900 | consumed samples:     27990016 | elapsed time per iteration (ms): 37639.6 | learning rate: 1.078E-04 | global batch size:  1024 | lm loss: 1.848431E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27335/   51900 | consumed samples:     27991040 | elapsed time per iteration (ms): 37678.5 | learning rate: 1.078E-04 | global batch size:  1024 | lm loss: 1.834747E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27336/   51900 | consumed samples:     27992064 | elapsed time per iteration (ms): 37592.8 | learning rate: 1.078E-04 | global batch size:  1024 | lm loss: 1.850312E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27337/   51900 | consumed samples:     27993088 | elapsed time per iteration (ms): 37597.1 | learning rate: 1.078E-04 | global batch size:  1024 | lm loss: 1.842863E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27338/   51900 | consumed samples:     27994112 | elapsed time per iteration (ms): 37572.3 | learning rate: 1.078E-04 | global batch size:  1024 | lm loss: 1.822349E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27339/   51900 | consumed samples:     27995136 | elapsed time per iteration (ms): 37710.6 | learning rate: 1.078E-04 | global batch size:  1024 | lm loss: 1.855964E+00 | loss scale: 1.0 | grad norm: 0.094 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27340/   51900 | consumed samples:     27996160 | elapsed time per iteration (ms): 37710.2 | learning rate: 1.078E-04 | global batch size:  1024 | lm loss: 1.846214E+00 | loss scale: 1.0 | grad norm: 0.087 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27341/   51900 | consumed samples:     27997184 | elapsed time per iteration (ms): 37645.0 | learning rate: 1.078E-04 | global batch size:  1024 | lm loss: 1.859671E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27342/   51900 | consumed samples:     27998208 | elapsed time per iteration (ms): 37711.4 | learning rate: 1.078E-04 | global batch size:  1024 | lm loss: 1.855529E+00 | loss scale: 1.0 | grad norm: 0.087 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27343/   51900 | consumed samples:     27999232 | elapsed time per iteration (ms): 37674.1 | learning rate: 1.078E-04 | global batch size:  1024 | lm loss: 1.833180E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27344/   51900 | consumed samples:     28000256 | elapsed time per iteration (ms): 37681.2 | learning rate: 1.078E-04 | global batch size:  1024 | lm loss: 1.850318E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27345/   51900 | consumed samples:     28001280 | elapsed time per iteration (ms): 37678.6 | learning rate: 1.078E-04 | global batch size:  1024 | lm loss: 1.827922E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27346/   51900 | consumed samples:     28002304 | elapsed time per iteration (ms): 37648.9 | learning rate: 1.078E-04 | global batch size:  1024 | lm loss: 1.842977E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27347/   51900 | consumed samples:     28003328 | elapsed time per iteration (ms): 37657.7 | learning rate: 1.078E-04 | global batch size:  1024 | lm loss: 1.841426E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27348/   51900 | consumed samples:     28004352 | elapsed time per iteration (ms): 37751.4 | learning rate: 1.077E-04 | global batch size:  1024 | lm loss: 1.857243E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27349/   51900 | consumed samples:     28005376 | elapsed time per iteration (ms): 37588.2 | learning rate: 1.077E-04 | global batch size:  1024 | lm loss: 1.840043E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27350/   51900 | consumed samples:     28006400 | elapsed time per iteration (ms): 37630.2 | learning rate: 1.077E-04 | global batch size:  1024 | lm loss: 1.840729E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27351/   51900 | consumed samples:     28007424 | elapsed time per iteration (ms): 37698.5 | learning rate: 1.077E-04 | global batch size:  1024 | lm loss: 1.851273E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27352/   51900 | consumed samples:     28008448 | elapsed time per iteration (ms): 37613.4 | learning rate: 1.077E-04 | global batch size:  1024 | lm loss: 1.846731E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27353/   51900 | consumed samples:     28009472 | elapsed time per iteration (ms): 37631.9 | learning rate: 1.077E-04 | global batch size:  1024 | lm loss: 1.828024E+00 | loss scale: 1.0 | grad norm: 0.099 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27354/   51900 | consumed samples:     28010496 | elapsed time per iteration (ms): 37764.2 | learning rate: 1.077E-04 | global batch size:  1024 | lm loss: 1.844303E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27355/   51900 | consumed samples:     28011520 | elapsed time per iteration (ms): 37547.3 | learning rate: 1.077E-04 | global batch size:  1024 | lm loss: 1.837033E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27356/   51900 | consumed samples:     28012544 | elapsed time per iteration (ms): 37703.3 | learning rate: 1.077E-04 | global batch size:  1024 | lm loss: 1.854177E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27357/   51900 | consumed samples:     28013568 | elapsed time per iteration (ms): 37612.6 | learning rate: 1.077E-04 | global batch size:  1024 | lm loss: 1.860216E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27358/   51900 | consumed samples:     28014592 | elapsed time per iteration (ms): 37616.9 | learning rate: 1.077E-04 | global batch size:  1024 | lm loss: 1.846885E+00 | loss scale: 1.0 | grad norm: 0.090 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27359/   51900 | consumed samples:     28015616 | elapsed time per iteration (ms): 37644.0 | learning rate: 1.077E-04 | global batch size:  1024 | lm loss: 1.842047E+00 | loss scale: 1.0 | grad norm: 0.087 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27360/   51900 | consumed samples:     28016640 | elapsed time per iteration (ms): 37627.0 | learning rate: 1.077E-04 | global batch size:  1024 | lm loss: 1.849835E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27361/   51900 | consumed samples:     28017664 | elapsed time per iteration (ms): 37652.5 | learning rate: 1.077E-04 | global batch size:  1024 | lm loss: 1.831930E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27362/   51900 | consumed samples:     28018688 | elapsed time per iteration (ms): 37737.7 | learning rate: 1.077E-04 | global batch size:  1024 | lm loss: 1.849864E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27363/   51900 | consumed samples:     28019712 | elapsed time per iteration (ms): 37625.4 | learning rate: 1.077E-04 | global batch size:  1024 | lm loss: 1.873918E+00 | loss scale: 1.0 | grad norm: 0.093 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27364/   51900 | consumed samples:     28020736 | elapsed time per iteration (ms): 37752.8 | learning rate: 1.077E-04 | global batch size:  1024 | lm loss: 1.838152E+00 | loss scale: 1.0 | grad norm: 0.130 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27365/   51900 | consumed samples:     28021760 | elapsed time per iteration (ms): 37661.9 | learning rate: 1.076E-04 | global batch size:  1024 | lm loss: 1.848209E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27366/   51900 | consumed samples:     28022784 | elapsed time per iteration (ms): 37623.3 | learning rate: 1.076E-04 | global batch size:  1024 | lm loss: 1.838050E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27367/   51900 | consumed samples:     28023808 | elapsed time per iteration (ms): 37656.2 | learning rate: 1.076E-04 | global batch size:  1024 | lm loss: 1.837029E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27368/   51900 | consumed samples:     28024832 | elapsed time per iteration (ms): 37608.5 | learning rate: 1.076E-04 | global batch size:  1024 | lm loss: 1.849473E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27369/   51900 | consumed samples:     28025856 | elapsed time per iteration (ms): 37659.6 | learning rate: 1.076E-04 | global batch size:  1024 | lm loss: 1.841427E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27370/   51900 | consumed samples:     28026880 | elapsed time per iteration (ms): 37783.3 | learning rate: 1.076E-04 | global batch size:  1024 | lm loss: 1.844721E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27371/   51900 | consumed samples:     28027904 | elapsed time per iteration (ms): 37632.2 | learning rate: 1.076E-04 | global batch size:  1024 | lm loss: 1.849711E+00 | loss scale: 1.0 | grad norm: 0.093 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27372/   51900 | consumed samples:     28028928 | elapsed time per iteration (ms): 37604.6 | learning rate: 1.076E-04 | global batch size:  1024 | lm loss: 1.845683E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27373/   51900 | consumed samples:     28029952 | elapsed time per iteration (ms): 37597.8 | learning rate: 1.076E-04 | global batch size:  1024 | lm loss: 1.834303E+00 | loss scale: 1.0 | grad norm: 0.089 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27374/   51900 | consumed samples:     28030976 | elapsed time per iteration (ms): 37602.4 | learning rate: 1.076E-04 | global batch size:  1024 | lm loss: 1.848228E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27375/   51900 | consumed samples:     28032000 | elapsed time per iteration (ms): 37705.6 | learning rate: 1.076E-04 | global batch size:  1024 | lm loss: 1.834379E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27376/   51900 | consumed samples:     28033024 | elapsed time per iteration (ms): 37786.6 | learning rate: 1.076E-04 | global batch size:  1024 | lm loss: 1.845828E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27377/   51900 | consumed samples:     28034048 | elapsed time per iteration (ms): 37661.7 | learning rate: 1.076E-04 | global batch size:  1024 | lm loss: 1.867060E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27378/   51900 | consumed samples:     28035072 | elapsed time per iteration (ms): 37768.9 | learning rate: 1.076E-04 | global batch size:  1024 | lm loss: 1.838753E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27379/   51900 | consumed samples:     28036096 | elapsed time per iteration (ms): 37668.2 | learning rate: 1.076E-04 | global batch size:  1024 | lm loss: 1.838006E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27380/   51900 | consumed samples:     28037120 | elapsed time per iteration (ms): 37563.8 | learning rate: 1.076E-04 | global batch size:  1024 | lm loss: 1.856491E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27381/   51900 | consumed samples:     28038144 | elapsed time per iteration (ms): 37631.5 | learning rate: 1.076E-04 | global batch size:  1024 | lm loss: 1.846072E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27382/   51900 | consumed samples:     28039168 | elapsed time per iteration (ms): 37553.2 | learning rate: 1.076E-04 | global batch size:  1024 | lm loss: 1.852574E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27383/   51900 | consumed samples:     28040192 | elapsed time per iteration (ms): 37639.8 | learning rate: 1.075E-04 | global batch size:  1024 | lm loss: 1.851222E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27384/   51900 | consumed samples:     28041216 | elapsed time per iteration (ms): 37568.8 | learning rate: 1.075E-04 | global batch size:  1024 | lm loss: 1.847410E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27385/   51900 | consumed samples:     28042240 | elapsed time per iteration (ms): 37563.0 | learning rate: 1.075E-04 | global batch size:  1024 | lm loss: 1.845222E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27386/   51900 | consumed samples:     28043264 | elapsed time per iteration (ms): 37668.0 | learning rate: 1.075E-04 | global batch size:  1024 | lm loss: 1.851078E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27387/   51900 | consumed samples:     28044288 | elapsed time per iteration (ms): 37707.9 | learning rate: 1.075E-04 | global batch size:  1024 | lm loss: 1.839928E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27388/   51900 | consumed samples:     28045312 | elapsed time per iteration (ms): 37684.9 | learning rate: 1.075E-04 | global batch size:  1024 | lm loss: 1.852293E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27389/   51900 | consumed samples:     28046336 | elapsed time per iteration (ms): 37633.8 | learning rate: 1.075E-04 | global batch size:  1024 | lm loss: 1.854725E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27390/   51900 | consumed samples:     28047360 | elapsed time per iteration (ms): 37666.0 | learning rate: 1.075E-04 | global batch size:  1024 | lm loss: 1.851398E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27391/   51900 | consumed samples:     28048384 | elapsed time per iteration (ms): 37630.2 | learning rate: 1.075E-04 | global batch size:  1024 | lm loss: 1.853335E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27392/   51900 | consumed samples:     28049408 | elapsed time per iteration (ms): 37564.6 | learning rate: 1.075E-04 | global batch size:  1024 | lm loss: 1.836163E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27393/   51900 | consumed samples:     28050432 | elapsed time per iteration (ms): 37658.9 | learning rate: 1.075E-04 | global batch size:  1024 | lm loss: 1.842871E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27394/   51900 | consumed samples:     28051456 | elapsed time per iteration (ms): 37628.3 | learning rate: 1.075E-04 | global batch size:  1024 | lm loss: 1.838489E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27395/   51900 | consumed samples:     28052480 | elapsed time per iteration (ms): 37588.5 | learning rate: 1.075E-04 | global batch size:  1024 | lm loss: 1.855865E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27396/   51900 | consumed samples:     28053504 | elapsed time per iteration (ms): 37694.1 | learning rate: 1.075E-04 | global batch size:  1024 | lm loss: 1.852314E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27397/   51900 | consumed samples:     28054528 | elapsed time per iteration (ms): 37614.2 | learning rate: 1.075E-04 | global batch size:  1024 | lm loss: 1.843502E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27398/   51900 | consumed samples:     28055552 | elapsed time per iteration (ms): 37699.4 | learning rate: 1.075E-04 | global batch size:  1024 | lm loss: 1.855745E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27399/   51900 | consumed samples:     28056576 | elapsed time per iteration (ms): 37572.2 | learning rate: 1.075E-04 | global batch size:  1024 | lm loss: 1.851696E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27400/   51900 | consumed samples:     28057600 | elapsed time per iteration (ms): 37540.1 | learning rate: 1.075E-04 | global batch size:  1024 | lm loss: 1.864973E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27401/   51900 | consumed samples:     28058624 | elapsed time per iteration (ms): 37658.0 | learning rate: 1.074E-04 | global batch size:  1024 | lm loss: 1.840753E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27402/   51900 | consumed samples:     28059648 | elapsed time per iteration (ms): 37675.2 | learning rate: 1.074E-04 | global batch size:  1024 | lm loss: 1.856987E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27403/   51900 | consumed samples:     28060672 | elapsed time per iteration (ms): 37761.2 | learning rate: 1.074E-04 | global batch size:  1024 | lm loss: 1.838298E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27404/   51900 | consumed samples:     28061696 | elapsed time per iteration (ms): 37798.1 | learning rate: 1.074E-04 | global batch size:  1024 | lm loss: 1.839831E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27405/   51900 | consumed samples:     28062720 | elapsed time per iteration (ms): 37523.5 | learning rate: 1.074E-04 | global batch size:  1024 | lm loss: 1.855495E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27406/   51900 | consumed samples:     28063744 | elapsed time per iteration (ms): 37615.6 | learning rate: 1.074E-04 | global batch size:  1024 | lm loss: 1.846104E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27407/   51900 | consumed samples:     28064768 | elapsed time per iteration (ms): 37591.2 | learning rate: 1.074E-04 | global batch size:  1024 | lm loss: 1.840411E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27408/   51900 | consumed samples:     28065792 | elapsed time per iteration (ms): 37683.7 | learning rate: 1.074E-04 | global batch size:  1024 | lm loss: 1.846652E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27409/   51900 | consumed samples:     28066816 | elapsed time per iteration (ms): 37641.8 | learning rate: 1.074E-04 | global batch size:  1024 | lm loss: 1.850424E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27410/   51900 | consumed samples:     28067840 | elapsed time per iteration (ms): 37603.4 | learning rate: 1.074E-04 | global batch size:  1024 | lm loss: 1.846014E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27411/   51900 | consumed samples:     28068864 | elapsed time per iteration (ms): 37638.5 | learning rate: 1.074E-04 | global batch size:  1024 | lm loss: 1.850106E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27412/   51900 | consumed samples:     28069888 | elapsed time per iteration (ms): 37570.4 | learning rate: 1.074E-04 | global batch size:  1024 | lm loss: 1.839929E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27413/   51900 | consumed samples:     28070912 | elapsed time per iteration (ms): 37661.3 | learning rate: 1.074E-04 | global batch size:  1024 | lm loss: 1.856888E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27414/   51900 | consumed samples:     28071936 | elapsed time per iteration (ms): 37525.6 | learning rate: 1.074E-04 | global batch size:  1024 | lm loss: 1.829111E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27415/   51900 | consumed samples:     28072960 | elapsed time per iteration (ms): 37740.7 | learning rate: 1.074E-04 | global batch size:  1024 | lm loss: 1.856081E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27416/   51900 | consumed samples:     28073984 | elapsed time per iteration (ms): 37664.4 | learning rate: 1.074E-04 | global batch size:  1024 | lm loss: 1.835958E+00 | loss scale: 1.0 | grad norm: 0.087 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27417/   51900 | consumed samples:     28075008 | elapsed time per iteration (ms): 37650.8 | learning rate: 1.074E-04 | global batch size:  1024 | lm loss: 1.835485E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27418/   51900 | consumed samples:     28076032 | elapsed time per iteration (ms): 37534.5 | learning rate: 1.073E-04 | global batch size:  1024 | lm loss: 1.836166E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27419/   51900 | consumed samples:     28077056 | elapsed time per iteration (ms): 37633.2 | learning rate: 1.073E-04 | global batch size:  1024 | lm loss: 1.844673E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27420/   51900 | consumed samples:     28078080 | elapsed time per iteration (ms): 37565.1 | learning rate: 1.073E-04 | global batch size:  1024 | lm loss: 1.845873E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27421/   51900 | consumed samples:     28079104 | elapsed time per iteration (ms): 37751.4 | learning rate: 1.073E-04 | global batch size:  1024 | lm loss: 1.851332E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27422/   51900 | consumed samples:     28080128 | elapsed time per iteration (ms): 37676.4 | learning rate: 1.073E-04 | global batch size:  1024 | lm loss: 1.836080E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27423/   51900 | consumed samples:     28081152 | elapsed time per iteration (ms): 37649.7 | learning rate: 1.073E-04 | global batch size:  1024 | lm loss: 1.845645E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27424/   51900 | consumed samples:     28082176 | elapsed time per iteration (ms): 37677.5 | learning rate: 1.073E-04 | global batch size:  1024 | lm loss: 1.836967E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27425/   51900 | consumed samples:     28083200 | elapsed time per iteration (ms): 37554.2 | learning rate: 1.073E-04 | global batch size:  1024 | lm loss: 1.863587E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27426/   51900 | consumed samples:     28084224 | elapsed time per iteration (ms): 37659.3 | learning rate: 1.073E-04 | global batch size:  1024 | lm loss: 1.845929E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27427/   51900 | consumed samples:     28085248 | elapsed time per iteration (ms): 37661.9 | learning rate: 1.073E-04 | global batch size:  1024 | lm loss: 1.847338E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27428/   51900 | consumed samples:     28086272 | elapsed time per iteration (ms): 37666.9 | learning rate: 1.073E-04 | global batch size:  1024 | lm loss: 1.860310E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27429/   51900 | consumed samples:     28087296 | elapsed time per iteration (ms): 37794.1 | learning rate: 1.073E-04 | global batch size:  1024 | lm loss: 1.854251E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27430/   51900 | consumed samples:     28088320 | elapsed time per iteration (ms): 37618.4 | learning rate: 1.073E-04 | global batch size:  1024 | lm loss: 1.847460E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27431/   51900 | consumed samples:     28089344 | elapsed time per iteration (ms): 37688.0 | learning rate: 1.073E-04 | global batch size:  1024 | lm loss: 1.851745E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27432/   51900 | consumed samples:     28090368 | elapsed time per iteration (ms): 37736.3 | learning rate: 1.073E-04 | global batch size:  1024 | lm loss: 1.849265E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27433/   51900 | consumed samples:     28091392 | elapsed time per iteration (ms): 37644.8 | learning rate: 1.073E-04 | global batch size:  1024 | lm loss: 1.853401E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27434/   51900 | consumed samples:     28092416 | elapsed time per iteration (ms): 37662.2 | learning rate: 1.073E-04 | global batch size:  1024 | lm loss: 1.849541E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27435/   51900 | consumed samples:     28093440 | elapsed time per iteration (ms): 37701.5 | learning rate: 1.073E-04 | global batch size:  1024 | lm loss: 1.849275E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27436/   51900 | consumed samples:     28094464 | elapsed time per iteration (ms): 37717.7 | learning rate: 1.072E-04 | global batch size:  1024 | lm loss: 1.840484E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27437/   51900 | consumed samples:     28095488 | elapsed time per iteration (ms): 37664.5 | learning rate: 1.072E-04 | global batch size:  1024 | lm loss: 1.845042E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27438/   51900 | consumed samples:     28096512 | elapsed time per iteration (ms): 37633.6 | learning rate: 1.072E-04 | global batch size:  1024 | lm loss: 1.865338E+00 | loss scale: 1.0 | grad norm: 0.351 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27439/   51900 | consumed samples:     28097536 | elapsed time per iteration (ms): 37623.8 | learning rate: 1.072E-04 | global batch size:  1024 | lm loss: 1.854715E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27440/   51900 | consumed samples:     28098560 | elapsed time per iteration (ms): 37597.3 | learning rate: 1.072E-04 | global batch size:  1024 | lm loss: 1.855730E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27441/   51900 | consumed samples:     28099584 | elapsed time per iteration (ms): 37618.9 | learning rate: 1.072E-04 | global batch size:  1024 | lm loss: 1.856721E+00 | loss scale: 1.0 | grad norm: 0.098 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27442/   51900 | consumed samples:     28100608 | elapsed time per iteration (ms): 37739.3 | learning rate: 1.072E-04 | global batch size:  1024 | lm loss: 1.855201E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27443/   51900 | consumed samples:     28101632 | elapsed time per iteration (ms): 37707.6 | learning rate: 1.072E-04 | global batch size:  1024 | lm loss: 1.821422E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27444/   51900 | consumed samples:     28102656 | elapsed time per iteration (ms): 37570.0 | learning rate: 1.072E-04 | global batch size:  1024 | lm loss: 1.833630E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27445/   51900 | consumed samples:     28103680 | elapsed time per iteration (ms): 37741.4 | learning rate: 1.072E-04 | global batch size:  1024 | lm loss: 1.845098E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27446/   51900 | consumed samples:     28104704 | elapsed time per iteration (ms): 37639.0 | learning rate: 1.072E-04 | global batch size:  1024 | lm loss: 1.866224E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27447/   51900 | consumed samples:     28105728 | elapsed time per iteration (ms): 37624.0 | learning rate: 1.072E-04 | global batch size:  1024 | lm loss: 1.847452E+00 | loss scale: 1.0 | grad norm: 0.101 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27448/   51900 | consumed samples:     28106752 | elapsed time per iteration (ms): 37726.2 | learning rate: 1.072E-04 | global batch size:  1024 | lm loss: 1.846811E+00 | loss scale: 1.0 | grad norm: 0.097 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27449/   51900 | consumed samples:     28107776 | elapsed time per iteration (ms): 37681.4 | learning rate: 1.072E-04 | global batch size:  1024 | lm loss: 1.832517E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27450/   51900 | consumed samples:     28108800 | elapsed time per iteration (ms): 37727.4 | learning rate: 1.072E-04 | global batch size:  1024 | lm loss: 1.853094E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27451/   51900 | consumed samples:     28109824 | elapsed time per iteration (ms): 37718.9 | learning rate: 1.072E-04 | global batch size:  1024 | lm loss: 1.846943E+00 | loss scale: 1.0 | grad norm: 0.088 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27452/   51900 | consumed samples:     28110848 | elapsed time per iteration (ms): 37573.3 | learning rate: 1.072E-04 | global batch size:  1024 | lm loss: 1.845457E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27453/   51900 | consumed samples:     28111872 | elapsed time per iteration (ms): 37670.1 | learning rate: 1.072E-04 | global batch size:  1024 | lm loss: 1.838432E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27454/   51900 | consumed samples:     28112896 | elapsed time per iteration (ms): 37693.0 | learning rate: 1.071E-04 | global batch size:  1024 | lm loss: 1.836671E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27455/   51900 | consumed samples:     28113920 | elapsed time per iteration (ms): 37714.2 | learning rate: 1.071E-04 | global batch size:  1024 | lm loss: 1.840172E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27456/   51900 | consumed samples:     28114944 | elapsed time per iteration (ms): 37786.4 | learning rate: 1.071E-04 | global batch size:  1024 | lm loss: 1.860482E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27457/   51900 | consumed samples:     28115968 | elapsed time per iteration (ms): 37609.2 | learning rate: 1.071E-04 | global batch size:  1024 | lm loss: 1.844558E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27458/   51900 | consumed samples:     28116992 | elapsed time per iteration (ms): 37701.7 | learning rate: 1.071E-04 | global batch size:  1024 | lm loss: 1.828176E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27459/   51900 | consumed samples:     28118016 | elapsed time per iteration (ms): 37607.5 | learning rate: 1.071E-04 | global batch size:  1024 | lm loss: 1.847029E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27460/   51900 | consumed samples:     28119040 | elapsed time per iteration (ms): 37651.6 | learning rate: 1.071E-04 | global batch size:  1024 | lm loss: 1.845502E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27461/   51900 | consumed samples:     28120064 | elapsed time per iteration (ms): 37596.1 | learning rate: 1.071E-04 | global batch size:  1024 | lm loss: 1.843822E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27462/   51900 | consumed samples:     28121088 | elapsed time per iteration (ms): 37656.1 | learning rate: 1.071E-04 | global batch size:  1024 | lm loss: 1.842722E+00 | loss scale: 1.0 | grad norm: 0.090 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27463/   51900 | consumed samples:     28122112 | elapsed time per iteration (ms): 37658.8 | learning rate: 1.071E-04 | global batch size:  1024 | lm loss: 1.846171E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27464/   51900 | consumed samples:     28123136 | elapsed time per iteration (ms): 37748.4 | learning rate: 1.071E-04 | global batch size:  1024 | lm loss: 1.827970E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27465/   51900 | consumed samples:     28124160 | elapsed time per iteration (ms): 37758.3 | learning rate: 1.071E-04 | global batch size:  1024 | lm loss: 1.837135E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27466/   51900 | consumed samples:     28125184 | elapsed time per iteration (ms): 37700.0 | learning rate: 1.071E-04 | global batch size:  1024 | lm loss: 1.843092E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27467/   51900 | consumed samples:     28126208 | elapsed time per iteration (ms): 37575.4 | learning rate: 1.071E-04 | global batch size:  1024 | lm loss: 1.846570E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27468/   51900 | consumed samples:     28127232 | elapsed time per iteration (ms): 37571.3 | learning rate: 1.071E-04 | global batch size:  1024 | lm loss: 1.833497E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27469/   51900 | consumed samples:     28128256 | elapsed time per iteration (ms): 37642.2 | learning rate: 1.071E-04 | global batch size:  1024 | lm loss: 1.852416E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27470/   51900 | consumed samples:     28129280 | elapsed time per iteration (ms): 37659.8 | learning rate: 1.071E-04 | global batch size:  1024 | lm loss: 1.844353E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27471/   51900 | consumed samples:     28130304 | elapsed time per iteration (ms): 37690.5 | learning rate: 1.070E-04 | global batch size:  1024 | lm loss: 1.870676E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27472/   51900 | consumed samples:     28131328 | elapsed time per iteration (ms): 37711.5 | learning rate: 1.070E-04 | global batch size:  1024 | lm loss: 1.838073E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27473/   51900 | consumed samples:     28132352 | elapsed time per iteration (ms): 37683.7 | learning rate: 1.070E-04 | global batch size:  1024 | lm loss: 1.839274E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27474/   51900 | consumed samples:     28133376 | elapsed time per iteration (ms): 37768.3 | learning rate: 1.070E-04 | global batch size:  1024 | lm loss: 1.847943E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27475/   51900 | consumed samples:     28134400 | elapsed time per iteration (ms): 37664.6 | learning rate: 1.070E-04 | global batch size:  1024 | lm loss: 1.852457E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27476/   51900 | consumed samples:     28135424 | elapsed time per iteration (ms): 37646.2 | learning rate: 1.070E-04 | global batch size:  1024 | lm loss: 1.847541E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27477/   51900 | consumed samples:     28136448 | elapsed time per iteration (ms): 37621.5 | learning rate: 1.070E-04 | global batch size:  1024 | lm loss: 1.839783E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27478/   51900 | consumed samples:     28137472 | elapsed time per iteration (ms): 37583.4 | learning rate: 1.070E-04 | global batch size:  1024 | lm loss: 1.849346E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27479/   51900 | consumed samples:     28138496 | elapsed time per iteration (ms): 37668.3 | learning rate: 1.070E-04 | global batch size:  1024 | lm loss: 1.878980E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27480/   51900 | consumed samples:     28139520 | elapsed time per iteration (ms): 37577.1 | learning rate: 1.070E-04 | global batch size:  1024 | lm loss: 1.849674E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27481/   51900 | consumed samples:     28140544 | elapsed time per iteration (ms): 37728.3 | learning rate: 1.070E-04 | global batch size:  1024 | lm loss: 1.838983E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27482/   51900 | consumed samples:     28141568 | elapsed time per iteration (ms): 37660.8 | learning rate: 1.070E-04 | global batch size:  1024 | lm loss: 1.838259E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27483/   51900 | consumed samples:     28142592 | elapsed time per iteration (ms): 37672.0 | learning rate: 1.070E-04 | global batch size:  1024 | lm loss: 1.844853E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27484/   51900 | consumed samples:     28143616 | elapsed time per iteration (ms): 37786.9 | learning rate: 1.070E-04 | global batch size:  1024 | lm loss: 1.837352E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27485/   51900 | consumed samples:     28144640 | elapsed time per iteration (ms): 37683.3 | learning rate: 1.070E-04 | global batch size:  1024 | lm loss: 1.830755E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27486/   51900 | consumed samples:     28145664 | elapsed time per iteration (ms): 37642.6 | learning rate: 1.070E-04 | global batch size:  1024 | lm loss: 1.864767E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27487/   51900 | consumed samples:     28146688 | elapsed time per iteration (ms): 37669.4 | learning rate: 1.070E-04 | global batch size:  1024 | lm loss: 1.855481E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27488/   51900 | consumed samples:     28147712 | elapsed time per iteration (ms): 37735.0 | learning rate: 1.070E-04 | global batch size:  1024 | lm loss: 1.849947E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27489/   51900 | consumed samples:     28148736 | elapsed time per iteration (ms): 37570.6 | learning rate: 1.069E-04 | global batch size:  1024 | lm loss: 1.852103E+00 | loss scale: 1.0 | grad norm: 0.087 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27490/   51900 | consumed samples:     28149760 | elapsed time per iteration (ms): 37560.5 | learning rate: 1.069E-04 | global batch size:  1024 | lm loss: 1.825674E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27491/   51900 | consumed samples:     28150784 | elapsed time per iteration (ms): 37654.3 | learning rate: 1.069E-04 | global batch size:  1024 | lm loss: 1.865504E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27492/   51900 | consumed samples:     28151808 | elapsed time per iteration (ms): 37728.1 | learning rate: 1.069E-04 | global batch size:  1024 | lm loss: 1.833763E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27493/   51900 | consumed samples:     28152832 | elapsed time per iteration (ms): 37679.9 | learning rate: 1.069E-04 | global batch size:  1024 | lm loss: 1.852343E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27494/   51900 | consumed samples:     28153856 | elapsed time per iteration (ms): 37722.8 | learning rate: 1.069E-04 | global batch size:  1024 | lm loss: 1.835518E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27495/   51900 | consumed samples:     28154880 | elapsed time per iteration (ms): 37681.8 | learning rate: 1.069E-04 | global batch size:  1024 | lm loss: 1.854917E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27496/   51900 | consumed samples:     28155904 | elapsed time per iteration (ms): 37665.2 | learning rate: 1.069E-04 | global batch size:  1024 | lm loss: 1.854828E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27497/   51900 | consumed samples:     28156928 | elapsed time per iteration (ms): 37501.0 | learning rate: 1.069E-04 | global batch size:  1024 | lm loss: 1.848927E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27498/   51900 | consumed samples:     28157952 | elapsed time per iteration (ms): 37693.1 | learning rate: 1.069E-04 | global batch size:  1024 | lm loss: 1.852976E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27499/   51900 | consumed samples:     28158976 | elapsed time per iteration (ms): 37622.5 | learning rate: 1.069E-04 | global batch size:  1024 | lm loss: 1.850235E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27500/   51900 | consumed samples:     28160000 | elapsed time per iteration (ms): 37682.6 | learning rate: 1.069E-04 | global batch size:  1024 | lm loss: 1.845592E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    save-checkpoint ................................: (176070.71, 176070.82)
 iteration    27501/   51900 | consumed samples:     28161024 | elapsed time per iteration (ms): 37312.9 | learning rate: 1.069E-04 | global batch size:  1024 | lm loss: 1.851276E+00 | loss scale: 1.0 | grad norm: 0.092 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27502/   51900 | consumed samples:     28162048 | elapsed time per iteration (ms): 37683.4 | learning rate: 1.069E-04 | global batch size:  1024 | lm loss: 1.868128E+00 | loss scale: 1.0 | grad norm: 0.094 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27503/   51900 | consumed samples:     28163072 | elapsed time per iteration (ms): 37623.9 | learning rate: 1.069E-04 | global batch size:  1024 | lm loss: 1.839502E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27504/   51900 | consumed samples:     28164096 | elapsed time per iteration (ms): 37550.3 | learning rate: 1.069E-04 | global batch size:  1024 | lm loss: 1.857527E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27505/   51900 | consumed samples:     28165120 | elapsed time per iteration (ms): 37655.5 | learning rate: 1.069E-04 | global batch size:  1024 | lm loss: 1.839053E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27506/   51900 | consumed samples:     28166144 | elapsed time per iteration (ms): 37665.0 | learning rate: 1.069E-04 | global batch size:  1024 | lm loss: 1.850546E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27507/   51900 | consumed samples:     28167168 | elapsed time per iteration (ms): 37701.8 | learning rate: 1.068E-04 | global batch size:  1024 | lm loss: 1.852589E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27508/   51900 | consumed samples:     28168192 | elapsed time per iteration (ms): 37634.8 | learning rate: 1.068E-04 | global batch size:  1024 | lm loss: 1.853336E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27509/   51900 | consumed samples:     28169216 | elapsed time per iteration (ms): 37658.8 | learning rate: 1.068E-04 | global batch size:  1024 | lm loss: 1.865523E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27510/   51900 | consumed samples:     28170240 | elapsed time per iteration (ms): 37719.9 | learning rate: 1.068E-04 | global batch size:  1024 | lm loss: 1.852160E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27511/   51900 | consumed samples:     28171264 | elapsed time per iteration (ms): 37585.9 | learning rate: 1.068E-04 | global batch size:  1024 | lm loss: 1.851651E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27512/   51900 | consumed samples:     28172288 | elapsed time per iteration (ms): 37572.5 | learning rate: 1.068E-04 | global batch size:  1024 | lm loss: 1.847324E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27513/   51900 | consumed samples:     28173312 | elapsed time per iteration (ms): 37586.5 | learning rate: 1.068E-04 | global batch size:  1024 | lm loss: 1.836147E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27514/   51900 | consumed samples:     28174336 | elapsed time per iteration (ms): 37511.7 | learning rate: 1.068E-04 | global batch size:  1024 | lm loss: 1.850632E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27515/   51900 | consumed samples:     28175360 | elapsed time per iteration (ms): 37610.6 | learning rate: 1.068E-04 | global batch size:  1024 | lm loss: 1.843529E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27516/   51900 | consumed samples:     28176384 | elapsed time per iteration (ms): 37715.5 | learning rate: 1.068E-04 | global batch size:  1024 | lm loss: 1.839711E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27517/   51900 | consumed samples:     28177408 | elapsed time per iteration (ms): 37754.8 | learning rate: 1.068E-04 | global batch size:  1024 | lm loss: 1.828949E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27518/   51900 | consumed samples:     28178432 | elapsed time per iteration (ms): 37588.8 | learning rate: 1.068E-04 | global batch size:  1024 | lm loss: 1.845819E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27519/   51900 | consumed samples:     28179456 | elapsed time per iteration (ms): 37735.4 | learning rate: 1.068E-04 | global batch size:  1024 | lm loss: 1.829361E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27520/   51900 | consumed samples:     28180480 | elapsed time per iteration (ms): 37673.7 | learning rate: 1.068E-04 | global batch size:  1024 | lm loss: 1.833965E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27521/   51900 | consumed samples:     28181504 | elapsed time per iteration (ms): 37613.9 | learning rate: 1.068E-04 | global batch size:  1024 | lm loss: 1.858325E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27522/   51900 | consumed samples:     28182528 | elapsed time per iteration (ms): 37621.5 | learning rate: 1.068E-04 | global batch size:  1024 | lm loss: 1.839974E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27523/   51900 | consumed samples:     28183552 | elapsed time per iteration (ms): 37590.0 | learning rate: 1.068E-04 | global batch size:  1024 | lm loss: 1.851666E+00 | loss scale: 1.0 | grad norm: 0.230 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27524/   51900 | consumed samples:     28184576 | elapsed time per iteration (ms): 37604.8 | learning rate: 1.067E-04 | global batch size:  1024 | lm loss: 1.852767E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27525/   51900 | consumed samples:     28185600 | elapsed time per iteration (ms): 37624.4 | learning rate: 1.067E-04 | global batch size:  1024 | lm loss: 1.840733E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27526/   51900 | consumed samples:     28186624 | elapsed time per iteration (ms): 37709.2 | learning rate: 1.067E-04 | global batch size:  1024 | lm loss: 1.856760E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27527/   51900 | consumed samples:     28187648 | elapsed time per iteration (ms): 37496.2 | learning rate: 1.067E-04 | global batch size:  1024 | lm loss: 1.861318E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27528/   51900 | consumed samples:     28188672 | elapsed time per iteration (ms): 37560.5 | learning rate: 1.067E-04 | global batch size:  1024 | lm loss: 1.839588E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27529/   51900 | consumed samples:     28189696 | elapsed time per iteration (ms): 37659.5 | learning rate: 1.067E-04 | global batch size:  1024 | lm loss: 1.845723E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27530/   51900 | consumed samples:     28190720 | elapsed time per iteration (ms): 37492.5 | learning rate: 1.067E-04 | global batch size:  1024 | lm loss: 1.849483E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27531/   51900 | consumed samples:     28191744 | elapsed time per iteration (ms): 37657.3 | learning rate: 1.067E-04 | global batch size:  1024 | lm loss: 1.849712E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27532/   51900 | consumed samples:     28192768 | elapsed time per iteration (ms): 37686.3 | learning rate: 1.067E-04 | global batch size:  1024 | lm loss: 1.852143E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27533/   51900 | consumed samples:     28193792 | elapsed time per iteration (ms): 37629.0 | learning rate: 1.067E-04 | global batch size:  1024 | lm loss: 1.856053E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27534/   51900 | consumed samples:     28194816 | elapsed time per iteration (ms): 37748.9 | learning rate: 1.067E-04 | global batch size:  1024 | lm loss: 1.840391E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27535/   51900 | consumed samples:     28195840 | elapsed time per iteration (ms): 37655.6 | learning rate: 1.067E-04 | global batch size:  1024 | lm loss: 1.861940E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27536/   51900 | consumed samples:     28196864 | elapsed time per iteration (ms): 37642.4 | learning rate: 1.067E-04 | global batch size:  1024 | lm loss: 1.864926E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27537/   51900 | consumed samples:     28197888 | elapsed time per iteration (ms): 37659.0 | learning rate: 1.067E-04 | global batch size:  1024 | lm loss: 1.860323E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27538/   51900 | consumed samples:     28198912 | elapsed time per iteration (ms): 37797.1 | learning rate: 1.067E-04 | global batch size:  1024 | lm loss: 1.817013E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27539/   51900 | consumed samples:     28199936 | elapsed time per iteration (ms): 37788.1 | learning rate: 1.067E-04 | global batch size:  1024 | lm loss: 1.848644E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27540/   51900 | consumed samples:     28200960 | elapsed time per iteration (ms): 37672.8 | learning rate: 1.067E-04 | global batch size:  1024 | lm loss: 1.846105E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27541/   51900 | consumed samples:     28201984 | elapsed time per iteration (ms): 37730.0 | learning rate: 1.067E-04 | global batch size:  1024 | lm loss: 1.853269E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27542/   51900 | consumed samples:     28203008 | elapsed time per iteration (ms): 37738.9 | learning rate: 1.066E-04 | global batch size:  1024 | lm loss: 1.821735E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27543/   51900 | consumed samples:     28204032 | elapsed time per iteration (ms): 37573.2 | learning rate: 1.066E-04 | global batch size:  1024 | lm loss: 1.847474E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27544/   51900 | consumed samples:     28205056 | elapsed time per iteration (ms): 37632.0 | learning rate: 1.066E-04 | global batch size:  1024 | lm loss: 1.838793E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27545/   51900 | consumed samples:     28206080 | elapsed time per iteration (ms): 37689.3 | learning rate: 1.066E-04 | global batch size:  1024 | lm loss: 1.842828E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27546/   51900 | consumed samples:     28207104 | elapsed time per iteration (ms): 37651.7 | learning rate: 1.066E-04 | global batch size:  1024 | lm loss: 1.850525E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27547/   51900 | consumed samples:     28208128 | elapsed time per iteration (ms): 37718.0 | learning rate: 1.066E-04 | global batch size:  1024 | lm loss: 1.838398E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27548/   51900 | consumed samples:     28209152 | elapsed time per iteration (ms): 37855.1 | learning rate: 1.066E-04 | global batch size:  1024 | lm loss: 1.855287E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27549/   51900 | consumed samples:     28210176 | elapsed time per iteration (ms): 37678.4 | learning rate: 1.066E-04 | global batch size:  1024 | lm loss: 1.852572E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27550/   51900 | consumed samples:     28211200 | elapsed time per iteration (ms): 37600.8 | learning rate: 1.066E-04 | global batch size:  1024 | lm loss: 1.863498E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27551/   51900 | consumed samples:     28212224 | elapsed time per iteration (ms): 37614.8 | learning rate: 1.066E-04 | global batch size:  1024 | lm loss: 1.831180E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27552/   51900 | consumed samples:     28213248 | elapsed time per iteration (ms): 37592.2 | learning rate: 1.066E-04 | global batch size:  1024 | lm loss: 1.832295E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27553/   51900 | consumed samples:     28214272 | elapsed time per iteration (ms): 37609.2 | learning rate: 1.066E-04 | global batch size:  1024 | lm loss: 1.838332E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27554/   51900 | consumed samples:     28215296 | elapsed time per iteration (ms): 37659.0 | learning rate: 1.066E-04 | global batch size:  1024 | lm loss: 1.860359E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27555/   51900 | consumed samples:     28216320 | elapsed time per iteration (ms): 37608.9 | learning rate: 1.066E-04 | global batch size:  1024 | lm loss: 1.865178E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27556/   51900 | consumed samples:     28217344 | elapsed time per iteration (ms): 37677.6 | learning rate: 1.066E-04 | global batch size:  1024 | lm loss: 1.850875E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27557/   51900 | consumed samples:     28218368 | elapsed time per iteration (ms): 37635.8 | learning rate: 1.066E-04 | global batch size:  1024 | lm loss: 1.840928E+00 | loss scale: 1.0 | grad norm: 0.093 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27558/   51900 | consumed samples:     28219392 | elapsed time per iteration (ms): 37756.8 | learning rate: 1.066E-04 | global batch size:  1024 | lm loss: 1.854150E+00 | loss scale: 1.0 | grad norm: 0.087 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27559/   51900 | consumed samples:     28220416 | elapsed time per iteration (ms): 37692.3 | learning rate: 1.066E-04 | global batch size:  1024 | lm loss: 1.852278E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27560/   51900 | consumed samples:     28221440 | elapsed time per iteration (ms): 37656.3 | learning rate: 1.065E-04 | global batch size:  1024 | lm loss: 1.849492E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27561/   51900 | consumed samples:     28222464 | elapsed time per iteration (ms): 37655.2 | learning rate: 1.065E-04 | global batch size:  1024 | lm loss: 1.837895E+00 | loss scale: 1.0 | grad norm: 0.089 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27562/   51900 | consumed samples:     28223488 | elapsed time per iteration (ms): 37530.0 | learning rate: 1.065E-04 | global batch size:  1024 | lm loss: 1.841745E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27563/   51900 | consumed samples:     28224512 | elapsed time per iteration (ms): 37587.5 | learning rate: 1.065E-04 | global batch size:  1024 | lm loss: 1.832337E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27564/   51900 | consumed samples:     28225536 | elapsed time per iteration (ms): 37678.8 | learning rate: 1.065E-04 | global batch size:  1024 | lm loss: 1.838025E+00 | loss scale: 1.0 | grad norm: 0.087 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27565/   51900 | consumed samples:     28226560 | elapsed time per iteration (ms): 37599.8 | learning rate: 1.065E-04 | global batch size:  1024 | lm loss: 1.854241E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27566/   51900 | consumed samples:     28227584 | elapsed time per iteration (ms): 37703.3 | learning rate: 1.065E-04 | global batch size:  1024 | lm loss: 1.822584E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27567/   51900 | consumed samples:     28228608 | elapsed time per iteration (ms): 37566.7 | learning rate: 1.065E-04 | global batch size:  1024 | lm loss: 1.849403E+00 | loss scale: 1.0 | grad norm: 0.092 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27568/   51900 | consumed samples:     28229632 | elapsed time per iteration (ms): 37668.5 | learning rate: 1.065E-04 | global batch size:  1024 | lm loss: 1.843767E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27569/   51900 | consumed samples:     28230656 | elapsed time per iteration (ms): 37642.5 | learning rate: 1.065E-04 | global batch size:  1024 | lm loss: 1.856483E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27570/   51900 | consumed samples:     28231680 | elapsed time per iteration (ms): 37688.6 | learning rate: 1.065E-04 | global batch size:  1024 | lm loss: 1.827275E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27571/   51900 | consumed samples:     28232704 | elapsed time per iteration (ms): 37687.1 | learning rate: 1.065E-04 | global batch size:  1024 | lm loss: 1.852542E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27572/   51900 | consumed samples:     28233728 | elapsed time per iteration (ms): 37707.1 | learning rate: 1.065E-04 | global batch size:  1024 | lm loss: 1.849682E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27573/   51900 | consumed samples:     28234752 | elapsed time per iteration (ms): 37599.0 | learning rate: 1.065E-04 | global batch size:  1024 | lm loss: 1.839497E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27574/   51900 | consumed samples:     28235776 | elapsed time per iteration (ms): 37630.9 | learning rate: 1.065E-04 | global batch size:  1024 | lm loss: 1.824758E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27575/   51900 | consumed samples:     28236800 | elapsed time per iteration (ms): 37763.5 | learning rate: 1.065E-04 | global batch size:  1024 | lm loss: 1.851398E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27576/   51900 | consumed samples:     28237824 | elapsed time per iteration (ms): 37725.5 | learning rate: 1.065E-04 | global batch size:  1024 | lm loss: 1.858090E+00 | loss scale: 1.0 | grad norm: 0.088 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27577/   51900 | consumed samples:     28238848 | elapsed time per iteration (ms): 37685.2 | learning rate: 1.064E-04 | global batch size:  1024 | lm loss: 1.852277E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27578/   51900 | consumed samples:     28239872 | elapsed time per iteration (ms): 37646.9 | learning rate: 1.064E-04 | global batch size:  1024 | lm loss: 1.857831E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27579/   51900 | consumed samples:     28240896 | elapsed time per iteration (ms): 37742.1 | learning rate: 1.064E-04 | global batch size:  1024 | lm loss: 1.846969E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27580/   51900 | consumed samples:     28241920 | elapsed time per iteration (ms): 37745.5 | learning rate: 1.064E-04 | global batch size:  1024 | lm loss: 1.839953E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27581/   51900 | consumed samples:     28242944 | elapsed time per iteration (ms): 37644.8 | learning rate: 1.064E-04 | global batch size:  1024 | lm loss: 1.852792E+00 | loss scale: 1.0 | grad norm: 0.118 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27582/   51900 | consumed samples:     28243968 | elapsed time per iteration (ms): 37657.6 | learning rate: 1.064E-04 | global batch size:  1024 | lm loss: 1.860498E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27583/   51900 | consumed samples:     28244992 | elapsed time per iteration (ms): 37656.9 | learning rate: 1.064E-04 | global batch size:  1024 | lm loss: 1.828346E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27584/   51900 | consumed samples:     28246016 | elapsed time per iteration (ms): 37622.3 | learning rate: 1.064E-04 | global batch size:  1024 | lm loss: 1.851392E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27585/   51900 | consumed samples:     28247040 | elapsed time per iteration (ms): 37561.6 | learning rate: 1.064E-04 | global batch size:  1024 | lm loss: 1.841911E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27586/   51900 | consumed samples:     28248064 | elapsed time per iteration (ms): 37725.3 | learning rate: 1.064E-04 | global batch size:  1024 | lm loss: 1.849205E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27587/   51900 | consumed samples:     28249088 | elapsed time per iteration (ms): 37772.6 | learning rate: 1.064E-04 | global batch size:  1024 | lm loss: 1.834119E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27588/   51900 | consumed samples:     28250112 | elapsed time per iteration (ms): 37684.5 | learning rate: 1.064E-04 | global batch size:  1024 | lm loss: 1.837170E+00 | loss scale: 1.0 | grad norm: 0.090 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27589/   51900 | consumed samples:     28251136 | elapsed time per iteration (ms): 37744.0 | learning rate: 1.064E-04 | global batch size:  1024 | lm loss: 1.853714E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27590/   51900 | consumed samples:     28252160 | elapsed time per iteration (ms): 37621.3 | learning rate: 1.064E-04 | global batch size:  1024 | lm loss: 1.849809E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27591/   51900 | consumed samples:     28253184 | elapsed time per iteration (ms): 37683.7 | learning rate: 1.064E-04 | global batch size:  1024 | lm loss: 1.838592E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27592/   51900 | consumed samples:     28254208 | elapsed time per iteration (ms): 37572.8 | learning rate: 1.064E-04 | global batch size:  1024 | lm loss: 1.854399E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27593/   51900 | consumed samples:     28255232 | elapsed time per iteration (ms): 37684.8 | learning rate: 1.064E-04 | global batch size:  1024 | lm loss: 1.844310E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27594/   51900 | consumed samples:     28256256 | elapsed time per iteration (ms): 37660.4 | learning rate: 1.064E-04 | global batch size:  1024 | lm loss: 1.842361E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27595/   51900 | consumed samples:     28257280 | elapsed time per iteration (ms): 37670.8 | learning rate: 1.063E-04 | global batch size:  1024 | lm loss: 1.839775E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27596/   51900 | consumed samples:     28258304 | elapsed time per iteration (ms): 37681.9 | learning rate: 1.063E-04 | global batch size:  1024 | lm loss: 1.855524E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27597/   51900 | consumed samples:     28259328 | elapsed time per iteration (ms): 37608.6 | learning rate: 1.063E-04 | global batch size:  1024 | lm loss: 1.840113E+00 | loss scale: 1.0 | grad norm: 0.087 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27598/   51900 | consumed samples:     28260352 | elapsed time per iteration (ms): 37611.6 | learning rate: 1.063E-04 | global batch size:  1024 | lm loss: 1.843969E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27599/   51900 | consumed samples:     28261376 | elapsed time per iteration (ms): 37592.4 | learning rate: 1.063E-04 | global batch size:  1024 | lm loss: 1.838596E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27600/   51900 | consumed samples:     28262400 | elapsed time per iteration (ms): 37613.1 | learning rate: 1.063E-04 | global batch size:  1024 | lm loss: 1.813080E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27601/   51900 | consumed samples:     28263424 | elapsed time per iteration (ms): 37565.2 | learning rate: 1.063E-04 | global batch size:  1024 | lm loss: 1.848338E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27602/   51900 | consumed samples:     28264448 | elapsed time per iteration (ms): 37657.4 | learning rate: 1.063E-04 | global batch size:  1024 | lm loss: 1.855343E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27603/   51900 | consumed samples:     28265472 | elapsed time per iteration (ms): 37643.3 | learning rate: 1.063E-04 | global batch size:  1024 | lm loss: 1.854779E+00 | loss scale: 1.0 | grad norm: 0.088 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27604/   51900 | consumed samples:     28266496 | elapsed time per iteration (ms): 37695.0 | learning rate: 1.063E-04 | global batch size:  1024 | lm loss: 1.849336E+00 | loss scale: 1.0 | grad norm: 0.097 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27605/   51900 | consumed samples:     28267520 | elapsed time per iteration (ms): 37720.0 | learning rate: 1.063E-04 | global batch size:  1024 | lm loss: 1.828771E+00 | loss scale: 1.0 | grad norm: 0.150 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27606/   51900 | consumed samples:     28268544 | elapsed time per iteration (ms): 37724.2 | learning rate: 1.063E-04 | global batch size:  1024 | lm loss: 1.870421E+00 | loss scale: 1.0 | grad norm: 0.088 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27607/   51900 | consumed samples:     28269568 | elapsed time per iteration (ms): 37577.8 | learning rate: 1.063E-04 | global batch size:  1024 | lm loss: 1.846808E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27608/   51900 | consumed samples:     28270592 | elapsed time per iteration (ms): 37710.4 | learning rate: 1.063E-04 | global batch size:  1024 | lm loss: 1.832476E+00 | loss scale: 1.0 | grad norm: 0.091 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27609/   51900 | consumed samples:     28271616 | elapsed time per iteration (ms): 37561.6 | learning rate: 1.063E-04 | global batch size:  1024 | lm loss: 1.849739E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27610/   51900 | consumed samples:     28272640 | elapsed time per iteration (ms): 37727.5 | learning rate: 1.063E-04 | global batch size:  1024 | lm loss: 1.852028E+00 | loss scale: 1.0 | grad norm: 0.103 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27611/   51900 | consumed samples:     28273664 | elapsed time per iteration (ms): 37683.3 | learning rate: 1.063E-04 | global batch size:  1024 | lm loss: 1.852979E+00 | loss scale: 1.0 | grad norm: 0.103 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27612/   51900 | consumed samples:     28274688 | elapsed time per iteration (ms): 37677.7 | learning rate: 1.063E-04 | global batch size:  1024 | lm loss: 1.857058E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27613/   51900 | consumed samples:     28275712 | elapsed time per iteration (ms): 37720.1 | learning rate: 1.062E-04 | global batch size:  1024 | lm loss: 1.848949E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27614/   51900 | consumed samples:     28276736 | elapsed time per iteration (ms): 37665.1 | learning rate: 1.062E-04 | global batch size:  1024 | lm loss: 1.853686E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27615/   51900 | consumed samples:     28277760 | elapsed time per iteration (ms): 37667.3 | learning rate: 1.062E-04 | global batch size:  1024 | lm loss: 1.853768E+00 | loss scale: 1.0 | grad norm: 0.088 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27616/   51900 | consumed samples:     28278784 | elapsed time per iteration (ms): 37604.7 | learning rate: 1.062E-04 | global batch size:  1024 | lm loss: 1.841859E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27617/   51900 | consumed samples:     28279808 | elapsed time per iteration (ms): 37634.4 | learning rate: 1.062E-04 | global batch size:  1024 | lm loss: 1.835753E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27618/   51900 | consumed samples:     28280832 | elapsed time per iteration (ms): 37652.3 | learning rate: 1.062E-04 | global batch size:  1024 | lm loss: 1.839332E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27619/   51900 | consumed samples:     28281856 | elapsed time per iteration (ms): 37673.7 | learning rate: 1.062E-04 | global batch size:  1024 | lm loss: 1.843988E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27620/   51900 | consumed samples:     28282880 | elapsed time per iteration (ms): 37630.1 | learning rate: 1.062E-04 | global batch size:  1024 | lm loss: 1.829819E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27621/   51900 | consumed samples:     28283904 | elapsed time per iteration (ms): 37628.9 | learning rate: 1.062E-04 | global batch size:  1024 | lm loss: 1.847640E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27622/   51900 | consumed samples:     28284928 | elapsed time per iteration (ms): 37791.9 | learning rate: 1.062E-04 | global batch size:  1024 | lm loss: 1.829407E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27623/   51900 | consumed samples:     28285952 | elapsed time per iteration (ms): 37632.9 | learning rate: 1.062E-04 | global batch size:  1024 | lm loss: 1.836222E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27624/   51900 | consumed samples:     28286976 | elapsed time per iteration (ms): 37579.7 | learning rate: 1.062E-04 | global batch size:  1024 | lm loss: 1.846746E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27625/   51900 | consumed samples:     28288000 | elapsed time per iteration (ms): 37672.4 | learning rate: 1.062E-04 | global batch size:  1024 | lm loss: 1.846425E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27626/   51900 | consumed samples:     28289024 | elapsed time per iteration (ms): 37682.0 | learning rate: 1.062E-04 | global batch size:  1024 | lm loss: 1.843825E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27627/   51900 | consumed samples:     28290048 | elapsed time per iteration (ms): 37632.9 | learning rate: 1.062E-04 | global batch size:  1024 | lm loss: 1.851491E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27628/   51900 | consumed samples:     28291072 | elapsed time per iteration (ms): 37720.2 | learning rate: 1.062E-04 | global batch size:  1024 | lm loss: 1.863765E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27629/   51900 | consumed samples:     28292096 | elapsed time per iteration (ms): 37697.7 | learning rate: 1.062E-04 | global batch size:  1024 | lm loss: 1.871595E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27630/   51900 | consumed samples:     28293120 | elapsed time per iteration (ms): 37688.3 | learning rate: 1.061E-04 | global batch size:  1024 | lm loss: 1.850544E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27631/   51900 | consumed samples:     28294144 | elapsed time per iteration (ms): 37685.0 | learning rate: 1.061E-04 | global batch size:  1024 | lm loss: 1.844085E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27632/   51900 | consumed samples:     28295168 | elapsed time per iteration (ms): 37583.4 | learning rate: 1.061E-04 | global batch size:  1024 | lm loss: 1.839431E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27633/   51900 | consumed samples:     28296192 | elapsed time per iteration (ms): 37605.9 | learning rate: 1.061E-04 | global batch size:  1024 | lm loss: 1.854118E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27634/   51900 | consumed samples:     28297216 | elapsed time per iteration (ms): 37562.0 | learning rate: 1.061E-04 | global batch size:  1024 | lm loss: 1.836276E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27635/   51900 | consumed samples:     28298240 | elapsed time per iteration (ms): 37690.1 | learning rate: 1.061E-04 | global batch size:  1024 | lm loss: 1.856962E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27636/   51900 | consumed samples:     28299264 | elapsed time per iteration (ms): 37647.3 | learning rate: 1.061E-04 | global batch size:  1024 | lm loss: 1.856914E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27637/   51900 | consumed samples:     28300288 | elapsed time per iteration (ms): 37602.0 | learning rate: 1.061E-04 | global batch size:  1024 | lm loss: 1.844366E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27638/   51900 | consumed samples:     28301312 | elapsed time per iteration (ms): 37704.2 | learning rate: 1.061E-04 | global batch size:  1024 | lm loss: 1.849004E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27639/   51900 | consumed samples:     28302336 | elapsed time per iteration (ms): 37833.7 | learning rate: 1.061E-04 | global batch size:  1024 | lm loss: 1.851377E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27640/   51900 | consumed samples:     28303360 | elapsed time per iteration (ms): 37699.5 | learning rate: 1.061E-04 | global batch size:  1024 | lm loss: 1.863650E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27641/   51900 | consumed samples:     28304384 | elapsed time per iteration (ms): 37661.8 | learning rate: 1.061E-04 | global batch size:  1024 | lm loss: 1.857703E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27642/   51900 | consumed samples:     28305408 | elapsed time per iteration (ms): 37684.6 | learning rate: 1.061E-04 | global batch size:  1024 | lm loss: 1.857573E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27643/   51900 | consumed samples:     28306432 | elapsed time per iteration (ms): 37655.5 | learning rate: 1.061E-04 | global batch size:  1024 | lm loss: 1.834927E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27644/   51900 | consumed samples:     28307456 | elapsed time per iteration (ms): 37651.0 | learning rate: 1.061E-04 | global batch size:  1024 | lm loss: 1.815775E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27645/   51900 | consumed samples:     28308480 | elapsed time per iteration (ms): 37603.7 | learning rate: 1.061E-04 | global batch size:  1024 | lm loss: 1.851211E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27646/   51900 | consumed samples:     28309504 | elapsed time per iteration (ms): 37646.2 | learning rate: 1.061E-04 | global batch size:  1024 | lm loss: 1.851385E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27647/   51900 | consumed samples:     28310528 | elapsed time per iteration (ms): 37609.3 | learning rate: 1.061E-04 | global batch size:  1024 | lm loss: 1.856280E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27648/   51900 | consumed samples:     28311552 | elapsed time per iteration (ms): 37759.4 | learning rate: 1.060E-04 | global batch size:  1024 | lm loss: 1.829185E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27649/   51900 | consumed samples:     28312576 | elapsed time per iteration (ms): 37603.5 | learning rate: 1.060E-04 | global batch size:  1024 | lm loss: 1.849768E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27650/   51900 | consumed samples:     28313600 | elapsed time per iteration (ms): 37607.1 | learning rate: 1.060E-04 | global batch size:  1024 | lm loss: 1.831287E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27651/   51900 | consumed samples:     28314624 | elapsed time per iteration (ms): 37609.1 | learning rate: 1.060E-04 | global batch size:  1024 | lm loss: 1.837388E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27652/   51900 | consumed samples:     28315648 | elapsed time per iteration (ms): 37584.2 | learning rate: 1.060E-04 | global batch size:  1024 | lm loss: 1.851009E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27653/   51900 | consumed samples:     28316672 | elapsed time per iteration (ms): 37648.7 | learning rate: 1.060E-04 | global batch size:  1024 | lm loss: 1.841963E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27654/   51900 | consumed samples:     28317696 | elapsed time per iteration (ms): 37628.6 | learning rate: 1.060E-04 | global batch size:  1024 | lm loss: 1.836828E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27655/   51900 | consumed samples:     28318720 | elapsed time per iteration (ms): 37600.7 | learning rate: 1.060E-04 | global batch size:  1024 | lm loss: 1.834471E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27656/   51900 | consumed samples:     28319744 | elapsed time per iteration (ms): 37492.3 | learning rate: 1.060E-04 | global batch size:  1024 | lm loss: 1.842972E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27657/   51900 | consumed samples:     28320768 | elapsed time per iteration (ms): 37625.6 | learning rate: 1.060E-04 | global batch size:  1024 | lm loss: 1.850843E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27658/   51900 | consumed samples:     28321792 | elapsed time per iteration (ms): 37681.2 | learning rate: 1.060E-04 | global batch size:  1024 | lm loss: 1.843074E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27659/   51900 | consumed samples:     28322816 | elapsed time per iteration (ms): 37531.7 | learning rate: 1.060E-04 | global batch size:  1024 | lm loss: 1.827061E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27660/   51900 | consumed samples:     28323840 | elapsed time per iteration (ms): 37613.1 | learning rate: 1.060E-04 | global batch size:  1024 | lm loss: 1.845832E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27661/   51900 | consumed samples:     28324864 | elapsed time per iteration (ms): 37716.7 | learning rate: 1.060E-04 | global batch size:  1024 | lm loss: 1.850458E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27662/   51900 | consumed samples:     28325888 | elapsed time per iteration (ms): 37642.1 | learning rate: 1.060E-04 | global batch size:  1024 | lm loss: 1.859806E+00 | loss scale: 1.0 | grad norm: 0.088 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27663/   51900 | consumed samples:     28326912 | elapsed time per iteration (ms): 37573.3 | learning rate: 1.060E-04 | global batch size:  1024 | lm loss: 1.854252E+00 | loss scale: 1.0 | grad norm: 0.088 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27664/   51900 | consumed samples:     28327936 | elapsed time per iteration (ms): 37649.1 | learning rate: 1.060E-04 | global batch size:  1024 | lm loss: 1.847304E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27665/   51900 | consumed samples:     28328960 | elapsed time per iteration (ms): 37706.9 | learning rate: 1.060E-04 | global batch size:  1024 | lm loss: 1.841793E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27666/   51900 | consumed samples:     28329984 | elapsed time per iteration (ms): 37723.0 | learning rate: 1.059E-04 | global batch size:  1024 | lm loss: 1.840622E+00 | loss scale: 1.0 | grad norm: 0.088 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27667/   51900 | consumed samples:     28331008 | elapsed time per iteration (ms): 37605.4 | learning rate: 1.059E-04 | global batch size:  1024 | lm loss: 1.845105E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27668/   51900 | consumed samples:     28332032 | elapsed time per iteration (ms): 37476.3 | learning rate: 1.059E-04 | global batch size:  1024 | lm loss: 1.830948E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27669/   51900 | consumed samples:     28333056 | elapsed time per iteration (ms): 37554.9 | learning rate: 1.059E-04 | global batch size:  1024 | lm loss: 1.854701E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27670/   51900 | consumed samples:     28334080 | elapsed time per iteration (ms): 37700.1 | learning rate: 1.059E-04 | global batch size:  1024 | lm loss: 1.836998E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27671/   51900 | consumed samples:     28335104 | elapsed time per iteration (ms): 37582.7 | learning rate: 1.059E-04 | global batch size:  1024 | lm loss: 1.843921E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27672/   51900 | consumed samples:     28336128 | elapsed time per iteration (ms): 37703.4 | learning rate: 1.059E-04 | global batch size:  1024 | lm loss: 1.833618E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27673/   51900 | consumed samples:     28337152 | elapsed time per iteration (ms): 37662.7 | learning rate: 1.059E-04 | global batch size:  1024 | lm loss: 1.836232E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27674/   51900 | consumed samples:     28338176 | elapsed time per iteration (ms): 37620.4 | learning rate: 1.059E-04 | global batch size:  1024 | lm loss: 1.826307E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27675/   51900 | consumed samples:     28339200 | elapsed time per iteration (ms): 37569.0 | learning rate: 1.059E-04 | global batch size:  1024 | lm loss: 1.837950E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27676/   51900 | consumed samples:     28340224 | elapsed time per iteration (ms): 37589.1 | learning rate: 1.059E-04 | global batch size:  1024 | lm loss: 1.853521E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27677/   51900 | consumed samples:     28341248 | elapsed time per iteration (ms): 37750.7 | learning rate: 1.059E-04 | global batch size:  1024 | lm loss: 1.856006E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27678/   51900 | consumed samples:     28342272 | elapsed time per iteration (ms): 37620.8 | learning rate: 1.059E-04 | global batch size:  1024 | lm loss: 1.862505E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27679/   51900 | consumed samples:     28343296 | elapsed time per iteration (ms): 37626.9 | learning rate: 1.059E-04 | global batch size:  1024 | lm loss: 1.842478E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27680/   51900 | consumed samples:     28344320 | elapsed time per iteration (ms): 37761.2 | learning rate: 1.059E-04 | global batch size:  1024 | lm loss: 1.858853E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27681/   51900 | consumed samples:     28345344 | elapsed time per iteration (ms): 37701.2 | learning rate: 1.059E-04 | global batch size:  1024 | lm loss: 1.828626E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27682/   51900 | consumed samples:     28346368 | elapsed time per iteration (ms): 37716.3 | learning rate: 1.059E-04 | global batch size:  1024 | lm loss: 1.843157E+00 | loss scale: 1.0 | grad norm: 0.088 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27683/   51900 | consumed samples:     28347392 | elapsed time per iteration (ms): 37660.8 | learning rate: 1.058E-04 | global batch size:  1024 | lm loss: 1.842915E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27684/   51900 | consumed samples:     28348416 | elapsed time per iteration (ms): 37636.2 | learning rate: 1.058E-04 | global batch size:  1024 | lm loss: 1.846874E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27685/   51900 | consumed samples:     28349440 | elapsed time per iteration (ms): 37677.1 | learning rate: 1.058E-04 | global batch size:  1024 | lm loss: 1.831080E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27686/   51900 | consumed samples:     28350464 | elapsed time per iteration (ms): 37674.5 | learning rate: 1.058E-04 | global batch size:  1024 | lm loss: 1.843033E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27687/   51900 | consumed samples:     28351488 | elapsed time per iteration (ms): 37735.4 | learning rate: 1.058E-04 | global batch size:  1024 | lm loss: 1.851227E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27688/   51900 | consumed samples:     28352512 | elapsed time per iteration (ms): 37621.4 | learning rate: 1.058E-04 | global batch size:  1024 | lm loss: 1.823411E+00 | loss scale: 1.0 | grad norm: 0.089 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27689/   51900 | consumed samples:     28353536 | elapsed time per iteration (ms): 37656.8 | learning rate: 1.058E-04 | global batch size:  1024 | lm loss: 1.846780E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27690/   51900 | consumed samples:     28354560 | elapsed time per iteration (ms): 37648.2 | learning rate: 1.058E-04 | global batch size:  1024 | lm loss: 1.850528E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27691/   51900 | consumed samples:     28355584 | elapsed time per iteration (ms): 37682.9 | learning rate: 1.058E-04 | global batch size:  1024 | lm loss: 1.839660E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27692/   51900 | consumed samples:     28356608 | elapsed time per iteration (ms): 37577.6 | learning rate: 1.058E-04 | global batch size:  1024 | lm loss: 1.851463E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27693/   51900 | consumed samples:     28357632 | elapsed time per iteration (ms): 37564.4 | learning rate: 1.058E-04 | global batch size:  1024 | lm loss: 1.836111E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27694/   51900 | consumed samples:     28358656 | elapsed time per iteration (ms): 37731.1 | learning rate: 1.058E-04 | global batch size:  1024 | lm loss: 1.853919E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27695/   51900 | consumed samples:     28359680 | elapsed time per iteration (ms): 37638.4 | learning rate: 1.058E-04 | global batch size:  1024 | lm loss: 1.848201E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27696/   51900 | consumed samples:     28360704 | elapsed time per iteration (ms): 37695.8 | learning rate: 1.058E-04 | global batch size:  1024 | lm loss: 1.848405E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27697/   51900 | consumed samples:     28361728 | elapsed time per iteration (ms): 37540.6 | learning rate: 1.058E-04 | global batch size:  1024 | lm loss: 1.850235E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27698/   51900 | consumed samples:     28362752 | elapsed time per iteration (ms): 37695.9 | learning rate: 1.058E-04 | global batch size:  1024 | lm loss: 1.840084E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27699/   51900 | consumed samples:     28363776 | elapsed time per iteration (ms): 37722.2 | learning rate: 1.058E-04 | global batch size:  1024 | lm loss: 1.829883E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27700/   51900 | consumed samples:     28364800 | elapsed time per iteration (ms): 37664.4 | learning rate: 1.058E-04 | global batch size:  1024 | lm loss: 1.847800E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27701/   51900 | consumed samples:     28365824 | elapsed time per iteration (ms): 37708.4 | learning rate: 1.057E-04 | global batch size:  1024 | lm loss: 1.853123E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27702/   51900 | consumed samples:     28366848 | elapsed time per iteration (ms): 37624.4 | learning rate: 1.057E-04 | global batch size:  1024 | lm loss: 1.851383E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27703/   51900 | consumed samples:     28367872 | elapsed time per iteration (ms): 37624.0 | learning rate: 1.057E-04 | global batch size:  1024 | lm loss: 1.834019E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27704/   51900 | consumed samples:     28368896 | elapsed time per iteration (ms): 37757.4 | learning rate: 1.057E-04 | global batch size:  1024 | lm loss: 1.873185E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27705/   51900 | consumed samples:     28369920 | elapsed time per iteration (ms): 37797.0 | learning rate: 1.057E-04 | global batch size:  1024 | lm loss: 1.833375E+00 | loss scale: 1.0 | grad norm: 0.092 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27706/   51900 | consumed samples:     28370944 | elapsed time per iteration (ms): 37771.4 | learning rate: 1.057E-04 | global batch size:  1024 | lm loss: 1.857435E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27707/   51900 | consumed samples:     28371968 | elapsed time per iteration (ms): 37649.9 | learning rate: 1.057E-04 | global batch size:  1024 | lm loss: 1.839763E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27708/   51900 | consumed samples:     28372992 | elapsed time per iteration (ms): 37543.2 | learning rate: 1.057E-04 | global batch size:  1024 | lm loss: 1.836824E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27709/   51900 | consumed samples:     28374016 | elapsed time per iteration (ms): 37692.4 | learning rate: 1.057E-04 | global batch size:  1024 | lm loss: 1.840822E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27710/   51900 | consumed samples:     28375040 | elapsed time per iteration (ms): 37731.3 | learning rate: 1.057E-04 | global batch size:  1024 | lm loss: 1.840538E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27711/   51900 | consumed samples:     28376064 | elapsed time per iteration (ms): 37636.7 | learning rate: 1.057E-04 | global batch size:  1024 | lm loss: 1.831709E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27712/   51900 | consumed samples:     28377088 | elapsed time per iteration (ms): 37671.0 | learning rate: 1.057E-04 | global batch size:  1024 | lm loss: 1.846547E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27713/   51900 | consumed samples:     28378112 | elapsed time per iteration (ms): 37562.4 | learning rate: 1.057E-04 | global batch size:  1024 | lm loss: 1.827571E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27714/   51900 | consumed samples:     28379136 | elapsed time per iteration (ms): 37676.4 | learning rate: 1.057E-04 | global batch size:  1024 | lm loss: 1.860588E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27715/   51900 | consumed samples:     28380160 | elapsed time per iteration (ms): 37550.9 | learning rate: 1.057E-04 | global batch size:  1024 | lm loss: 1.849535E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27716/   51900 | consumed samples:     28381184 | elapsed time per iteration (ms): 37582.5 | learning rate: 1.057E-04 | global batch size:  1024 | lm loss: 1.845817E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27717/   51900 | consumed samples:     28382208 | elapsed time per iteration (ms): 37642.9 | learning rate: 1.057E-04 | global batch size:  1024 | lm loss: 1.841704E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27718/   51900 | consumed samples:     28383232 | elapsed time per iteration (ms): 37583.3 | learning rate: 1.057E-04 | global batch size:  1024 | lm loss: 1.840907E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27719/   51900 | consumed samples:     28384256 | elapsed time per iteration (ms): 37651.3 | learning rate: 1.056E-04 | global batch size:  1024 | lm loss: 1.834536E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27720/   51900 | consumed samples:     28385280 | elapsed time per iteration (ms): 37770.0 | learning rate: 1.056E-04 | global batch size:  1024 | lm loss: 1.837009E+00 | loss scale: 1.0 | grad norm: 0.098 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27721/   51900 | consumed samples:     28386304 | elapsed time per iteration (ms): 37733.5 | learning rate: 1.056E-04 | global batch size:  1024 | lm loss: 1.845717E+00 | loss scale: 1.0 | grad norm: 0.090 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27722/   51900 | consumed samples:     28387328 | elapsed time per iteration (ms): 37637.7 | learning rate: 1.056E-04 | global batch size:  1024 | lm loss: 1.857001E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27723/   51900 | consumed samples:     28388352 | elapsed time per iteration (ms): 37690.0 | learning rate: 1.056E-04 | global batch size:  1024 | lm loss: 1.846706E+00 | loss scale: 1.0 | grad norm: 0.089 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27724/   51900 | consumed samples:     28389376 | elapsed time per iteration (ms): 37664.8 | learning rate: 1.056E-04 | global batch size:  1024 | lm loss: 1.861770E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27725/   51900 | consumed samples:     28390400 | elapsed time per iteration (ms): 37653.4 | learning rate: 1.056E-04 | global batch size:  1024 | lm loss: 1.849927E+00 | loss scale: 1.0 | grad norm: 0.087 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27726/   51900 | consumed samples:     28391424 | elapsed time per iteration (ms): 37737.8 | learning rate: 1.056E-04 | global batch size:  1024 | lm loss: 1.858752E+00 | loss scale: 1.0 | grad norm: 0.088 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27727/   51900 | consumed samples:     28392448 | elapsed time per iteration (ms): 37801.5 | learning rate: 1.056E-04 | global batch size:  1024 | lm loss: 1.841993E+00 | loss scale: 1.0 | grad norm: 0.087 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27728/   51900 | consumed samples:     28393472 | elapsed time per iteration (ms): 37683.8 | learning rate: 1.056E-04 | global batch size:  1024 | lm loss: 1.854308E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27729/   51900 | consumed samples:     28394496 | elapsed time per iteration (ms): 37712.2 | learning rate: 1.056E-04 | global batch size:  1024 | lm loss: 1.861002E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27730/   51900 | consumed samples:     28395520 | elapsed time per iteration (ms): 37597.4 | learning rate: 1.056E-04 | global batch size:  1024 | lm loss: 1.828149E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27731/   51900 | consumed samples:     28396544 | elapsed time per iteration (ms): 37539.5 | learning rate: 1.056E-04 | global batch size:  1024 | lm loss: 1.853706E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27732/   51900 | consumed samples:     28397568 | elapsed time per iteration (ms): 37566.5 | learning rate: 1.056E-04 | global batch size:  1024 | lm loss: 1.825615E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27733/   51900 | consumed samples:     28398592 | elapsed time per iteration (ms): 37556.0 | learning rate: 1.056E-04 | global batch size:  1024 | lm loss: 1.863861E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27734/   51900 | consumed samples:     28399616 | elapsed time per iteration (ms): 37567.6 | learning rate: 1.056E-04 | global batch size:  1024 | lm loss: 1.868875E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27735/   51900 | consumed samples:     28400640 | elapsed time per iteration (ms): 37656.5 | learning rate: 1.056E-04 | global batch size:  1024 | lm loss: 1.824578E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27736/   51900 | consumed samples:     28401664 | elapsed time per iteration (ms): 37594.9 | learning rate: 1.055E-04 | global batch size:  1024 | lm loss: 1.843825E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27737/   51900 | consumed samples:     28402688 | elapsed time per iteration (ms): 37552.1 | learning rate: 1.055E-04 | global batch size:  1024 | lm loss: 1.863485E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27738/   51900 | consumed samples:     28403712 | elapsed time per iteration (ms): 37556.3 | learning rate: 1.055E-04 | global batch size:  1024 | lm loss: 1.838835E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27739/   51900 | consumed samples:     28404736 | elapsed time per iteration (ms): 37665.3 | learning rate: 1.055E-04 | global batch size:  1024 | lm loss: 1.848181E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27740/   51900 | consumed samples:     28405760 | elapsed time per iteration (ms): 37715.9 | learning rate: 1.055E-04 | global batch size:  1024 | lm loss: 1.862949E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27741/   51900 | consumed samples:     28406784 | elapsed time per iteration (ms): 37619.5 | learning rate: 1.055E-04 | global batch size:  1024 | lm loss: 1.834329E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27742/   51900 | consumed samples:     28407808 | elapsed time per iteration (ms): 37603.6 | learning rate: 1.055E-04 | global batch size:  1024 | lm loss: 1.842450E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27743/   51900 | consumed samples:     28408832 | elapsed time per iteration (ms): 37573.1 | learning rate: 1.055E-04 | global batch size:  1024 | lm loss: 1.842324E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27744/   51900 | consumed samples:     28409856 | elapsed time per iteration (ms): 37549.8 | learning rate: 1.055E-04 | global batch size:  1024 | lm loss: 1.841104E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27745/   51900 | consumed samples:     28410880 | elapsed time per iteration (ms): 37631.3 | learning rate: 1.055E-04 | global batch size:  1024 | lm loss: 1.839528E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27746/   51900 | consumed samples:     28411904 | elapsed time per iteration (ms): 37558.3 | learning rate: 1.055E-04 | global batch size:  1024 | lm loss: 1.835119E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27747/   51900 | consumed samples:     28412928 | elapsed time per iteration (ms): 37638.1 | learning rate: 1.055E-04 | global batch size:  1024 | lm loss: 1.830144E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27748/   51900 | consumed samples:     28413952 | elapsed time per iteration (ms): 37638.5 | learning rate: 1.055E-04 | global batch size:  1024 | lm loss: 1.855434E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27749/   51900 | consumed samples:     28414976 | elapsed time per iteration (ms): 37631.7 | learning rate: 1.055E-04 | global batch size:  1024 | lm loss: 1.846128E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27750/   51900 | consumed samples:     28416000 | elapsed time per iteration (ms): 37623.9 | learning rate: 1.055E-04 | global batch size:  1024 | lm loss: 1.845223E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27751/   51900 | consumed samples:     28417024 | elapsed time per iteration (ms): 37546.4 | learning rate: 1.055E-04 | global batch size:  1024 | lm loss: 1.849409E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27752/   51900 | consumed samples:     28418048 | elapsed time per iteration (ms): 37587.1 | learning rate: 1.055E-04 | global batch size:  1024 | lm loss: 1.842842E+00 | loss scale: 1.0 | grad norm: 0.089 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27753/   51900 | consumed samples:     28419072 | elapsed time per iteration (ms): 37614.3 | learning rate: 1.055E-04 | global batch size:  1024 | lm loss: 1.853052E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27754/   51900 | consumed samples:     28420096 | elapsed time per iteration (ms): 37688.3 | learning rate: 1.054E-04 | global batch size:  1024 | lm loss: 1.853363E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27755/   51900 | consumed samples:     28421120 | elapsed time per iteration (ms): 37594.9 | learning rate: 1.054E-04 | global batch size:  1024 | lm loss: 1.851546E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27756/   51900 | consumed samples:     28422144 | elapsed time per iteration (ms): 37530.8 | learning rate: 1.054E-04 | global batch size:  1024 | lm loss: 1.844682E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27757/   51900 | consumed samples:     28423168 | elapsed time per iteration (ms): 37675.0 | learning rate: 1.054E-04 | global batch size:  1024 | lm loss: 1.845511E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27758/   51900 | consumed samples:     28424192 | elapsed time per iteration (ms): 37607.2 | learning rate: 1.054E-04 | global batch size:  1024 | lm loss: 1.854012E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27759/   51900 | consumed samples:     28425216 | elapsed time per iteration (ms): 37569.5 | learning rate: 1.054E-04 | global batch size:  1024 | lm loss: 1.854968E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27760/   51900 | consumed samples:     28426240 | elapsed time per iteration (ms): 37510.1 | learning rate: 1.054E-04 | global batch size:  1024 | lm loss: 1.852345E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27761/   51900 | consumed samples:     28427264 | elapsed time per iteration (ms): 37757.1 | learning rate: 1.054E-04 | global batch size:  1024 | lm loss: 1.844734E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27762/   51900 | consumed samples:     28428288 | elapsed time per iteration (ms): 37635.3 | learning rate: 1.054E-04 | global batch size:  1024 | lm loss: 1.853739E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27763/   51900 | consumed samples:     28429312 | elapsed time per iteration (ms): 37750.6 | learning rate: 1.054E-04 | global batch size:  1024 | lm loss: 1.843240E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27764/   51900 | consumed samples:     28430336 | elapsed time per iteration (ms): 37691.8 | learning rate: 1.054E-04 | global batch size:  1024 | lm loss: 1.829468E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27765/   51900 | consumed samples:     28431360 | elapsed time per iteration (ms): 37762.1 | learning rate: 1.054E-04 | global batch size:  1024 | lm loss: 1.817747E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27766/   51900 | consumed samples:     28432384 | elapsed time per iteration (ms): 37636.4 | learning rate: 1.054E-04 | global batch size:  1024 | lm loss: 1.856981E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27767/   51900 | consumed samples:     28433408 | elapsed time per iteration (ms): 37586.1 | learning rate: 1.054E-04 | global batch size:  1024 | lm loss: 1.840500E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27768/   51900 | consumed samples:     28434432 | elapsed time per iteration (ms): 37646.3 | learning rate: 1.054E-04 | global batch size:  1024 | lm loss: 1.826973E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27769/   51900 | consumed samples:     28435456 | elapsed time per iteration (ms): 37638.6 | learning rate: 1.054E-04 | global batch size:  1024 | lm loss: 1.850560E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27770/   51900 | consumed samples:     28436480 | elapsed time per iteration (ms): 37646.1 | learning rate: 1.054E-04 | global batch size:  1024 | lm loss: 1.829058E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27771/   51900 | consumed samples:     28437504 | elapsed time per iteration (ms): 37662.5 | learning rate: 1.054E-04 | global batch size:  1024 | lm loss: 1.841468E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27772/   51900 | consumed samples:     28438528 | elapsed time per iteration (ms): 37626.0 | learning rate: 1.053E-04 | global batch size:  1024 | lm loss: 1.846215E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27773/   51900 | consumed samples:     28439552 | elapsed time per iteration (ms): 37558.6 | learning rate: 1.053E-04 | global batch size:  1024 | lm loss: 1.870146E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27774/   51900 | consumed samples:     28440576 | elapsed time per iteration (ms): 37607.8 | learning rate: 1.053E-04 | global batch size:  1024 | lm loss: 1.850293E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27775/   51900 | consumed samples:     28441600 | elapsed time per iteration (ms): 37703.1 | learning rate: 1.053E-04 | global batch size:  1024 | lm loss: 1.850995E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27776/   51900 | consumed samples:     28442624 | elapsed time per iteration (ms): 37630.3 | learning rate: 1.053E-04 | global batch size:  1024 | lm loss: 1.863499E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27777/   51900 | consumed samples:     28443648 | elapsed time per iteration (ms): 37634.0 | learning rate: 1.053E-04 | global batch size:  1024 | lm loss: 1.839688E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27778/   51900 | consumed samples:     28444672 | elapsed time per iteration (ms): 37688.5 | learning rate: 1.053E-04 | global batch size:  1024 | lm loss: 1.842607E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27779/   51900 | consumed samples:     28445696 | elapsed time per iteration (ms): 37652.5 | learning rate: 1.053E-04 | global batch size:  1024 | lm loss: 1.834101E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27780/   51900 | consumed samples:     28446720 | elapsed time per iteration (ms): 37728.0 | learning rate: 1.053E-04 | global batch size:  1024 | lm loss: 1.824248E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27781/   51900 | consumed samples:     28447744 | elapsed time per iteration (ms): 37675.0 | learning rate: 1.053E-04 | global batch size:  1024 | lm loss: 1.852315E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27782/   51900 | consumed samples:     28448768 | elapsed time per iteration (ms): 37655.4 | learning rate: 1.053E-04 | global batch size:  1024 | lm loss: 1.862648E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27783/   51900 | consumed samples:     28449792 | elapsed time per iteration (ms): 37575.9 | learning rate: 1.053E-04 | global batch size:  1024 | lm loss: 1.846389E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27784/   51900 | consumed samples:     28450816 | elapsed time per iteration (ms): 37552.6 | learning rate: 1.053E-04 | global batch size:  1024 | lm loss: 1.843337E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27785/   51900 | consumed samples:     28451840 | elapsed time per iteration (ms): 37703.4 | learning rate: 1.053E-04 | global batch size:  1024 | lm loss: 1.843405E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27786/   51900 | consumed samples:     28452864 | elapsed time per iteration (ms): 37666.8 | learning rate: 1.053E-04 | global batch size:  1024 | lm loss: 1.860802E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27787/   51900 | consumed samples:     28453888 | elapsed time per iteration (ms): 37594.4 | learning rate: 1.053E-04 | global batch size:  1024 | lm loss: 1.836820E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27788/   51900 | consumed samples:     28454912 | elapsed time per iteration (ms): 37689.8 | learning rate: 1.053E-04 | global batch size:  1024 | lm loss: 1.843673E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27789/   51900 | consumed samples:     28455936 | elapsed time per iteration (ms): 37575.9 | learning rate: 1.052E-04 | global batch size:  1024 | lm loss: 1.832482E+00 | loss scale: 1.0 | grad norm: 0.091 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27790/   51900 | consumed samples:     28456960 | elapsed time per iteration (ms): 37648.0 | learning rate: 1.052E-04 | global batch size:  1024 | lm loss: 1.840888E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27791/   51900 | consumed samples:     28457984 | elapsed time per iteration (ms): 37726.3 | learning rate: 1.052E-04 | global batch size:  1024 | lm loss: 1.857183E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27792/   51900 | consumed samples:     28459008 | elapsed time per iteration (ms): 37577.9 | learning rate: 1.052E-04 | global batch size:  1024 | lm loss: 1.853126E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27793/   51900 | consumed samples:     28460032 | elapsed time per iteration (ms): 37718.8 | learning rate: 1.052E-04 | global batch size:  1024 | lm loss: 1.848865E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27794/   51900 | consumed samples:     28461056 | elapsed time per iteration (ms): 37715.2 | learning rate: 1.052E-04 | global batch size:  1024 | lm loss: 1.851997E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27795/   51900 | consumed samples:     28462080 | elapsed time per iteration (ms): 37642.1 | learning rate: 1.052E-04 | global batch size:  1024 | lm loss: 1.855253E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27796/   51900 | consumed samples:     28463104 | elapsed time per iteration (ms): 37560.2 | learning rate: 1.052E-04 | global batch size:  1024 | lm loss: 1.851117E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27797/   51900 | consumed samples:     28464128 | elapsed time per iteration (ms): 37557.7 | learning rate: 1.052E-04 | global batch size:  1024 | lm loss: 1.835456E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27798/   51900 | consumed samples:     28465152 | elapsed time per iteration (ms): 37550.3 | learning rate: 1.052E-04 | global batch size:  1024 | lm loss: 1.845624E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27799/   51900 | consumed samples:     28466176 | elapsed time per iteration (ms): 37610.0 | learning rate: 1.052E-04 | global batch size:  1024 | lm loss: 1.860137E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27800/   51900 | consumed samples:     28467200 | elapsed time per iteration (ms): 37626.9 | learning rate: 1.052E-04 | global batch size:  1024 | lm loss: 1.849194E+00 | loss scale: 1.0 | grad norm: 0.087 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27801/   51900 | consumed samples:     28468224 | elapsed time per iteration (ms): 37668.8 | learning rate: 1.052E-04 | global batch size:  1024 | lm loss: 1.840648E+00 | loss scale: 1.0 | grad norm: 0.089 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27802/   51900 | consumed samples:     28469248 | elapsed time per iteration (ms): 37622.9 | learning rate: 1.052E-04 | global batch size:  1024 | lm loss: 1.845478E+00 | loss scale: 1.0 | grad norm: 0.087 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27803/   51900 | consumed samples:     28470272 | elapsed time per iteration (ms): 37628.2 | learning rate: 1.052E-04 | global batch size:  1024 | lm loss: 1.843586E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27804/   51900 | consumed samples:     28471296 | elapsed time per iteration (ms): 37729.2 | learning rate: 1.052E-04 | global batch size:  1024 | lm loss: 1.839068E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27805/   51900 | consumed samples:     28472320 | elapsed time per iteration (ms): 37657.5 | learning rate: 1.052E-04 | global batch size:  1024 | lm loss: 1.845648E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27806/   51900 | consumed samples:     28473344 | elapsed time per iteration (ms): 37614.2 | learning rate: 1.052E-04 | global batch size:  1024 | lm loss: 1.850715E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27807/   51900 | consumed samples:     28474368 | elapsed time per iteration (ms): 37521.0 | learning rate: 1.051E-04 | global batch size:  1024 | lm loss: 1.834526E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27808/   51900 | consumed samples:     28475392 | elapsed time per iteration (ms): 37590.3 | learning rate: 1.051E-04 | global batch size:  1024 | lm loss: 1.837950E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27809/   51900 | consumed samples:     28476416 | elapsed time per iteration (ms): 37641.5 | learning rate: 1.051E-04 | global batch size:  1024 | lm loss: 1.872416E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27810/   51900 | consumed samples:     28477440 | elapsed time per iteration (ms): 37653.4 | learning rate: 1.051E-04 | global batch size:  1024 | lm loss: 1.864879E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27811/   51900 | consumed samples:     28478464 | elapsed time per iteration (ms): 37660.8 | learning rate: 1.051E-04 | global batch size:  1024 | lm loss: 1.847585E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27812/   51900 | consumed samples:     28479488 | elapsed time per iteration (ms): 37657.9 | learning rate: 1.051E-04 | global batch size:  1024 | lm loss: 1.859126E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27813/   51900 | consumed samples:     28480512 | elapsed time per iteration (ms): 37538.2 | learning rate: 1.051E-04 | global batch size:  1024 | lm loss: 1.845421E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27814/   51900 | consumed samples:     28481536 | elapsed time per iteration (ms): 37625.4 | learning rate: 1.051E-04 | global batch size:  1024 | lm loss: 1.855312E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27815/   51900 | consumed samples:     28482560 | elapsed time per iteration (ms): 37629.9 | learning rate: 1.051E-04 | global batch size:  1024 | lm loss: 1.849847E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27816/   51900 | consumed samples:     28483584 | elapsed time per iteration (ms): 37649.3 | learning rate: 1.051E-04 | global batch size:  1024 | lm loss: 1.843879E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27817/   51900 | consumed samples:     28484608 | elapsed time per iteration (ms): 37530.1 | learning rate: 1.051E-04 | global batch size:  1024 | lm loss: 1.842701E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27818/   51900 | consumed samples:     28485632 | elapsed time per iteration (ms): 37800.4 | learning rate: 1.051E-04 | global batch size:  1024 | lm loss: 1.855831E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27819/   51900 | consumed samples:     28486656 | elapsed time per iteration (ms): 37641.0 | learning rate: 1.051E-04 | global batch size:  1024 | lm loss: 1.844587E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27820/   51900 | consumed samples:     28487680 | elapsed time per iteration (ms): 37607.8 | learning rate: 1.051E-04 | global batch size:  1024 | lm loss: 1.849477E+00 | loss scale: 1.0 | grad norm: 0.090 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27821/   51900 | consumed samples:     28488704 | elapsed time per iteration (ms): 37618.9 | learning rate: 1.051E-04 | global batch size:  1024 | lm loss: 1.842293E+00 | loss scale: 1.0 | grad norm: 0.089 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27822/   51900 | consumed samples:     28489728 | elapsed time per iteration (ms): 37534.5 | learning rate: 1.051E-04 | global batch size:  1024 | lm loss: 1.833189E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27823/   51900 | consumed samples:     28490752 | elapsed time per iteration (ms): 37671.2 | learning rate: 1.051E-04 | global batch size:  1024 | lm loss: 1.859363E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27824/   51900 | consumed samples:     28491776 | elapsed time per iteration (ms): 37765.6 | learning rate: 1.051E-04 | global batch size:  1024 | lm loss: 1.820325E+00 | loss scale: 1.0 | grad norm: 0.092 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27825/   51900 | consumed samples:     28492800 | elapsed time per iteration (ms): 37591.5 | learning rate: 1.050E-04 | global batch size:  1024 | lm loss: 1.845350E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27826/   51900 | consumed samples:     28493824 | elapsed time per iteration (ms): 37651.9 | learning rate: 1.050E-04 | global batch size:  1024 | lm loss: 1.851258E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27827/   51900 | consumed samples:     28494848 | elapsed time per iteration (ms): 37591.6 | learning rate: 1.050E-04 | global batch size:  1024 | lm loss: 1.853817E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27828/   51900 | consumed samples:     28495872 | elapsed time per iteration (ms): 37578.3 | learning rate: 1.050E-04 | global batch size:  1024 | lm loss: 1.846080E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27829/   51900 | consumed samples:     28496896 | elapsed time per iteration (ms): 37556.4 | learning rate: 1.050E-04 | global batch size:  1024 | lm loss: 1.834727E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27830/   51900 | consumed samples:     28497920 | elapsed time per iteration (ms): 37677.5 | learning rate: 1.050E-04 | global batch size:  1024 | lm loss: 1.845013E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27831/   51900 | consumed samples:     28498944 | elapsed time per iteration (ms): 37608.7 | learning rate: 1.050E-04 | global batch size:  1024 | lm loss: 1.862889E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27832/   51900 | consumed samples:     28499968 | elapsed time per iteration (ms): 37640.9 | learning rate: 1.050E-04 | global batch size:  1024 | lm loss: 1.846967E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27833/   51900 | consumed samples:     28500992 | elapsed time per iteration (ms): 37655.8 | learning rate: 1.050E-04 | global batch size:  1024 | lm loss: 1.858670E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27834/   51900 | consumed samples:     28502016 | elapsed time per iteration (ms): 37585.4 | learning rate: 1.050E-04 | global batch size:  1024 | lm loss: 1.841495E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27835/   51900 | consumed samples:     28503040 | elapsed time per iteration (ms): 37614.1 | learning rate: 1.050E-04 | global batch size:  1024 | lm loss: 1.839525E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27836/   51900 | consumed samples:     28504064 | elapsed time per iteration (ms): 37701.4 | learning rate: 1.050E-04 | global batch size:  1024 | lm loss: 1.846521E+00 | loss scale: 1.0 | grad norm: 0.202 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27837/   51900 | consumed samples:     28505088 | elapsed time per iteration (ms): 37579.2 | learning rate: 1.050E-04 | global batch size:  1024 | lm loss: 1.832497E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27838/   51900 | consumed samples:     28506112 | elapsed time per iteration (ms): 37711.9 | learning rate: 1.050E-04 | global batch size:  1024 | lm loss: 1.847839E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27839/   51900 | consumed samples:     28507136 | elapsed time per iteration (ms): 37601.3 | learning rate: 1.050E-04 | global batch size:  1024 | lm loss: 1.846099E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27840/   51900 | consumed samples:     28508160 | elapsed time per iteration (ms): 37588.6 | learning rate: 1.050E-04 | global batch size:  1024 | lm loss: 1.840112E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27841/   51900 | consumed samples:     28509184 | elapsed time per iteration (ms): 37577.4 | learning rate: 1.050E-04 | global batch size:  1024 | lm loss: 1.837952E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27842/   51900 | consumed samples:     28510208 | elapsed time per iteration (ms): 37623.2 | learning rate: 1.049E-04 | global batch size:  1024 | lm loss: 1.847033E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27843/   51900 | consumed samples:     28511232 | elapsed time per iteration (ms): 37685.1 | learning rate: 1.049E-04 | global batch size:  1024 | lm loss: 1.841417E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27844/   51900 | consumed samples:     28512256 | elapsed time per iteration (ms): 37620.4 | learning rate: 1.049E-04 | global batch size:  1024 | lm loss: 1.843190E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27845/   51900 | consumed samples:     28513280 | elapsed time per iteration (ms): 37619.1 | learning rate: 1.049E-04 | global batch size:  1024 | lm loss: 1.828354E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27846/   51900 | consumed samples:     28514304 | elapsed time per iteration (ms): 37685.7 | learning rate: 1.049E-04 | global batch size:  1024 | lm loss: 1.841210E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27847/   51900 | consumed samples:     28515328 | elapsed time per iteration (ms): 37609.5 | learning rate: 1.049E-04 | global batch size:  1024 | lm loss: 1.841161E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27848/   51900 | consumed samples:     28516352 | elapsed time per iteration (ms): 37631.9 | learning rate: 1.049E-04 | global batch size:  1024 | lm loss: 1.831662E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27849/   51900 | consumed samples:     28517376 | elapsed time per iteration (ms): 37647.0 | learning rate: 1.049E-04 | global batch size:  1024 | lm loss: 1.849114E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27850/   51900 | consumed samples:     28518400 | elapsed time per iteration (ms): 37650.5 | learning rate: 1.049E-04 | global batch size:  1024 | lm loss: 1.840381E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27851/   51900 | consumed samples:     28519424 | elapsed time per iteration (ms): 37691.1 | learning rate: 1.049E-04 | global batch size:  1024 | lm loss: 1.828915E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27852/   51900 | consumed samples:     28520448 | elapsed time per iteration (ms): 37656.5 | learning rate: 1.049E-04 | global batch size:  1024 | lm loss: 1.846598E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27853/   51900 | consumed samples:     28521472 | elapsed time per iteration (ms): 37629.8 | learning rate: 1.049E-04 | global batch size:  1024 | lm loss: 1.853707E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27854/   51900 | consumed samples:     28522496 | elapsed time per iteration (ms): 37548.5 | learning rate: 1.049E-04 | global batch size:  1024 | lm loss: 1.849508E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27855/   51900 | consumed samples:     28523520 | elapsed time per iteration (ms): 37654.5 | learning rate: 1.049E-04 | global batch size:  1024 | lm loss: 1.840726E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27856/   51900 | consumed samples:     28524544 | elapsed time per iteration (ms): 37650.5 | learning rate: 1.049E-04 | global batch size:  1024 | lm loss: 1.855341E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27857/   51900 | consumed samples:     28525568 | elapsed time per iteration (ms): 37665.4 | learning rate: 1.049E-04 | global batch size:  1024 | lm loss: 1.842074E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27858/   51900 | consumed samples:     28526592 | elapsed time per iteration (ms): 37588.9 | learning rate: 1.049E-04 | global batch size:  1024 | lm loss: 1.845667E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27859/   51900 | consumed samples:     28527616 | elapsed time per iteration (ms): 37685.3 | learning rate: 1.049E-04 | global batch size:  1024 | lm loss: 1.841130E+00 | loss scale: 1.0 | grad norm: 0.094 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27860/   51900 | consumed samples:     28528640 | elapsed time per iteration (ms): 37734.0 | learning rate: 1.048E-04 | global batch size:  1024 | lm loss: 1.835633E+00 | loss scale: 1.0 | grad norm: 0.095 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27861/   51900 | consumed samples:     28529664 | elapsed time per iteration (ms): 37669.5 | learning rate: 1.048E-04 | global batch size:  1024 | lm loss: 1.846630E+00 | loss scale: 1.0 | grad norm: 0.088 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27862/   51900 | consumed samples:     28530688 | elapsed time per iteration (ms): 37671.3 | learning rate: 1.048E-04 | global batch size:  1024 | lm loss: 1.849196E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27863/   51900 | consumed samples:     28531712 | elapsed time per iteration (ms): 37630.0 | learning rate: 1.048E-04 | global batch size:  1024 | lm loss: 1.831765E+00 | loss scale: 1.0 | grad norm: 0.088 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27864/   51900 | consumed samples:     28532736 | elapsed time per iteration (ms): 37673.9 | learning rate: 1.048E-04 | global batch size:  1024 | lm loss: 1.850644E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27865/   51900 | consumed samples:     28533760 | elapsed time per iteration (ms): 37599.4 | learning rate: 1.048E-04 | global batch size:  1024 | lm loss: 1.846357E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27866/   51900 | consumed samples:     28534784 | elapsed time per iteration (ms): 37632.1 | learning rate: 1.048E-04 | global batch size:  1024 | lm loss: 1.863133E+00 | loss scale: 1.0 | grad norm: 0.087 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27867/   51900 | consumed samples:     28535808 | elapsed time per iteration (ms): 37740.4 | learning rate: 1.048E-04 | global batch size:  1024 | lm loss: 1.845065E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27868/   51900 | consumed samples:     28536832 | elapsed time per iteration (ms): 37530.1 | learning rate: 1.048E-04 | global batch size:  1024 | lm loss: 1.845651E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27869/   51900 | consumed samples:     28537856 | elapsed time per iteration (ms): 37681.7 | learning rate: 1.048E-04 | global batch size:  1024 | lm loss: 1.852159E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27870/   51900 | consumed samples:     28538880 | elapsed time per iteration (ms): 37599.2 | learning rate: 1.048E-04 | global batch size:  1024 | lm loss: 1.830534E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27871/   51900 | consumed samples:     28539904 | elapsed time per iteration (ms): 37612.9 | learning rate: 1.048E-04 | global batch size:  1024 | lm loss: 1.851447E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27872/   51900 | consumed samples:     28540928 | elapsed time per iteration (ms): 37708.6 | learning rate: 1.048E-04 | global batch size:  1024 | lm loss: 1.838654E+00 | loss scale: 1.0 | grad norm: 0.109 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27873/   51900 | consumed samples:     28541952 | elapsed time per iteration (ms): 37705.1 | learning rate: 1.048E-04 | global batch size:  1024 | lm loss: 1.846199E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27874/   51900 | consumed samples:     28542976 | elapsed time per iteration (ms): 37681.3 | learning rate: 1.048E-04 | global batch size:  1024 | lm loss: 1.852610E+00 | loss scale: 1.0 | grad norm: 0.088 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27875/   51900 | consumed samples:     28544000 | elapsed time per iteration (ms): 37648.3 | learning rate: 1.048E-04 | global batch size:  1024 | lm loss: 1.859257E+00 | loss scale: 1.0 | grad norm: 0.065 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27876/   51900 | consumed samples:     28545024 | elapsed time per iteration (ms): 37664.8 | learning rate: 1.048E-04 | global batch size:  1024 | lm loss: 1.826928E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27877/   51900 | consumed samples:     28546048 | elapsed time per iteration (ms): 37624.4 | learning rate: 1.048E-04 | global batch size:  1024 | lm loss: 1.832609E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27878/   51900 | consumed samples:     28547072 | elapsed time per iteration (ms): 37553.3 | learning rate: 1.047E-04 | global batch size:  1024 | lm loss: 1.843701E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27879/   51900 | consumed samples:     28548096 | elapsed time per iteration (ms): 37561.8 | learning rate: 1.047E-04 | global batch size:  1024 | lm loss: 1.841912E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27880/   51900 | consumed samples:     28549120 | elapsed time per iteration (ms): 37585.2 | learning rate: 1.047E-04 | global batch size:  1024 | lm loss: 1.855697E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27881/   51900 | consumed samples:     28550144 | elapsed time per iteration (ms): 37587.1 | learning rate: 1.047E-04 | global batch size:  1024 | lm loss: 1.832893E+00 | loss scale: 1.0 | grad norm: 0.109 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27882/   51900 | consumed samples:     28551168 | elapsed time per iteration (ms): 37594.1 | learning rate: 1.047E-04 | global batch size:  1024 | lm loss: 1.840030E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27883/   51900 | consumed samples:     28552192 | elapsed time per iteration (ms): 37744.8 | learning rate: 1.047E-04 | global batch size:  1024 | lm loss: 1.830376E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27884/   51900 | consumed samples:     28553216 | elapsed time per iteration (ms): 37755.0 | learning rate: 1.047E-04 | global batch size:  1024 | lm loss: 1.858638E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27885/   51900 | consumed samples:     28554240 | elapsed time per iteration (ms): 37622.5 | learning rate: 1.047E-04 | global batch size:  1024 | lm loss: 1.850699E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27886/   51900 | consumed samples:     28555264 | elapsed time per iteration (ms): 37585.7 | learning rate: 1.047E-04 | global batch size:  1024 | lm loss: 1.836169E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27887/   51900 | consumed samples:     28556288 | elapsed time per iteration (ms): 37646.6 | learning rate: 1.047E-04 | global batch size:  1024 | lm loss: 1.844158E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27888/   51900 | consumed samples:     28557312 | elapsed time per iteration (ms): 37653.5 | learning rate: 1.047E-04 | global batch size:  1024 | lm loss: 1.844293E+00 | loss scale: 1.0 | grad norm: 0.089 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27889/   51900 | consumed samples:     28558336 | elapsed time per iteration (ms): 37705.9 | learning rate: 1.047E-04 | global batch size:  1024 | lm loss: 1.835338E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27890/   51900 | consumed samples:     28559360 | elapsed time per iteration (ms): 37647.3 | learning rate: 1.047E-04 | global batch size:  1024 | lm loss: 1.837861E+00 | loss scale: 1.0 | grad norm: 0.090 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27891/   51900 | consumed samples:     28560384 | elapsed time per iteration (ms): 37604.5 | learning rate: 1.047E-04 | global batch size:  1024 | lm loss: 1.859696E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27892/   51900 | consumed samples:     28561408 | elapsed time per iteration (ms): 37616.2 | learning rate: 1.047E-04 | global batch size:  1024 | lm loss: 1.831869E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27893/   51900 | consumed samples:     28562432 | elapsed time per iteration (ms): 37655.4 | learning rate: 1.047E-04 | global batch size:  1024 | lm loss: 1.854023E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27894/   51900 | consumed samples:     28563456 | elapsed time per iteration (ms): 37695.6 | learning rate: 1.047E-04 | global batch size:  1024 | lm loss: 1.845128E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27895/   51900 | consumed samples:     28564480 | elapsed time per iteration (ms): 37644.5 | learning rate: 1.046E-04 | global batch size:  1024 | lm loss: 1.823584E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27896/   51900 | consumed samples:     28565504 | elapsed time per iteration (ms): 37700.0 | learning rate: 1.046E-04 | global batch size:  1024 | lm loss: 1.859490E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27897/   51900 | consumed samples:     28566528 | elapsed time per iteration (ms): 37630.7 | learning rate: 1.046E-04 | global batch size:  1024 | lm loss: 1.846869E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27898/   51900 | consumed samples:     28567552 | elapsed time per iteration (ms): 37706.1 | learning rate: 1.046E-04 | global batch size:  1024 | lm loss: 1.852452E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27899/   51900 | consumed samples:     28568576 | elapsed time per iteration (ms): 37708.8 | learning rate: 1.046E-04 | global batch size:  1024 | lm loss: 1.823986E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27900/   51900 | consumed samples:     28569600 | elapsed time per iteration (ms): 37724.9 | learning rate: 1.046E-04 | global batch size:  1024 | lm loss: 1.852844E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27901/   51900 | consumed samples:     28570624 | elapsed time per iteration (ms): 37700.0 | learning rate: 1.046E-04 | global batch size:  1024 | lm loss: 1.838177E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27902/   51900 | consumed samples:     28571648 | elapsed time per iteration (ms): 37720.9 | learning rate: 1.046E-04 | global batch size:  1024 | lm loss: 1.853754E+00 | loss scale: 1.0 | grad norm: 0.089 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27903/   51900 | consumed samples:     28572672 | elapsed time per iteration (ms): 37587.4 | learning rate: 1.046E-04 | global batch size:  1024 | lm loss: 1.866673E+00 | loss scale: 1.0 | grad norm: 0.095 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27904/   51900 | consumed samples:     28573696 | elapsed time per iteration (ms): 37568.2 | learning rate: 1.046E-04 | global batch size:  1024 | lm loss: 1.852410E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27905/   51900 | consumed samples:     28574720 | elapsed time per iteration (ms): 37700.8 | learning rate: 1.046E-04 | global batch size:  1024 | lm loss: 1.853818E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27906/   51900 | consumed samples:     28575744 | elapsed time per iteration (ms): 37689.8 | learning rate: 1.046E-04 | global batch size:  1024 | lm loss: 1.830605E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27907/   51900 | consumed samples:     28576768 | elapsed time per iteration (ms): 37661.7 | learning rate: 1.046E-04 | global batch size:  1024 | lm loss: 1.844305E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27908/   51900 | consumed samples:     28577792 | elapsed time per iteration (ms): 37673.6 | learning rate: 1.046E-04 | global batch size:  1024 | lm loss: 1.846784E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27909/   51900 | consumed samples:     28578816 | elapsed time per iteration (ms): 37670.8 | learning rate: 1.046E-04 | global batch size:  1024 | lm loss: 1.855619E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27910/   51900 | consumed samples:     28579840 | elapsed time per iteration (ms): 37658.1 | learning rate: 1.046E-04 | global batch size:  1024 | lm loss: 1.842218E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27911/   51900 | consumed samples:     28580864 | elapsed time per iteration (ms): 37603.9 | learning rate: 1.046E-04 | global batch size:  1024 | lm loss: 1.858358E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27912/   51900 | consumed samples:     28581888 | elapsed time per iteration (ms): 37607.1 | learning rate: 1.046E-04 | global batch size:  1024 | lm loss: 1.856800E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27913/   51900 | consumed samples:     28582912 | elapsed time per iteration (ms): 37537.9 | learning rate: 1.045E-04 | global batch size:  1024 | lm loss: 1.824521E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27914/   51900 | consumed samples:     28583936 | elapsed time per iteration (ms): 37680.5 | learning rate: 1.045E-04 | global batch size:  1024 | lm loss: 1.839125E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27915/   51900 | consumed samples:     28584960 | elapsed time per iteration (ms): 37576.1 | learning rate: 1.045E-04 | global batch size:  1024 | lm loss: 1.825884E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27916/   51900 | consumed samples:     28585984 | elapsed time per iteration (ms): 37617.5 | learning rate: 1.045E-04 | global batch size:  1024 | lm loss: 1.845709E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27917/   51900 | consumed samples:     28587008 | elapsed time per iteration (ms): 37629.7 | learning rate: 1.045E-04 | global batch size:  1024 | lm loss: 1.831812E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27918/   51900 | consumed samples:     28588032 | elapsed time per iteration (ms): 37651.5 | learning rate: 1.045E-04 | global batch size:  1024 | lm loss: 1.839920E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27919/   51900 | consumed samples:     28589056 | elapsed time per iteration (ms): 37577.3 | learning rate: 1.045E-04 | global batch size:  1024 | lm loss: 1.854373E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27920/   51900 | consumed samples:     28590080 | elapsed time per iteration (ms): 37593.3 | learning rate: 1.045E-04 | global batch size:  1024 | lm loss: 1.832291E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27921/   51900 | consumed samples:     28591104 | elapsed time per iteration (ms): 37649.0 | learning rate: 1.045E-04 | global batch size:  1024 | lm loss: 1.863205E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27922/   51900 | consumed samples:     28592128 | elapsed time per iteration (ms): 37559.5 | learning rate: 1.045E-04 | global batch size:  1024 | lm loss: 1.852881E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27923/   51900 | consumed samples:     28593152 | elapsed time per iteration (ms): 37569.7 | learning rate: 1.045E-04 | global batch size:  1024 | lm loss: 1.854168E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27924/   51900 | consumed samples:     28594176 | elapsed time per iteration (ms): 37596.1 | learning rate: 1.045E-04 | global batch size:  1024 | lm loss: 1.847411E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27925/   51900 | consumed samples:     28595200 | elapsed time per iteration (ms): 37658.5 | learning rate: 1.045E-04 | global batch size:  1024 | lm loss: 1.852544E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27926/   51900 | consumed samples:     28596224 | elapsed time per iteration (ms): 37548.9 | learning rate: 1.045E-04 | global batch size:  1024 | lm loss: 1.833388E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27927/   51900 | consumed samples:     28597248 | elapsed time per iteration (ms): 37551.6 | learning rate: 1.045E-04 | global batch size:  1024 | lm loss: 1.849672E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27928/   51900 | consumed samples:     28598272 | elapsed time per iteration (ms): 37637.2 | learning rate: 1.045E-04 | global batch size:  1024 | lm loss: 1.862515E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27929/   51900 | consumed samples:     28599296 | elapsed time per iteration (ms): 37694.7 | learning rate: 1.045E-04 | global batch size:  1024 | lm loss: 1.836222E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27930/   51900 | consumed samples:     28600320 | elapsed time per iteration (ms): 37663.6 | learning rate: 1.045E-04 | global batch size:  1024 | lm loss: 1.834313E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27931/   51900 | consumed samples:     28601344 | elapsed time per iteration (ms): 37705.1 | learning rate: 1.044E-04 | global batch size:  1024 | lm loss: 1.845615E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27932/   51900 | consumed samples:     28602368 | elapsed time per iteration (ms): 37668.3 | learning rate: 1.044E-04 | global batch size:  1024 | lm loss: 1.843018E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27933/   51900 | consumed samples:     28603392 | elapsed time per iteration (ms): 37601.2 | learning rate: 1.044E-04 | global batch size:  1024 | lm loss: 1.847137E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27934/   51900 | consumed samples:     28604416 | elapsed time per iteration (ms): 37779.0 | learning rate: 1.044E-04 | global batch size:  1024 | lm loss: 1.840903E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27935/   51900 | consumed samples:     28605440 | elapsed time per iteration (ms): 37772.7 | learning rate: 1.044E-04 | global batch size:  1024 | lm loss: 1.836720E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27936/   51900 | consumed samples:     28606464 | elapsed time per iteration (ms): 37646.0 | learning rate: 1.044E-04 | global batch size:  1024 | lm loss: 1.840749E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27937/   51900 | consumed samples:     28607488 | elapsed time per iteration (ms): 37594.0 | learning rate: 1.044E-04 | global batch size:  1024 | lm loss: 1.838882E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27938/   51900 | consumed samples:     28608512 | elapsed time per iteration (ms): 37575.6 | learning rate: 1.044E-04 | global batch size:  1024 | lm loss: 1.844951E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27939/   51900 | consumed samples:     28609536 | elapsed time per iteration (ms): 37517.4 | learning rate: 1.044E-04 | global batch size:  1024 | lm loss: 1.834577E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27940/   51900 | consumed samples:     28610560 | elapsed time per iteration (ms): 37558.2 | learning rate: 1.044E-04 | global batch size:  1024 | lm loss: 1.847223E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27941/   51900 | consumed samples:     28611584 | elapsed time per iteration (ms): 37689.3 | learning rate: 1.044E-04 | global batch size:  1024 | lm loss: 1.842423E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27942/   51900 | consumed samples:     28612608 | elapsed time per iteration (ms): 37580.8 | learning rate: 1.044E-04 | global batch size:  1024 | lm loss: 1.823327E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27943/   51900 | consumed samples:     28613632 | elapsed time per iteration (ms): 37724.0 | learning rate: 1.044E-04 | global batch size:  1024 | lm loss: 1.853469E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27944/   51900 | consumed samples:     28614656 | elapsed time per iteration (ms): 37592.3 | learning rate: 1.044E-04 | global batch size:  1024 | lm loss: 1.851148E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27945/   51900 | consumed samples:     28615680 | elapsed time per iteration (ms): 37625.6 | learning rate: 1.044E-04 | global batch size:  1024 | lm loss: 1.849184E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27946/   51900 | consumed samples:     28616704 | elapsed time per iteration (ms): 37609.6 | learning rate: 1.044E-04 | global batch size:  1024 | lm loss: 1.851256E+00 | loss scale: 1.0 | grad norm: 0.099 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27947/   51900 | consumed samples:     28617728 | elapsed time per iteration (ms): 37666.5 | learning rate: 1.044E-04 | global batch size:  1024 | lm loss: 1.838431E+00 | loss scale: 1.0 | grad norm: 0.088 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27948/   51900 | consumed samples:     28618752 | elapsed time per iteration (ms): 37638.1 | learning rate: 1.043E-04 | global batch size:  1024 | lm loss: 1.844357E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27949/   51900 | consumed samples:     28619776 | elapsed time per iteration (ms): 37675.9 | learning rate: 1.043E-04 | global batch size:  1024 | lm loss: 1.843780E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27950/   51900 | consumed samples:     28620800 | elapsed time per iteration (ms): 37782.6 | learning rate: 1.043E-04 | global batch size:  1024 | lm loss: 1.847529E+00 | loss scale: 1.0 | grad norm: 0.095 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27951/   51900 | consumed samples:     28621824 | elapsed time per iteration (ms): 37757.2 | learning rate: 1.043E-04 | global batch size:  1024 | lm loss: 1.862546E+00 | loss scale: 1.0 | grad norm: 0.089 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27952/   51900 | consumed samples:     28622848 | elapsed time per iteration (ms): 37585.8 | learning rate: 1.043E-04 | global batch size:  1024 | lm loss: 1.836517E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27953/   51900 | consumed samples:     28623872 | elapsed time per iteration (ms): 37718.5 | learning rate: 1.043E-04 | global batch size:  1024 | lm loss: 1.835913E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27954/   51900 | consumed samples:     28624896 | elapsed time per iteration (ms): 37643.7 | learning rate: 1.043E-04 | global batch size:  1024 | lm loss: 1.853574E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27955/   51900 | consumed samples:     28625920 | elapsed time per iteration (ms): 37546.3 | learning rate: 1.043E-04 | global batch size:  1024 | lm loss: 1.830117E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27956/   51900 | consumed samples:     28626944 | elapsed time per iteration (ms): 37731.0 | learning rate: 1.043E-04 | global batch size:  1024 | lm loss: 1.842429E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27957/   51900 | consumed samples:     28627968 | elapsed time per iteration (ms): 37609.7 | learning rate: 1.043E-04 | global batch size:  1024 | lm loss: 1.819358E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27958/   51900 | consumed samples:     28628992 | elapsed time per iteration (ms): 37544.3 | learning rate: 1.043E-04 | global batch size:  1024 | lm loss: 1.847849E+00 | loss scale: 1.0 | grad norm: 0.089 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27959/   51900 | consumed samples:     28630016 | elapsed time per iteration (ms): 37631.9 | learning rate: 1.043E-04 | global batch size:  1024 | lm loss: 1.827969E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27960/   51900 | consumed samples:     28631040 | elapsed time per iteration (ms): 37548.0 | learning rate: 1.043E-04 | global batch size:  1024 | lm loss: 1.856909E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27961/   51900 | consumed samples:     28632064 | elapsed time per iteration (ms): 37548.7 | learning rate: 1.043E-04 | global batch size:  1024 | lm loss: 1.834811E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27962/   51900 | consumed samples:     28633088 | elapsed time per iteration (ms): 37654.6 | learning rate: 1.043E-04 | global batch size:  1024 | lm loss: 1.858545E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27963/   51900 | consumed samples:     28634112 | elapsed time per iteration (ms): 37566.8 | learning rate: 1.043E-04 | global batch size:  1024 | lm loss: 1.837563E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27964/   51900 | consumed samples:     28635136 | elapsed time per iteration (ms): 37586.6 | learning rate: 1.043E-04 | global batch size:  1024 | lm loss: 1.841631E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27965/   51900 | consumed samples:     28636160 | elapsed time per iteration (ms): 37566.9 | learning rate: 1.043E-04 | global batch size:  1024 | lm loss: 1.852268E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27966/   51900 | consumed samples:     28637184 | elapsed time per iteration (ms): 37696.0 | learning rate: 1.042E-04 | global batch size:  1024 | lm loss: 1.854982E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27967/   51900 | consumed samples:     28638208 | elapsed time per iteration (ms): 37659.1 | learning rate: 1.042E-04 | global batch size:  1024 | lm loss: 1.829814E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27968/   51900 | consumed samples:     28639232 | elapsed time per iteration (ms): 37644.3 | learning rate: 1.042E-04 | global batch size:  1024 | lm loss: 1.840778E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27969/   51900 | consumed samples:     28640256 | elapsed time per iteration (ms): 37813.7 | learning rate: 1.042E-04 | global batch size:  1024 | lm loss: 1.865785E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27970/   51900 | consumed samples:     28641280 | elapsed time per iteration (ms): 37611.5 | learning rate: 1.042E-04 | global batch size:  1024 | lm loss: 1.850604E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27971/   51900 | consumed samples:     28642304 | elapsed time per iteration (ms): 37643.4 | learning rate: 1.042E-04 | global batch size:  1024 | lm loss: 1.840747E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27972/   51900 | consumed samples:     28643328 | elapsed time per iteration (ms): 37560.6 | learning rate: 1.042E-04 | global batch size:  1024 | lm loss: 1.862307E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27973/   51900 | consumed samples:     28644352 | elapsed time per iteration (ms): 37531.8 | learning rate: 1.042E-04 | global batch size:  1024 | lm loss: 1.828467E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27974/   51900 | consumed samples:     28645376 | elapsed time per iteration (ms): 37695.1 | learning rate: 1.042E-04 | global batch size:  1024 | lm loss: 1.829352E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27975/   51900 | consumed samples:     28646400 | elapsed time per iteration (ms): 37745.7 | learning rate: 1.042E-04 | global batch size:  1024 | lm loss: 1.820571E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27976/   51900 | consumed samples:     28647424 | elapsed time per iteration (ms): 37532.6 | learning rate: 1.042E-04 | global batch size:  1024 | lm loss: 1.856748E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27977/   51900 | consumed samples:     28648448 | elapsed time per iteration (ms): 37540.1 | learning rate: 1.042E-04 | global batch size:  1024 | lm loss: 1.844064E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27978/   51900 | consumed samples:     28649472 | elapsed time per iteration (ms): 37640.1 | learning rate: 1.042E-04 | global batch size:  1024 | lm loss: 1.846874E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27979/   51900 | consumed samples:     28650496 | elapsed time per iteration (ms): 37604.8 | learning rate: 1.042E-04 | global batch size:  1024 | lm loss: 1.841046E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27980/   51900 | consumed samples:     28651520 | elapsed time per iteration (ms): 37629.4 | learning rate: 1.042E-04 | global batch size:  1024 | lm loss: 1.850324E+00 | loss scale: 1.0 | grad norm: 0.090 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27981/   51900 | consumed samples:     28652544 | elapsed time per iteration (ms): 37654.2 | learning rate: 1.042E-04 | global batch size:  1024 | lm loss: 1.847604E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27982/   51900 | consumed samples:     28653568 | elapsed time per iteration (ms): 37668.5 | learning rate: 1.042E-04 | global batch size:  1024 | lm loss: 1.868439E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27983/   51900 | consumed samples:     28654592 | elapsed time per iteration (ms): 37755.0 | learning rate: 1.042E-04 | global batch size:  1024 | lm loss: 1.843458E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27984/   51900 | consumed samples:     28655616 | elapsed time per iteration (ms): 37569.3 | learning rate: 1.041E-04 | global batch size:  1024 | lm loss: 1.837346E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27985/   51900 | consumed samples:     28656640 | elapsed time per iteration (ms): 37646.2 | learning rate: 1.041E-04 | global batch size:  1024 | lm loss: 1.843358E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27986/   51900 | consumed samples:     28657664 | elapsed time per iteration (ms): 37597.6 | learning rate: 1.041E-04 | global batch size:  1024 | lm loss: 1.831681E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27987/   51900 | consumed samples:     28658688 | elapsed time per iteration (ms): 37681.7 | learning rate: 1.041E-04 | global batch size:  1024 | lm loss: 1.856515E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27988/   51900 | consumed samples:     28659712 | elapsed time per iteration (ms): 37876.1 | learning rate: 1.041E-04 | global batch size:  1024 | lm loss: 1.848875E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27989/   51900 | consumed samples:     28660736 | elapsed time per iteration (ms): 37746.1 | learning rate: 1.041E-04 | global batch size:  1024 | lm loss: 1.845388E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27990/   51900 | consumed samples:     28661760 | elapsed time per iteration (ms): 37698.8 | learning rate: 1.041E-04 | global batch size:  1024 | lm loss: 1.833755E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27991/   51900 | consumed samples:     28662784 | elapsed time per iteration (ms): 37594.8 | learning rate: 1.041E-04 | global batch size:  1024 | lm loss: 1.851628E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27992/   51900 | consumed samples:     28663808 | elapsed time per iteration (ms): 37636.1 | learning rate: 1.041E-04 | global batch size:  1024 | lm loss: 1.848795E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27993/   51900 | consumed samples:     28664832 | elapsed time per iteration (ms): 37670.3 | learning rate: 1.041E-04 | global batch size:  1024 | lm loss: 1.838606E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27994/   51900 | consumed samples:     28665856 | elapsed time per iteration (ms): 37612.4 | learning rate: 1.041E-04 | global batch size:  1024 | lm loss: 1.825582E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27995/   51900 | consumed samples:     28666880 | elapsed time per iteration (ms): 37786.9 | learning rate: 1.041E-04 | global batch size:  1024 | lm loss: 1.833117E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27996/   51900 | consumed samples:     28667904 | elapsed time per iteration (ms): 37608.2 | learning rate: 1.041E-04 | global batch size:  1024 | lm loss: 1.851231E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27997/   51900 | consumed samples:     28668928 | elapsed time per iteration (ms): 37559.8 | learning rate: 1.041E-04 | global batch size:  1024 | lm loss: 1.848121E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27998/   51900 | consumed samples:     28669952 | elapsed time per iteration (ms): 37581.9 | learning rate: 1.041E-04 | global batch size:  1024 | lm loss: 1.852895E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    27999/   51900 | consumed samples:     28670976 | elapsed time per iteration (ms): 37577.6 | learning rate: 1.041E-04 | global batch size:  1024 | lm loss: 1.836805E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28000/   51900 | consumed samples:     28672000 | elapsed time per iteration (ms): 37649.7 | learning rate: 1.041E-04 | global batch size:  1024 | lm loss: 1.839382E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    save-checkpoint ................................: (171663.31, 171663.39)
 iteration    28001/   51900 | consumed samples:     28673024 | elapsed time per iteration (ms): 37181.8 | learning rate: 1.040E-04 | global batch size:  1024 | lm loss: 1.834283E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28002/   51900 | consumed samples:     28674048 | elapsed time per iteration (ms): 37633.1 | learning rate: 1.040E-04 | global batch size:  1024 | lm loss: 1.848157E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28003/   51900 | consumed samples:     28675072 | elapsed time per iteration (ms): 37701.8 | learning rate: 1.040E-04 | global batch size:  1024 | lm loss: 1.856145E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28004/   51900 | consumed samples:     28676096 | elapsed time per iteration (ms): 37622.6 | learning rate: 1.040E-04 | global batch size:  1024 | lm loss: 1.857322E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28005/   51900 | consumed samples:     28677120 | elapsed time per iteration (ms): 37672.6 | learning rate: 1.040E-04 | global batch size:  1024 | lm loss: 1.850195E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28006/   51900 | consumed samples:     28678144 | elapsed time per iteration (ms): 37614.5 | learning rate: 1.040E-04 | global batch size:  1024 | lm loss: 1.846846E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28007/   51900 | consumed samples:     28679168 | elapsed time per iteration (ms): 37612.7 | learning rate: 1.040E-04 | global batch size:  1024 | lm loss: 1.831312E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28008/   51900 | consumed samples:     28680192 | elapsed time per iteration (ms): 37539.3 | learning rate: 1.040E-04 | global batch size:  1024 | lm loss: 1.839866E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28009/   51900 | consumed samples:     28681216 | elapsed time per iteration (ms): 37606.2 | learning rate: 1.040E-04 | global batch size:  1024 | lm loss: 1.841152E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28010/   51900 | consumed samples:     28682240 | elapsed time per iteration (ms): 37706.9 | learning rate: 1.040E-04 | global batch size:  1024 | lm loss: 1.845645E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28011/   51900 | consumed samples:     28683264 | elapsed time per iteration (ms): 37568.8 | learning rate: 1.040E-04 | global batch size:  1024 | lm loss: 1.835338E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28012/   51900 | consumed samples:     28684288 | elapsed time per iteration (ms): 37659.9 | learning rate: 1.040E-04 | global batch size:  1024 | lm loss: 1.850155E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28013/   51900 | consumed samples:     28685312 | elapsed time per iteration (ms): 37677.3 | learning rate: 1.040E-04 | global batch size:  1024 | lm loss: 1.873280E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28014/   51900 | consumed samples:     28686336 | elapsed time per iteration (ms): 37596.6 | learning rate: 1.040E-04 | global batch size:  1024 | lm loss: 1.850662E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28015/   51900 | consumed samples:     28687360 | elapsed time per iteration (ms): 37694.9 | learning rate: 1.040E-04 | global batch size:  1024 | lm loss: 1.842879E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28016/   51900 | consumed samples:     28688384 | elapsed time per iteration (ms): 37708.3 | learning rate: 1.040E-04 | global batch size:  1024 | lm loss: 1.836613E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28017/   51900 | consumed samples:     28689408 | elapsed time per iteration (ms): 37674.6 | learning rate: 1.040E-04 | global batch size:  1024 | lm loss: 1.848826E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28018/   51900 | consumed samples:     28690432 | elapsed time per iteration (ms): 37628.7 | learning rate: 1.040E-04 | global batch size:  1024 | lm loss: 1.837146E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28019/   51900 | consumed samples:     28691456 | elapsed time per iteration (ms): 37757.9 | learning rate: 1.039E-04 | global batch size:  1024 | lm loss: 1.842136E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28020/   51900 | consumed samples:     28692480 | elapsed time per iteration (ms): 37658.3 | learning rate: 1.039E-04 | global batch size:  1024 | lm loss: 1.846942E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28021/   51900 | consumed samples:     28693504 | elapsed time per iteration (ms): 37566.8 | learning rate: 1.039E-04 | global batch size:  1024 | lm loss: 1.843215E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28022/   51900 | consumed samples:     28694528 | elapsed time per iteration (ms): 37558.1 | learning rate: 1.039E-04 | global batch size:  1024 | lm loss: 1.852600E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28023/   51900 | consumed samples:     28695552 | elapsed time per iteration (ms): 37544.1 | learning rate: 1.039E-04 | global batch size:  1024 | lm loss: 1.835532E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28024/   51900 | consumed samples:     28696576 | elapsed time per iteration (ms): 37747.0 | learning rate: 1.039E-04 | global batch size:  1024 | lm loss: 1.830033E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28025/   51900 | consumed samples:     28697600 | elapsed time per iteration (ms): 37574.1 | learning rate: 1.039E-04 | global batch size:  1024 | lm loss: 1.833172E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28026/   51900 | consumed samples:     28698624 | elapsed time per iteration (ms): 37579.1 | learning rate: 1.039E-04 | global batch size:  1024 | lm loss: 1.844900E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28027/   51900 | consumed samples:     28699648 | elapsed time per iteration (ms): 37738.9 | learning rate: 1.039E-04 | global batch size:  1024 | lm loss: 1.842051E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28028/   51900 | consumed samples:     28700672 | elapsed time per iteration (ms): 37614.3 | learning rate: 1.039E-04 | global batch size:  1024 | lm loss: 1.824043E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28029/   51900 | consumed samples:     28701696 | elapsed time per iteration (ms): 37626.2 | learning rate: 1.039E-04 | global batch size:  1024 | lm loss: 1.835957E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28030/   51900 | consumed samples:     28702720 | elapsed time per iteration (ms): 37663.6 | learning rate: 1.039E-04 | global batch size:  1024 | lm loss: 1.860088E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28031/   51900 | consumed samples:     28703744 | elapsed time per iteration (ms): 37668.4 | learning rate: 1.039E-04 | global batch size:  1024 | lm loss: 1.846014E+00 | loss scale: 1.0 | grad norm: 0.090 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28032/   51900 | consumed samples:     28704768 | elapsed time per iteration (ms): 37672.7 | learning rate: 1.039E-04 | global batch size:  1024 | lm loss: 1.843332E+00 | loss scale: 1.0 | grad norm: 0.091 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28033/   51900 | consumed samples:     28705792 | elapsed time per iteration (ms): 37681.0 | learning rate: 1.039E-04 | global batch size:  1024 | lm loss: 1.841578E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28034/   51900 | consumed samples:     28706816 | elapsed time per iteration (ms): 37679.1 | learning rate: 1.039E-04 | global batch size:  1024 | lm loss: 1.839367E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28035/   51900 | consumed samples:     28707840 | elapsed time per iteration (ms): 37650.9 | learning rate: 1.039E-04 | global batch size:  1024 | lm loss: 1.842537E+00 | loss scale: 1.0 | grad norm: 0.087 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28036/   51900 | consumed samples:     28708864 | elapsed time per iteration (ms): 37569.6 | learning rate: 1.039E-04 | global batch size:  1024 | lm loss: 1.836275E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28037/   51900 | consumed samples:     28709888 | elapsed time per iteration (ms): 37511.0 | learning rate: 1.038E-04 | global batch size:  1024 | lm loss: 1.837349E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28038/   51900 | consumed samples:     28710912 | elapsed time per iteration (ms): 37657.7 | learning rate: 1.038E-04 | global batch size:  1024 | lm loss: 1.841369E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28039/   51900 | consumed samples:     28711936 | elapsed time per iteration (ms): 37633.9 | learning rate: 1.038E-04 | global batch size:  1024 | lm loss: 1.853551E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28040/   51900 | consumed samples:     28712960 | elapsed time per iteration (ms): 37740.9 | learning rate: 1.038E-04 | global batch size:  1024 | lm loss: 1.851942E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28041/   51900 | consumed samples:     28713984 | elapsed time per iteration (ms): 37669.4 | learning rate: 1.038E-04 | global batch size:  1024 | lm loss: 1.831698E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28042/   51900 | consumed samples:     28715008 | elapsed time per iteration (ms): 37564.9 | learning rate: 1.038E-04 | global batch size:  1024 | lm loss: 1.847151E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28043/   51900 | consumed samples:     28716032 | elapsed time per iteration (ms): 37697.8 | learning rate: 1.038E-04 | global batch size:  1024 | lm loss: 1.838251E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28044/   51900 | consumed samples:     28717056 | elapsed time per iteration (ms): 37697.6 | learning rate: 1.038E-04 | global batch size:  1024 | lm loss: 1.848165E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28045/   51900 | consumed samples:     28718080 | elapsed time per iteration (ms): 37759.9 | learning rate: 1.038E-04 | global batch size:  1024 | lm loss: 1.866794E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28046/   51900 | consumed samples:     28719104 | elapsed time per iteration (ms): 37561.5 | learning rate: 1.038E-04 | global batch size:  1024 | lm loss: 1.843511E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28047/   51900 | consumed samples:     28720128 | elapsed time per iteration (ms): 37490.5 | learning rate: 1.038E-04 | global batch size:  1024 | lm loss: 1.838721E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28048/   51900 | consumed samples:     28721152 | elapsed time per iteration (ms): 37552.8 | learning rate: 1.038E-04 | global batch size:  1024 | lm loss: 1.831812E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28049/   51900 | consumed samples:     28722176 | elapsed time per iteration (ms): 37699.0 | learning rate: 1.038E-04 | global batch size:  1024 | lm loss: 1.832951E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28050/   51900 | consumed samples:     28723200 | elapsed time per iteration (ms): 37636.5 | learning rate: 1.038E-04 | global batch size:  1024 | lm loss: 1.836830E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28051/   51900 | consumed samples:     28724224 | elapsed time per iteration (ms): 37612.2 | learning rate: 1.038E-04 | global batch size:  1024 | lm loss: 1.851259E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28052/   51900 | consumed samples:     28725248 | elapsed time per iteration (ms): 37596.7 | learning rate: 1.038E-04 | global batch size:  1024 | lm loss: 1.834016E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28053/   51900 | consumed samples:     28726272 | elapsed time per iteration (ms): 37652.6 | learning rate: 1.038E-04 | global batch size:  1024 | lm loss: 1.830914E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28054/   51900 | consumed samples:     28727296 | elapsed time per iteration (ms): 37556.8 | learning rate: 1.037E-04 | global batch size:  1024 | lm loss: 1.864025E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28055/   51900 | consumed samples:     28728320 | elapsed time per iteration (ms): 37717.3 | learning rate: 1.037E-04 | global batch size:  1024 | lm loss: 1.819131E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28056/   51900 | consumed samples:     28729344 | elapsed time per iteration (ms): 37682.9 | learning rate: 1.037E-04 | global batch size:  1024 | lm loss: 1.854311E+00 | loss scale: 1.0 | grad norm: 0.087 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28057/   51900 | consumed samples:     28730368 | elapsed time per iteration (ms): 37492.8 | learning rate: 1.037E-04 | global batch size:  1024 | lm loss: 1.848562E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28058/   51900 | consumed samples:     28731392 | elapsed time per iteration (ms): 37525.1 | learning rate: 1.037E-04 | global batch size:  1024 | lm loss: 1.822969E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28059/   51900 | consumed samples:     28732416 | elapsed time per iteration (ms): 37691.2 | learning rate: 1.037E-04 | global batch size:  1024 | lm loss: 1.849122E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28060/   51900 | consumed samples:     28733440 | elapsed time per iteration (ms): 37643.8 | learning rate: 1.037E-04 | global batch size:  1024 | lm loss: 1.839782E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28061/   51900 | consumed samples:     28734464 | elapsed time per iteration (ms): 37601.6 | learning rate: 1.037E-04 | global batch size:  1024 | lm loss: 1.846255E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28062/   51900 | consumed samples:     28735488 | elapsed time per iteration (ms): 37552.3 | learning rate: 1.037E-04 | global batch size:  1024 | lm loss: 1.842877E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28063/   51900 | consumed samples:     28736512 | elapsed time per iteration (ms): 37621.4 | learning rate: 1.037E-04 | global batch size:  1024 | lm loss: 1.835612E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28064/   51900 | consumed samples:     28737536 | elapsed time per iteration (ms): 37718.0 | learning rate: 1.037E-04 | global batch size:  1024 | lm loss: 1.851714E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28065/   51900 | consumed samples:     28738560 | elapsed time per iteration (ms): 37617.1 | learning rate: 1.037E-04 | global batch size:  1024 | lm loss: 1.821592E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28066/   51900 | consumed samples:     28739584 | elapsed time per iteration (ms): 37666.5 | learning rate: 1.037E-04 | global batch size:  1024 | lm loss: 1.856684E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28067/   51900 | consumed samples:     28740608 | elapsed time per iteration (ms): 37626.6 | learning rate: 1.037E-04 | global batch size:  1024 | lm loss: 1.852528E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28068/   51900 | consumed samples:     28741632 | elapsed time per iteration (ms): 37519.5 | learning rate: 1.037E-04 | global batch size:  1024 | lm loss: 1.849395E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28069/   51900 | consumed samples:     28742656 | elapsed time per iteration (ms): 37749.0 | learning rate: 1.037E-04 | global batch size:  1024 | lm loss: 1.847253E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28070/   51900 | consumed samples:     28743680 | elapsed time per iteration (ms): 37554.2 | learning rate: 1.037E-04 | global batch size:  1024 | lm loss: 1.857870E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28071/   51900 | consumed samples:     28744704 | elapsed time per iteration (ms): 37690.3 | learning rate: 1.037E-04 | global batch size:  1024 | lm loss: 1.842379E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28072/   51900 | consumed samples:     28745728 | elapsed time per iteration (ms): 37655.8 | learning rate: 1.036E-04 | global batch size:  1024 | lm loss: 1.861633E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28073/   51900 | consumed samples:     28746752 | elapsed time per iteration (ms): 37656.8 | learning rate: 1.036E-04 | global batch size:  1024 | lm loss: 1.843804E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28074/   51900 | consumed samples:     28747776 | elapsed time per iteration (ms): 37622.1 | learning rate: 1.036E-04 | global batch size:  1024 | lm loss: 1.860298E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28075/   51900 | consumed samples:     28748800 | elapsed time per iteration (ms): 37571.0 | learning rate: 1.036E-04 | global batch size:  1024 | lm loss: 1.829008E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28076/   51900 | consumed samples:     28749824 | elapsed time per iteration (ms): 37728.4 | learning rate: 1.036E-04 | global batch size:  1024 | lm loss: 1.836656E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28077/   51900 | consumed samples:     28750848 | elapsed time per iteration (ms): 37633.2 | learning rate: 1.036E-04 | global batch size:  1024 | lm loss: 1.851909E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28078/   51900 | consumed samples:     28751872 | elapsed time per iteration (ms): 37575.1 | learning rate: 1.036E-04 | global batch size:  1024 | lm loss: 1.829953E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28079/   51900 | consumed samples:     28752896 | elapsed time per iteration (ms): 37729.7 | learning rate: 1.036E-04 | global batch size:  1024 | lm loss: 1.835278E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28080/   51900 | consumed samples:     28753920 | elapsed time per iteration (ms): 37677.7 | learning rate: 1.036E-04 | global batch size:  1024 | lm loss: 1.857303E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28081/   51900 | consumed samples:     28754944 | elapsed time per iteration (ms): 37717.5 | learning rate: 1.036E-04 | global batch size:  1024 | lm loss: 1.869899E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28082/   51900 | consumed samples:     28755968 | elapsed time per iteration (ms): 37651.9 | learning rate: 1.036E-04 | global batch size:  1024 | lm loss: 1.843283E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28083/   51900 | consumed samples:     28756992 | elapsed time per iteration (ms): 37668.6 | learning rate: 1.036E-04 | global batch size:  1024 | lm loss: 1.832401E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28084/   51900 | consumed samples:     28758016 | elapsed time per iteration (ms): 37613.3 | learning rate: 1.036E-04 | global batch size:  1024 | lm loss: 1.860225E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28085/   51900 | consumed samples:     28759040 | elapsed time per iteration (ms): 37751.9 | learning rate: 1.036E-04 | global batch size:  1024 | lm loss: 1.845712E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28086/   51900 | consumed samples:     28760064 | elapsed time per iteration (ms): 37676.2 | learning rate: 1.036E-04 | global batch size:  1024 | lm loss: 1.859195E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28087/   51900 | consumed samples:     28761088 | elapsed time per iteration (ms): 37651.0 | learning rate: 1.036E-04 | global batch size:  1024 | lm loss: 1.834306E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28088/   51900 | consumed samples:     28762112 | elapsed time per iteration (ms): 37622.7 | learning rate: 1.036E-04 | global batch size:  1024 | lm loss: 1.838885E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28089/   51900 | consumed samples:     28763136 | elapsed time per iteration (ms): 37667.8 | learning rate: 1.036E-04 | global batch size:  1024 | lm loss: 1.853158E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28090/   51900 | consumed samples:     28764160 | elapsed time per iteration (ms): 37723.5 | learning rate: 1.035E-04 | global batch size:  1024 | lm loss: 1.834532E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28091/   51900 | consumed samples:     28765184 | elapsed time per iteration (ms): 37630.4 | learning rate: 1.035E-04 | global batch size:  1024 | lm loss: 1.836645E+00 | loss scale: 1.0 | grad norm: 0.145 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28092/   51900 | consumed samples:     28766208 | elapsed time per iteration (ms): 37576.6 | learning rate: 1.035E-04 | global batch size:  1024 | lm loss: 1.852821E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28093/   51900 | consumed samples:     28767232 | elapsed time per iteration (ms): 37761.7 | learning rate: 1.035E-04 | global batch size:  1024 | lm loss: 1.836634E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28094/   51900 | consumed samples:     28768256 | elapsed time per iteration (ms): 37598.4 | learning rate: 1.035E-04 | global batch size:  1024 | lm loss: 1.849763E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28095/   51900 | consumed samples:     28769280 | elapsed time per iteration (ms): 37706.9 | learning rate: 1.035E-04 | global batch size:  1024 | lm loss: 1.833252E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28096/   51900 | consumed samples:     28770304 | elapsed time per iteration (ms): 37688.6 | learning rate: 1.035E-04 | global batch size:  1024 | lm loss: 1.836107E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28097/   51900 | consumed samples:     28771328 | elapsed time per iteration (ms): 37670.6 | learning rate: 1.035E-04 | global batch size:  1024 | lm loss: 1.834360E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28098/   51900 | consumed samples:     28772352 | elapsed time per iteration (ms): 37648.1 | learning rate: 1.035E-04 | global batch size:  1024 | lm loss: 1.847971E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28099/   51900 | consumed samples:     28773376 | elapsed time per iteration (ms): 37604.3 | learning rate: 1.035E-04 | global batch size:  1024 | lm loss: 1.845651E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28100/   51900 | consumed samples:     28774400 | elapsed time per iteration (ms): 37680.1 | learning rate: 1.035E-04 | global batch size:  1024 | lm loss: 1.853947E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28101/   51900 | consumed samples:     28775424 | elapsed time per iteration (ms): 37703.5 | learning rate: 1.035E-04 | global batch size:  1024 | lm loss: 1.845584E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28102/   51900 | consumed samples:     28776448 | elapsed time per iteration (ms): 37596.0 | learning rate: 1.035E-04 | global batch size:  1024 | lm loss: 1.847529E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28103/   51900 | consumed samples:     28777472 | elapsed time per iteration (ms): 37539.9 | learning rate: 1.035E-04 | global batch size:  1024 | lm loss: 1.843983E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28104/   51900 | consumed samples:     28778496 | elapsed time per iteration (ms): 37702.1 | learning rate: 1.035E-04 | global batch size:  1024 | lm loss: 1.827203E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28105/   51900 | consumed samples:     28779520 | elapsed time per iteration (ms): 37707.6 | learning rate: 1.035E-04 | global batch size:  1024 | lm loss: 1.825180E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28106/   51900 | consumed samples:     28780544 | elapsed time per iteration (ms): 37727.3 | learning rate: 1.035E-04 | global batch size:  1024 | lm loss: 1.835239E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28107/   51900 | consumed samples:     28781568 | elapsed time per iteration (ms): 37641.7 | learning rate: 1.035E-04 | global batch size:  1024 | lm loss: 1.846761E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28108/   51900 | consumed samples:     28782592 | elapsed time per iteration (ms): 37720.2 | learning rate: 1.034E-04 | global batch size:  1024 | lm loss: 1.848403E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28109/   51900 | consumed samples:     28783616 | elapsed time per iteration (ms): 37683.8 | learning rate: 1.034E-04 | global batch size:  1024 | lm loss: 1.839740E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28110/   51900 | consumed samples:     28784640 | elapsed time per iteration (ms): 37678.6 | learning rate: 1.034E-04 | global batch size:  1024 | lm loss: 1.838145E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28111/   51900 | consumed samples:     28785664 | elapsed time per iteration (ms): 37670.5 | learning rate: 1.034E-04 | global batch size:  1024 | lm loss: 1.851723E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28112/   51900 | consumed samples:     28786688 | elapsed time per iteration (ms): 37644.0 | learning rate: 1.034E-04 | global batch size:  1024 | lm loss: 1.838319E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28113/   51900 | consumed samples:     28787712 | elapsed time per iteration (ms): 37562.1 | learning rate: 1.034E-04 | global batch size:  1024 | lm loss: 1.831753E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28114/   51900 | consumed samples:     28788736 | elapsed time per iteration (ms): 37676.1 | learning rate: 1.034E-04 | global batch size:  1024 | lm loss: 1.818875E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28115/   51900 | consumed samples:     28789760 | elapsed time per iteration (ms): 37528.1 | learning rate: 1.034E-04 | global batch size:  1024 | lm loss: 1.844062E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28116/   51900 | consumed samples:     28790784 | elapsed time per iteration (ms): 37744.2 | learning rate: 1.034E-04 | global batch size:  1024 | lm loss: 1.845616E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28117/   51900 | consumed samples:     28791808 | elapsed time per iteration (ms): 37714.2 | learning rate: 1.034E-04 | global batch size:  1024 | lm loss: 1.871752E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28118/   51900 | consumed samples:     28792832 | elapsed time per iteration (ms): 37670.2 | learning rate: 1.034E-04 | global batch size:  1024 | lm loss: 1.867950E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28119/   51900 | consumed samples:     28793856 | elapsed time per iteration (ms): 37607.0 | learning rate: 1.034E-04 | global batch size:  1024 | lm loss: 1.839936E+00 | loss scale: 1.0 | grad norm: 0.087 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28120/   51900 | consumed samples:     28794880 | elapsed time per iteration (ms): 37609.2 | learning rate: 1.034E-04 | global batch size:  1024 | lm loss: 1.844891E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28121/   51900 | consumed samples:     28795904 | elapsed time per iteration (ms): 37655.6 | learning rate: 1.034E-04 | global batch size:  1024 | lm loss: 1.829458E+00 | loss scale: 1.0 | grad norm: 0.095 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28122/   51900 | consumed samples:     28796928 | elapsed time per iteration (ms): 37607.8 | learning rate: 1.034E-04 | global batch size:  1024 | lm loss: 1.853784E+00 | loss scale: 1.0 | grad norm: 0.105 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28123/   51900 | consumed samples:     28797952 | elapsed time per iteration (ms): 37677.8 | learning rate: 1.034E-04 | global batch size:  1024 | lm loss: 1.857434E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28124/   51900 | consumed samples:     28798976 | elapsed time per iteration (ms): 37706.1 | learning rate: 1.034E-04 | global batch size:  1024 | lm loss: 1.846438E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28125/   51900 | consumed samples:     28800000 | elapsed time per iteration (ms): 37641.7 | learning rate: 1.033E-04 | global batch size:  1024 | lm loss: 1.849480E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28126/   51900 | consumed samples:     28801024 | elapsed time per iteration (ms): 37638.2 | learning rate: 1.033E-04 | global batch size:  1024 | lm loss: 1.838492E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28127/   51900 | consumed samples:     28802048 | elapsed time per iteration (ms): 37574.7 | learning rate: 1.033E-04 | global batch size:  1024 | lm loss: 1.841062E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28128/   51900 | consumed samples:     28803072 | elapsed time per iteration (ms): 37749.0 | learning rate: 1.033E-04 | global batch size:  1024 | lm loss: 1.836069E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28129/   51900 | consumed samples:     28804096 | elapsed time per iteration (ms): 37676.9 | learning rate: 1.033E-04 | global batch size:  1024 | lm loss: 1.842577E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28130/   51900 | consumed samples:     28805120 | elapsed time per iteration (ms): 37635.1 | learning rate: 1.033E-04 | global batch size:  1024 | lm loss: 1.842415E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28131/   51900 | consumed samples:     28806144 | elapsed time per iteration (ms): 37614.9 | learning rate: 1.033E-04 | global batch size:  1024 | lm loss: 1.840056E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28132/   51900 | consumed samples:     28807168 | elapsed time per iteration (ms): 37555.6 | learning rate: 1.033E-04 | global batch size:  1024 | lm loss: 1.824042E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28133/   51900 | consumed samples:     28808192 | elapsed time per iteration (ms): 37682.4 | learning rate: 1.033E-04 | global batch size:  1024 | lm loss: 1.848857E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28134/   51900 | consumed samples:     28809216 | elapsed time per iteration (ms): 37626.9 | learning rate: 1.033E-04 | global batch size:  1024 | lm loss: 1.852679E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28135/   51900 | consumed samples:     28810240 | elapsed time per iteration (ms): 37662.7 | learning rate: 1.033E-04 | global batch size:  1024 | lm loss: 1.850210E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28136/   51900 | consumed samples:     28811264 | elapsed time per iteration (ms): 37576.5 | learning rate: 1.033E-04 | global batch size:  1024 | lm loss: 1.831807E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28137/   51900 | consumed samples:     28812288 | elapsed time per iteration (ms): 37689.9 | learning rate: 1.033E-04 | global batch size:  1024 | lm loss: 1.849181E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28138/   51900 | consumed samples:     28813312 | elapsed time per iteration (ms): 37738.2 | learning rate: 1.033E-04 | global batch size:  1024 | lm loss: 1.850495E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28139/   51900 | consumed samples:     28814336 | elapsed time per iteration (ms): 37637.5 | learning rate: 1.033E-04 | global batch size:  1024 | lm loss: 1.857845E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28140/   51900 | consumed samples:     28815360 | elapsed time per iteration (ms): 37733.2 | learning rate: 1.033E-04 | global batch size:  1024 | lm loss: 1.838488E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28141/   51900 | consumed samples:     28816384 | elapsed time per iteration (ms): 37606.2 | learning rate: 1.033E-04 | global batch size:  1024 | lm loss: 1.839744E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28142/   51900 | consumed samples:     28817408 | elapsed time per iteration (ms): 37697.0 | learning rate: 1.033E-04 | global batch size:  1024 | lm loss: 1.845492E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28143/   51900 | consumed samples:     28818432 | elapsed time per iteration (ms): 37689.9 | learning rate: 1.032E-04 | global batch size:  1024 | lm loss: 1.832309E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28144/   51900 | consumed samples:     28819456 | elapsed time per iteration (ms): 37704.1 | learning rate: 1.032E-04 | global batch size:  1024 | lm loss: 1.868588E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28145/   51900 | consumed samples:     28820480 | elapsed time per iteration (ms): 37631.5 | learning rate: 1.032E-04 | global batch size:  1024 | lm loss: 1.843191E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28146/   51900 | consumed samples:     28821504 | elapsed time per iteration (ms): 37663.1 | learning rate: 1.032E-04 | global batch size:  1024 | lm loss: 1.850399E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28147/   51900 | consumed samples:     28822528 | elapsed time per iteration (ms): 37718.3 | learning rate: 1.032E-04 | global batch size:  1024 | lm loss: 1.831224E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28148/   51900 | consumed samples:     28823552 | elapsed time per iteration (ms): 37601.0 | learning rate: 1.032E-04 | global batch size:  1024 | lm loss: 1.846185E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28149/   51900 | consumed samples:     28824576 | elapsed time per iteration (ms): 37602.5 | learning rate: 1.032E-04 | global batch size:  1024 | lm loss: 1.841929E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28150/   51900 | consumed samples:     28825600 | elapsed time per iteration (ms): 37703.6 | learning rate: 1.032E-04 | global batch size:  1024 | lm loss: 1.827310E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28151/   51900 | consumed samples:     28826624 | elapsed time per iteration (ms): 37600.0 | learning rate: 1.032E-04 | global batch size:  1024 | lm loss: 1.858274E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28152/   51900 | consumed samples:     28827648 | elapsed time per iteration (ms): 37648.2 | learning rate: 1.032E-04 | global batch size:  1024 | lm loss: 1.829471E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28153/   51900 | consumed samples:     28828672 | elapsed time per iteration (ms): 37530.9 | learning rate: 1.032E-04 | global batch size:  1024 | lm loss: 1.831166E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28154/   51900 | consumed samples:     28829696 | elapsed time per iteration (ms): 37650.0 | learning rate: 1.032E-04 | global batch size:  1024 | lm loss: 1.865622E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28155/   51900 | consumed samples:     28830720 | elapsed time per iteration (ms): 37557.5 | learning rate: 1.032E-04 | global batch size:  1024 | lm loss: 1.835724E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28156/   51900 | consumed samples:     28831744 | elapsed time per iteration (ms): 37664.2 | learning rate: 1.032E-04 | global batch size:  1024 | lm loss: 1.838296E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28157/   51900 | consumed samples:     28832768 | elapsed time per iteration (ms): 37739.6 | learning rate: 1.032E-04 | global batch size:  1024 | lm loss: 1.853014E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28158/   51900 | consumed samples:     28833792 | elapsed time per iteration (ms): 37651.5 | learning rate: 1.032E-04 | global batch size:  1024 | lm loss: 1.842685E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28159/   51900 | consumed samples:     28834816 | elapsed time per iteration (ms): 37618.1 | learning rate: 1.032E-04 | global batch size:  1024 | lm loss: 1.841554E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28160/   51900 | consumed samples:     28835840 | elapsed time per iteration (ms): 37592.3 | learning rate: 1.032E-04 | global batch size:  1024 | lm loss: 1.844258E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28161/   51900 | consumed samples:     28836864 | elapsed time per iteration (ms): 37598.9 | learning rate: 1.031E-04 | global batch size:  1024 | lm loss: 1.839472E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28162/   51900 | consumed samples:     28837888 | elapsed time per iteration (ms): 37675.9 | learning rate: 1.031E-04 | global batch size:  1024 | lm loss: 1.850183E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28163/   51900 | consumed samples:     28838912 | elapsed time per iteration (ms): 37493.1 | learning rate: 1.031E-04 | global batch size:  1024 | lm loss: 1.856722E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28164/   51900 | consumed samples:     28839936 | elapsed time per iteration (ms): 37605.0 | learning rate: 1.031E-04 | global batch size:  1024 | lm loss: 1.853284E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28165/   51900 | consumed samples:     28840960 | elapsed time per iteration (ms): 37634.2 | learning rate: 1.031E-04 | global batch size:  1024 | lm loss: 1.836909E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28166/   51900 | consumed samples:     28841984 | elapsed time per iteration (ms): 37622.3 | learning rate: 1.031E-04 | global batch size:  1024 | lm loss: 1.851694E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28167/   51900 | consumed samples:     28843008 | elapsed time per iteration (ms): 37620.7 | learning rate: 1.031E-04 | global batch size:  1024 | lm loss: 1.860400E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28168/   51900 | consumed samples:     28844032 | elapsed time per iteration (ms): 37598.9 | learning rate: 1.031E-04 | global batch size:  1024 | lm loss: 1.839171E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28169/   51900 | consumed samples:     28845056 | elapsed time per iteration (ms): 37606.6 | learning rate: 1.031E-04 | global batch size:  1024 | lm loss: 1.843821E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28170/   51900 | consumed samples:     28846080 | elapsed time per iteration (ms): 37692.0 | learning rate: 1.031E-04 | global batch size:  1024 | lm loss: 1.841635E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28171/   51900 | consumed samples:     28847104 | elapsed time per iteration (ms): 37672.4 | learning rate: 1.031E-04 | global batch size:  1024 | lm loss: 1.846573E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28172/   51900 | consumed samples:     28848128 | elapsed time per iteration (ms): 37731.6 | learning rate: 1.031E-04 | global batch size:  1024 | lm loss: 1.838200E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28173/   51900 | consumed samples:     28849152 | elapsed time per iteration (ms): 37578.0 | learning rate: 1.031E-04 | global batch size:  1024 | lm loss: 1.849475E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28174/   51900 | consumed samples:     28850176 | elapsed time per iteration (ms): 37555.7 | learning rate: 1.031E-04 | global batch size:  1024 | lm loss: 1.826309E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28175/   51900 | consumed samples:     28851200 | elapsed time per iteration (ms): 37613.0 | learning rate: 1.031E-04 | global batch size:  1024 | lm loss: 1.835391E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28176/   51900 | consumed samples:     28852224 | elapsed time per iteration (ms): 37525.3 | learning rate: 1.031E-04 | global batch size:  1024 | lm loss: 1.851570E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28177/   51900 | consumed samples:     28853248 | elapsed time per iteration (ms): 37555.0 | learning rate: 1.031E-04 | global batch size:  1024 | lm loss: 1.845486E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28178/   51900 | consumed samples:     28854272 | elapsed time per iteration (ms): 37729.1 | learning rate: 1.030E-04 | global batch size:  1024 | lm loss: 1.844114E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28179/   51900 | consumed samples:     28855296 | elapsed time per iteration (ms): 37574.1 | learning rate: 1.030E-04 | global batch size:  1024 | lm loss: 1.843597E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28180/   51900 | consumed samples:     28856320 | elapsed time per iteration (ms): 37736.0 | learning rate: 1.030E-04 | global batch size:  1024 | lm loss: 1.831897E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28181/   51900 | consumed samples:     28857344 | elapsed time per iteration (ms): 37558.5 | learning rate: 1.030E-04 | global batch size:  1024 | lm loss: 1.844532E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28182/   51900 | consumed samples:     28858368 | elapsed time per iteration (ms): 37594.8 | learning rate: 1.030E-04 | global batch size:  1024 | lm loss: 1.851613E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28183/   51900 | consumed samples:     28859392 | elapsed time per iteration (ms): 37743.8 | learning rate: 1.030E-04 | global batch size:  1024 | lm loss: 1.853140E+00 | loss scale: 1.0 | grad norm: 0.093 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28184/   51900 | consumed samples:     28860416 | elapsed time per iteration (ms): 37717.9 | learning rate: 1.030E-04 | global batch size:  1024 | lm loss: 1.840038E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28185/   51900 | consumed samples:     28861440 | elapsed time per iteration (ms): 37671.7 | learning rate: 1.030E-04 | global batch size:  1024 | lm loss: 1.838574E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28186/   51900 | consumed samples:     28862464 | elapsed time per iteration (ms): 37614.8 | learning rate: 1.030E-04 | global batch size:  1024 | lm loss: 1.857131E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28187/   51900 | consumed samples:     28863488 | elapsed time per iteration (ms): 37666.8 | learning rate: 1.030E-04 | global batch size:  1024 | lm loss: 1.828320E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28188/   51900 | consumed samples:     28864512 | elapsed time per iteration (ms): 37693.4 | learning rate: 1.030E-04 | global batch size:  1024 | lm loss: 1.845701E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28189/   51900 | consumed samples:     28865536 | elapsed time per iteration (ms): 37677.4 | learning rate: 1.030E-04 | global batch size:  1024 | lm loss: 1.845742E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28190/   51900 | consumed samples:     28866560 | elapsed time per iteration (ms): 37678.7 | learning rate: 1.030E-04 | global batch size:  1024 | lm loss: 1.839045E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28191/   51900 | consumed samples:     28867584 | elapsed time per iteration (ms): 37585.4 | learning rate: 1.030E-04 | global batch size:  1024 | lm loss: 1.854062E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28192/   51900 | consumed samples:     28868608 | elapsed time per iteration (ms): 37586.1 | learning rate: 1.030E-04 | global batch size:  1024 | lm loss: 1.836176E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28193/   51900 | consumed samples:     28869632 | elapsed time per iteration (ms): 37687.4 | learning rate: 1.030E-04 | global batch size:  1024 | lm loss: 1.844706E+00 | loss scale: 1.0 | grad norm: 0.087 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28194/   51900 | consumed samples:     28870656 | elapsed time per iteration (ms): 37637.7 | learning rate: 1.030E-04 | global batch size:  1024 | lm loss: 1.838661E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28195/   51900 | consumed samples:     28871680 | elapsed time per iteration (ms): 37738.1 | learning rate: 1.030E-04 | global batch size:  1024 | lm loss: 1.836601E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28196/   51900 | consumed samples:     28872704 | elapsed time per iteration (ms): 37670.9 | learning rate: 1.029E-04 | global batch size:  1024 | lm loss: 1.842589E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28197/   51900 | consumed samples:     28873728 | elapsed time per iteration (ms): 37597.5 | learning rate: 1.029E-04 | global batch size:  1024 | lm loss: 1.839670E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28198/   51900 | consumed samples:     28874752 | elapsed time per iteration (ms): 37567.4 | learning rate: 1.029E-04 | global batch size:  1024 | lm loss: 1.841631E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28199/   51900 | consumed samples:     28875776 | elapsed time per iteration (ms): 37634.0 | learning rate: 1.029E-04 | global batch size:  1024 | lm loss: 1.841799E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28200/   51900 | consumed samples:     28876800 | elapsed time per iteration (ms): 37459.7 | learning rate: 1.029E-04 | global batch size:  1024 | lm loss: 1.830948E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28201/   51900 | consumed samples:     28877824 | elapsed time per iteration (ms): 37721.9 | learning rate: 1.029E-04 | global batch size:  1024 | lm loss: 1.832836E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28202/   51900 | consumed samples:     28878848 | elapsed time per iteration (ms): 37599.8 | learning rate: 1.029E-04 | global batch size:  1024 | lm loss: 1.836193E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28203/   51900 | consumed samples:     28879872 | elapsed time per iteration (ms): 37652.8 | learning rate: 1.029E-04 | global batch size:  1024 | lm loss: 1.837284E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28204/   51900 | consumed samples:     28880896 | elapsed time per iteration (ms): 37578.9 | learning rate: 1.029E-04 | global batch size:  1024 | lm loss: 1.853492E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28205/   51900 | consumed samples:     28881920 | elapsed time per iteration (ms): 37623.7 | learning rate: 1.029E-04 | global batch size:  1024 | lm loss: 1.824832E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28206/   51900 | consumed samples:     28882944 | elapsed time per iteration (ms): 37690.8 | learning rate: 1.029E-04 | global batch size:  1024 | lm loss: 1.841874E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28207/   51900 | consumed samples:     28883968 | elapsed time per iteration (ms): 37606.4 | learning rate: 1.029E-04 | global batch size:  1024 | lm loss: 1.848984E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28208/   51900 | consumed samples:     28884992 | elapsed time per iteration (ms): 37681.4 | learning rate: 1.029E-04 | global batch size:  1024 | lm loss: 1.827541E+00 | loss scale: 1.0 | grad norm: 0.088 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28209/   51900 | consumed samples:     28886016 | elapsed time per iteration (ms): 37724.9 | learning rate: 1.029E-04 | global batch size:  1024 | lm loss: 1.849329E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28210/   51900 | consumed samples:     28887040 | elapsed time per iteration (ms): 37613.1 | learning rate: 1.029E-04 | global batch size:  1024 | lm loss: 1.835423E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28211/   51900 | consumed samples:     28888064 | elapsed time per iteration (ms): 37598.7 | learning rate: 1.029E-04 | global batch size:  1024 | lm loss: 1.860324E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28212/   51900 | consumed samples:     28889088 | elapsed time per iteration (ms): 37578.7 | learning rate: 1.029E-04 | global batch size:  1024 | lm loss: 1.845687E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28213/   51900 | consumed samples:     28890112 | elapsed time per iteration (ms): 37631.6 | learning rate: 1.029E-04 | global batch size:  1024 | lm loss: 1.836260E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28214/   51900 | consumed samples:     28891136 | elapsed time per iteration (ms): 37625.2 | learning rate: 1.028E-04 | global batch size:  1024 | lm loss: 1.852017E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28215/   51900 | consumed samples:     28892160 | elapsed time per iteration (ms): 37565.9 | learning rate: 1.028E-04 | global batch size:  1024 | lm loss: 1.843123E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28216/   51900 | consumed samples:     28893184 | elapsed time per iteration (ms): 37694.8 | learning rate: 1.028E-04 | global batch size:  1024 | lm loss: 1.846400E+00 | loss scale: 1.0 | grad norm: 0.225 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28217/   51900 | consumed samples:     28894208 | elapsed time per iteration (ms): 37664.2 | learning rate: 1.028E-04 | global batch size:  1024 | lm loss: 1.849455E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28218/   51900 | consumed samples:     28895232 | elapsed time per iteration (ms): 37531.8 | learning rate: 1.028E-04 | global batch size:  1024 | lm loss: 1.840191E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28219/   51900 | consumed samples:     28896256 | elapsed time per iteration (ms): 37576.7 | learning rate: 1.028E-04 | global batch size:  1024 | lm loss: 1.866652E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28220/   51900 | consumed samples:     28897280 | elapsed time per iteration (ms): 37671.4 | learning rate: 1.028E-04 | global batch size:  1024 | lm loss: 1.841696E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28221/   51900 | consumed samples:     28898304 | elapsed time per iteration (ms): 37608.2 | learning rate: 1.028E-04 | global batch size:  1024 | lm loss: 1.841539E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28222/   51900 | consumed samples:     28899328 | elapsed time per iteration (ms): 37545.6 | learning rate: 1.028E-04 | global batch size:  1024 | lm loss: 1.845779E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28223/   51900 | consumed samples:     28900352 | elapsed time per iteration (ms): 37552.2 | learning rate: 1.028E-04 | global batch size:  1024 | lm loss: 1.842379E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28224/   51900 | consumed samples:     28901376 | elapsed time per iteration (ms): 37683.1 | learning rate: 1.028E-04 | global batch size:  1024 | lm loss: 1.852861E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28225/   51900 | consumed samples:     28902400 | elapsed time per iteration (ms): 37591.4 | learning rate: 1.028E-04 | global batch size:  1024 | lm loss: 1.816855E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28226/   51900 | consumed samples:     28903424 | elapsed time per iteration (ms): 37547.6 | learning rate: 1.028E-04 | global batch size:  1024 | lm loss: 1.844820E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28227/   51900 | consumed samples:     28904448 | elapsed time per iteration (ms): 37438.7 | learning rate: 1.028E-04 | global batch size:  1024 | lm loss: 1.833527E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28228/   51900 | consumed samples:     28905472 | elapsed time per iteration (ms): 37547.0 | learning rate: 1.028E-04 | global batch size:  1024 | lm loss: 1.852409E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28229/   51900 | consumed samples:     28906496 | elapsed time per iteration (ms): 37593.1 | learning rate: 1.028E-04 | global batch size:  1024 | lm loss: 1.836620E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28230/   51900 | consumed samples:     28907520 | elapsed time per iteration (ms): 37668.5 | learning rate: 1.028E-04 | global batch size:  1024 | lm loss: 1.859872E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28231/   51900 | consumed samples:     28908544 | elapsed time per iteration (ms): 37556.5 | learning rate: 1.027E-04 | global batch size:  1024 | lm loss: 1.857560E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28232/   51900 | consumed samples:     28909568 | elapsed time per iteration (ms): 37647.4 | learning rate: 1.027E-04 | global batch size:  1024 | lm loss: 1.862109E+00 | loss scale: 1.0 | grad norm: 0.087 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28233/   51900 | consumed samples:     28910592 | elapsed time per iteration (ms): 37561.0 | learning rate: 1.027E-04 | global batch size:  1024 | lm loss: 1.838337E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28234/   51900 | consumed samples:     28911616 | elapsed time per iteration (ms): 37682.6 | learning rate: 1.027E-04 | global batch size:  1024 | lm loss: 1.823242E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28235/   51900 | consumed samples:     28912640 | elapsed time per iteration (ms): 37611.8 | learning rate: 1.027E-04 | global batch size:  1024 | lm loss: 1.841442E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28236/   51900 | consumed samples:     28913664 | elapsed time per iteration (ms): 37618.1 | learning rate: 1.027E-04 | global batch size:  1024 | lm loss: 1.823165E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28237/   51900 | consumed samples:     28914688 | elapsed time per iteration (ms): 37613.6 | learning rate: 1.027E-04 | global batch size:  1024 | lm loss: 1.838215E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28238/   51900 | consumed samples:     28915712 | elapsed time per iteration (ms): 37633.4 | learning rate: 1.027E-04 | global batch size:  1024 | lm loss: 1.850904E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28239/   51900 | consumed samples:     28916736 | elapsed time per iteration (ms): 37490.0 | learning rate: 1.027E-04 | global batch size:  1024 | lm loss: 1.863773E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28240/   51900 | consumed samples:     28917760 | elapsed time per iteration (ms): 37638.2 | learning rate: 1.027E-04 | global batch size:  1024 | lm loss: 1.863125E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28241/   51900 | consumed samples:     28918784 | elapsed time per iteration (ms): 37620.5 | learning rate: 1.027E-04 | global batch size:  1024 | lm loss: 1.838392E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28242/   51900 | consumed samples:     28919808 | elapsed time per iteration (ms): 37680.2 | learning rate: 1.027E-04 | global batch size:  1024 | lm loss: 1.834754E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28243/   51900 | consumed samples:     28920832 | elapsed time per iteration (ms): 37505.3 | learning rate: 1.027E-04 | global batch size:  1024 | lm loss: 1.836561E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28244/   51900 | consumed samples:     28921856 | elapsed time per iteration (ms): 37580.5 | learning rate: 1.027E-04 | global batch size:  1024 | lm loss: 1.843671E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28245/   51900 | consumed samples:     28922880 | elapsed time per iteration (ms): 37682.6 | learning rate: 1.027E-04 | global batch size:  1024 | lm loss: 1.831642E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28246/   51900 | consumed samples:     28923904 | elapsed time per iteration (ms): 37692.8 | learning rate: 1.027E-04 | global batch size:  1024 | lm loss: 1.860109E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28247/   51900 | consumed samples:     28924928 | elapsed time per iteration (ms): 37683.7 | learning rate: 1.027E-04 | global batch size:  1024 | lm loss: 1.866044E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28248/   51900 | consumed samples:     28925952 | elapsed time per iteration (ms): 37672.1 | learning rate: 1.027E-04 | global batch size:  1024 | lm loss: 1.840475E+00 | loss scale: 1.0 | grad norm: 0.159 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28249/   51900 | consumed samples:     28926976 | elapsed time per iteration (ms): 37611.8 | learning rate: 1.026E-04 | global batch size:  1024 | lm loss: 1.845637E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28250/   51900 | consumed samples:     28928000 | elapsed time per iteration (ms): 37678.6 | learning rate: 1.026E-04 | global batch size:  1024 | lm loss: 1.834090E+00 | loss scale: 1.0 | grad norm: 0.089 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28251/   51900 | consumed samples:     28929024 | elapsed time per iteration (ms): 37612.8 | learning rate: 1.026E-04 | global batch size:  1024 | lm loss: 1.846786E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28252/   51900 | consumed samples:     28930048 | elapsed time per iteration (ms): 37698.0 | learning rate: 1.026E-04 | global batch size:  1024 | lm loss: 1.842903E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28253/   51900 | consumed samples:     28931072 | elapsed time per iteration (ms): 37557.1 | learning rate: 1.026E-04 | global batch size:  1024 | lm loss: 1.839611E+00 | loss scale: 1.0 | grad norm: 0.087 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28254/   51900 | consumed samples:     28932096 | elapsed time per iteration (ms): 37592.5 | learning rate: 1.026E-04 | global batch size:  1024 | lm loss: 1.838951E+00 | loss scale: 1.0 | grad norm: 0.088 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28255/   51900 | consumed samples:     28933120 | elapsed time per iteration (ms): 37606.4 | learning rate: 1.026E-04 | global batch size:  1024 | lm loss: 1.857029E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28256/   51900 | consumed samples:     28934144 | elapsed time per iteration (ms): 37632.3 | learning rate: 1.026E-04 | global batch size:  1024 | lm loss: 1.845198E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28257/   51900 | consumed samples:     28935168 | elapsed time per iteration (ms): 37552.2 | learning rate: 1.026E-04 | global batch size:  1024 | lm loss: 1.863550E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28258/   51900 | consumed samples:     28936192 | elapsed time per iteration (ms): 37686.6 | learning rate: 1.026E-04 | global batch size:  1024 | lm loss: 1.833978E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28259/   51900 | consumed samples:     28937216 | elapsed time per iteration (ms): 37595.3 | learning rate: 1.026E-04 | global batch size:  1024 | lm loss: 1.841420E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28260/   51900 | consumed samples:     28938240 | elapsed time per iteration (ms): 37625.5 | learning rate: 1.026E-04 | global batch size:  1024 | lm loss: 1.843377E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28261/   51900 | consumed samples:     28939264 | elapsed time per iteration (ms): 37579.6 | learning rate: 1.026E-04 | global batch size:  1024 | lm loss: 1.845576E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28262/   51900 | consumed samples:     28940288 | elapsed time per iteration (ms): 37553.7 | learning rate: 1.026E-04 | global batch size:  1024 | lm loss: 1.855712E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28263/   51900 | consumed samples:     28941312 | elapsed time per iteration (ms): 37736.3 | learning rate: 1.026E-04 | global batch size:  1024 | lm loss: 1.838529E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28264/   51900 | consumed samples:     28942336 | elapsed time per iteration (ms): 37541.9 | learning rate: 1.026E-04 | global batch size:  1024 | lm loss: 1.846995E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28265/   51900 | consumed samples:     28943360 | elapsed time per iteration (ms): 37619.0 | learning rate: 1.026E-04 | global batch size:  1024 | lm loss: 1.847003E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28266/   51900 | consumed samples:     28944384 | elapsed time per iteration (ms): 37554.2 | learning rate: 1.026E-04 | global batch size:  1024 | lm loss: 1.840308E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28267/   51900 | consumed samples:     28945408 | elapsed time per iteration (ms): 37644.1 | learning rate: 1.025E-04 | global batch size:  1024 | lm loss: 1.834644E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28268/   51900 | consumed samples:     28946432 | elapsed time per iteration (ms): 37723.0 | learning rate: 1.025E-04 | global batch size:  1024 | lm loss: 1.859541E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28269/   51900 | consumed samples:     28947456 | elapsed time per iteration (ms): 37598.3 | learning rate: 1.025E-04 | global batch size:  1024 | lm loss: 1.846023E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28270/   51900 | consumed samples:     28948480 | elapsed time per iteration (ms): 37645.0 | learning rate: 1.025E-04 | global batch size:  1024 | lm loss: 1.857173E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28271/   51900 | consumed samples:     28949504 | elapsed time per iteration (ms): 37682.6 | learning rate: 1.025E-04 | global batch size:  1024 | lm loss: 1.841363E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28272/   51900 | consumed samples:     28950528 | elapsed time per iteration (ms): 37670.6 | learning rate: 1.025E-04 | global batch size:  1024 | lm loss: 1.835261E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28273/   51900 | consumed samples:     28951552 | elapsed time per iteration (ms): 37636.4 | learning rate: 1.025E-04 | global batch size:  1024 | lm loss: 1.835711E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28274/   51900 | consumed samples:     28952576 | elapsed time per iteration (ms): 37581.1 | learning rate: 1.025E-04 | global batch size:  1024 | lm loss: 1.843070E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28275/   51900 | consumed samples:     28953600 | elapsed time per iteration (ms): 37561.9 | learning rate: 1.025E-04 | global batch size:  1024 | lm loss: 1.835640E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28276/   51900 | consumed samples:     28954624 | elapsed time per iteration (ms): 37525.7 | learning rate: 1.025E-04 | global batch size:  1024 | lm loss: 1.858165E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28277/   51900 | consumed samples:     28955648 | elapsed time per iteration (ms): 37619.3 | learning rate: 1.025E-04 | global batch size:  1024 | lm loss: 1.820249E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28278/   51900 | consumed samples:     28956672 | elapsed time per iteration (ms): 37631.5 | learning rate: 1.025E-04 | global batch size:  1024 | lm loss: 1.829377E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28279/   51900 | consumed samples:     28957696 | elapsed time per iteration (ms): 37673.4 | learning rate: 1.025E-04 | global batch size:  1024 | lm loss: 1.839877E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28280/   51900 | consumed samples:     28958720 | elapsed time per iteration (ms): 37561.5 | learning rate: 1.025E-04 | global batch size:  1024 | lm loss: 1.849364E+00 | loss scale: 1.0 | grad norm: 0.099 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28281/   51900 | consumed samples:     28959744 | elapsed time per iteration (ms): 37631.5 | learning rate: 1.025E-04 | global batch size:  1024 | lm loss: 1.830659E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28282/   51900 | consumed samples:     28960768 | elapsed time per iteration (ms): 37606.1 | learning rate: 1.025E-04 | global batch size:  1024 | lm loss: 1.829562E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28283/   51900 | consumed samples:     28961792 | elapsed time per iteration (ms): 37626.4 | learning rate: 1.025E-04 | global batch size:  1024 | lm loss: 1.832191E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28284/   51900 | consumed samples:     28962816 | elapsed time per iteration (ms): 37647.8 | learning rate: 1.025E-04 | global batch size:  1024 | lm loss: 1.837335E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28285/   51900 | consumed samples:     28963840 | elapsed time per iteration (ms): 37684.3 | learning rate: 1.024E-04 | global batch size:  1024 | lm loss: 1.834403E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28286/   51900 | consumed samples:     28964864 | elapsed time per iteration (ms): 37662.1 | learning rate: 1.024E-04 | global batch size:  1024 | lm loss: 1.836213E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28287/   51900 | consumed samples:     28965888 | elapsed time per iteration (ms): 37643.0 | learning rate: 1.024E-04 | global batch size:  1024 | lm loss: 1.860441E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28288/   51900 | consumed samples:     28966912 | elapsed time per iteration (ms): 37716.7 | learning rate: 1.024E-04 | global batch size:  1024 | lm loss: 1.824833E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28289/   51900 | consumed samples:     28967936 | elapsed time per iteration (ms): 37761.7 | learning rate: 1.024E-04 | global batch size:  1024 | lm loss: 1.836778E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28290/   51900 | consumed samples:     28968960 | elapsed time per iteration (ms): 37603.1 | learning rate: 1.024E-04 | global batch size:  1024 | lm loss: 1.837018E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28291/   51900 | consumed samples:     28969984 | elapsed time per iteration (ms): 37617.4 | learning rate: 1.024E-04 | global batch size:  1024 | lm loss: 1.842012E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28292/   51900 | consumed samples:     28971008 | elapsed time per iteration (ms): 37636.3 | learning rate: 1.024E-04 | global batch size:  1024 | lm loss: 1.825054E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28293/   51900 | consumed samples:     28972032 | elapsed time per iteration (ms): 37540.8 | learning rate: 1.024E-04 | global batch size:  1024 | lm loss: 1.844949E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28294/   51900 | consumed samples:     28973056 | elapsed time per iteration (ms): 37715.4 | learning rate: 1.024E-04 | global batch size:  1024 | lm loss: 1.837148E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28295/   51900 | consumed samples:     28974080 | elapsed time per iteration (ms): 37642.0 | learning rate: 1.024E-04 | global batch size:  1024 | lm loss: 1.841264E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28296/   51900 | consumed samples:     28975104 | elapsed time per iteration (ms): 37528.6 | learning rate: 1.024E-04 | global batch size:  1024 | lm loss: 1.852447E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28297/   51900 | consumed samples:     28976128 | elapsed time per iteration (ms): 37644.0 | learning rate: 1.024E-04 | global batch size:  1024 | lm loss: 1.849255E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28298/   51900 | consumed samples:     28977152 | elapsed time per iteration (ms): 37644.0 | learning rate: 1.024E-04 | global batch size:  1024 | lm loss: 1.858347E+00 | loss scale: 1.0 | grad norm: 0.087 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28299/   51900 | consumed samples:     28978176 | elapsed time per iteration (ms): 37712.3 | learning rate: 1.024E-04 | global batch size:  1024 | lm loss: 1.853774E+00 | loss scale: 1.0 | grad norm: 0.089 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28300/   51900 | consumed samples:     28979200 | elapsed time per iteration (ms): 37598.2 | learning rate: 1.024E-04 | global batch size:  1024 | lm loss: 1.848271E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28301/   51900 | consumed samples:     28980224 | elapsed time per iteration (ms): 37743.4 | learning rate: 1.024E-04 | global batch size:  1024 | lm loss: 1.841883E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28302/   51900 | consumed samples:     28981248 | elapsed time per iteration (ms): 37712.3 | learning rate: 1.023E-04 | global batch size:  1024 | lm loss: 1.839139E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28303/   51900 | consumed samples:     28982272 | elapsed time per iteration (ms): 37574.0 | learning rate: 1.023E-04 | global batch size:  1024 | lm loss: 1.862632E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28304/   51900 | consumed samples:     28983296 | elapsed time per iteration (ms): 37612.6 | learning rate: 1.023E-04 | global batch size:  1024 | lm loss: 1.843387E+00 | loss scale: 1.0 | grad norm: 0.090 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28305/   51900 | consumed samples:     28984320 | elapsed time per iteration (ms): 37625.3 | learning rate: 1.023E-04 | global batch size:  1024 | lm loss: 1.829876E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28306/   51900 | consumed samples:     28985344 | elapsed time per iteration (ms): 37635.6 | learning rate: 1.023E-04 | global batch size:  1024 | lm loss: 1.852485E+00 | loss scale: 1.0 | grad norm: 0.087 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28307/   51900 | consumed samples:     28986368 | elapsed time per iteration (ms): 37655.2 | learning rate: 1.023E-04 | global batch size:  1024 | lm loss: 1.843966E+00 | loss scale: 1.0 | grad norm: 0.087 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28308/   51900 | consumed samples:     28987392 | elapsed time per iteration (ms): 37717.4 | learning rate: 1.023E-04 | global batch size:  1024 | lm loss: 1.832036E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28309/   51900 | consumed samples:     28988416 | elapsed time per iteration (ms): 37591.9 | learning rate: 1.023E-04 | global batch size:  1024 | lm loss: 1.853356E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28310/   51900 | consumed samples:     28989440 | elapsed time per iteration (ms): 37727.4 | learning rate: 1.023E-04 | global batch size:  1024 | lm loss: 1.846699E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28311/   51900 | consumed samples:     28990464 | elapsed time per iteration (ms): 37617.4 | learning rate: 1.023E-04 | global batch size:  1024 | lm loss: 1.847934E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28312/   51900 | consumed samples:     28991488 | elapsed time per iteration (ms): 37732.4 | learning rate: 1.023E-04 | global batch size:  1024 | lm loss: 1.847330E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28313/   51900 | consumed samples:     28992512 | elapsed time per iteration (ms): 37724.0 | learning rate: 1.023E-04 | global batch size:  1024 | lm loss: 1.845462E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28314/   51900 | consumed samples:     28993536 | elapsed time per iteration (ms): 37597.0 | learning rate: 1.023E-04 | global batch size:  1024 | lm loss: 1.859331E+00 | loss scale: 1.0 | grad norm: 0.318 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28315/   51900 | consumed samples:     28994560 | elapsed time per iteration (ms): 37634.3 | learning rate: 1.023E-04 | global batch size:  1024 | lm loss: 1.833526E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28316/   51900 | consumed samples:     28995584 | elapsed time per iteration (ms): 37590.6 | learning rate: 1.023E-04 | global batch size:  1024 | lm loss: 1.851330E+00 | loss scale: 1.0 | grad norm: 0.131 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28317/   51900 | consumed samples:     28996608 | elapsed time per iteration (ms): 37640.8 | learning rate: 1.023E-04 | global batch size:  1024 | lm loss: 1.843870E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28318/   51900 | consumed samples:     28997632 | elapsed time per iteration (ms): 37597.2 | learning rate: 1.023E-04 | global batch size:  1024 | lm loss: 1.838828E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28319/   51900 | consumed samples:     28998656 | elapsed time per iteration (ms): 37664.0 | learning rate: 1.023E-04 | global batch size:  1024 | lm loss: 1.844619E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28320/   51900 | consumed samples:     28999680 | elapsed time per iteration (ms): 37660.2 | learning rate: 1.022E-04 | global batch size:  1024 | lm loss: 1.850676E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28321/   51900 | consumed samples:     29000704 | elapsed time per iteration (ms): 37694.6 | learning rate: 1.022E-04 | global batch size:  1024 | lm loss: 1.834964E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28322/   51900 | consumed samples:     29001728 | elapsed time per iteration (ms): 37743.7 | learning rate: 1.022E-04 | global batch size:  1024 | lm loss: 1.847786E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28323/   51900 | consumed samples:     29002752 | elapsed time per iteration (ms): 37618.9 | learning rate: 1.022E-04 | global batch size:  1024 | lm loss: 1.836709E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28324/   51900 | consumed samples:     29003776 | elapsed time per iteration (ms): 37660.4 | learning rate: 1.022E-04 | global batch size:  1024 | lm loss: 1.852579E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28325/   51900 | consumed samples:     29004800 | elapsed time per iteration (ms): 37627.4 | learning rate: 1.022E-04 | global batch size:  1024 | lm loss: 1.854794E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28326/   51900 | consumed samples:     29005824 | elapsed time per iteration (ms): 37583.7 | learning rate: 1.022E-04 | global batch size:  1024 | lm loss: 1.842760E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28327/   51900 | consumed samples:     29006848 | elapsed time per iteration (ms): 37666.6 | learning rate: 1.022E-04 | global batch size:  1024 | lm loss: 1.854929E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28328/   51900 | consumed samples:     29007872 | elapsed time per iteration (ms): 37726.1 | learning rate: 1.022E-04 | global batch size:  1024 | lm loss: 1.833037E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28329/   51900 | consumed samples:     29008896 | elapsed time per iteration (ms): 37678.3 | learning rate: 1.022E-04 | global batch size:  1024 | lm loss: 1.835899E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28330/   51900 | consumed samples:     29009920 | elapsed time per iteration (ms): 37714.2 | learning rate: 1.022E-04 | global batch size:  1024 | lm loss: 1.847502E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28331/   51900 | consumed samples:     29010944 | elapsed time per iteration (ms): 37654.3 | learning rate: 1.022E-04 | global batch size:  1024 | lm loss: 1.837312E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28332/   51900 | consumed samples:     29011968 | elapsed time per iteration (ms): 37619.8 | learning rate: 1.022E-04 | global batch size:  1024 | lm loss: 1.841512E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28333/   51900 | consumed samples:     29012992 | elapsed time per iteration (ms): 37529.0 | learning rate: 1.022E-04 | global batch size:  1024 | lm loss: 1.832958E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28334/   51900 | consumed samples:     29014016 | elapsed time per iteration (ms): 37654.9 | learning rate: 1.022E-04 | global batch size:  1024 | lm loss: 1.844141E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28335/   51900 | consumed samples:     29015040 | elapsed time per iteration (ms): 37617.4 | learning rate: 1.022E-04 | global batch size:  1024 | lm loss: 1.836634E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28336/   51900 | consumed samples:     29016064 | elapsed time per iteration (ms): 37603.5 | learning rate: 1.022E-04 | global batch size:  1024 | lm loss: 1.838283E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28337/   51900 | consumed samples:     29017088 | elapsed time per iteration (ms): 37617.2 | learning rate: 1.022E-04 | global batch size:  1024 | lm loss: 1.847396E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28338/   51900 | consumed samples:     29018112 | elapsed time per iteration (ms): 37672.2 | learning rate: 1.021E-04 | global batch size:  1024 | lm loss: 1.856868E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28339/   51900 | consumed samples:     29019136 | elapsed time per iteration (ms): 37739.0 | learning rate: 1.021E-04 | global batch size:  1024 | lm loss: 1.854381E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28340/   51900 | consumed samples:     29020160 | elapsed time per iteration (ms): 37561.6 | learning rate: 1.021E-04 | global batch size:  1024 | lm loss: 1.838618E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28341/   51900 | consumed samples:     29021184 | elapsed time per iteration (ms): 37644.8 | learning rate: 1.021E-04 | global batch size:  1024 | lm loss: 1.832430E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28342/   51900 | consumed samples:     29022208 | elapsed time per iteration (ms): 37565.0 | learning rate: 1.021E-04 | global batch size:  1024 | lm loss: 1.846368E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28343/   51900 | consumed samples:     29023232 | elapsed time per iteration (ms): 37641.5 | learning rate: 1.021E-04 | global batch size:  1024 | lm loss: 1.837942E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28344/   51900 | consumed samples:     29024256 | elapsed time per iteration (ms): 37529.3 | learning rate: 1.021E-04 | global batch size:  1024 | lm loss: 1.847577E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28345/   51900 | consumed samples:     29025280 | elapsed time per iteration (ms): 37632.4 | learning rate: 1.021E-04 | global batch size:  1024 | lm loss: 1.856870E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28346/   51900 | consumed samples:     29026304 | elapsed time per iteration (ms): 37713.1 | learning rate: 1.021E-04 | global batch size:  1024 | lm loss: 1.869777E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28347/   51900 | consumed samples:     29027328 | elapsed time per iteration (ms): 37540.6 | learning rate: 1.021E-04 | global batch size:  1024 | lm loss: 1.850172E+00 | loss scale: 1.0 | grad norm: 0.087 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28348/   51900 | consumed samples:     29028352 | elapsed time per iteration (ms): 37561.2 | learning rate: 1.021E-04 | global batch size:  1024 | lm loss: 1.825679E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28349/   51900 | consumed samples:     29029376 | elapsed time per iteration (ms): 37603.4 | learning rate: 1.021E-04 | global batch size:  1024 | lm loss: 1.836111E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28350/   51900 | consumed samples:     29030400 | elapsed time per iteration (ms): 37637.3 | learning rate: 1.021E-04 | global batch size:  1024 | lm loss: 1.850163E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28351/   51900 | consumed samples:     29031424 | elapsed time per iteration (ms): 37628.4 | learning rate: 1.021E-04 | global batch size:  1024 | lm loss: 1.845510E+00 | loss scale: 1.0 | grad norm: 0.090 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28352/   51900 | consumed samples:     29032448 | elapsed time per iteration (ms): 37667.2 | learning rate: 1.021E-04 | global batch size:  1024 | lm loss: 1.842412E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28353/   51900 | consumed samples:     29033472 | elapsed time per iteration (ms): 37620.9 | learning rate: 1.021E-04 | global batch size:  1024 | lm loss: 1.836692E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28354/   51900 | consumed samples:     29034496 | elapsed time per iteration (ms): 37587.1 | learning rate: 1.021E-04 | global batch size:  1024 | lm loss: 1.825933E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28355/   51900 | consumed samples:     29035520 | elapsed time per iteration (ms): 37635.2 | learning rate: 1.020E-04 | global batch size:  1024 | lm loss: 1.839123E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28356/   51900 | consumed samples:     29036544 | elapsed time per iteration (ms): 37643.5 | learning rate: 1.020E-04 | global batch size:  1024 | lm loss: 1.860021E+00 | loss scale: 1.0 | grad norm: 0.122 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28357/   51900 | consumed samples:     29037568 | elapsed time per iteration (ms): 37537.5 | learning rate: 1.020E-04 | global batch size:  1024 | lm loss: 1.834261E+00 | loss scale: 1.0 | grad norm: 0.103 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28358/   51900 | consumed samples:     29038592 | elapsed time per iteration (ms): 37645.6 | learning rate: 1.020E-04 | global batch size:  1024 | lm loss: 1.868117E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28359/   51900 | consumed samples:     29039616 | elapsed time per iteration (ms): 37757.9 | learning rate: 1.020E-04 | global batch size:  1024 | lm loss: 1.849044E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28360/   51900 | consumed samples:     29040640 | elapsed time per iteration (ms): 37583.8 | learning rate: 1.020E-04 | global batch size:  1024 | lm loss: 1.845360E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28361/   51900 | consumed samples:     29041664 | elapsed time per iteration (ms): 37679.9 | learning rate: 1.020E-04 | global batch size:  1024 | lm loss: 1.847098E+00 | loss scale: 1.0 | grad norm: 0.091 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28362/   51900 | consumed samples:     29042688 | elapsed time per iteration (ms): 37610.2 | learning rate: 1.020E-04 | global batch size:  1024 | lm loss: 1.852807E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28363/   51900 | consumed samples:     29043712 | elapsed time per iteration (ms): 37657.9 | learning rate: 1.020E-04 | global batch size:  1024 | lm loss: 1.837487E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28364/   51900 | consumed samples:     29044736 | elapsed time per iteration (ms): 37834.6 | learning rate: 1.020E-04 | global batch size:  1024 | lm loss: 1.847393E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28365/   51900 | consumed samples:     29045760 | elapsed time per iteration (ms): 37618.0 | learning rate: 1.020E-04 | global batch size:  1024 | lm loss: 1.842087E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28366/   51900 | consumed samples:     29046784 | elapsed time per iteration (ms): 37560.5 | learning rate: 1.020E-04 | global batch size:  1024 | lm loss: 1.840310E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28367/   51900 | consumed samples:     29047808 | elapsed time per iteration (ms): 37563.1 | learning rate: 1.020E-04 | global batch size:  1024 | lm loss: 1.837242E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28368/   51900 | consumed samples:     29048832 | elapsed time per iteration (ms): 37576.8 | learning rate: 1.020E-04 | global batch size:  1024 | lm loss: 1.812997E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28369/   51900 | consumed samples:     29049856 | elapsed time per iteration (ms): 37669.4 | learning rate: 1.020E-04 | global batch size:  1024 | lm loss: 1.842301E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28370/   51900 | consumed samples:     29050880 | elapsed time per iteration (ms): 37664.8 | learning rate: 1.020E-04 | global batch size:  1024 | lm loss: 1.852758E+00 | loss scale: 1.0 | grad norm: 0.064 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28371/   51900 | consumed samples:     29051904 | elapsed time per iteration (ms): 37621.5 | learning rate: 1.020E-04 | global batch size:  1024 | lm loss: 1.821182E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28372/   51900 | consumed samples:     29052928 | elapsed time per iteration (ms): 37618.5 | learning rate: 1.020E-04 | global batch size:  1024 | lm loss: 1.856995E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28373/   51900 | consumed samples:     29053952 | elapsed time per iteration (ms): 37647.2 | learning rate: 1.019E-04 | global batch size:  1024 | lm loss: 1.828314E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28374/   51900 | consumed samples:     29054976 | elapsed time per iteration (ms): 37653.3 | learning rate: 1.019E-04 | global batch size:  1024 | lm loss: 1.832849E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28375/   51900 | consumed samples:     29056000 | elapsed time per iteration (ms): 37655.4 | learning rate: 1.019E-04 | global batch size:  1024 | lm loss: 1.842163E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28376/   51900 | consumed samples:     29057024 | elapsed time per iteration (ms): 37634.4 | learning rate: 1.019E-04 | global batch size:  1024 | lm loss: 1.853048E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28377/   51900 | consumed samples:     29058048 | elapsed time per iteration (ms): 37672.1 | learning rate: 1.019E-04 | global batch size:  1024 | lm loss: 1.836777E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28378/   51900 | consumed samples:     29059072 | elapsed time per iteration (ms): 37683.2 | learning rate: 1.019E-04 | global batch size:  1024 | lm loss: 1.833400E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28379/   51900 | consumed samples:     29060096 | elapsed time per iteration (ms): 37754.2 | learning rate: 1.019E-04 | global batch size:  1024 | lm loss: 1.841280E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28380/   51900 | consumed samples:     29061120 | elapsed time per iteration (ms): 37578.2 | learning rate: 1.019E-04 | global batch size:  1024 | lm loss: 1.841130E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28381/   51900 | consumed samples:     29062144 | elapsed time per iteration (ms): 37624.0 | learning rate: 1.019E-04 | global batch size:  1024 | lm loss: 1.835742E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28382/   51900 | consumed samples:     29063168 | elapsed time per iteration (ms): 37652.8 | learning rate: 1.019E-04 | global batch size:  1024 | lm loss: 1.847542E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28383/   51900 | consumed samples:     29064192 | elapsed time per iteration (ms): 37565.5 | learning rate: 1.019E-04 | global batch size:  1024 | lm loss: 1.857534E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28384/   51900 | consumed samples:     29065216 | elapsed time per iteration (ms): 37558.9 | learning rate: 1.019E-04 | global batch size:  1024 | lm loss: 1.850958E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28385/   51900 | consumed samples:     29066240 | elapsed time per iteration (ms): 37749.2 | learning rate: 1.019E-04 | global batch size:  1024 | lm loss: 1.840538E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28386/   51900 | consumed samples:     29067264 | elapsed time per iteration (ms): 37683.7 | learning rate: 1.019E-04 | global batch size:  1024 | lm loss: 1.836337E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28387/   51900 | consumed samples:     29068288 | elapsed time per iteration (ms): 37660.4 | learning rate: 1.019E-04 | global batch size:  1024 | lm loss: 1.832547E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28388/   51900 | consumed samples:     29069312 | elapsed time per iteration (ms): 37553.3 | learning rate: 1.019E-04 | global batch size:  1024 | lm loss: 1.846843E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28389/   51900 | consumed samples:     29070336 | elapsed time per iteration (ms): 37674.0 | learning rate: 1.019E-04 | global batch size:  1024 | lm loss: 1.874476E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28390/   51900 | consumed samples:     29071360 | elapsed time per iteration (ms): 37657.8 | learning rate: 1.019E-04 | global batch size:  1024 | lm loss: 1.830081E+00 | loss scale: 1.0 | grad norm: 0.087 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28391/   51900 | consumed samples:     29072384 | elapsed time per iteration (ms): 37660.9 | learning rate: 1.018E-04 | global batch size:  1024 | lm loss: 1.836307E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28392/   51900 | consumed samples:     29073408 | elapsed time per iteration (ms): 37566.8 | learning rate: 1.018E-04 | global batch size:  1024 | lm loss: 1.827050E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28393/   51900 | consumed samples:     29074432 | elapsed time per iteration (ms): 37555.4 | learning rate: 1.018E-04 | global batch size:  1024 | lm loss: 1.843881E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28394/   51900 | consumed samples:     29075456 | elapsed time per iteration (ms): 37624.1 | learning rate: 1.018E-04 | global batch size:  1024 | lm loss: 1.851338E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28395/   51900 | consumed samples:     29076480 | elapsed time per iteration (ms): 37724.6 | learning rate: 1.018E-04 | global batch size:  1024 | lm loss: 1.845764E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28396/   51900 | consumed samples:     29077504 | elapsed time per iteration (ms): 37639.5 | learning rate: 1.018E-04 | global batch size:  1024 | lm loss: 1.841568E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28397/   51900 | consumed samples:     29078528 | elapsed time per iteration (ms): 37711.1 | learning rate: 1.018E-04 | global batch size:  1024 | lm loss: 1.835687E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28398/   51900 | consumed samples:     29079552 | elapsed time per iteration (ms): 37595.6 | learning rate: 1.018E-04 | global batch size:  1024 | lm loss: 1.833365E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28399/   51900 | consumed samples:     29080576 | elapsed time per iteration (ms): 37617.9 | learning rate: 1.018E-04 | global batch size:  1024 | lm loss: 1.832078E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28400/   51900 | consumed samples:     29081600 | elapsed time per iteration (ms): 37674.7 | learning rate: 1.018E-04 | global batch size:  1024 | lm loss: 1.856897E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28401/   51900 | consumed samples:     29082624 | elapsed time per iteration (ms): 37609.7 | learning rate: 1.018E-04 | global batch size:  1024 | lm loss: 1.848333E+00 | loss scale: 1.0 | grad norm: 0.736 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28402/   51900 | consumed samples:     29083648 | elapsed time per iteration (ms): 37877.0 | learning rate: 1.018E-04 | global batch size:  1024 | lm loss: 1.851615E+00 | loss scale: 1.0 | grad norm: 0.101 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28403/   51900 | consumed samples:     29084672 | elapsed time per iteration (ms): 37611.5 | learning rate: 1.018E-04 | global batch size:  1024 | lm loss: 1.844098E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28404/   51900 | consumed samples:     29085696 | elapsed time per iteration (ms): 37625.2 | learning rate: 1.018E-04 | global batch size:  1024 | lm loss: 1.839913E+00 | loss scale: 1.0 | grad norm: 0.095 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28405/   51900 | consumed samples:     29086720 | elapsed time per iteration (ms): 37652.2 | learning rate: 1.018E-04 | global batch size:  1024 | lm loss: 1.859009E+00 | loss scale: 1.0 | grad norm: 0.089 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28406/   51900 | consumed samples:     29087744 | elapsed time per iteration (ms): 37483.4 | learning rate: 1.018E-04 | global batch size:  1024 | lm loss: 1.839258E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28407/   51900 | consumed samples:     29088768 | elapsed time per iteration (ms): 37577.5 | learning rate: 1.018E-04 | global batch size:  1024 | lm loss: 1.845487E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28408/   51900 | consumed samples:     29089792 | elapsed time per iteration (ms): 37626.4 | learning rate: 1.018E-04 | global batch size:  1024 | lm loss: 1.834165E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28409/   51900 | consumed samples:     29090816 | elapsed time per iteration (ms): 37551.0 | learning rate: 1.017E-04 | global batch size:  1024 | lm loss: 1.844339E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28410/   51900 | consumed samples:     29091840 | elapsed time per iteration (ms): 37680.7 | learning rate: 1.017E-04 | global batch size:  1024 | lm loss: 1.848495E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28411/   51900 | consumed samples:     29092864 | elapsed time per iteration (ms): 37595.6 | learning rate: 1.017E-04 | global batch size:  1024 | lm loss: 1.836336E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28412/   51900 | consumed samples:     29093888 | elapsed time per iteration (ms): 37616.2 | learning rate: 1.017E-04 | global batch size:  1024 | lm loss: 1.837749E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28413/   51900 | consumed samples:     29094912 | elapsed time per iteration (ms): 37543.1 | learning rate: 1.017E-04 | global batch size:  1024 | lm loss: 1.839584E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28414/   51900 | consumed samples:     29095936 | elapsed time per iteration (ms): 37577.0 | learning rate: 1.017E-04 | global batch size:  1024 | lm loss: 1.849096E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28415/   51900 | consumed samples:     29096960 | elapsed time per iteration (ms): 37520.1 | learning rate: 1.017E-04 | global batch size:  1024 | lm loss: 1.852597E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28416/   51900 | consumed samples:     29097984 | elapsed time per iteration (ms): 37684.6 | learning rate: 1.017E-04 | global batch size:  1024 | lm loss: 1.845181E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28417/   51900 | consumed samples:     29099008 | elapsed time per iteration (ms): 37500.3 | learning rate: 1.017E-04 | global batch size:  1024 | lm loss: 1.842713E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28418/   51900 | consumed samples:     29100032 | elapsed time per iteration (ms): 37687.8 | learning rate: 1.017E-04 | global batch size:  1024 | lm loss: 1.858207E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28419/   51900 | consumed samples:     29101056 | elapsed time per iteration (ms): 37674.9 | learning rate: 1.017E-04 | global batch size:  1024 | lm loss: 1.860978E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28420/   51900 | consumed samples:     29102080 | elapsed time per iteration (ms): 37638.9 | learning rate: 1.017E-04 | global batch size:  1024 | lm loss: 1.818823E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28421/   51900 | consumed samples:     29103104 | elapsed time per iteration (ms): 37637.2 | learning rate: 1.017E-04 | global batch size:  1024 | lm loss: 1.829533E+00 | loss scale: 1.0 | grad norm: 0.089 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28422/   51900 | consumed samples:     29104128 | elapsed time per iteration (ms): 37646.4 | learning rate: 1.017E-04 | global batch size:  1024 | lm loss: 1.850423E+00 | loss scale: 1.0 | grad norm: 0.088 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28423/   51900 | consumed samples:     29105152 | elapsed time per iteration (ms): 37681.9 | learning rate: 1.017E-04 | global batch size:  1024 | lm loss: 1.846302E+00 | loss scale: 1.0 | grad norm: 0.087 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28424/   51900 | consumed samples:     29106176 | elapsed time per iteration (ms): 37584.9 | learning rate: 1.017E-04 | global batch size:  1024 | lm loss: 1.858193E+00 | loss scale: 1.0 | grad norm: 0.089 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28425/   51900 | consumed samples:     29107200 | elapsed time per iteration (ms): 37675.4 | learning rate: 1.017E-04 | global batch size:  1024 | lm loss: 1.846519E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28426/   51900 | consumed samples:     29108224 | elapsed time per iteration (ms): 37642.8 | learning rate: 1.016E-04 | global batch size:  1024 | lm loss: 1.840664E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28427/   51900 | consumed samples:     29109248 | elapsed time per iteration (ms): 37626.7 | learning rate: 1.016E-04 | global batch size:  1024 | lm loss: 1.865229E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28428/   51900 | consumed samples:     29110272 | elapsed time per iteration (ms): 37709.1 | learning rate: 1.016E-04 | global batch size:  1024 | lm loss: 1.844683E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28429/   51900 | consumed samples:     29111296 | elapsed time per iteration (ms): 37588.9 | learning rate: 1.016E-04 | global batch size:  1024 | lm loss: 1.826205E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28430/   51900 | consumed samples:     29112320 | elapsed time per iteration (ms): 37638.8 | learning rate: 1.016E-04 | global batch size:  1024 | lm loss: 1.831375E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28431/   51900 | consumed samples:     29113344 | elapsed time per iteration (ms): 37748.2 | learning rate: 1.016E-04 | global batch size:  1024 | lm loss: 1.829594E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28432/   51900 | consumed samples:     29114368 | elapsed time per iteration (ms): 37573.0 | learning rate: 1.016E-04 | global batch size:  1024 | lm loss: 1.836998E+00 | loss scale: 1.0 | grad norm: 0.087 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28433/   51900 | consumed samples:     29115392 | elapsed time per iteration (ms): 37587.6 | learning rate: 1.016E-04 | global batch size:  1024 | lm loss: 1.841372E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28434/   51900 | consumed samples:     29116416 | elapsed time per iteration (ms): 37572.4 | learning rate: 1.016E-04 | global batch size:  1024 | lm loss: 1.828176E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28435/   51900 | consumed samples:     29117440 | elapsed time per iteration (ms): 37585.8 | learning rate: 1.016E-04 | global batch size:  1024 | lm loss: 1.840843E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28436/   51900 | consumed samples:     29118464 | elapsed time per iteration (ms): 37586.0 | learning rate: 1.016E-04 | global batch size:  1024 | lm loss: 1.824234E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28437/   51900 | consumed samples:     29119488 | elapsed time per iteration (ms): 37596.3 | learning rate: 1.016E-04 | global batch size:  1024 | lm loss: 1.839687E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28438/   51900 | consumed samples:     29120512 | elapsed time per iteration (ms): 37622.0 | learning rate: 1.016E-04 | global batch size:  1024 | lm loss: 1.836154E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28439/   51900 | consumed samples:     29121536 | elapsed time per iteration (ms): 37537.4 | learning rate: 1.016E-04 | global batch size:  1024 | lm loss: 1.844721E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28440/   51900 | consumed samples:     29122560 | elapsed time per iteration (ms): 37538.0 | learning rate: 1.016E-04 | global batch size:  1024 | lm loss: 1.864689E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28441/   51900 | consumed samples:     29123584 | elapsed time per iteration (ms): 37607.6 | learning rate: 1.016E-04 | global batch size:  1024 | lm loss: 1.836867E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28442/   51900 | consumed samples:     29124608 | elapsed time per iteration (ms): 37495.7 | learning rate: 1.016E-04 | global batch size:  1024 | lm loss: 1.832549E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28443/   51900 | consumed samples:     29125632 | elapsed time per iteration (ms): 37565.2 | learning rate: 1.016E-04 | global batch size:  1024 | lm loss: 1.859241E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28444/   51900 | consumed samples:     29126656 | elapsed time per iteration (ms): 37682.4 | learning rate: 1.015E-04 | global batch size:  1024 | lm loss: 1.839761E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28445/   51900 | consumed samples:     29127680 | elapsed time per iteration (ms): 37739.9 | learning rate: 1.015E-04 | global batch size:  1024 | lm loss: 1.855242E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28446/   51900 | consumed samples:     29128704 | elapsed time per iteration (ms): 37742.3 | learning rate: 1.015E-04 | global batch size:  1024 | lm loss: 1.833118E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28447/   51900 | consumed samples:     29129728 | elapsed time per iteration (ms): 37561.3 | learning rate: 1.015E-04 | global batch size:  1024 | lm loss: 1.839167E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28448/   51900 | consumed samples:     29130752 | elapsed time per iteration (ms): 37553.7 | learning rate: 1.015E-04 | global batch size:  1024 | lm loss: 1.870661E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28449/   51900 | consumed samples:     29131776 | elapsed time per iteration (ms): 37550.9 | learning rate: 1.015E-04 | global batch size:  1024 | lm loss: 1.841954E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28450/   51900 | consumed samples:     29132800 | elapsed time per iteration (ms): 37531.6 | learning rate: 1.015E-04 | global batch size:  1024 | lm loss: 1.854110E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28451/   51900 | consumed samples:     29133824 | elapsed time per iteration (ms): 37586.4 | learning rate: 1.015E-04 | global batch size:  1024 | lm loss: 1.844952E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28452/   51900 | consumed samples:     29134848 | elapsed time per iteration (ms): 37687.2 | learning rate: 1.015E-04 | global batch size:  1024 | lm loss: 1.842132E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28453/   51900 | consumed samples:     29135872 | elapsed time per iteration (ms): 37528.2 | learning rate: 1.015E-04 | global batch size:  1024 | lm loss: 1.842236E+00 | loss scale: 1.0 | grad norm: 0.089 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28454/   51900 | consumed samples:     29136896 | elapsed time per iteration (ms): 37661.6 | learning rate: 1.015E-04 | global batch size:  1024 | lm loss: 1.850529E+00 | loss scale: 1.0 | grad norm: 0.087 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28455/   51900 | consumed samples:     29137920 | elapsed time per iteration (ms): 37732.4 | learning rate: 1.015E-04 | global batch size:  1024 | lm loss: 1.855417E+00 | loss scale: 1.0 | grad norm: 0.091 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28456/   51900 | consumed samples:     29138944 | elapsed time per iteration (ms): 37608.3 | learning rate: 1.015E-04 | global batch size:  1024 | lm loss: 1.836964E+00 | loss scale: 1.0 | grad norm: 0.088 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28457/   51900 | consumed samples:     29139968 | elapsed time per iteration (ms): 37773.0 | learning rate: 1.015E-04 | global batch size:  1024 | lm loss: 1.848673E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28458/   51900 | consumed samples:     29140992 | elapsed time per iteration (ms): 37588.7 | learning rate: 1.015E-04 | global batch size:  1024 | lm loss: 1.833864E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28459/   51900 | consumed samples:     29142016 | elapsed time per iteration (ms): 37705.5 | learning rate: 1.015E-04 | global batch size:  1024 | lm loss: 1.843938E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28460/   51900 | consumed samples:     29143040 | elapsed time per iteration (ms): 37591.8 | learning rate: 1.015E-04 | global batch size:  1024 | lm loss: 1.855949E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28461/   51900 | consumed samples:     29144064 | elapsed time per iteration (ms): 37552.2 | learning rate: 1.015E-04 | global batch size:  1024 | lm loss: 1.847996E+00 | loss scale: 1.0 | grad norm: 0.090 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28462/   51900 | consumed samples:     29145088 | elapsed time per iteration (ms): 37694.5 | learning rate: 1.014E-04 | global batch size:  1024 | lm loss: 1.842466E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28463/   51900 | consumed samples:     29146112 | elapsed time per iteration (ms): 37661.3 | learning rate: 1.014E-04 | global batch size:  1024 | lm loss: 1.845123E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28464/   51900 | consumed samples:     29147136 | elapsed time per iteration (ms): 37638.2 | learning rate: 1.014E-04 | global batch size:  1024 | lm loss: 1.839031E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28465/   51900 | consumed samples:     29148160 | elapsed time per iteration (ms): 37570.5 | learning rate: 1.014E-04 | global batch size:  1024 | lm loss: 1.870599E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28466/   51900 | consumed samples:     29149184 | elapsed time per iteration (ms): 37670.8 | learning rate: 1.014E-04 | global batch size:  1024 | lm loss: 1.830154E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28467/   51900 | consumed samples:     29150208 | elapsed time per iteration (ms): 37591.9 | learning rate: 1.014E-04 | global batch size:  1024 | lm loss: 1.845884E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28468/   51900 | consumed samples:     29151232 | elapsed time per iteration (ms): 37653.9 | learning rate: 1.014E-04 | global batch size:  1024 | lm loss: 1.853269E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28469/   51900 | consumed samples:     29152256 | elapsed time per iteration (ms): 37680.1 | learning rate: 1.014E-04 | global batch size:  1024 | lm loss: 1.840237E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28470/   51900 | consumed samples:     29153280 | elapsed time per iteration (ms): 37518.7 | learning rate: 1.014E-04 | global batch size:  1024 | lm loss: 1.824749E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28471/   51900 | consumed samples:     29154304 | elapsed time per iteration (ms): 37636.4 | learning rate: 1.014E-04 | global batch size:  1024 | lm loss: 1.849417E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28472/   51900 | consumed samples:     29155328 | elapsed time per iteration (ms): 37584.6 | learning rate: 1.014E-04 | global batch size:  1024 | lm loss: 1.833576E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28473/   51900 | consumed samples:     29156352 | elapsed time per iteration (ms): 37581.9 | learning rate: 1.014E-04 | global batch size:  1024 | lm loss: 1.848098E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28474/   51900 | consumed samples:     29157376 | elapsed time per iteration (ms): 37649.0 | learning rate: 1.014E-04 | global batch size:  1024 | lm loss: 1.853312E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28475/   51900 | consumed samples:     29158400 | elapsed time per iteration (ms): 37593.4 | learning rate: 1.014E-04 | global batch size:  1024 | lm loss: 1.839173E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28476/   51900 | consumed samples:     29159424 | elapsed time per iteration (ms): 37551.6 | learning rate: 1.014E-04 | global batch size:  1024 | lm loss: 1.829054E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28477/   51900 | consumed samples:     29160448 | elapsed time per iteration (ms): 37601.7 | learning rate: 1.014E-04 | global batch size:  1024 | lm loss: 1.848048E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28478/   51900 | consumed samples:     29161472 | elapsed time per iteration (ms): 37576.2 | learning rate: 1.014E-04 | global batch size:  1024 | lm loss: 1.834275E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28479/   51900 | consumed samples:     29162496 | elapsed time per iteration (ms): 37629.3 | learning rate: 1.013E-04 | global batch size:  1024 | lm loss: 1.836949E+00 | loss scale: 1.0 | grad norm: 0.087 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28480/   51900 | consumed samples:     29163520 | elapsed time per iteration (ms): 37465.7 | learning rate: 1.013E-04 | global batch size:  1024 | lm loss: 1.846523E+00 | loss scale: 1.0 | grad norm: 0.087 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28481/   51900 | consumed samples:     29164544 | elapsed time per iteration (ms): 37633.0 | learning rate: 1.013E-04 | global batch size:  1024 | lm loss: 1.837047E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28482/   51900 | consumed samples:     29165568 | elapsed time per iteration (ms): 37592.0 | learning rate: 1.013E-04 | global batch size:  1024 | lm loss: 1.862350E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28483/   51900 | consumed samples:     29166592 | elapsed time per iteration (ms): 37700.8 | learning rate: 1.013E-04 | global batch size:  1024 | lm loss: 1.841881E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28484/   51900 | consumed samples:     29167616 | elapsed time per iteration (ms): 37648.7 | learning rate: 1.013E-04 | global batch size:  1024 | lm loss: 1.838490E+00 | loss scale: 1.0 | grad norm: 0.092 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28485/   51900 | consumed samples:     29168640 | elapsed time per iteration (ms): 37610.6 | learning rate: 1.013E-04 | global batch size:  1024 | lm loss: 1.840622E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28486/   51900 | consumed samples:     29169664 | elapsed time per iteration (ms): 37667.5 | learning rate: 1.013E-04 | global batch size:  1024 | lm loss: 1.833616E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28487/   51900 | consumed samples:     29170688 | elapsed time per iteration (ms): 37562.6 | learning rate: 1.013E-04 | global batch size:  1024 | lm loss: 1.846234E+00 | loss scale: 1.0 | grad norm: 0.092 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28488/   51900 | consumed samples:     29171712 | elapsed time per iteration (ms): 37775.9 | learning rate: 1.013E-04 | global batch size:  1024 | lm loss: 1.828539E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28489/   51900 | consumed samples:     29172736 | elapsed time per iteration (ms): 37682.7 | learning rate: 1.013E-04 | global batch size:  1024 | lm loss: 1.834859E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28490/   51900 | consumed samples:     29173760 | elapsed time per iteration (ms): 37568.7 | learning rate: 1.013E-04 | global batch size:  1024 | lm loss: 1.842983E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28491/   51900 | consumed samples:     29174784 | elapsed time per iteration (ms): 37556.5 | learning rate: 1.013E-04 | global batch size:  1024 | lm loss: 1.834332E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28492/   51900 | consumed samples:     29175808 | elapsed time per iteration (ms): 37550.7 | learning rate: 1.013E-04 | global batch size:  1024 | lm loss: 1.850263E+00 | loss scale: 1.0 | grad norm: 0.089 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28493/   51900 | consumed samples:     29176832 | elapsed time per iteration (ms): 37582.6 | learning rate: 1.013E-04 | global batch size:  1024 | lm loss: 1.822153E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28494/   51900 | consumed samples:     29177856 | elapsed time per iteration (ms): 37454.6 | learning rate: 1.013E-04 | global batch size:  1024 | lm loss: 1.841199E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28495/   51900 | consumed samples:     29178880 | elapsed time per iteration (ms): 37604.9 | learning rate: 1.013E-04 | global batch size:  1024 | lm loss: 1.839998E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28496/   51900 | consumed samples:     29179904 | elapsed time per iteration (ms): 37743.1 | learning rate: 1.013E-04 | global batch size:  1024 | lm loss: 1.830743E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28497/   51900 | consumed samples:     29180928 | elapsed time per iteration (ms): 37588.8 | learning rate: 1.012E-04 | global batch size:  1024 | lm loss: 1.834052E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28498/   51900 | consumed samples:     29181952 | elapsed time per iteration (ms): 37569.2 | learning rate: 1.012E-04 | global batch size:  1024 | lm loss: 1.832003E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28499/   51900 | consumed samples:     29182976 | elapsed time per iteration (ms): 37556.7 | learning rate: 1.012E-04 | global batch size:  1024 | lm loss: 1.835327E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28500/   51900 | consumed samples:     29184000 | elapsed time per iteration (ms): 37621.5 | learning rate: 1.012E-04 | global batch size:  1024 | lm loss: 1.842607E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 2.5 seconds.), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 4.8 seconds.), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 9.1 seconds.), retrying request
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 17.6 seconds.), retrying request
(min, max) time across ranks (ms):
    save-checkpoint ................................: (153802.63, 153802.67)
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 37.3 seconds.), retrying request
 iteration    28501/   51900 | consumed samples:     29185024 | elapsed time per iteration (ms): 37228.8 | learning rate: 1.012E-04 | global batch size:  1024 | lm loss: 1.834341E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 77.4 seconds.), retrying request
 iteration    28502/   51900 | consumed samples:     29186048 | elapsed time per iteration (ms): 37673.0 | learning rate: 1.012E-04 | global batch size:  1024 | lm loss: 1.827767E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28503/   51900 | consumed samples:     29187072 | elapsed time per iteration (ms): 37560.1 | learning rate: 1.012E-04 | global batch size:  1024 | lm loss: 1.845211E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
wandb: 429 encountered (Filestream rate limit exceeded, retrying in 154.9 seconds.), retrying request
 iteration    28504/   51900 | consumed samples:     29188096 | elapsed time per iteration (ms): 37601.4 | learning rate: 1.012E-04 | global batch size:  1024 | lm loss: 1.834891E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28505/   51900 | consumed samples:     29189120 | elapsed time per iteration (ms): 37648.2 | learning rate: 1.012E-04 | global batch size:  1024 | lm loss: 1.838077E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28506/   51900 | consumed samples:     29190144 | elapsed time per iteration (ms): 37658.9 | learning rate: 1.012E-04 | global batch size:  1024 | lm loss: 1.842650E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28507/   51900 | consumed samples:     29191168 | elapsed time per iteration (ms): 37574.7 | learning rate: 1.012E-04 | global batch size:  1024 | lm loss: 1.840954E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28508/   51900 | consumed samples:     29192192 | elapsed time per iteration (ms): 37666.9 | learning rate: 1.012E-04 | global batch size:  1024 | lm loss: 1.831078E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28509/   51900 | consumed samples:     29193216 | elapsed time per iteration (ms): 37645.4 | learning rate: 1.012E-04 | global batch size:  1024 | lm loss: 1.838303E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28510/   51900 | consumed samples:     29194240 | elapsed time per iteration (ms): 37479.5 | learning rate: 1.012E-04 | global batch size:  1024 | lm loss: 1.851136E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28511/   51900 | consumed samples:     29195264 | elapsed time per iteration (ms): 37586.0 | learning rate: 1.012E-04 | global batch size:  1024 | lm loss: 1.845947E+00 | loss scale: 1.0 | grad norm: 0.065 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28512/   51900 | consumed samples:     29196288 | elapsed time per iteration (ms): 37686.6 | learning rate: 1.012E-04 | global batch size:  1024 | lm loss: 1.856435E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28513/   51900 | consumed samples:     29197312 | elapsed time per iteration (ms): 37676.3 | learning rate: 1.012E-04 | global batch size:  1024 | lm loss: 1.840469E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28514/   51900 | consumed samples:     29198336 | elapsed time per iteration (ms): 37676.3 | learning rate: 1.012E-04 | global batch size:  1024 | lm loss: 1.852190E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28515/   51900 | consumed samples:     29199360 | elapsed time per iteration (ms): 37690.2 | learning rate: 1.011E-04 | global batch size:  1024 | lm loss: 1.845550E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28516/   51900 | consumed samples:     29200384 | elapsed time per iteration (ms): 37676.8 | learning rate: 1.011E-04 | global batch size:  1024 | lm loss: 1.837343E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28517/   51900 | consumed samples:     29201408 | elapsed time per iteration (ms): 37561.4 | learning rate: 1.011E-04 | global batch size:  1024 | lm loss: 1.840899E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28518/   51900 | consumed samples:     29202432 | elapsed time per iteration (ms): 37543.9 | learning rate: 1.011E-04 | global batch size:  1024 | lm loss: 1.829746E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28519/   51900 | consumed samples:     29203456 | elapsed time per iteration (ms): 37715.8 | learning rate: 1.011E-04 | global batch size:  1024 | lm loss: 1.852421E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28520/   51900 | consumed samples:     29204480 | elapsed time per iteration (ms): 37666.8 | learning rate: 1.011E-04 | global batch size:  1024 | lm loss: 1.852547E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28521/   51900 | consumed samples:     29205504 | elapsed time per iteration (ms): 37714.5 | learning rate: 1.011E-04 | global batch size:  1024 | lm loss: 1.847066E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28522/   51900 | consumed samples:     29206528 | elapsed time per iteration (ms): 37640.2 | learning rate: 1.011E-04 | global batch size:  1024 | lm loss: 1.842145E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28523/   51900 | consumed samples:     29207552 | elapsed time per iteration (ms): 37650.0 | learning rate: 1.011E-04 | global batch size:  1024 | lm loss: 1.837678E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28524/   51900 | consumed samples:     29208576 | elapsed time per iteration (ms): 37535.6 | learning rate: 1.011E-04 | global batch size:  1024 | lm loss: 1.846457E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28525/   51900 | consumed samples:     29209600 | elapsed time per iteration (ms): 37663.5 | learning rate: 1.011E-04 | global batch size:  1024 | lm loss: 1.847754E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28526/   51900 | consumed samples:     29210624 | elapsed time per iteration (ms): 37659.3 | learning rate: 1.011E-04 | global batch size:  1024 | lm loss: 1.845222E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28527/   51900 | consumed samples:     29211648 | elapsed time per iteration (ms): 37533.8 | learning rate: 1.011E-04 | global batch size:  1024 | lm loss: 1.826555E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28528/   51900 | consumed samples:     29212672 | elapsed time per iteration (ms): 37564.6 | learning rate: 1.011E-04 | global batch size:  1024 | lm loss: 1.850335E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28529/   51900 | consumed samples:     29213696 | elapsed time per iteration (ms): 37530.2 | learning rate: 1.011E-04 | global batch size:  1024 | lm loss: 1.836873E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28530/   51900 | consumed samples:     29214720 | elapsed time per iteration (ms): 37645.6 | learning rate: 1.011E-04 | global batch size:  1024 | lm loss: 1.848021E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28531/   51900 | consumed samples:     29215744 | elapsed time per iteration (ms): 37513.8 | learning rate: 1.011E-04 | global batch size:  1024 | lm loss: 1.835100E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28532/   51900 | consumed samples:     29216768 | elapsed time per iteration (ms): 37735.6 | learning rate: 1.011E-04 | global batch size:  1024 | lm loss: 1.843622E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28533/   51900 | consumed samples:     29217792 | elapsed time per iteration (ms): 37592.0 | learning rate: 1.010E-04 | global batch size:  1024 | lm loss: 1.845457E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28534/   51900 | consumed samples:     29218816 | elapsed time per iteration (ms): 37579.9 | learning rate: 1.010E-04 | global batch size:  1024 | lm loss: 1.839649E+00 | loss scale: 1.0 | grad norm: 0.091 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28535/   51900 | consumed samples:     29219840 | elapsed time per iteration (ms): 37729.7 | learning rate: 1.010E-04 | global batch size:  1024 | lm loss: 1.834128E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28536/   51900 | consumed samples:     29220864 | elapsed time per iteration (ms): 37668.4 | learning rate: 1.010E-04 | global batch size:  1024 | lm loss: 1.846790E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28537/   51900 | consumed samples:     29221888 | elapsed time per iteration (ms): 37540.9 | learning rate: 1.010E-04 | global batch size:  1024 | lm loss: 1.830929E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28538/   51900 | consumed samples:     29222912 | elapsed time per iteration (ms): 37618.3 | learning rate: 1.010E-04 | global batch size:  1024 | lm loss: 1.847785E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28539/   51900 | consumed samples:     29223936 | elapsed time per iteration (ms): 37578.1 | learning rate: 1.010E-04 | global batch size:  1024 | lm loss: 1.830591E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28540/   51900 | consumed samples:     29224960 | elapsed time per iteration (ms): 37691.3 | learning rate: 1.010E-04 | global batch size:  1024 | lm loss: 1.826340E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28541/   51900 | consumed samples:     29225984 | elapsed time per iteration (ms): 37654.2 | learning rate: 1.010E-04 | global batch size:  1024 | lm loss: 1.836893E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28542/   51900 | consumed samples:     29227008 | elapsed time per iteration (ms): 37586.7 | learning rate: 1.010E-04 | global batch size:  1024 | lm loss: 1.855659E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28543/   51900 | consumed samples:     29228032 | elapsed time per iteration (ms): 37727.4 | learning rate: 1.010E-04 | global batch size:  1024 | lm loss: 1.834210E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28544/   51900 | consumed samples:     29229056 | elapsed time per iteration (ms): 37648.7 | learning rate: 1.010E-04 | global batch size:  1024 | lm loss: 1.835433E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28545/   51900 | consumed samples:     29230080 | elapsed time per iteration (ms): 37606.8 | learning rate: 1.010E-04 | global batch size:  1024 | lm loss: 1.847936E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28546/   51900 | consumed samples:     29231104 | elapsed time per iteration (ms): 37546.7 | learning rate: 1.010E-04 | global batch size:  1024 | lm loss: 1.843564E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28547/   51900 | consumed samples:     29232128 | elapsed time per iteration (ms): 37685.3 | learning rate: 1.010E-04 | global batch size:  1024 | lm loss: 1.850671E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28548/   51900 | consumed samples:     29233152 | elapsed time per iteration (ms): 37630.6 | learning rate: 1.010E-04 | global batch size:  1024 | lm loss: 1.846327E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28549/   51900 | consumed samples:     29234176 | elapsed time per iteration (ms): 37592.3 | learning rate: 1.010E-04 | global batch size:  1024 | lm loss: 1.855031E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28550/   51900 | consumed samples:     29235200 | elapsed time per iteration (ms): 37615.6 | learning rate: 1.009E-04 | global batch size:  1024 | lm loss: 1.833112E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28551/   51900 | consumed samples:     29236224 | elapsed time per iteration (ms): 37670.0 | learning rate: 1.009E-04 | global batch size:  1024 | lm loss: 1.835497E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28552/   51900 | consumed samples:     29237248 | elapsed time per iteration (ms): 37715.6 | learning rate: 1.009E-04 | global batch size:  1024 | lm loss: 1.850169E+00 | loss scale: 1.0 | grad norm: 0.166 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28553/   51900 | consumed samples:     29238272 | elapsed time per iteration (ms): 37588.7 | learning rate: 1.009E-04 | global batch size:  1024 | lm loss: 1.855550E+00 | loss scale: 1.0 | grad norm: 0.208 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28554/   51900 | consumed samples:     29239296 | elapsed time per iteration (ms): 37633.9 | learning rate: 1.009E-04 | global batch size:  1024 | lm loss: 1.849947E+00 | loss scale: 1.0 | grad norm: 0.087 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28555/   51900 | consumed samples:     29240320 | elapsed time per iteration (ms): 37600.0 | learning rate: 1.009E-04 | global batch size:  1024 | lm loss: 1.848974E+00 | loss scale: 1.0 | grad norm: 0.099 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28556/   51900 | consumed samples:     29241344 | elapsed time per iteration (ms): 37668.2 | learning rate: 1.009E-04 | global batch size:  1024 | lm loss: 1.848947E+00 | loss scale: 1.0 | grad norm: 0.096 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28557/   51900 | consumed samples:     29242368 | elapsed time per iteration (ms): 37750.8 | learning rate: 1.009E-04 | global batch size:  1024 | lm loss: 1.862792E+00 | loss scale: 1.0 | grad norm: 0.102 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28558/   51900 | consumed samples:     29243392 | elapsed time per iteration (ms): 37630.8 | learning rate: 1.009E-04 | global batch size:  1024 | lm loss: 1.843854E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28559/   51900 | consumed samples:     29244416 | elapsed time per iteration (ms): 37799.9 | learning rate: 1.009E-04 | global batch size:  1024 | lm loss: 1.852464E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28560/   51900 | consumed samples:     29245440 | elapsed time per iteration (ms): 37672.8 | learning rate: 1.009E-04 | global batch size:  1024 | lm loss: 1.854174E+00 | loss scale: 1.0 | grad norm: 0.091 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28561/   51900 | consumed samples:     29246464 | elapsed time per iteration (ms): 37643.9 | learning rate: 1.009E-04 | global batch size:  1024 | lm loss: 1.843580E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28562/   51900 | consumed samples:     29247488 | elapsed time per iteration (ms): 37628.2 | learning rate: 1.009E-04 | global batch size:  1024 | lm loss: 1.831250E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28563/   51900 | consumed samples:     29248512 | elapsed time per iteration (ms): 37579.9 | learning rate: 1.009E-04 | global batch size:  1024 | lm loss: 1.851167E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28564/   51900 | consumed samples:     29249536 | elapsed time per iteration (ms): 37654.1 | learning rate: 1.009E-04 | global batch size:  1024 | lm loss: 1.837030E+00 | loss scale: 1.0 | grad norm: 0.088 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28565/   51900 | consumed samples:     29250560 | elapsed time per iteration (ms): 37597.7 | learning rate: 1.009E-04 | global batch size:  1024 | lm loss: 1.854660E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28566/   51900 | consumed samples:     29251584 | elapsed time per iteration (ms): 37599.3 | learning rate: 1.009E-04 | global batch size:  1024 | lm loss: 1.832631E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28567/   51900 | consumed samples:     29252608 | elapsed time per iteration (ms): 37710.2 | learning rate: 1.009E-04 | global batch size:  1024 | lm loss: 1.836811E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28568/   51900 | consumed samples:     29253632 | elapsed time per iteration (ms): 37667.3 | learning rate: 1.008E-04 | global batch size:  1024 | lm loss: 1.833357E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28569/   51900 | consumed samples:     29254656 | elapsed time per iteration (ms): 37718.3 | learning rate: 1.008E-04 | global batch size:  1024 | lm loss: 1.839919E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28570/   51900 | consumed samples:     29255680 | elapsed time per iteration (ms): 37823.8 | learning rate: 1.008E-04 | global batch size:  1024 | lm loss: 1.842204E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28571/   51900 | consumed samples:     29256704 | elapsed time per iteration (ms): 37688.8 | learning rate: 1.008E-04 | global batch size:  1024 | lm loss: 1.839363E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28572/   51900 | consumed samples:     29257728 | elapsed time per iteration (ms): 37586.2 | learning rate: 1.008E-04 | global batch size:  1024 | lm loss: 1.852934E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28573/   51900 | consumed samples:     29258752 | elapsed time per iteration (ms): 37622.0 | learning rate: 1.008E-04 | global batch size:  1024 | lm loss: 1.842612E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28574/   51900 | consumed samples:     29259776 | elapsed time per iteration (ms): 37642.4 | learning rate: 1.008E-04 | global batch size:  1024 | lm loss: 1.848145E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28575/   51900 | consumed samples:     29260800 | elapsed time per iteration (ms): 37628.7 | learning rate: 1.008E-04 | global batch size:  1024 | lm loss: 1.832870E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28576/   51900 | consumed samples:     29261824 | elapsed time per iteration (ms): 37642.2 | learning rate: 1.008E-04 | global batch size:  1024 | lm loss: 1.855487E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28577/   51900 | consumed samples:     29262848 | elapsed time per iteration (ms): 37699.0 | learning rate: 1.008E-04 | global batch size:  1024 | lm loss: 1.854575E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28578/   51900 | consumed samples:     29263872 | elapsed time per iteration (ms): 37666.4 | learning rate: 1.008E-04 | global batch size:  1024 | lm loss: 1.865265E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28579/   51900 | consumed samples:     29264896 | elapsed time per iteration (ms): 37559.9 | learning rate: 1.008E-04 | global batch size:  1024 | lm loss: 1.825786E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28580/   51900 | consumed samples:     29265920 | elapsed time per iteration (ms): 37539.5 | learning rate: 1.008E-04 | global batch size:  1024 | lm loss: 1.833445E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28581/   51900 | consumed samples:     29266944 | elapsed time per iteration (ms): 37609.6 | learning rate: 1.008E-04 | global batch size:  1024 | lm loss: 1.845477E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28582/   51900 | consumed samples:     29267968 | elapsed time per iteration (ms): 37527.5 | learning rate: 1.008E-04 | global batch size:  1024 | lm loss: 1.844438E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28583/   51900 | consumed samples:     29268992 | elapsed time per iteration (ms): 37565.4 | learning rate: 1.008E-04 | global batch size:  1024 | lm loss: 1.845396E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28584/   51900 | consumed samples:     29270016 | elapsed time per iteration (ms): 37740.7 | learning rate: 1.008E-04 | global batch size:  1024 | lm loss: 1.853694E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28585/   51900 | consumed samples:     29271040 | elapsed time per iteration (ms): 37592.4 | learning rate: 1.008E-04 | global batch size:  1024 | lm loss: 1.832710E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28586/   51900 | consumed samples:     29272064 | elapsed time per iteration (ms): 37687.4 | learning rate: 1.007E-04 | global batch size:  1024 | lm loss: 1.842307E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28587/   51900 | consumed samples:     29273088 | elapsed time per iteration (ms): 37675.9 | learning rate: 1.007E-04 | global batch size:  1024 | lm loss: 1.854080E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28588/   51900 | consumed samples:     29274112 | elapsed time per iteration (ms): 37734.1 | learning rate: 1.007E-04 | global batch size:  1024 | lm loss: 1.840187E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28589/   51900 | consumed samples:     29275136 | elapsed time per iteration (ms): 37610.6 | learning rate: 1.007E-04 | global batch size:  1024 | lm loss: 1.832262E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28590/   51900 | consumed samples:     29276160 | elapsed time per iteration (ms): 37548.8 | learning rate: 1.007E-04 | global batch size:  1024 | lm loss: 1.850140E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28591/   51900 | consumed samples:     29277184 | elapsed time per iteration (ms): 37576.4 | learning rate: 1.007E-04 | global batch size:  1024 | lm loss: 1.830341E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28592/   51900 | consumed samples:     29278208 | elapsed time per iteration (ms): 37666.8 | learning rate: 1.007E-04 | global batch size:  1024 | lm loss: 1.860748E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28593/   51900 | consumed samples:     29279232 | elapsed time per iteration (ms): 37722.2 | learning rate: 1.007E-04 | global batch size:  1024 | lm loss: 1.846649E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28594/   51900 | consumed samples:     29280256 | elapsed time per iteration (ms): 37503.0 | learning rate: 1.007E-04 | global batch size:  1024 | lm loss: 1.845766E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28595/   51900 | consumed samples:     29281280 | elapsed time per iteration (ms): 37627.6 | learning rate: 1.007E-04 | global batch size:  1024 | lm loss: 1.841097E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28596/   51900 | consumed samples:     29282304 | elapsed time per iteration (ms): 37693.8 | learning rate: 1.007E-04 | global batch size:  1024 | lm loss: 1.847275E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28597/   51900 | consumed samples:     29283328 | elapsed time per iteration (ms): 37637.6 | learning rate: 1.007E-04 | global batch size:  1024 | lm loss: 1.806522E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28598/   51900 | consumed samples:     29284352 | elapsed time per iteration (ms): 37619.5 | learning rate: 1.007E-04 | global batch size:  1024 | lm loss: 1.844147E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28599/   51900 | consumed samples:     29285376 | elapsed time per iteration (ms): 37666.8 | learning rate: 1.007E-04 | global batch size:  1024 | lm loss: 1.839676E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28600/   51900 | consumed samples:     29286400 | elapsed time per iteration (ms): 37759.1 | learning rate: 1.007E-04 | global batch size:  1024 | lm loss: 1.857429E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28601/   51900 | consumed samples:     29287424 | elapsed time per iteration (ms): 37607.5 | learning rate: 1.007E-04 | global batch size:  1024 | lm loss: 1.853842E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28602/   51900 | consumed samples:     29288448 | elapsed time per iteration (ms): 37773.7 | learning rate: 1.007E-04 | global batch size:  1024 | lm loss: 1.840856E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28603/   51900 | consumed samples:     29289472 | elapsed time per iteration (ms): 37644.1 | learning rate: 1.007E-04 | global batch size:  1024 | lm loss: 1.813642E+00 | loss scale: 1.0 | grad norm: 0.246 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28604/   51900 | consumed samples:     29290496 | elapsed time per iteration (ms): 37648.7 | learning rate: 1.006E-04 | global batch size:  1024 | lm loss: 1.845017E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28605/   51900 | consumed samples:     29291520 | elapsed time per iteration (ms): 37601.4 | learning rate: 1.006E-04 | global batch size:  1024 | lm loss: 1.841227E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28606/   51900 | consumed samples:     29292544 | elapsed time per iteration (ms): 37728.1 | learning rate: 1.006E-04 | global batch size:  1024 | lm loss: 1.850284E+00 | loss scale: 1.0 | grad norm: 0.094 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28607/   51900 | consumed samples:     29293568 | elapsed time per iteration (ms): 37707.9 | learning rate: 1.006E-04 | global batch size:  1024 | lm loss: 1.831335E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28608/   51900 | consumed samples:     29294592 | elapsed time per iteration (ms): 37720.1 | learning rate: 1.006E-04 | global batch size:  1024 | lm loss: 1.842168E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28609/   51900 | consumed samples:     29295616 | elapsed time per iteration (ms): 37626.4 | learning rate: 1.006E-04 | global batch size:  1024 | lm loss: 1.832841E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28610/   51900 | consumed samples:     29296640 | elapsed time per iteration (ms): 37503.9 | learning rate: 1.006E-04 | global batch size:  1024 | lm loss: 1.847033E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28611/   51900 | consumed samples:     29297664 | elapsed time per iteration (ms): 37600.8 | learning rate: 1.006E-04 | global batch size:  1024 | lm loss: 1.839986E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28612/   51900 | consumed samples:     29298688 | elapsed time per iteration (ms): 37559.5 | learning rate: 1.006E-04 | global batch size:  1024 | lm loss: 1.838562E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28613/   51900 | consumed samples:     29299712 | elapsed time per iteration (ms): 37650.3 | learning rate: 1.006E-04 | global batch size:  1024 | lm loss: 1.834103E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28614/   51900 | consumed samples:     29300736 | elapsed time per iteration (ms): 37674.0 | learning rate: 1.006E-04 | global batch size:  1024 | lm loss: 1.829957E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28615/   51900 | consumed samples:     29301760 | elapsed time per iteration (ms): 37585.3 | learning rate: 1.006E-04 | global batch size:  1024 | lm loss: 1.855046E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28616/   51900 | consumed samples:     29302784 | elapsed time per iteration (ms): 37698.7 | learning rate: 1.006E-04 | global batch size:  1024 | lm loss: 1.839075E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28617/   51900 | consumed samples:     29303808 | elapsed time per iteration (ms): 37545.0 | learning rate: 1.006E-04 | global batch size:  1024 | lm loss: 1.838942E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28618/   51900 | consumed samples:     29304832 | elapsed time per iteration (ms): 37626.0 | learning rate: 1.006E-04 | global batch size:  1024 | lm loss: 1.821935E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28619/   51900 | consumed samples:     29305856 | elapsed time per iteration (ms): 37561.7 | learning rate: 1.006E-04 | global batch size:  1024 | lm loss: 1.830662E+00 | loss scale: 1.0 | grad norm: 0.089 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28620/   51900 | consumed samples:     29306880 | elapsed time per iteration (ms): 37661.9 | learning rate: 1.006E-04 | global batch size:  1024 | lm loss: 1.844027E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28621/   51900 | consumed samples:     29307904 | elapsed time per iteration (ms): 37544.6 | learning rate: 1.005E-04 | global batch size:  1024 | lm loss: 1.846098E+00 | loss scale: 1.0 | grad norm: 0.089 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28622/   51900 | consumed samples:     29308928 | elapsed time per iteration (ms): 37659.9 | learning rate: 1.005E-04 | global batch size:  1024 | lm loss: 1.836230E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28623/   51900 | consumed samples:     29309952 | elapsed time per iteration (ms): 37633.8 | learning rate: 1.005E-04 | global batch size:  1024 | lm loss: 1.836116E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28624/   51900 | consumed samples:     29310976 | elapsed time per iteration (ms): 37680.3 | learning rate: 1.005E-04 | global batch size:  1024 | lm loss: 1.848285E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28625/   51900 | consumed samples:     29312000 | elapsed time per iteration (ms): 37536.7 | learning rate: 1.005E-04 | global batch size:  1024 | lm loss: 1.833495E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28626/   51900 | consumed samples:     29313024 | elapsed time per iteration (ms): 37846.6 | learning rate: 1.005E-04 | global batch size:  1024 | lm loss: 1.838028E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28627/   51900 | consumed samples:     29314048 | elapsed time per iteration (ms): 37649.8 | learning rate: 1.005E-04 | global batch size:  1024 | lm loss: 1.858205E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28628/   51900 | consumed samples:     29315072 | elapsed time per iteration (ms): 37657.6 | learning rate: 1.005E-04 | global batch size:  1024 | lm loss: 1.829621E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28629/   51900 | consumed samples:     29316096 | elapsed time per iteration (ms): 37663.2 | learning rate: 1.005E-04 | global batch size:  1024 | lm loss: 1.840216E+00 | loss scale: 1.0 | grad norm: 0.098 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28630/   51900 | consumed samples:     29317120 | elapsed time per iteration (ms): 37622.7 | learning rate: 1.005E-04 | global batch size:  1024 | lm loss: 1.828158E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28631/   51900 | consumed samples:     29318144 | elapsed time per iteration (ms): 37518.2 | learning rate: 1.005E-04 | global batch size:  1024 | lm loss: 1.838042E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28632/   51900 | consumed samples:     29319168 | elapsed time per iteration (ms): 37647.3 | learning rate: 1.005E-04 | global batch size:  1024 | lm loss: 1.848421E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28633/   51900 | consumed samples:     29320192 | elapsed time per iteration (ms): 37755.7 | learning rate: 1.005E-04 | global batch size:  1024 | lm loss: 1.828915E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28634/   51900 | consumed samples:     29321216 | elapsed time per iteration (ms): 37639.3 | learning rate: 1.005E-04 | global batch size:  1024 | lm loss: 1.848461E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28635/   51900 | consumed samples:     29322240 | elapsed time per iteration (ms): 37668.8 | learning rate: 1.005E-04 | global batch size:  1024 | lm loss: 1.843830E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28636/   51900 | consumed samples:     29323264 | elapsed time per iteration (ms): 37650.9 | learning rate: 1.005E-04 | global batch size:  1024 | lm loss: 1.855168E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28637/   51900 | consumed samples:     29324288 | elapsed time per iteration (ms): 37690.4 | learning rate: 1.005E-04 | global batch size:  1024 | lm loss: 1.846594E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28638/   51900 | consumed samples:     29325312 | elapsed time per iteration (ms): 37713.5 | learning rate: 1.005E-04 | global batch size:  1024 | lm loss: 1.829878E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28639/   51900 | consumed samples:     29326336 | elapsed time per iteration (ms): 37688.8 | learning rate: 1.004E-04 | global batch size:  1024 | lm loss: 1.856075E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28640/   51900 | consumed samples:     29327360 | elapsed time per iteration (ms): 37701.9 | learning rate: 1.004E-04 | global batch size:  1024 | lm loss: 1.852770E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28641/   51900 | consumed samples:     29328384 | elapsed time per iteration (ms): 37653.7 | learning rate: 1.004E-04 | global batch size:  1024 | lm loss: 1.819489E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28642/   51900 | consumed samples:     29329408 | elapsed time per iteration (ms): 37703.5 | learning rate: 1.004E-04 | global batch size:  1024 | lm loss: 1.848459E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28643/   51900 | consumed samples:     29330432 | elapsed time per iteration (ms): 37695.4 | learning rate: 1.004E-04 | global batch size:  1024 | lm loss: 1.842150E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28644/   51900 | consumed samples:     29331456 | elapsed time per iteration (ms): 37731.8 | learning rate: 1.004E-04 | global batch size:  1024 | lm loss: 1.857933E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28645/   51900 | consumed samples:     29332480 | elapsed time per iteration (ms): 37627.9 | learning rate: 1.004E-04 | global batch size:  1024 | lm loss: 1.834965E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28646/   51900 | consumed samples:     29333504 | elapsed time per iteration (ms): 37708.5 | learning rate: 1.004E-04 | global batch size:  1024 | lm loss: 1.831205E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28647/   51900 | consumed samples:     29334528 | elapsed time per iteration (ms): 37556.7 | learning rate: 1.004E-04 | global batch size:  1024 | lm loss: 1.830126E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28648/   51900 | consumed samples:     29335552 | elapsed time per iteration (ms): 37571.9 | learning rate: 1.004E-04 | global batch size:  1024 | lm loss: 1.835320E+00 | loss scale: 1.0 | grad norm: 0.111 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28649/   51900 | consumed samples:     29336576 | elapsed time per iteration (ms): 37649.5 | learning rate: 1.004E-04 | global batch size:  1024 | lm loss: 1.824040E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28650/   51900 | consumed samples:     29337600 | elapsed time per iteration (ms): 37765.4 | learning rate: 1.004E-04 | global batch size:  1024 | lm loss: 1.831413E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28651/   51900 | consumed samples:     29338624 | elapsed time per iteration (ms): 37574.9 | learning rate: 1.004E-04 | global batch size:  1024 | lm loss: 1.847905E+00 | loss scale: 1.0 | grad norm: 0.087 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28652/   51900 | consumed samples:     29339648 | elapsed time per iteration (ms): 37666.8 | learning rate: 1.004E-04 | global batch size:  1024 | lm loss: 1.843665E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28653/   51900 | consumed samples:     29340672 | elapsed time per iteration (ms): 37641.7 | learning rate: 1.004E-04 | global batch size:  1024 | lm loss: 1.847477E+00 | loss scale: 1.0 | grad norm: 0.087 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28654/   51900 | consumed samples:     29341696 | elapsed time per iteration (ms): 37668.9 | learning rate: 1.004E-04 | global batch size:  1024 | lm loss: 1.823512E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28655/   51900 | consumed samples:     29342720 | elapsed time per iteration (ms): 37701.2 | learning rate: 1.004E-04 | global batch size:  1024 | lm loss: 1.818637E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28656/   51900 | consumed samples:     29343744 | elapsed time per iteration (ms): 37609.6 | learning rate: 1.004E-04 | global batch size:  1024 | lm loss: 1.844208E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28657/   51900 | consumed samples:     29344768 | elapsed time per iteration (ms): 37598.6 | learning rate: 1.003E-04 | global batch size:  1024 | lm loss: 1.839836E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28658/   51900 | consumed samples:     29345792 | elapsed time per iteration (ms): 37661.5 | learning rate: 1.003E-04 | global batch size:  1024 | lm loss: 1.837605E+00 | loss scale: 1.0 | grad norm: 0.089 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28659/   51900 | consumed samples:     29346816 | elapsed time per iteration (ms): 37665.5 | learning rate: 1.003E-04 | global batch size:  1024 | lm loss: 1.850570E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28660/   51900 | consumed samples:     29347840 | elapsed time per iteration (ms): 37620.8 | learning rate: 1.003E-04 | global batch size:  1024 | lm loss: 1.838800E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28661/   51900 | consumed samples:     29348864 | elapsed time per iteration (ms): 37662.0 | learning rate: 1.003E-04 | global batch size:  1024 | lm loss: 1.844809E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28662/   51900 | consumed samples:     29349888 | elapsed time per iteration (ms): 37678.5 | learning rate: 1.003E-04 | global batch size:  1024 | lm loss: 1.833079E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28663/   51900 | consumed samples:     29350912 | elapsed time per iteration (ms): 37544.0 | learning rate: 1.003E-04 | global batch size:  1024 | lm loss: 1.844917E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28664/   51900 | consumed samples:     29351936 | elapsed time per iteration (ms): 37737.7 | learning rate: 1.003E-04 | global batch size:  1024 | lm loss: 1.840031E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28665/   51900 | consumed samples:     29352960 | elapsed time per iteration (ms): 37507.0 | learning rate: 1.003E-04 | global batch size:  1024 | lm loss: 1.832158E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28666/   51900 | consumed samples:     29353984 | elapsed time per iteration (ms): 37738.0 | learning rate: 1.003E-04 | global batch size:  1024 | lm loss: 1.829962E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28667/   51900 | consumed samples:     29355008 | elapsed time per iteration (ms): 37646.2 | learning rate: 1.003E-04 | global batch size:  1024 | lm loss: 1.838771E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28668/   51900 | consumed samples:     29356032 | elapsed time per iteration (ms): 37614.0 | learning rate: 1.003E-04 | global batch size:  1024 | lm loss: 1.831232E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28669/   51900 | consumed samples:     29357056 | elapsed time per iteration (ms): 37597.9 | learning rate: 1.003E-04 | global batch size:  1024 | lm loss: 1.852691E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28670/   51900 | consumed samples:     29358080 | elapsed time per iteration (ms): 37579.3 | learning rate: 1.003E-04 | global batch size:  1024 | lm loss: 1.846410E+00 | loss scale: 1.0 | grad norm: 0.118 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28671/   51900 | consumed samples:     29359104 | elapsed time per iteration (ms): 37656.7 | learning rate: 1.003E-04 | global batch size:  1024 | lm loss: 1.823321E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28672/   51900 | consumed samples:     29360128 | elapsed time per iteration (ms): 37648.4 | learning rate: 1.003E-04 | global batch size:  1024 | lm loss: 1.859266E+00 | loss scale: 1.0 | grad norm: 0.087 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28673/   51900 | consumed samples:     29361152 | elapsed time per iteration (ms): 37609.0 | learning rate: 1.003E-04 | global batch size:  1024 | lm loss: 1.851966E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28674/   51900 | consumed samples:     29362176 | elapsed time per iteration (ms): 37569.5 | learning rate: 1.003E-04 | global batch size:  1024 | lm loss: 1.850020E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28675/   51900 | consumed samples:     29363200 | elapsed time per iteration (ms): 37657.2 | learning rate: 1.002E-04 | global batch size:  1024 | lm loss: 1.835764E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28676/   51900 | consumed samples:     29364224 | elapsed time per iteration (ms): 37659.6 | learning rate: 1.002E-04 | global batch size:  1024 | lm loss: 1.843754E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28677/   51900 | consumed samples:     29365248 | elapsed time per iteration (ms): 37676.6 | learning rate: 1.002E-04 | global batch size:  1024 | lm loss: 1.843393E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28678/   51900 | consumed samples:     29366272 | elapsed time per iteration (ms): 37692.0 | learning rate: 1.002E-04 | global batch size:  1024 | lm loss: 1.843032E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28679/   51900 | consumed samples:     29367296 | elapsed time per iteration (ms): 37594.3 | learning rate: 1.002E-04 | global batch size:  1024 | lm loss: 1.825096E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28680/   51900 | consumed samples:     29368320 | elapsed time per iteration (ms): 37616.4 | learning rate: 1.002E-04 | global batch size:  1024 | lm loss: 1.860311E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28681/   51900 | consumed samples:     29369344 | elapsed time per iteration (ms): 37641.4 | learning rate: 1.002E-04 | global batch size:  1024 | lm loss: 1.828819E+00 | loss scale: 1.0 | grad norm: 0.092 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28682/   51900 | consumed samples:     29370368 | elapsed time per iteration (ms): 37611.9 | learning rate: 1.002E-04 | global batch size:  1024 | lm loss: 1.825755E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28683/   51900 | consumed samples:     29371392 | elapsed time per iteration (ms): 37651.0 | learning rate: 1.002E-04 | global batch size:  1024 | lm loss: 1.850443E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28684/   51900 | consumed samples:     29372416 | elapsed time per iteration (ms): 37648.9 | learning rate: 1.002E-04 | global batch size:  1024 | lm loss: 1.850060E+00 | loss scale: 1.0 | grad norm: 0.090 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28685/   51900 | consumed samples:     29373440 | elapsed time per iteration (ms): 37654.4 | learning rate: 1.002E-04 | global batch size:  1024 | lm loss: 1.843426E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28686/   51900 | consumed samples:     29374464 | elapsed time per iteration (ms): 37611.9 | learning rate: 1.002E-04 | global batch size:  1024 | lm loss: 1.849814E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28687/   51900 | consumed samples:     29375488 | elapsed time per iteration (ms): 37497.9 | learning rate: 1.002E-04 | global batch size:  1024 | lm loss: 1.837827E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28688/   51900 | consumed samples:     29376512 | elapsed time per iteration (ms): 37611.3 | learning rate: 1.002E-04 | global batch size:  1024 | lm loss: 1.846092E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28689/   51900 | consumed samples:     29377536 | elapsed time per iteration (ms): 37629.3 | learning rate: 1.002E-04 | global batch size:  1024 | lm loss: 1.857640E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28690/   51900 | consumed samples:     29378560 | elapsed time per iteration (ms): 37573.4 | learning rate: 1.002E-04 | global batch size:  1024 | lm loss: 1.844486E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28691/   51900 | consumed samples:     29379584 | elapsed time per iteration (ms): 37532.1 | learning rate: 1.002E-04 | global batch size:  1024 | lm loss: 1.826214E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28692/   51900 | consumed samples:     29380608 | elapsed time per iteration (ms): 37584.7 | learning rate: 1.001E-04 | global batch size:  1024 | lm loss: 1.847453E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28693/   51900 | consumed samples:     29381632 | elapsed time per iteration (ms): 37641.4 | learning rate: 1.001E-04 | global batch size:  1024 | lm loss: 1.845725E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28694/   51900 | consumed samples:     29382656 | elapsed time per iteration (ms): 37798.5 | learning rate: 1.001E-04 | global batch size:  1024 | lm loss: 1.831496E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28695/   51900 | consumed samples:     29383680 | elapsed time per iteration (ms): 37579.3 | learning rate: 1.001E-04 | global batch size:  1024 | lm loss: 1.831327E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28696/   51900 | consumed samples:     29384704 | elapsed time per iteration (ms): 37757.3 | learning rate: 1.001E-04 | global batch size:  1024 | lm loss: 1.827920E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28697/   51900 | consumed samples:     29385728 | elapsed time per iteration (ms): 37653.9 | learning rate: 1.001E-04 | global batch size:  1024 | lm loss: 1.834631E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28698/   51900 | consumed samples:     29386752 | elapsed time per iteration (ms): 37701.7 | learning rate: 1.001E-04 | global batch size:  1024 | lm loss: 1.842068E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28699/   51900 | consumed samples:     29387776 | elapsed time per iteration (ms): 37630.2 | learning rate: 1.001E-04 | global batch size:  1024 | lm loss: 1.836759E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28700/   51900 | consumed samples:     29388800 | elapsed time per iteration (ms): 37739.1 | learning rate: 1.001E-04 | global batch size:  1024 | lm loss: 1.850871E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28701/   51900 | consumed samples:     29389824 | elapsed time per iteration (ms): 37601.9 | learning rate: 1.001E-04 | global batch size:  1024 | lm loss: 1.867066E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28702/   51900 | consumed samples:     29390848 | elapsed time per iteration (ms): 37782.8 | learning rate: 1.001E-04 | global batch size:  1024 | lm loss: 1.842029E+00 | loss scale: 1.0 | grad norm: 0.087 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28703/   51900 | consumed samples:     29391872 | elapsed time per iteration (ms): 37683.0 | learning rate: 1.001E-04 | global batch size:  1024 | lm loss: 1.841168E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28704/   51900 | consumed samples:     29392896 | elapsed time per iteration (ms): 37596.8 | learning rate: 1.001E-04 | global batch size:  1024 | lm loss: 1.851726E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28705/   51900 | consumed samples:     29393920 | elapsed time per iteration (ms): 37579.6 | learning rate: 1.001E-04 | global batch size:  1024 | lm loss: 1.838065E+00 | loss scale: 1.0 | grad norm: 0.089 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28706/   51900 | consumed samples:     29394944 | elapsed time per iteration (ms): 37547.3 | learning rate: 1.001E-04 | global batch size:  1024 | lm loss: 1.863248E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28707/   51900 | consumed samples:     29395968 | elapsed time per iteration (ms): 37681.9 | learning rate: 1.001E-04 | global batch size:  1024 | lm loss: 1.846627E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28708/   51900 | consumed samples:     29396992 | elapsed time per iteration (ms): 37658.4 | learning rate: 1.001E-04 | global batch size:  1024 | lm loss: 1.832875E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28709/   51900 | consumed samples:     29398016 | elapsed time per iteration (ms): 37656.7 | learning rate: 1.001E-04 | global batch size:  1024 | lm loss: 1.840078E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28710/   51900 | consumed samples:     29399040 | elapsed time per iteration (ms): 37616.7 | learning rate: 1.000E-04 | global batch size:  1024 | lm loss: 1.854656E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28711/   51900 | consumed samples:     29400064 | elapsed time per iteration (ms): 37719.8 | learning rate: 1.000E-04 | global batch size:  1024 | lm loss: 1.852158E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28712/   51900 | consumed samples:     29401088 | elapsed time per iteration (ms): 37692.8 | learning rate: 1.000E-04 | global batch size:  1024 | lm loss: 1.830731E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28713/   51900 | consumed samples:     29402112 | elapsed time per iteration (ms): 37667.7 | learning rate: 1.000E-04 | global batch size:  1024 | lm loss: 1.837232E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28714/   51900 | consumed samples:     29403136 | elapsed time per iteration (ms): 37637.1 | learning rate: 1.000E-04 | global batch size:  1024 | lm loss: 1.845914E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28715/   51900 | consumed samples:     29404160 | elapsed time per iteration (ms): 37617.5 | learning rate: 1.000E-04 | global batch size:  1024 | lm loss: 1.842672E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28716/   51900 | consumed samples:     29405184 | elapsed time per iteration (ms): 37590.0 | learning rate: 1.000E-04 | global batch size:  1024 | lm loss: 1.841788E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28717/   51900 | consumed samples:     29406208 | elapsed time per iteration (ms): 37525.9 | learning rate: 1.000E-04 | global batch size:  1024 | lm loss: 1.849998E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28718/   51900 | consumed samples:     29407232 | elapsed time per iteration (ms): 37750.7 | learning rate: 1.000E-04 | global batch size:  1024 | lm loss: 1.822778E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28719/   51900 | consumed samples:     29408256 | elapsed time per iteration (ms): 37688.3 | learning rate: 1.000E-04 | global batch size:  1024 | lm loss: 1.841913E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28720/   51900 | consumed samples:     29409280 | elapsed time per iteration (ms): 37548.6 | learning rate: 9.999E-05 | global batch size:  1024 | lm loss: 1.846980E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28721/   51900 | consumed samples:     29410304 | elapsed time per iteration (ms): 37673.8 | learning rate: 9.999E-05 | global batch size:  1024 | lm loss: 1.838661E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28722/   51900 | consumed samples:     29411328 | elapsed time per iteration (ms): 37650.7 | learning rate: 9.998E-05 | global batch size:  1024 | lm loss: 1.865718E+00 | loss scale: 1.0 | grad norm: 0.088 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28723/   51900 | consumed samples:     29412352 | elapsed time per iteration (ms): 37663.7 | learning rate: 9.997E-05 | global batch size:  1024 | lm loss: 1.819118E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28724/   51900 | consumed samples:     29413376 | elapsed time per iteration (ms): 37622.9 | learning rate: 9.997E-05 | global batch size:  1024 | lm loss: 1.852779E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28725/   51900 | consumed samples:     29414400 | elapsed time per iteration (ms): 37600.5 | learning rate: 9.996E-05 | global batch size:  1024 | lm loss: 1.870526E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28726/   51900 | consumed samples:     29415424 | elapsed time per iteration (ms): 37755.5 | learning rate: 9.996E-05 | global batch size:  1024 | lm loss: 1.845638E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28727/   51900 | consumed samples:     29416448 | elapsed time per iteration (ms): 37628.7 | learning rate: 9.995E-05 | global batch size:  1024 | lm loss: 1.832366E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28728/   51900 | consumed samples:     29417472 | elapsed time per iteration (ms): 37599.6 | learning rate: 9.995E-05 | global batch size:  1024 | lm loss: 1.833752E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28729/   51900 | consumed samples:     29418496 | elapsed time per iteration (ms): 37656.3 | learning rate: 9.994E-05 | global batch size:  1024 | lm loss: 1.831835E+00 | loss scale: 1.0 | grad norm: 0.100 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28730/   51900 | consumed samples:     29419520 | elapsed time per iteration (ms): 37553.3 | learning rate: 9.994E-05 | global batch size:  1024 | lm loss: 1.851044E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28731/   51900 | consumed samples:     29420544 | elapsed time per iteration (ms): 37650.5 | learning rate: 9.993E-05 | global batch size:  1024 | lm loss: 1.827637E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28732/   51900 | consumed samples:     29421568 | elapsed time per iteration (ms): 37708.2 | learning rate: 9.992E-05 | global batch size:  1024 | lm loss: 1.834978E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28733/   51900 | consumed samples:     29422592 | elapsed time per iteration (ms): 37731.2 | learning rate: 9.992E-05 | global batch size:  1024 | lm loss: 1.846528E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28734/   51900 | consumed samples:     29423616 | elapsed time per iteration (ms): 37651.9 | learning rate: 9.991E-05 | global batch size:  1024 | lm loss: 1.803161E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28735/   51900 | consumed samples:     29424640 | elapsed time per iteration (ms): 37685.9 | learning rate: 9.991E-05 | global batch size:  1024 | lm loss: 1.835117E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28736/   51900 | consumed samples:     29425664 | elapsed time per iteration (ms): 37728.4 | learning rate: 9.990E-05 | global batch size:  1024 | lm loss: 1.836306E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28737/   51900 | consumed samples:     29426688 | elapsed time per iteration (ms): 37664.9 | learning rate: 9.990E-05 | global batch size:  1024 | lm loss: 1.831224E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28738/   51900 | consumed samples:     29427712 | elapsed time per iteration (ms): 37708.6 | learning rate: 9.989E-05 | global batch size:  1024 | lm loss: 1.830605E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28739/   51900 | consumed samples:     29428736 | elapsed time per iteration (ms): 37594.8 | learning rate: 9.988E-05 | global batch size:  1024 | lm loss: 1.846441E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28740/   51900 | consumed samples:     29429760 | elapsed time per iteration (ms): 37687.7 | learning rate: 9.988E-05 | global batch size:  1024 | lm loss: 1.849661E+00 | loss scale: 1.0 | grad norm: 0.119 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28741/   51900 | consumed samples:     29430784 | elapsed time per iteration (ms): 37529.6 | learning rate: 9.987E-05 | global batch size:  1024 | lm loss: 1.832882E+00 | loss scale: 1.0 | grad norm: 0.087 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28742/   51900 | consumed samples:     29431808 | elapsed time per iteration (ms): 37650.5 | learning rate: 9.987E-05 | global batch size:  1024 | lm loss: 1.839931E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28743/   51900 | consumed samples:     29432832 | elapsed time per iteration (ms): 37704.9 | learning rate: 9.986E-05 | global batch size:  1024 | lm loss: 1.873589E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28744/   51900 | consumed samples:     29433856 | elapsed time per iteration (ms): 37581.8 | learning rate: 9.986E-05 | global batch size:  1024 | lm loss: 1.828167E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28745/   51900 | consumed samples:     29434880 | elapsed time per iteration (ms): 37705.2 | learning rate: 9.985E-05 | global batch size:  1024 | lm loss: 1.850741E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28746/   51900 | consumed samples:     29435904 | elapsed time per iteration (ms): 37697.0 | learning rate: 9.985E-05 | global batch size:  1024 | lm loss: 1.841815E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28747/   51900 | consumed samples:     29436928 | elapsed time per iteration (ms): 37658.3 | learning rate: 9.984E-05 | global batch size:  1024 | lm loss: 1.859841E+00 | loss scale: 1.0 | grad norm: 0.089 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28748/   51900 | consumed samples:     29437952 | elapsed time per iteration (ms): 37649.0 | learning rate: 9.983E-05 | global batch size:  1024 | lm loss: 1.837736E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28749/   51900 | consumed samples:     29438976 | elapsed time per iteration (ms): 37733.9 | learning rate: 9.983E-05 | global batch size:  1024 | lm loss: 1.847695E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28750/   51900 | consumed samples:     29440000 | elapsed time per iteration (ms): 37819.0 | learning rate: 9.982E-05 | global batch size:  1024 | lm loss: 1.842212E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28751/   51900 | consumed samples:     29441024 | elapsed time per iteration (ms): 37583.5 | learning rate: 9.982E-05 | global batch size:  1024 | lm loss: 1.842758E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28752/   51900 | consumed samples:     29442048 | elapsed time per iteration (ms): 37720.4 | learning rate: 9.981E-05 | global batch size:  1024 | lm loss: 1.850053E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28753/   51900 | consumed samples:     29443072 | elapsed time per iteration (ms): 37626.7 | learning rate: 9.981E-05 | global batch size:  1024 | lm loss: 1.826789E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28754/   51900 | consumed samples:     29444096 | elapsed time per iteration (ms): 37688.9 | learning rate: 9.980E-05 | global batch size:  1024 | lm loss: 1.839683E+00 | loss scale: 1.0 | grad norm: 0.087 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28755/   51900 | consumed samples:     29445120 | elapsed time per iteration (ms): 37692.7 | learning rate: 9.979E-05 | global batch size:  1024 | lm loss: 1.832589E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28756/   51900 | consumed samples:     29446144 | elapsed time per iteration (ms): 37562.2 | learning rate: 9.979E-05 | global batch size:  1024 | lm loss: 1.833948E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28757/   51900 | consumed samples:     29447168 | elapsed time per iteration (ms): 37554.5 | learning rate: 9.978E-05 | global batch size:  1024 | lm loss: 1.827770E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28758/   51900 | consumed samples:     29448192 | elapsed time per iteration (ms): 37600.6 | learning rate: 9.978E-05 | global batch size:  1024 | lm loss: 1.852443E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28759/   51900 | consumed samples:     29449216 | elapsed time per iteration (ms): 37575.0 | learning rate: 9.977E-05 | global batch size:  1024 | lm loss: 1.828297E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28760/   51900 | consumed samples:     29450240 | elapsed time per iteration (ms): 37519.4 | learning rate: 9.977E-05 | global batch size:  1024 | lm loss: 1.828939E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28761/   51900 | consumed samples:     29451264 | elapsed time per iteration (ms): 37661.8 | learning rate: 9.976E-05 | global batch size:  1024 | lm loss: 1.825416E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28762/   51900 | consumed samples:     29452288 | elapsed time per iteration (ms): 37676.2 | learning rate: 9.976E-05 | global batch size:  1024 | lm loss: 1.848769E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28763/   51900 | consumed samples:     29453312 | elapsed time per iteration (ms): 37637.4 | learning rate: 9.975E-05 | global batch size:  1024 | lm loss: 1.844858E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28764/   51900 | consumed samples:     29454336 | elapsed time per iteration (ms): 37697.0 | learning rate: 9.974E-05 | global batch size:  1024 | lm loss: 1.855315E+00 | loss scale: 1.0 | grad norm: 0.088 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28765/   51900 | consumed samples:     29455360 | elapsed time per iteration (ms): 37686.5 | learning rate: 9.974E-05 | global batch size:  1024 | lm loss: 1.851677E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28766/   51900 | consumed samples:     29456384 | elapsed time per iteration (ms): 37627.4 | learning rate: 9.973E-05 | global batch size:  1024 | lm loss: 1.819071E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28767/   51900 | consumed samples:     29457408 | elapsed time per iteration (ms): 37539.6 | learning rate: 9.973E-05 | global batch size:  1024 | lm loss: 1.836757E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28768/   51900 | consumed samples:     29458432 | elapsed time per iteration (ms): 37548.5 | learning rate: 9.972E-05 | global batch size:  1024 | lm loss: 1.836516E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28769/   51900 | consumed samples:     29459456 | elapsed time per iteration (ms): 37655.3 | learning rate: 9.972E-05 | global batch size:  1024 | lm loss: 1.850219E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28770/   51900 | consumed samples:     29460480 | elapsed time per iteration (ms): 37687.7 | learning rate: 9.971E-05 | global batch size:  1024 | lm loss: 1.843700E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28771/   51900 | consumed samples:     29461504 | elapsed time per iteration (ms): 37603.0 | learning rate: 9.970E-05 | global batch size:  1024 | lm loss: 1.828989E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28772/   51900 | consumed samples:     29462528 | elapsed time per iteration (ms): 37661.7 | learning rate: 9.970E-05 | global batch size:  1024 | lm loss: 1.842251E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28773/   51900 | consumed samples:     29463552 | elapsed time per iteration (ms): 37678.5 | learning rate: 9.969E-05 | global batch size:  1024 | lm loss: 1.835641E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28774/   51900 | consumed samples:     29464576 | elapsed time per iteration (ms): 37691.3 | learning rate: 9.969E-05 | global batch size:  1024 | lm loss: 1.827778E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28775/   51900 | consumed samples:     29465600 | elapsed time per iteration (ms): 37612.8 | learning rate: 9.968E-05 | global batch size:  1024 | lm loss: 1.844890E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28776/   51900 | consumed samples:     29466624 | elapsed time per iteration (ms): 37751.3 | learning rate: 9.968E-05 | global batch size:  1024 | lm loss: 1.839090E+00 | loss scale: 1.0 | grad norm: 0.088 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28777/   51900 | consumed samples:     29467648 | elapsed time per iteration (ms): 37692.1 | learning rate: 9.967E-05 | global batch size:  1024 | lm loss: 1.840859E+00 | loss scale: 1.0 | grad norm: 0.109 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28778/   51900 | consumed samples:     29468672 | elapsed time per iteration (ms): 37632.0 | learning rate: 9.967E-05 | global batch size:  1024 | lm loss: 1.833225E+00 | loss scale: 1.0 | grad norm: 0.087 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28779/   51900 | consumed samples:     29469696 | elapsed time per iteration (ms): 37762.1 | learning rate: 9.966E-05 | global batch size:  1024 | lm loss: 1.848976E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28780/   51900 | consumed samples:     29470720 | elapsed time per iteration (ms): 37619.0 | learning rate: 9.965E-05 | global batch size:  1024 | lm loss: 1.858140E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28781/   51900 | consumed samples:     29471744 | elapsed time per iteration (ms): 37584.5 | learning rate: 9.965E-05 | global batch size:  1024 | lm loss: 1.824833E+00 | loss scale: 1.0 | grad norm: 0.177 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28782/   51900 | consumed samples:     29472768 | elapsed time per iteration (ms): 37613.7 | learning rate: 9.964E-05 | global batch size:  1024 | lm loss: 1.829955E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28783/   51900 | consumed samples:     29473792 | elapsed time per iteration (ms): 37705.0 | learning rate: 9.964E-05 | global batch size:  1024 | lm loss: 1.851969E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28784/   51900 | consumed samples:     29474816 | elapsed time per iteration (ms): 37666.6 | learning rate: 9.963E-05 | global batch size:  1024 | lm loss: 1.838274E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28785/   51900 | consumed samples:     29475840 | elapsed time per iteration (ms): 37622.7 | learning rate: 9.963E-05 | global batch size:  1024 | lm loss: 1.849216E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28786/   51900 | consumed samples:     29476864 | elapsed time per iteration (ms): 37662.6 | learning rate: 9.962E-05 | global batch size:  1024 | lm loss: 1.847776E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28787/   51900 | consumed samples:     29477888 | elapsed time per iteration (ms): 37606.3 | learning rate: 9.961E-05 | global batch size:  1024 | lm loss: 1.837884E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28788/   51900 | consumed samples:     29478912 | elapsed time per iteration (ms): 37611.7 | learning rate: 9.961E-05 | global batch size:  1024 | lm loss: 1.841408E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28789/   51900 | consumed samples:     29479936 | elapsed time per iteration (ms): 37678.4 | learning rate: 9.960E-05 | global batch size:  1024 | lm loss: 1.834148E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28790/   51900 | consumed samples:     29480960 | elapsed time per iteration (ms): 37689.8 | learning rate: 9.960E-05 | global batch size:  1024 | lm loss: 1.851124E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28791/   51900 | consumed samples:     29481984 | elapsed time per iteration (ms): 37611.5 | learning rate: 9.959E-05 | global batch size:  1024 | lm loss: 1.830963E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28792/   51900 | consumed samples:     29483008 | elapsed time per iteration (ms): 37639.2 | learning rate: 9.959E-05 | global batch size:  1024 | lm loss: 1.835164E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28793/   51900 | consumed samples:     29484032 | elapsed time per iteration (ms): 37624.5 | learning rate: 9.958E-05 | global batch size:  1024 | lm loss: 1.850356E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28794/   51900 | consumed samples:     29485056 | elapsed time per iteration (ms): 37602.8 | learning rate: 9.957E-05 | global batch size:  1024 | lm loss: 1.849133E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28795/   51900 | consumed samples:     29486080 | elapsed time per iteration (ms): 37642.8 | learning rate: 9.957E-05 | global batch size:  1024 | lm loss: 1.845232E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28796/   51900 | consumed samples:     29487104 | elapsed time per iteration (ms): 37656.2 | learning rate: 9.956E-05 | global batch size:  1024 | lm loss: 1.838593E+00 | loss scale: 1.0 | grad norm: 0.096 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28797/   51900 | consumed samples:     29488128 | elapsed time per iteration (ms): 37626.7 | learning rate: 9.956E-05 | global batch size:  1024 | lm loss: 1.837808E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28798/   51900 | consumed samples:     29489152 | elapsed time per iteration (ms): 37608.8 | learning rate: 9.955E-05 | global batch size:  1024 | lm loss: 1.839755E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28799/   51900 | consumed samples:     29490176 | elapsed time per iteration (ms): 37657.5 | learning rate: 9.955E-05 | global batch size:  1024 | lm loss: 1.850477E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28800/   51900 | consumed samples:     29491200 | elapsed time per iteration (ms): 37736.4 | learning rate: 9.954E-05 | global batch size:  1024 | lm loss: 1.866011E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28801/   51900 | consumed samples:     29492224 | elapsed time per iteration (ms): 37600.2 | learning rate: 9.954E-05 | global batch size:  1024 | lm loss: 1.839690E+00 | loss scale: 1.0 | grad norm: 0.090 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28802/   51900 | consumed samples:     29493248 | elapsed time per iteration (ms): 37627.3 | learning rate: 9.953E-05 | global batch size:  1024 | lm loss: 1.853968E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28803/   51900 | consumed samples:     29494272 | elapsed time per iteration (ms): 37695.0 | learning rate: 9.952E-05 | global batch size:  1024 | lm loss: 1.838461E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28804/   51900 | consumed samples:     29495296 | elapsed time per iteration (ms): 37628.7 | learning rate: 9.952E-05 | global batch size:  1024 | lm loss: 1.852667E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28805/   51900 | consumed samples:     29496320 | elapsed time per iteration (ms): 37683.5 | learning rate: 9.951E-05 | global batch size:  1024 | lm loss: 1.843271E+00 | loss scale: 1.0 | grad norm: 0.095 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28806/   51900 | consumed samples:     29497344 | elapsed time per iteration (ms): 37676.1 | learning rate: 9.951E-05 | global batch size:  1024 | lm loss: 1.839734E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28807/   51900 | consumed samples:     29498368 | elapsed time per iteration (ms): 37680.8 | learning rate: 9.950E-05 | global batch size:  1024 | lm loss: 1.857423E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28808/   51900 | consumed samples:     29499392 | elapsed time per iteration (ms): 37571.2 | learning rate: 9.950E-05 | global batch size:  1024 | lm loss: 1.838292E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28809/   51900 | consumed samples:     29500416 | elapsed time per iteration (ms): 37665.3 | learning rate: 9.949E-05 | global batch size:  1024 | lm loss: 1.822790E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28810/   51900 | consumed samples:     29501440 | elapsed time per iteration (ms): 37526.6 | learning rate: 9.948E-05 | global batch size:  1024 | lm loss: 1.821722E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28811/   51900 | consumed samples:     29502464 | elapsed time per iteration (ms): 37607.9 | learning rate: 9.948E-05 | global batch size:  1024 | lm loss: 1.850742E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28812/   51900 | consumed samples:     29503488 | elapsed time per iteration (ms): 37607.3 | learning rate: 9.947E-05 | global batch size:  1024 | lm loss: 1.836242E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28813/   51900 | consumed samples:     29504512 | elapsed time per iteration (ms): 37673.4 | learning rate: 9.947E-05 | global batch size:  1024 | lm loss: 1.845531E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28814/   51900 | consumed samples:     29505536 | elapsed time per iteration (ms): 37707.9 | learning rate: 9.946E-05 | global batch size:  1024 | lm loss: 1.853673E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28815/   51900 | consumed samples:     29506560 | elapsed time per iteration (ms): 37623.7 | learning rate: 9.946E-05 | global batch size:  1024 | lm loss: 1.845492E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28816/   51900 | consumed samples:     29507584 | elapsed time per iteration (ms): 37590.5 | learning rate: 9.945E-05 | global batch size:  1024 | lm loss: 1.849182E+00 | loss scale: 1.0 | grad norm: 0.094 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28817/   51900 | consumed samples:     29508608 | elapsed time per iteration (ms): 37688.7 | learning rate: 9.945E-05 | global batch size:  1024 | lm loss: 1.831410E+00 | loss scale: 1.0 | grad norm: 0.093 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28818/   51900 | consumed samples:     29509632 | elapsed time per iteration (ms): 37618.3 | learning rate: 9.944E-05 | global batch size:  1024 | lm loss: 1.852955E+00 | loss scale: 1.0 | grad norm: 0.092 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28819/   51900 | consumed samples:     29510656 | elapsed time per iteration (ms): 37714.0 | learning rate: 9.943E-05 | global batch size:  1024 | lm loss: 1.840062E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28820/   51900 | consumed samples:     29511680 | elapsed time per iteration (ms): 37615.6 | learning rate: 9.943E-05 | global batch size:  1024 | lm loss: 1.835795E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28821/   51900 | consumed samples:     29512704 | elapsed time per iteration (ms): 37670.4 | learning rate: 9.942E-05 | global batch size:  1024 | lm loss: 1.844163E+00 | loss scale: 1.0 | grad norm: 0.088 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28822/   51900 | consumed samples:     29513728 | elapsed time per iteration (ms): 37646.5 | learning rate: 9.942E-05 | global batch size:  1024 | lm loss: 1.846940E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28823/   51900 | consumed samples:     29514752 | elapsed time per iteration (ms): 37546.5 | learning rate: 9.941E-05 | global batch size:  1024 | lm loss: 1.838396E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28824/   51900 | consumed samples:     29515776 | elapsed time per iteration (ms): 37630.1 | learning rate: 9.941E-05 | global batch size:  1024 | lm loss: 1.857619E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28825/   51900 | consumed samples:     29516800 | elapsed time per iteration (ms): 37689.0 | learning rate: 9.940E-05 | global batch size:  1024 | lm loss: 1.843524E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28826/   51900 | consumed samples:     29517824 | elapsed time per iteration (ms): 37662.7 | learning rate: 9.939E-05 | global batch size:  1024 | lm loss: 1.858567E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28827/   51900 | consumed samples:     29518848 | elapsed time per iteration (ms): 37597.1 | learning rate: 9.939E-05 | global batch size:  1024 | lm loss: 1.847484E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28828/   51900 | consumed samples:     29519872 | elapsed time per iteration (ms): 37656.9 | learning rate: 9.938E-05 | global batch size:  1024 | lm loss: 1.831193E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28829/   51900 | consumed samples:     29520896 | elapsed time per iteration (ms): 37671.8 | learning rate: 9.938E-05 | global batch size:  1024 | lm loss: 1.847172E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28830/   51900 | consumed samples:     29521920 | elapsed time per iteration (ms): 37615.6 | learning rate: 9.937E-05 | global batch size:  1024 | lm loss: 1.857535E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28831/   51900 | consumed samples:     29522944 | elapsed time per iteration (ms): 37573.4 | learning rate: 9.937E-05 | global batch size:  1024 | lm loss: 1.853744E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28832/   51900 | consumed samples:     29523968 | elapsed time per iteration (ms): 37674.5 | learning rate: 9.936E-05 | global batch size:  1024 | lm loss: 1.831132E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28833/   51900 | consumed samples:     29524992 | elapsed time per iteration (ms): 37654.9 | learning rate: 9.936E-05 | global batch size:  1024 | lm loss: 1.833747E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28834/   51900 | consumed samples:     29526016 | elapsed time per iteration (ms): 37742.1 | learning rate: 9.935E-05 | global batch size:  1024 | lm loss: 1.830616E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28835/   51900 | consumed samples:     29527040 | elapsed time per iteration (ms): 37562.4 | learning rate: 9.934E-05 | global batch size:  1024 | lm loss: 1.861637E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28836/   51900 | consumed samples:     29528064 | elapsed time per iteration (ms): 37664.3 | learning rate: 9.934E-05 | global batch size:  1024 | lm loss: 1.832508E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28837/   51900 | consumed samples:     29529088 | elapsed time per iteration (ms): 37535.1 | learning rate: 9.933E-05 | global batch size:  1024 | lm loss: 1.838328E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28838/   51900 | consumed samples:     29530112 | elapsed time per iteration (ms): 37585.0 | learning rate: 9.933E-05 | global batch size:  1024 | lm loss: 1.839865E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28839/   51900 | consumed samples:     29531136 | elapsed time per iteration (ms): 37617.0 | learning rate: 9.932E-05 | global batch size:  1024 | lm loss: 1.849934E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28840/   51900 | consumed samples:     29532160 | elapsed time per iteration (ms): 37734.3 | learning rate: 9.932E-05 | global batch size:  1024 | lm loss: 1.855014E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28841/   51900 | consumed samples:     29533184 | elapsed time per iteration (ms): 37611.5 | learning rate: 9.931E-05 | global batch size:  1024 | lm loss: 1.849690E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28842/   51900 | consumed samples:     29534208 | elapsed time per iteration (ms): 37564.3 | learning rate: 9.930E-05 | global batch size:  1024 | lm loss: 1.839963E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28843/   51900 | consumed samples:     29535232 | elapsed time per iteration (ms): 37636.9 | learning rate: 9.930E-05 | global batch size:  1024 | lm loss: 1.849319E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28844/   51900 | consumed samples:     29536256 | elapsed time per iteration (ms): 37574.6 | learning rate: 9.929E-05 | global batch size:  1024 | lm loss: 1.829657E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28845/   51900 | consumed samples:     29537280 | elapsed time per iteration (ms): 37673.7 | learning rate: 9.929E-05 | global batch size:  1024 | lm loss: 1.845833E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28846/   51900 | consumed samples:     29538304 | elapsed time per iteration (ms): 37606.7 | learning rate: 9.928E-05 | global batch size:  1024 | lm loss: 1.834043E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28847/   51900 | consumed samples:     29539328 | elapsed time per iteration (ms): 37653.8 | learning rate: 9.928E-05 | global batch size:  1024 | lm loss: 1.842848E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28848/   51900 | consumed samples:     29540352 | elapsed time per iteration (ms): 37551.4 | learning rate: 9.927E-05 | global batch size:  1024 | lm loss: 1.834154E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28849/   51900 | consumed samples:     29541376 | elapsed time per iteration (ms): 37647.4 | learning rate: 9.927E-05 | global batch size:  1024 | lm loss: 1.829986E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28850/   51900 | consumed samples:     29542400 | elapsed time per iteration (ms): 37716.1 | learning rate: 9.926E-05 | global batch size:  1024 | lm loss: 1.845367E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28851/   51900 | consumed samples:     29543424 | elapsed time per iteration (ms): 37596.9 | learning rate: 9.925E-05 | global batch size:  1024 | lm loss: 1.836179E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28852/   51900 | consumed samples:     29544448 | elapsed time per iteration (ms): 37582.0 | learning rate: 9.925E-05 | global batch size:  1024 | lm loss: 1.842250E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28853/   51900 | consumed samples:     29545472 | elapsed time per iteration (ms): 37595.7 | learning rate: 9.924E-05 | global batch size:  1024 | lm loss: 1.835640E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28854/   51900 | consumed samples:     29546496 | elapsed time per iteration (ms): 37673.4 | learning rate: 9.924E-05 | global batch size:  1024 | lm loss: 1.843893E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28855/   51900 | consumed samples:     29547520 | elapsed time per iteration (ms): 37770.8 | learning rate: 9.923E-05 | global batch size:  1024 | lm loss: 1.859865E+00 | loss scale: 1.0 | grad norm: 0.087 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28856/   51900 | consumed samples:     29548544 | elapsed time per iteration (ms): 37554.0 | learning rate: 9.923E-05 | global batch size:  1024 | lm loss: 1.845110E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28857/   51900 | consumed samples:     29549568 | elapsed time per iteration (ms): 37605.9 | learning rate: 9.922E-05 | global batch size:  1024 | lm loss: 1.831597E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28858/   51900 | consumed samples:     29550592 | elapsed time per iteration (ms): 37700.9 | learning rate: 9.921E-05 | global batch size:  1024 | lm loss: 1.842685E+00 | loss scale: 1.0 | grad norm: 0.096 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28859/   51900 | consumed samples:     29551616 | elapsed time per iteration (ms): 37609.6 | learning rate: 9.921E-05 | global batch size:  1024 | lm loss: 1.846693E+00 | loss scale: 1.0 | grad norm: 0.095 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28860/   51900 | consumed samples:     29552640 | elapsed time per iteration (ms): 37628.8 | learning rate: 9.920E-05 | global batch size:  1024 | lm loss: 1.837100E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28861/   51900 | consumed samples:     29553664 | elapsed time per iteration (ms): 37656.4 | learning rate: 9.920E-05 | global batch size:  1024 | lm loss: 1.842286E+00 | loss scale: 1.0 | grad norm: 0.094 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28862/   51900 | consumed samples:     29554688 | elapsed time per iteration (ms): 37741.9 | learning rate: 9.919E-05 | global batch size:  1024 | lm loss: 1.810504E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28863/   51900 | consumed samples:     29555712 | elapsed time per iteration (ms): 37652.0 | learning rate: 9.919E-05 | global batch size:  1024 | lm loss: 1.843383E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28864/   51900 | consumed samples:     29556736 | elapsed time per iteration (ms): 37568.9 | learning rate: 9.918E-05 | global batch size:  1024 | lm loss: 1.845264E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28865/   51900 | consumed samples:     29557760 | elapsed time per iteration (ms): 37615.8 | learning rate: 9.918E-05 | global batch size:  1024 | lm loss: 1.828653E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28866/   51900 | consumed samples:     29558784 | elapsed time per iteration (ms): 37647.9 | learning rate: 9.917E-05 | global batch size:  1024 | lm loss: 1.853211E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28867/   51900 | consumed samples:     29559808 | elapsed time per iteration (ms): 37604.7 | learning rate: 9.916E-05 | global batch size:  1024 | lm loss: 1.834753E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28868/   51900 | consumed samples:     29560832 | elapsed time per iteration (ms): 37661.0 | learning rate: 9.916E-05 | global batch size:  1024 | lm loss: 1.860136E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28869/   51900 | consumed samples:     29561856 | elapsed time per iteration (ms): 37689.8 | learning rate: 9.915E-05 | global batch size:  1024 | lm loss: 1.836704E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28870/   51900 | consumed samples:     29562880 | elapsed time per iteration (ms): 37555.3 | learning rate: 9.915E-05 | global batch size:  1024 | lm loss: 1.829227E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28871/   51900 | consumed samples:     29563904 | elapsed time per iteration (ms): 37710.9 | learning rate: 9.914E-05 | global batch size:  1024 | lm loss: 1.845206E+00 | loss scale: 1.0 | grad norm: 0.088 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28872/   51900 | consumed samples:     29564928 | elapsed time per iteration (ms): 37678.4 | learning rate: 9.914E-05 | global batch size:  1024 | lm loss: 1.844658E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28873/   51900 | consumed samples:     29565952 | elapsed time per iteration (ms): 37613.4 | learning rate: 9.913E-05 | global batch size:  1024 | lm loss: 1.825560E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28874/   51900 | consumed samples:     29566976 | elapsed time per iteration (ms): 37590.2 | learning rate: 9.912E-05 | global batch size:  1024 | lm loss: 1.845377E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28875/   51900 | consumed samples:     29568000 | elapsed time per iteration (ms): 37640.8 | learning rate: 9.912E-05 | global batch size:  1024 | lm loss: 1.840429E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28876/   51900 | consumed samples:     29569024 | elapsed time per iteration (ms): 37564.8 | learning rate: 9.911E-05 | global batch size:  1024 | lm loss: 1.827721E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28877/   51900 | consumed samples:     29570048 | elapsed time per iteration (ms): 37671.1 | learning rate: 9.911E-05 | global batch size:  1024 | lm loss: 1.829753E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28878/   51900 | consumed samples:     29571072 | elapsed time per iteration (ms): 37703.8 | learning rate: 9.910E-05 | global batch size:  1024 | lm loss: 1.823728E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28879/   51900 | consumed samples:     29572096 | elapsed time per iteration (ms): 37631.6 | learning rate: 9.910E-05 | global batch size:  1024 | lm loss: 1.841233E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28880/   51900 | consumed samples:     29573120 | elapsed time per iteration (ms): 37701.3 | learning rate: 9.909E-05 | global batch size:  1024 | lm loss: 1.858765E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28881/   51900 | consumed samples:     29574144 | elapsed time per iteration (ms): 37595.9 | learning rate: 9.909E-05 | global batch size:  1024 | lm loss: 1.824839E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28882/   51900 | consumed samples:     29575168 | elapsed time per iteration (ms): 37611.7 | learning rate: 9.908E-05 | global batch size:  1024 | lm loss: 1.838570E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28883/   51900 | consumed samples:     29576192 | elapsed time per iteration (ms): 37639.8 | learning rate: 9.907E-05 | global batch size:  1024 | lm loss: 1.853444E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28884/   51900 | consumed samples:     29577216 | elapsed time per iteration (ms): 37596.5 | learning rate: 9.907E-05 | global batch size:  1024 | lm loss: 1.843004E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28885/   51900 | consumed samples:     29578240 | elapsed time per iteration (ms): 37611.8 | learning rate: 9.906E-05 | global batch size:  1024 | lm loss: 1.834032E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28886/   51900 | consumed samples:     29579264 | elapsed time per iteration (ms): 37644.0 | learning rate: 9.906E-05 | global batch size:  1024 | lm loss: 1.817482E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28887/   51900 | consumed samples:     29580288 | elapsed time per iteration (ms): 37605.5 | learning rate: 9.905E-05 | global batch size:  1024 | lm loss: 1.839049E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28888/   51900 | consumed samples:     29581312 | elapsed time per iteration (ms): 37600.5 | learning rate: 9.905E-05 | global batch size:  1024 | lm loss: 1.821868E+00 | loss scale: 1.0 | grad norm: 0.095 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28889/   51900 | consumed samples:     29582336 | elapsed time per iteration (ms): 37600.4 | learning rate: 9.904E-05 | global batch size:  1024 | lm loss: 1.832203E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28890/   51900 | consumed samples:     29583360 | elapsed time per iteration (ms): 37652.7 | learning rate: 9.903E-05 | global batch size:  1024 | lm loss: 1.845785E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28891/   51900 | consumed samples:     29584384 | elapsed time per iteration (ms): 37690.4 | learning rate: 9.903E-05 | global batch size:  1024 | lm loss: 1.832412E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28892/   51900 | consumed samples:     29585408 | elapsed time per iteration (ms): 37590.6 | learning rate: 9.902E-05 | global batch size:  1024 | lm loss: 1.822537E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28893/   51900 | consumed samples:     29586432 | elapsed time per iteration (ms): 37822.7 | learning rate: 9.902E-05 | global batch size:  1024 | lm loss: 1.837125E+00 | loss scale: 1.0 | grad norm: 0.090 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28894/   51900 | consumed samples:     29587456 | elapsed time per iteration (ms): 37735.2 | learning rate: 9.901E-05 | global batch size:  1024 | lm loss: 1.845644E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28895/   51900 | consumed samples:     29588480 | elapsed time per iteration (ms): 37632.5 | learning rate: 9.901E-05 | global batch size:  1024 | lm loss: 1.835022E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28896/   51900 | consumed samples:     29589504 | elapsed time per iteration (ms): 37673.2 | learning rate: 9.900E-05 | global batch size:  1024 | lm loss: 1.845961E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28897/   51900 | consumed samples:     29590528 | elapsed time per iteration (ms): 37695.8 | learning rate: 9.900E-05 | global batch size:  1024 | lm loss: 1.834975E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28898/   51900 | consumed samples:     29591552 | elapsed time per iteration (ms): 37680.0 | learning rate: 9.899E-05 | global batch size:  1024 | lm loss: 1.824009E+00 | loss scale: 1.0 | grad norm: 0.140 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28899/   51900 | consumed samples:     29592576 | elapsed time per iteration (ms): 37599.7 | learning rate: 9.898E-05 | global batch size:  1024 | lm loss: 1.855431E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28900/   51900 | consumed samples:     29593600 | elapsed time per iteration (ms): 37500.9 | learning rate: 9.898E-05 | global batch size:  1024 | lm loss: 1.839739E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28901/   51900 | consumed samples:     29594624 | elapsed time per iteration (ms): 37533.5 | learning rate: 9.897E-05 | global batch size:  1024 | lm loss: 1.848211E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28902/   51900 | consumed samples:     29595648 | elapsed time per iteration (ms): 37552.0 | learning rate: 9.897E-05 | global batch size:  1024 | lm loss: 1.839722E+00 | loss scale: 1.0 | grad norm: 0.089 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28903/   51900 | consumed samples:     29596672 | elapsed time per iteration (ms): 37622.8 | learning rate: 9.896E-05 | global batch size:  1024 | lm loss: 1.827770E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28904/   51900 | consumed samples:     29597696 | elapsed time per iteration (ms): 37564.5 | learning rate: 9.896E-05 | global batch size:  1024 | lm loss: 1.839477E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28905/   51900 | consumed samples:     29598720 | elapsed time per iteration (ms): 37673.0 | learning rate: 9.895E-05 | global batch size:  1024 | lm loss: 1.849133E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28906/   51900 | consumed samples:     29599744 | elapsed time per iteration (ms): 37540.8 | learning rate: 9.894E-05 | global batch size:  1024 | lm loss: 1.840591E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28907/   51900 | consumed samples:     29600768 | elapsed time per iteration (ms): 37625.0 | learning rate: 9.894E-05 | global batch size:  1024 | lm loss: 1.835903E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28908/   51900 | consumed samples:     29601792 | elapsed time per iteration (ms): 37555.1 | learning rate: 9.893E-05 | global batch size:  1024 | lm loss: 1.829679E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28909/   51900 | consumed samples:     29602816 | elapsed time per iteration (ms): 37658.5 | learning rate: 9.893E-05 | global batch size:  1024 | lm loss: 1.848794E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28910/   51900 | consumed samples:     29603840 | elapsed time per iteration (ms): 37663.8 | learning rate: 9.892E-05 | global batch size:  1024 | lm loss: 1.819155E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28911/   51900 | consumed samples:     29604864 | elapsed time per iteration (ms): 37636.5 | learning rate: 9.892E-05 | global batch size:  1024 | lm loss: 1.845354E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28912/   51900 | consumed samples:     29605888 | elapsed time per iteration (ms): 37642.3 | learning rate: 9.891E-05 | global batch size:  1024 | lm loss: 1.838263E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28913/   51900 | consumed samples:     29606912 | elapsed time per iteration (ms): 37705.0 | learning rate: 9.891E-05 | global batch size:  1024 | lm loss: 1.848049E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28914/   51900 | consumed samples:     29607936 | elapsed time per iteration (ms): 37606.9 | learning rate: 9.890E-05 | global batch size:  1024 | lm loss: 1.848031E+00 | loss scale: 1.0 | grad norm: 0.089 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28915/   51900 | consumed samples:     29608960 | elapsed time per iteration (ms): 37506.6 | learning rate: 9.889E-05 | global batch size:  1024 | lm loss: 1.831266E+00 | loss scale: 1.0 | grad norm: 0.095 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28916/   51900 | consumed samples:     29609984 | elapsed time per iteration (ms): 37576.4 | learning rate: 9.889E-05 | global batch size:  1024 | lm loss: 1.857557E+00 | loss scale: 1.0 | grad norm: 0.090 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28917/   51900 | consumed samples:     29611008 | elapsed time per iteration (ms): 37501.6 | learning rate: 9.888E-05 | global batch size:  1024 | lm loss: 1.832622E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28918/   51900 | consumed samples:     29612032 | elapsed time per iteration (ms): 37573.4 | learning rate: 9.888E-05 | global batch size:  1024 | lm loss: 1.841842E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28919/   51900 | consumed samples:     29613056 | elapsed time per iteration (ms): 37644.6 | learning rate: 9.887E-05 | global batch size:  1024 | lm loss: 1.835165E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28920/   51900 | consumed samples:     29614080 | elapsed time per iteration (ms): 37570.5 | learning rate: 9.887E-05 | global batch size:  1024 | lm loss: 1.817998E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28921/   51900 | consumed samples:     29615104 | elapsed time per iteration (ms): 37620.1 | learning rate: 9.886E-05 | global batch size:  1024 | lm loss: 1.842319E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28922/   51900 | consumed samples:     29616128 | elapsed time per iteration (ms): 37710.4 | learning rate: 9.885E-05 | global batch size:  1024 | lm loss: 1.842021E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28923/   51900 | consumed samples:     29617152 | elapsed time per iteration (ms): 37769.0 | learning rate: 9.885E-05 | global batch size:  1024 | lm loss: 1.826512E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28924/   51900 | consumed samples:     29618176 | elapsed time per iteration (ms): 37521.6 | learning rate: 9.884E-05 | global batch size:  1024 | lm loss: 1.837365E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28925/   51900 | consumed samples:     29619200 | elapsed time per iteration (ms): 37580.6 | learning rate: 9.884E-05 | global batch size:  1024 | lm loss: 1.847197E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28926/   51900 | consumed samples:     29620224 | elapsed time per iteration (ms): 37614.2 | learning rate: 9.883E-05 | global batch size:  1024 | lm loss: 1.832742E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28927/   51900 | consumed samples:     29621248 | elapsed time per iteration (ms): 37558.2 | learning rate: 9.883E-05 | global batch size:  1024 | lm loss: 1.834540E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28928/   51900 | consumed samples:     29622272 | elapsed time per iteration (ms): 37681.1 | learning rate: 9.882E-05 | global batch size:  1024 | lm loss: 1.830957E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28929/   51900 | consumed samples:     29623296 | elapsed time per iteration (ms): 37574.1 | learning rate: 9.882E-05 | global batch size:  1024 | lm loss: 1.841728E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28930/   51900 | consumed samples:     29624320 | elapsed time per iteration (ms): 37567.6 | learning rate: 9.881E-05 | global batch size:  1024 | lm loss: 1.841657E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28931/   51900 | consumed samples:     29625344 | elapsed time per iteration (ms): 37715.1 | learning rate: 9.880E-05 | global batch size:  1024 | lm loss: 1.847456E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28932/   51900 | consumed samples:     29626368 | elapsed time per iteration (ms): 37629.7 | learning rate: 9.880E-05 | global batch size:  1024 | lm loss: 1.843383E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28933/   51900 | consumed samples:     29627392 | elapsed time per iteration (ms): 37658.0 | learning rate: 9.879E-05 | global batch size:  1024 | lm loss: 1.823871E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28934/   51900 | consumed samples:     29628416 | elapsed time per iteration (ms): 37590.4 | learning rate: 9.879E-05 | global batch size:  1024 | lm loss: 1.837745E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28935/   51900 | consumed samples:     29629440 | elapsed time per iteration (ms): 37665.2 | learning rate: 9.878E-05 | global batch size:  1024 | lm loss: 1.855414E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28936/   51900 | consumed samples:     29630464 | elapsed time per iteration (ms): 37576.3 | learning rate: 9.878E-05 | global batch size:  1024 | lm loss: 1.848831E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28937/   51900 | consumed samples:     29631488 | elapsed time per iteration (ms): 37628.5 | learning rate: 9.877E-05 | global batch size:  1024 | lm loss: 1.838000E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28938/   51900 | consumed samples:     29632512 | elapsed time per iteration (ms): 37633.2 | learning rate: 9.876E-05 | global batch size:  1024 | lm loss: 1.829820E+00 | loss scale: 1.0 | grad norm: 0.090 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28939/   51900 | consumed samples:     29633536 | elapsed time per iteration (ms): 37714.9 | learning rate: 9.876E-05 | global batch size:  1024 | lm loss: 1.834837E+00 | loss scale: 1.0 | grad norm: 0.095 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28940/   51900 | consumed samples:     29634560 | elapsed time per iteration (ms): 37735.9 | learning rate: 9.875E-05 | global batch size:  1024 | lm loss: 1.839894E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28941/   51900 | consumed samples:     29635584 | elapsed time per iteration (ms): 37558.4 | learning rate: 9.875E-05 | global batch size:  1024 | lm loss: 1.836050E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28942/   51900 | consumed samples:     29636608 | elapsed time per iteration (ms): 37649.9 | learning rate: 9.874E-05 | global batch size:  1024 | lm loss: 1.842370E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28943/   51900 | consumed samples:     29637632 | elapsed time per iteration (ms): 37771.9 | learning rate: 9.874E-05 | global batch size:  1024 | lm loss: 1.823409E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28944/   51900 | consumed samples:     29638656 | elapsed time per iteration (ms): 37572.3 | learning rate: 9.873E-05 | global batch size:  1024 | lm loss: 1.838970E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28945/   51900 | consumed samples:     29639680 | elapsed time per iteration (ms): 37656.4 | learning rate: 9.873E-05 | global batch size:  1024 | lm loss: 1.830386E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28946/   51900 | consumed samples:     29640704 | elapsed time per iteration (ms): 37663.7 | learning rate: 9.872E-05 | global batch size:  1024 | lm loss: 1.857162E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28947/   51900 | consumed samples:     29641728 | elapsed time per iteration (ms): 37595.2 | learning rate: 9.871E-05 | global batch size:  1024 | lm loss: 1.836535E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28948/   51900 | consumed samples:     29642752 | elapsed time per iteration (ms): 37588.4 | learning rate: 9.871E-05 | global batch size:  1024 | lm loss: 1.832771E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28949/   51900 | consumed samples:     29643776 | elapsed time per iteration (ms): 37692.3 | learning rate: 9.870E-05 | global batch size:  1024 | lm loss: 1.833556E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28950/   51900 | consumed samples:     29644800 | elapsed time per iteration (ms): 37704.1 | learning rate: 9.870E-05 | global batch size:  1024 | lm loss: 1.850507E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28951/   51900 | consumed samples:     29645824 | elapsed time per iteration (ms): 37603.4 | learning rate: 9.869E-05 | global batch size:  1024 | lm loss: 1.840099E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28952/   51900 | consumed samples:     29646848 | elapsed time per iteration (ms): 37620.7 | learning rate: 9.869E-05 | global batch size:  1024 | lm loss: 1.838880E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28953/   51900 | consumed samples:     29647872 | elapsed time per iteration (ms): 37521.1 | learning rate: 9.868E-05 | global batch size:  1024 | lm loss: 1.851950E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28954/   51900 | consumed samples:     29648896 | elapsed time per iteration (ms): 37600.4 | learning rate: 9.868E-05 | global batch size:  1024 | lm loss: 1.836515E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28955/   51900 | consumed samples:     29649920 | elapsed time per iteration (ms): 37618.6 | learning rate: 9.867E-05 | global batch size:  1024 | lm loss: 1.856846E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28956/   51900 | consumed samples:     29650944 | elapsed time per iteration (ms): 37536.6 | learning rate: 9.866E-05 | global batch size:  1024 | lm loss: 1.850994E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28957/   51900 | consumed samples:     29651968 | elapsed time per iteration (ms): 37611.9 | learning rate: 9.866E-05 | global batch size:  1024 | lm loss: 1.858135E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28958/   51900 | consumed samples:     29652992 | elapsed time per iteration (ms): 37628.5 | learning rate: 9.865E-05 | global batch size:  1024 | lm loss: 1.859539E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28959/   51900 | consumed samples:     29654016 | elapsed time per iteration (ms): 37699.4 | learning rate: 9.865E-05 | global batch size:  1024 | lm loss: 1.838042E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28960/   51900 | consumed samples:     29655040 | elapsed time per iteration (ms): 37627.0 | learning rate: 9.864E-05 | global batch size:  1024 | lm loss: 1.848341E+00 | loss scale: 1.0 | grad norm: 0.088 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28961/   51900 | consumed samples:     29656064 | elapsed time per iteration (ms): 37618.3 | learning rate: 9.864E-05 | global batch size:  1024 | lm loss: 1.840401E+00 | loss scale: 1.0 | grad norm: 0.094 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28962/   51900 | consumed samples:     29657088 | elapsed time per iteration (ms): 37653.3 | learning rate: 9.863E-05 | global batch size:  1024 | lm loss: 1.828443E+00 | loss scale: 1.0 | grad norm: 0.089 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28963/   51900 | consumed samples:     29658112 | elapsed time per iteration (ms): 37721.5 | learning rate: 9.862E-05 | global batch size:  1024 | lm loss: 1.839704E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28964/   51900 | consumed samples:     29659136 | elapsed time per iteration (ms): 37636.7 | learning rate: 9.862E-05 | global batch size:  1024 | lm loss: 1.835159E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28965/   51900 | consumed samples:     29660160 | elapsed time per iteration (ms): 37560.7 | learning rate: 9.861E-05 | global batch size:  1024 | lm loss: 1.855664E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28966/   51900 | consumed samples:     29661184 | elapsed time per iteration (ms): 37534.5 | learning rate: 9.861E-05 | global batch size:  1024 | lm loss: 1.834633E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28967/   51900 | consumed samples:     29662208 | elapsed time per iteration (ms): 37518.1 | learning rate: 9.860E-05 | global batch size:  1024 | lm loss: 1.839889E+00 | loss scale: 1.0 | grad norm: 0.088 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28968/   51900 | consumed samples:     29663232 | elapsed time per iteration (ms): 37644.0 | learning rate: 9.860E-05 | global batch size:  1024 | lm loss: 1.844675E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28969/   51900 | consumed samples:     29664256 | elapsed time per iteration (ms): 37580.0 | learning rate: 9.859E-05 | global batch size:  1024 | lm loss: 1.839755E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28970/   51900 | consumed samples:     29665280 | elapsed time per iteration (ms): 37693.3 | learning rate: 9.859E-05 | global batch size:  1024 | lm loss: 1.827153E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28971/   51900 | consumed samples:     29666304 | elapsed time per iteration (ms): 37588.9 | learning rate: 9.858E-05 | global batch size:  1024 | lm loss: 1.843875E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28972/   51900 | consumed samples:     29667328 | elapsed time per iteration (ms): 37667.5 | learning rate: 9.857E-05 | global batch size:  1024 | lm loss: 1.837068E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28973/   51900 | consumed samples:     29668352 | elapsed time per iteration (ms): 37616.6 | learning rate: 9.857E-05 | global batch size:  1024 | lm loss: 1.872981E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28974/   51900 | consumed samples:     29669376 | elapsed time per iteration (ms): 37644.5 | learning rate: 9.856E-05 | global batch size:  1024 | lm loss: 1.851501E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28975/   51900 | consumed samples:     29670400 | elapsed time per iteration (ms): 37687.5 | learning rate: 9.856E-05 | global batch size:  1024 | lm loss: 1.847306E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28976/   51900 | consumed samples:     29671424 | elapsed time per iteration (ms): 37581.3 | learning rate: 9.855E-05 | global batch size:  1024 | lm loss: 1.817208E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28977/   51900 | consumed samples:     29672448 | elapsed time per iteration (ms): 37688.0 | learning rate: 9.855E-05 | global batch size:  1024 | lm loss: 1.826803E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28978/   51900 | consumed samples:     29673472 | elapsed time per iteration (ms): 37639.5 | learning rate: 9.854E-05 | global batch size:  1024 | lm loss: 1.843301E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28979/   51900 | consumed samples:     29674496 | elapsed time per iteration (ms): 37667.3 | learning rate: 9.853E-05 | global batch size:  1024 | lm loss: 1.836221E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28980/   51900 | consumed samples:     29675520 | elapsed time per iteration (ms): 37556.4 | learning rate: 9.853E-05 | global batch size:  1024 | lm loss: 1.836364E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28981/   51900 | consumed samples:     29676544 | elapsed time per iteration (ms): 37541.1 | learning rate: 9.852E-05 | global batch size:  1024 | lm loss: 1.822052E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28982/   51900 | consumed samples:     29677568 | elapsed time per iteration (ms): 37611.0 | learning rate: 9.852E-05 | global batch size:  1024 | lm loss: 1.833891E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28983/   51900 | consumed samples:     29678592 | elapsed time per iteration (ms): 37606.5 | learning rate: 9.851E-05 | global batch size:  1024 | lm loss: 1.849927E+00 | loss scale: 1.0 | grad norm: 0.089 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28984/   51900 | consumed samples:     29679616 | elapsed time per iteration (ms): 37612.6 | learning rate: 9.851E-05 | global batch size:  1024 | lm loss: 1.823259E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28985/   51900 | consumed samples:     29680640 | elapsed time per iteration (ms): 37591.0 | learning rate: 9.850E-05 | global batch size:  1024 | lm loss: 1.845600E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28986/   51900 | consumed samples:     29681664 | elapsed time per iteration (ms): 37674.5 | learning rate: 9.850E-05 | global batch size:  1024 | lm loss: 1.822690E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28987/   51900 | consumed samples:     29682688 | elapsed time per iteration (ms): 37613.0 | learning rate: 9.849E-05 | global batch size:  1024 | lm loss: 1.831105E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28988/   51900 | consumed samples:     29683712 | elapsed time per iteration (ms): 37653.1 | learning rate: 9.848E-05 | global batch size:  1024 | lm loss: 1.853637E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28989/   51900 | consumed samples:     29684736 | elapsed time per iteration (ms): 37612.0 | learning rate: 9.848E-05 | global batch size:  1024 | lm loss: 1.853732E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28990/   51900 | consumed samples:     29685760 | elapsed time per iteration (ms): 37679.4 | learning rate: 9.847E-05 | global batch size:  1024 | lm loss: 1.847046E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28991/   51900 | consumed samples:     29686784 | elapsed time per iteration (ms): 37651.1 | learning rate: 9.847E-05 | global batch size:  1024 | lm loss: 1.845931E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28992/   51900 | consumed samples:     29687808 | elapsed time per iteration (ms): 37645.6 | learning rate: 9.846E-05 | global batch size:  1024 | lm loss: 1.844201E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28993/   51900 | consumed samples:     29688832 | elapsed time per iteration (ms): 37639.1 | learning rate: 9.846E-05 | global batch size:  1024 | lm loss: 1.839035E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28994/   51900 | consumed samples:     29689856 | elapsed time per iteration (ms): 37572.9 | learning rate: 9.845E-05 | global batch size:  1024 | lm loss: 1.838021E+00 | loss scale: 1.0 | grad norm: 0.090 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28995/   51900 | consumed samples:     29690880 | elapsed time per iteration (ms): 37643.8 | learning rate: 9.844E-05 | global batch size:  1024 | lm loss: 1.834044E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28996/   51900 | consumed samples:     29691904 | elapsed time per iteration (ms): 37573.8 | learning rate: 9.844E-05 | global batch size:  1024 | lm loss: 1.850610E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28997/   51900 | consumed samples:     29692928 | elapsed time per iteration (ms): 37678.2 | learning rate: 9.843E-05 | global batch size:  1024 | lm loss: 1.821112E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28998/   51900 | consumed samples:     29693952 | elapsed time per iteration (ms): 37586.8 | learning rate: 9.843E-05 | global batch size:  1024 | lm loss: 1.854097E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    28999/   51900 | consumed samples:     29694976 | elapsed time per iteration (ms): 37615.2 | learning rate: 9.842E-05 | global batch size:  1024 | lm loss: 1.838520E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29000/   51900 | consumed samples:     29696000 | elapsed time per iteration (ms): 37757.5 | learning rate: 9.842E-05 | global batch size:  1024 | lm loss: 1.825626E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    save-checkpoint ................................: (146294.89, 146294.95)
 iteration    29001/   51900 | consumed samples:     29697024 | elapsed time per iteration (ms): 37234.0 | learning rate: 9.841E-05 | global batch size:  1024 | lm loss: 1.853438E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29002/   51900 | consumed samples:     29698048 | elapsed time per iteration (ms): 37703.8 | learning rate: 9.841E-05 | global batch size:  1024 | lm loss: 1.843202E+00 | loss scale: 1.0 | grad norm: 0.088 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29003/   51900 | consumed samples:     29699072 | elapsed time per iteration (ms): 37611.4 | learning rate: 9.840E-05 | global batch size:  1024 | lm loss: 1.845090E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29004/   51900 | consumed samples:     29700096 | elapsed time per iteration (ms): 37616.2 | learning rate: 9.839E-05 | global batch size:  1024 | lm loss: 1.843161E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29005/   51900 | consumed samples:     29701120 | elapsed time per iteration (ms): 37625.5 | learning rate: 9.839E-05 | global batch size:  1024 | lm loss: 1.857304E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29006/   51900 | consumed samples:     29702144 | elapsed time per iteration (ms): 37617.1 | learning rate: 9.838E-05 | global batch size:  1024 | lm loss: 1.834028E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29007/   51900 | consumed samples:     29703168 | elapsed time per iteration (ms): 37687.2 | learning rate: 9.838E-05 | global batch size:  1024 | lm loss: 1.816933E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29008/   51900 | consumed samples:     29704192 | elapsed time per iteration (ms): 37568.4 | learning rate: 9.837E-05 | global batch size:  1024 | lm loss: 1.851960E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29009/   51900 | consumed samples:     29705216 | elapsed time per iteration (ms): 37543.2 | learning rate: 9.837E-05 | global batch size:  1024 | lm loss: 1.820112E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29010/   51900 | consumed samples:     29706240 | elapsed time per iteration (ms): 37621.0 | learning rate: 9.836E-05 | global batch size:  1024 | lm loss: 1.852991E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29011/   51900 | consumed samples:     29707264 | elapsed time per iteration (ms): 37597.8 | learning rate: 9.835E-05 | global batch size:  1024 | lm loss: 1.822395E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29012/   51900 | consumed samples:     29708288 | elapsed time per iteration (ms): 37633.5 | learning rate: 9.835E-05 | global batch size:  1024 | lm loss: 1.851065E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29013/   51900 | consumed samples:     29709312 | elapsed time per iteration (ms): 37592.8 | learning rate: 9.834E-05 | global batch size:  1024 | lm loss: 1.845073E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29014/   51900 | consumed samples:     29710336 | elapsed time per iteration (ms): 37741.2 | learning rate: 9.834E-05 | global batch size:  1024 | lm loss: 1.829554E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29015/   51900 | consumed samples:     29711360 | elapsed time per iteration (ms): 37651.5 | learning rate: 9.833E-05 | global batch size:  1024 | lm loss: 1.837550E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29016/   51900 | consumed samples:     29712384 | elapsed time per iteration (ms): 37617.4 | learning rate: 9.833E-05 | global batch size:  1024 | lm loss: 1.831285E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29017/   51900 | consumed samples:     29713408 | elapsed time per iteration (ms): 37688.2 | learning rate: 9.832E-05 | global batch size:  1024 | lm loss: 1.840919E+00 | loss scale: 1.0 | grad norm: 0.090 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29018/   51900 | consumed samples:     29714432 | elapsed time per iteration (ms): 37519.8 | learning rate: 9.832E-05 | global batch size:  1024 | lm loss: 1.847504E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29019/   51900 | consumed samples:     29715456 | elapsed time per iteration (ms): 37641.3 | learning rate: 9.831E-05 | global batch size:  1024 | lm loss: 1.831774E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29020/   51900 | consumed samples:     29716480 | elapsed time per iteration (ms): 37666.7 | learning rate: 9.830E-05 | global batch size:  1024 | lm loss: 1.829449E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29021/   51900 | consumed samples:     29717504 | elapsed time per iteration (ms): 37692.2 | learning rate: 9.830E-05 | global batch size:  1024 | lm loss: 1.834334E+00 | loss scale: 1.0 | grad norm: 0.087 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29022/   51900 | consumed samples:     29718528 | elapsed time per iteration (ms): 37654.8 | learning rate: 9.829E-05 | global batch size:  1024 | lm loss: 1.842210E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29023/   51900 | consumed samples:     29719552 | elapsed time per iteration (ms): 37592.5 | learning rate: 9.829E-05 | global batch size:  1024 | lm loss: 1.813637E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29024/   51900 | consumed samples:     29720576 | elapsed time per iteration (ms): 37635.8 | learning rate: 9.828E-05 | global batch size:  1024 | lm loss: 1.845573E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29025/   51900 | consumed samples:     29721600 | elapsed time per iteration (ms): 37572.2 | learning rate: 9.828E-05 | global batch size:  1024 | lm loss: 1.858946E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29026/   51900 | consumed samples:     29722624 | elapsed time per iteration (ms): 37671.2 | learning rate: 9.827E-05 | global batch size:  1024 | lm loss: 1.823448E+00 | loss scale: 1.0 | grad norm: 0.089 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29027/   51900 | consumed samples:     29723648 | elapsed time per iteration (ms): 37583.7 | learning rate: 9.826E-05 | global batch size:  1024 | lm loss: 1.828664E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29028/   51900 | consumed samples:     29724672 | elapsed time per iteration (ms): 37630.4 | learning rate: 9.826E-05 | global batch size:  1024 | lm loss: 1.828377E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29029/   51900 | consumed samples:     29725696 | elapsed time per iteration (ms): 37530.4 | learning rate: 9.825E-05 | global batch size:  1024 | lm loss: 1.841860E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29030/   51900 | consumed samples:     29726720 | elapsed time per iteration (ms): 37670.6 | learning rate: 9.825E-05 | global batch size:  1024 | lm loss: 1.822932E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29031/   51900 | consumed samples:     29727744 | elapsed time per iteration (ms): 37558.6 | learning rate: 9.824E-05 | global batch size:  1024 | lm loss: 1.838960E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29032/   51900 | consumed samples:     29728768 | elapsed time per iteration (ms): 37561.5 | learning rate: 9.824E-05 | global batch size:  1024 | lm loss: 1.823951E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29033/   51900 | consumed samples:     29729792 | elapsed time per iteration (ms): 37540.3 | learning rate: 9.823E-05 | global batch size:  1024 | lm loss: 1.831774E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29034/   51900 | consumed samples:     29730816 | elapsed time per iteration (ms): 37625.6 | learning rate: 9.823E-05 | global batch size:  1024 | lm loss: 1.828123E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29035/   51900 | consumed samples:     29731840 | elapsed time per iteration (ms): 37695.5 | learning rate: 9.822E-05 | global batch size:  1024 | lm loss: 1.848623E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29036/   51900 | consumed samples:     29732864 | elapsed time per iteration (ms): 37678.1 | learning rate: 9.821E-05 | global batch size:  1024 | lm loss: 1.836606E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29037/   51900 | consumed samples:     29733888 | elapsed time per iteration (ms): 37635.8 | learning rate: 9.821E-05 | global batch size:  1024 | lm loss: 1.836702E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29038/   51900 | consumed samples:     29734912 | elapsed time per iteration (ms): 37646.0 | learning rate: 9.820E-05 | global batch size:  1024 | lm loss: 1.822374E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29039/   51900 | consumed samples:     29735936 | elapsed time per iteration (ms): 37761.9 | learning rate: 9.820E-05 | global batch size:  1024 | lm loss: 1.840214E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29040/   51900 | consumed samples:     29736960 | elapsed time per iteration (ms): 37583.7 | learning rate: 9.819E-05 | global batch size:  1024 | lm loss: 1.835042E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29041/   51900 | consumed samples:     29737984 | elapsed time per iteration (ms): 37590.8 | learning rate: 9.819E-05 | global batch size:  1024 | lm loss: 1.848094E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29042/   51900 | consumed samples:     29739008 | elapsed time per iteration (ms): 37585.6 | learning rate: 9.818E-05 | global batch size:  1024 | lm loss: 1.823583E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29043/   51900 | consumed samples:     29740032 | elapsed time per iteration (ms): 37694.9 | learning rate: 9.817E-05 | global batch size:  1024 | lm loss: 1.842304E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29044/   51900 | consumed samples:     29741056 | elapsed time per iteration (ms): 37586.7 | learning rate: 9.817E-05 | global batch size:  1024 | lm loss: 1.851802E+00 | loss scale: 1.0 | grad norm: 0.106 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29045/   51900 | consumed samples:     29742080 | elapsed time per iteration (ms): 37663.8 | learning rate: 9.816E-05 | global batch size:  1024 | lm loss: 1.853130E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29046/   51900 | consumed samples:     29743104 | elapsed time per iteration (ms): 37654.7 | learning rate: 9.816E-05 | global batch size:  1024 | lm loss: 1.841781E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29047/   51900 | consumed samples:     29744128 | elapsed time per iteration (ms): 37697.7 | learning rate: 9.815E-05 | global batch size:  1024 | lm loss: 1.803771E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29048/   51900 | consumed samples:     29745152 | elapsed time per iteration (ms): 37582.4 | learning rate: 9.815E-05 | global batch size:  1024 | lm loss: 1.844023E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29049/   51900 | consumed samples:     29746176 | elapsed time per iteration (ms): 37618.6 | learning rate: 9.814E-05 | global batch size:  1024 | lm loss: 1.838114E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29050/   51900 | consumed samples:     29747200 | elapsed time per iteration (ms): 37557.0 | learning rate: 9.814E-05 | global batch size:  1024 | lm loss: 1.829753E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29051/   51900 | consumed samples:     29748224 | elapsed time per iteration (ms): 37603.8 | learning rate: 9.813E-05 | global batch size:  1024 | lm loss: 1.852250E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29052/   51900 | consumed samples:     29749248 | elapsed time per iteration (ms): 37698.9 | learning rate: 9.812E-05 | global batch size:  1024 | lm loss: 1.846625E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29053/   51900 | consumed samples:     29750272 | elapsed time per iteration (ms): 37604.4 | learning rate: 9.812E-05 | global batch size:  1024 | lm loss: 1.847411E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29054/   51900 | consumed samples:     29751296 | elapsed time per iteration (ms): 37525.9 | learning rate: 9.811E-05 | global batch size:  1024 | lm loss: 1.838940E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29055/   51900 | consumed samples:     29752320 | elapsed time per iteration (ms): 37563.8 | learning rate: 9.811E-05 | global batch size:  1024 | lm loss: 1.851841E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29056/   51900 | consumed samples:     29753344 | elapsed time per iteration (ms): 37655.4 | learning rate: 9.810E-05 | global batch size:  1024 | lm loss: 1.837501E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29057/   51900 | consumed samples:     29754368 | elapsed time per iteration (ms): 37663.3 | learning rate: 9.810E-05 | global batch size:  1024 | lm loss: 1.831009E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29058/   51900 | consumed samples:     29755392 | elapsed time per iteration (ms): 37566.5 | learning rate: 9.809E-05 | global batch size:  1024 | lm loss: 1.840514E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29059/   51900 | consumed samples:     29756416 | elapsed time per iteration (ms): 37699.5 | learning rate: 9.809E-05 | global batch size:  1024 | lm loss: 1.839741E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29060/   51900 | consumed samples:     29757440 | elapsed time per iteration (ms): 37579.2 | learning rate: 9.808E-05 | global batch size:  1024 | lm loss: 1.847149E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29061/   51900 | consumed samples:     29758464 | elapsed time per iteration (ms): 37604.9 | learning rate: 9.807E-05 | global batch size:  1024 | lm loss: 1.837183E+00 | loss scale: 1.0 | grad norm: 0.088 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29062/   51900 | consumed samples:     29759488 | elapsed time per iteration (ms): 37468.9 | learning rate: 9.807E-05 | global batch size:  1024 | lm loss: 1.839267E+00 | loss scale: 1.0 | grad norm: 0.096 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29063/   51900 | consumed samples:     29760512 | elapsed time per iteration (ms): 37624.4 | learning rate: 9.806E-05 | global batch size:  1024 | lm loss: 1.840869E+00 | loss scale: 1.0 | grad norm: 0.095 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29064/   51900 | consumed samples:     29761536 | elapsed time per iteration (ms): 37758.0 | learning rate: 9.806E-05 | global batch size:  1024 | lm loss: 1.827325E+00 | loss scale: 1.0 | grad norm: 0.089 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29065/   51900 | consumed samples:     29762560 | elapsed time per iteration (ms): 37716.9 | learning rate: 9.805E-05 | global batch size:  1024 | lm loss: 1.845876E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29066/   51900 | consumed samples:     29763584 | elapsed time per iteration (ms): 37591.8 | learning rate: 9.805E-05 | global batch size:  1024 | lm loss: 1.843534E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29067/   51900 | consumed samples:     29764608 | elapsed time per iteration (ms): 37645.3 | learning rate: 9.804E-05 | global batch size:  1024 | lm loss: 1.844304E+00 | loss scale: 1.0 | grad norm: 0.087 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29068/   51900 | consumed samples:     29765632 | elapsed time per iteration (ms): 37624.0 | learning rate: 9.803E-05 | global batch size:  1024 | lm loss: 1.828867E+00 | loss scale: 1.0 | grad norm: 0.097 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29069/   51900 | consumed samples:     29766656 | elapsed time per iteration (ms): 37586.9 | learning rate: 9.803E-05 | global batch size:  1024 | lm loss: 1.835504E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29070/   51900 | consumed samples:     29767680 | elapsed time per iteration (ms): 37624.6 | learning rate: 9.802E-05 | global batch size:  1024 | lm loss: 1.855902E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29071/   51900 | consumed samples:     29768704 | elapsed time per iteration (ms): 37681.0 | learning rate: 9.802E-05 | global batch size:  1024 | lm loss: 1.824596E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29072/   51900 | consumed samples:     29769728 | elapsed time per iteration (ms): 37614.0 | learning rate: 9.801E-05 | global batch size:  1024 | lm loss: 1.833337E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29073/   51900 | consumed samples:     29770752 | elapsed time per iteration (ms): 37716.2 | learning rate: 9.801E-05 | global batch size:  1024 | lm loss: 1.859211E+00 | loss scale: 1.0 | grad norm: 0.089 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29074/   51900 | consumed samples:     29771776 | elapsed time per iteration (ms): 37622.7 | learning rate: 9.800E-05 | global batch size:  1024 | lm loss: 1.847883E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29075/   51900 | consumed samples:     29772800 | elapsed time per iteration (ms): 37604.5 | learning rate: 9.800E-05 | global batch size:  1024 | lm loss: 1.838482E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29076/   51900 | consumed samples:     29773824 | elapsed time per iteration (ms): 37680.1 | learning rate: 9.799E-05 | global batch size:  1024 | lm loss: 1.848083E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29077/   51900 | consumed samples:     29774848 | elapsed time per iteration (ms): 37688.8 | learning rate: 9.798E-05 | global batch size:  1024 | lm loss: 1.836847E+00 | loss scale: 1.0 | grad norm: 0.087 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29078/   51900 | consumed samples:     29775872 | elapsed time per iteration (ms): 37748.0 | learning rate: 9.798E-05 | global batch size:  1024 | lm loss: 1.834111E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29079/   51900 | consumed samples:     29776896 | elapsed time per iteration (ms): 37673.6 | learning rate: 9.797E-05 | global batch size:  1024 | lm loss: 1.842919E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29080/   51900 | consumed samples:     29777920 | elapsed time per iteration (ms): 37717.9 | learning rate: 9.797E-05 | global batch size:  1024 | lm loss: 1.845019E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29081/   51900 | consumed samples:     29778944 | elapsed time per iteration (ms): 37630.0 | learning rate: 9.796E-05 | global batch size:  1024 | lm loss: 1.842299E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29082/   51900 | consumed samples:     29779968 | elapsed time per iteration (ms): 37731.1 | learning rate: 9.796E-05 | global batch size:  1024 | lm loss: 1.827688E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29083/   51900 | consumed samples:     29780992 | elapsed time per iteration (ms): 37767.4 | learning rate: 9.795E-05 | global batch size:  1024 | lm loss: 1.838130E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29084/   51900 | consumed samples:     29782016 | elapsed time per iteration (ms): 37681.8 | learning rate: 9.794E-05 | global batch size:  1024 | lm loss: 1.846398E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29085/   51900 | consumed samples:     29783040 | elapsed time per iteration (ms): 37626.6 | learning rate: 9.794E-05 | global batch size:  1024 | lm loss: 1.828574E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29086/   51900 | consumed samples:     29784064 | elapsed time per iteration (ms): 37585.2 | learning rate: 9.793E-05 | global batch size:  1024 | lm loss: 1.822409E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29087/   51900 | consumed samples:     29785088 | elapsed time per iteration (ms): 37557.6 | learning rate: 9.793E-05 | global batch size:  1024 | lm loss: 1.844253E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29088/   51900 | consumed samples:     29786112 | elapsed time per iteration (ms): 37515.2 | learning rate: 9.792E-05 | global batch size:  1024 | lm loss: 1.834149E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29089/   51900 | consumed samples:     29787136 | elapsed time per iteration (ms): 37593.1 | learning rate: 9.792E-05 | global batch size:  1024 | lm loss: 1.832731E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29090/   51900 | consumed samples:     29788160 | elapsed time per iteration (ms): 37671.3 | learning rate: 9.791E-05 | global batch size:  1024 | lm loss: 1.836813E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29091/   51900 | consumed samples:     29789184 | elapsed time per iteration (ms): 37707.8 | learning rate: 9.791E-05 | global batch size:  1024 | lm loss: 1.848151E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29092/   51900 | consumed samples:     29790208 | elapsed time per iteration (ms): 37685.3 | learning rate: 9.790E-05 | global batch size:  1024 | lm loss: 1.833562E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29093/   51900 | consumed samples:     29791232 | elapsed time per iteration (ms): 37594.3 | learning rate: 9.789E-05 | global batch size:  1024 | lm loss: 1.839105E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29094/   51900 | consumed samples:     29792256 | elapsed time per iteration (ms): 37691.8 | learning rate: 9.789E-05 | global batch size:  1024 | lm loss: 1.832603E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29095/   51900 | consumed samples:     29793280 | elapsed time per iteration (ms): 37598.2 | learning rate: 9.788E-05 | global batch size:  1024 | lm loss: 1.839386E+00 | loss scale: 1.0 | grad norm: 0.110 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29096/   51900 | consumed samples:     29794304 | elapsed time per iteration (ms): 37589.5 | learning rate: 9.788E-05 | global batch size:  1024 | lm loss: 1.847736E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29097/   51900 | consumed samples:     29795328 | elapsed time per iteration (ms): 37556.1 | learning rate: 9.787E-05 | global batch size:  1024 | lm loss: 1.828264E+00 | loss scale: 1.0 | grad norm: 0.087 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29098/   51900 | consumed samples:     29796352 | elapsed time per iteration (ms): 37597.6 | learning rate: 9.787E-05 | global batch size:  1024 | lm loss: 1.838121E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29099/   51900 | consumed samples:     29797376 | elapsed time per iteration (ms): 37580.2 | learning rate: 9.786E-05 | global batch size:  1024 | lm loss: 1.839334E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29100/   51900 | consumed samples:     29798400 | elapsed time per iteration (ms): 37609.7 | learning rate: 9.785E-05 | global batch size:  1024 | lm loss: 1.819476E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29101/   51900 | consumed samples:     29799424 | elapsed time per iteration (ms): 37671.4 | learning rate: 9.785E-05 | global batch size:  1024 | lm loss: 1.843190E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29102/   51900 | consumed samples:     29800448 | elapsed time per iteration (ms): 37606.7 | learning rate: 9.784E-05 | global batch size:  1024 | lm loss: 1.841443E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29103/   51900 | consumed samples:     29801472 | elapsed time per iteration (ms): 37604.5 | learning rate: 9.784E-05 | global batch size:  1024 | lm loss: 1.828917E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29104/   51900 | consumed samples:     29802496 | elapsed time per iteration (ms): 37725.8 | learning rate: 9.783E-05 | global batch size:  1024 | lm loss: 1.842288E+00 | loss scale: 1.0 | grad norm: 0.311 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29105/   51900 | consumed samples:     29803520 | elapsed time per iteration (ms): 37568.1 | learning rate: 9.783E-05 | global batch size:  1024 | lm loss: 1.861455E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29106/   51900 | consumed samples:     29804544 | elapsed time per iteration (ms): 37720.2 | learning rate: 9.782E-05 | global batch size:  1024 | lm loss: 1.841234E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29107/   51900 | consumed samples:     29805568 | elapsed time per iteration (ms): 37500.1 | learning rate: 9.782E-05 | global batch size:  1024 | lm loss: 1.832559E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29108/   51900 | consumed samples:     29806592 | elapsed time per iteration (ms): 37592.5 | learning rate: 9.781E-05 | global batch size:  1024 | lm loss: 1.852745E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29109/   51900 | consumed samples:     29807616 | elapsed time per iteration (ms): 37603.2 | learning rate: 9.780E-05 | global batch size:  1024 | lm loss: 1.822807E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29110/   51900 | consumed samples:     29808640 | elapsed time per iteration (ms): 37721.1 | learning rate: 9.780E-05 | global batch size:  1024 | lm loss: 1.843523E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29111/   51900 | consumed samples:     29809664 | elapsed time per iteration (ms): 37852.9 | learning rate: 9.779E-05 | global batch size:  1024 | lm loss: 1.841997E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29112/   51900 | consumed samples:     29810688 | elapsed time per iteration (ms): 37635.0 | learning rate: 9.779E-05 | global batch size:  1024 | lm loss: 1.826254E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29113/   51900 | consumed samples:     29811712 | elapsed time per iteration (ms): 37643.3 | learning rate: 9.778E-05 | global batch size:  1024 | lm loss: 1.834157E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29114/   51900 | consumed samples:     29812736 | elapsed time per iteration (ms): 37561.5 | learning rate: 9.778E-05 | global batch size:  1024 | lm loss: 1.845265E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29115/   51900 | consumed samples:     29813760 | elapsed time per iteration (ms): 37604.4 | learning rate: 9.777E-05 | global batch size:  1024 | lm loss: 1.839016E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29116/   51900 | consumed samples:     29814784 | elapsed time per iteration (ms): 37699.5 | learning rate: 9.777E-05 | global batch size:  1024 | lm loss: 1.852741E+00 | loss scale: 1.0 | grad norm: 0.095 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29117/   51900 | consumed samples:     29815808 | elapsed time per iteration (ms): 37625.4 | learning rate: 9.776E-05 | global batch size:  1024 | lm loss: 1.848555E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29118/   51900 | consumed samples:     29816832 | elapsed time per iteration (ms): 37787.9 | learning rate: 9.775E-05 | global batch size:  1024 | lm loss: 1.862867E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29119/   51900 | consumed samples:     29817856 | elapsed time per iteration (ms): 37622.0 | learning rate: 9.775E-05 | global batch size:  1024 | lm loss: 1.832383E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29120/   51900 | consumed samples:     29818880 | elapsed time per iteration (ms): 37654.0 | learning rate: 9.774E-05 | global batch size:  1024 | lm loss: 1.841784E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29121/   51900 | consumed samples:     29819904 | elapsed time per iteration (ms): 37696.5 | learning rate: 9.774E-05 | global batch size:  1024 | lm loss: 1.837015E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29122/   51900 | consumed samples:     29820928 | elapsed time per iteration (ms): 37618.9 | learning rate: 9.773E-05 | global batch size:  1024 | lm loss: 1.819513E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29123/   51900 | consumed samples:     29821952 | elapsed time per iteration (ms): 37577.2 | learning rate: 9.773E-05 | global batch size:  1024 | lm loss: 1.822288E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29124/   51900 | consumed samples:     29822976 | elapsed time per iteration (ms): 37664.1 | learning rate: 9.772E-05 | global batch size:  1024 | lm loss: 1.842004E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29125/   51900 | consumed samples:     29824000 | elapsed time per iteration (ms): 37740.9 | learning rate: 9.771E-05 | global batch size:  1024 | lm loss: 1.839307E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29126/   51900 | consumed samples:     29825024 | elapsed time per iteration (ms): 37643.2 | learning rate: 9.771E-05 | global batch size:  1024 | lm loss: 1.837842E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29127/   51900 | consumed samples:     29826048 | elapsed time per iteration (ms): 37641.2 | learning rate: 9.770E-05 | global batch size:  1024 | lm loss: 1.844322E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29128/   51900 | consumed samples:     29827072 | elapsed time per iteration (ms): 37667.3 | learning rate: 9.770E-05 | global batch size:  1024 | lm loss: 1.844796E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29129/   51900 | consumed samples:     29828096 | elapsed time per iteration (ms): 37650.1 | learning rate: 9.769E-05 | global batch size:  1024 | lm loss: 1.845715E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29130/   51900 | consumed samples:     29829120 | elapsed time per iteration (ms): 37570.1 | learning rate: 9.769E-05 | global batch size:  1024 | lm loss: 1.837955E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29131/   51900 | consumed samples:     29830144 | elapsed time per iteration (ms): 37783.5 | learning rate: 9.768E-05 | global batch size:  1024 | lm loss: 1.834982E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29132/   51900 | consumed samples:     29831168 | elapsed time per iteration (ms): 37640.8 | learning rate: 9.768E-05 | global batch size:  1024 | lm loss: 1.855272E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29133/   51900 | consumed samples:     29832192 | elapsed time per iteration (ms): 37642.7 | learning rate: 9.767E-05 | global batch size:  1024 | lm loss: 1.830324E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29134/   51900 | consumed samples:     29833216 | elapsed time per iteration (ms): 37609.9 | learning rate: 9.766E-05 | global batch size:  1024 | lm loss: 1.821009E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29135/   51900 | consumed samples:     29834240 | elapsed time per iteration (ms): 37650.6 | learning rate: 9.766E-05 | global batch size:  1024 | lm loss: 1.841029E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29136/   51900 | consumed samples:     29835264 | elapsed time per iteration (ms): 37600.1 | learning rate: 9.765E-05 | global batch size:  1024 | lm loss: 1.830117E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29137/   51900 | consumed samples:     29836288 | elapsed time per iteration (ms): 37677.0 | learning rate: 9.765E-05 | global batch size:  1024 | lm loss: 1.832274E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29138/   51900 | consumed samples:     29837312 | elapsed time per iteration (ms): 37743.1 | learning rate: 9.764E-05 | global batch size:  1024 | lm loss: 1.838304E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29139/   51900 | consumed samples:     29838336 | elapsed time per iteration (ms): 37577.2 | learning rate: 9.764E-05 | global batch size:  1024 | lm loss: 1.802772E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29140/   51900 | consumed samples:     29839360 | elapsed time per iteration (ms): 37584.1 | learning rate: 9.763E-05 | global batch size:  1024 | lm loss: 1.829276E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29141/   51900 | consumed samples:     29840384 | elapsed time per iteration (ms): 37691.0 | learning rate: 9.762E-05 | global batch size:  1024 | lm loss: 1.843621E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29142/   51900 | consumed samples:     29841408 | elapsed time per iteration (ms): 37585.9 | learning rate: 9.762E-05 | global batch size:  1024 | lm loss: 1.843265E+00 | loss scale: 1.0 | grad norm: 0.088 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29143/   51900 | consumed samples:     29842432 | elapsed time per iteration (ms): 37521.7 | learning rate: 9.761E-05 | global batch size:  1024 | lm loss: 1.839122E+00 | loss scale: 1.0 | grad norm: 0.092 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29144/   51900 | consumed samples:     29843456 | elapsed time per iteration (ms): 37630.3 | learning rate: 9.761E-05 | global batch size:  1024 | lm loss: 1.847607E+00 | loss scale: 1.0 | grad norm: 0.092 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29145/   51900 | consumed samples:     29844480 | elapsed time per iteration (ms): 37751.3 | learning rate: 9.760E-05 | global batch size:  1024 | lm loss: 1.842370E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29146/   51900 | consumed samples:     29845504 | elapsed time per iteration (ms): 37675.5 | learning rate: 9.760E-05 | global batch size:  1024 | lm loss: 1.837531E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29147/   51900 | consumed samples:     29846528 | elapsed time per iteration (ms): 37706.8 | learning rate: 9.759E-05 | global batch size:  1024 | lm loss: 1.837142E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29148/   51900 | consumed samples:     29847552 | elapsed time per iteration (ms): 37589.2 | learning rate: 9.759E-05 | global batch size:  1024 | lm loss: 1.849661E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29149/   51900 | consumed samples:     29848576 | elapsed time per iteration (ms): 37599.0 | learning rate: 9.758E-05 | global batch size:  1024 | lm loss: 1.850026E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29150/   51900 | consumed samples:     29849600 | elapsed time per iteration (ms): 37614.9 | learning rate: 9.757E-05 | global batch size:  1024 | lm loss: 1.840530E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29151/   51900 | consumed samples:     29850624 | elapsed time per iteration (ms): 37601.0 | learning rate: 9.757E-05 | global batch size:  1024 | lm loss: 1.831525E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29152/   51900 | consumed samples:     29851648 | elapsed time per iteration (ms): 37661.2 | learning rate: 9.756E-05 | global batch size:  1024 | lm loss: 1.837091E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29153/   51900 | consumed samples:     29852672 | elapsed time per iteration (ms): 37616.1 | learning rate: 9.756E-05 | global batch size:  1024 | lm loss: 1.834811E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29154/   51900 | consumed samples:     29853696 | elapsed time per iteration (ms): 37717.8 | learning rate: 9.755E-05 | global batch size:  1024 | lm loss: 1.831243E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29155/   51900 | consumed samples:     29854720 | elapsed time per iteration (ms): 37559.9 | learning rate: 9.755E-05 | global batch size:  1024 | lm loss: 1.833276E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29156/   51900 | consumed samples:     29855744 | elapsed time per iteration (ms): 37533.6 | learning rate: 9.754E-05 | global batch size:  1024 | lm loss: 1.824884E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29157/   51900 | consumed samples:     29856768 | elapsed time per iteration (ms): 37588.4 | learning rate: 9.753E-05 | global batch size:  1024 | lm loss: 1.836635E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29158/   51900 | consumed samples:     29857792 | elapsed time per iteration (ms): 37573.9 | learning rate: 9.753E-05 | global batch size:  1024 | lm loss: 1.819061E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29159/   51900 | consumed samples:     29858816 | elapsed time per iteration (ms): 37732.1 | learning rate: 9.752E-05 | global batch size:  1024 | lm loss: 1.831256E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29160/   51900 | consumed samples:     29859840 | elapsed time per iteration (ms): 37607.7 | learning rate: 9.752E-05 | global batch size:  1024 | lm loss: 1.849183E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29161/   51900 | consumed samples:     29860864 | elapsed time per iteration (ms): 37698.7 | learning rate: 9.751E-05 | global batch size:  1024 | lm loss: 1.857550E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29162/   51900 | consumed samples:     29861888 | elapsed time per iteration (ms): 37656.4 | learning rate: 9.751E-05 | global batch size:  1024 | lm loss: 1.847404E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29163/   51900 | consumed samples:     29862912 | elapsed time per iteration (ms): 37655.9 | learning rate: 9.750E-05 | global batch size:  1024 | lm loss: 1.831200E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29164/   51900 | consumed samples:     29863936 | elapsed time per iteration (ms): 37652.5 | learning rate: 9.750E-05 | global batch size:  1024 | lm loss: 1.832883E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29165/   51900 | consumed samples:     29864960 | elapsed time per iteration (ms): 37595.7 | learning rate: 9.749E-05 | global batch size:  1024 | lm loss: 1.838371E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29166/   51900 | consumed samples:     29865984 | elapsed time per iteration (ms): 37569.6 | learning rate: 9.748E-05 | global batch size:  1024 | lm loss: 1.839206E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29167/   51900 | consumed samples:     29867008 | elapsed time per iteration (ms): 37572.3 | learning rate: 9.748E-05 | global batch size:  1024 | lm loss: 1.834003E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29168/   51900 | consumed samples:     29868032 | elapsed time per iteration (ms): 37732.9 | learning rate: 9.747E-05 | global batch size:  1024 | lm loss: 1.820689E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29169/   51900 | consumed samples:     29869056 | elapsed time per iteration (ms): 37548.4 | learning rate: 9.747E-05 | global batch size:  1024 | lm loss: 1.829859E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29170/   51900 | consumed samples:     29870080 | elapsed time per iteration (ms): 37672.8 | learning rate: 9.746E-05 | global batch size:  1024 | lm loss: 1.860924E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29171/   51900 | consumed samples:     29871104 | elapsed time per iteration (ms): 37664.5 | learning rate: 9.746E-05 | global batch size:  1024 | lm loss: 1.833610E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29172/   51900 | consumed samples:     29872128 | elapsed time per iteration (ms): 37712.0 | learning rate: 9.745E-05 | global batch size:  1024 | lm loss: 1.838081E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29173/   51900 | consumed samples:     29873152 | elapsed time per iteration (ms): 37597.2 | learning rate: 9.745E-05 | global batch size:  1024 | lm loss: 1.841919E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29174/   51900 | consumed samples:     29874176 | elapsed time per iteration (ms): 37632.1 | learning rate: 9.744E-05 | global batch size:  1024 | lm loss: 1.849512E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29175/   51900 | consumed samples:     29875200 | elapsed time per iteration (ms): 37610.5 | learning rate: 9.743E-05 | global batch size:  1024 | lm loss: 1.846217E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29176/   51900 | consumed samples:     29876224 | elapsed time per iteration (ms): 37568.6 | learning rate: 9.743E-05 | global batch size:  1024 | lm loss: 1.857329E+00 | loss scale: 1.0 | grad norm: 0.087 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29177/   51900 | consumed samples:     29877248 | elapsed time per iteration (ms): 37690.5 | learning rate: 9.742E-05 | global batch size:  1024 | lm loss: 1.836283E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29178/   51900 | consumed samples:     29878272 | elapsed time per iteration (ms): 37633.6 | learning rate: 9.742E-05 | global batch size:  1024 | lm loss: 1.836412E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29179/   51900 | consumed samples:     29879296 | elapsed time per iteration (ms): 37626.6 | learning rate: 9.741E-05 | global batch size:  1024 | lm loss: 1.841004E+00 | loss scale: 1.0 | grad norm: 0.117 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29180/   51900 | consumed samples:     29880320 | elapsed time per iteration (ms): 37587.6 | learning rate: 9.741E-05 | global batch size:  1024 | lm loss: 1.820118E+00 | loss scale: 1.0 | grad norm: 0.090 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29181/   51900 | consumed samples:     29881344 | elapsed time per iteration (ms): 37719.2 | learning rate: 9.740E-05 | global batch size:  1024 | lm loss: 1.841657E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29182/   51900 | consumed samples:     29882368 | elapsed time per iteration (ms): 37521.7 | learning rate: 9.739E-05 | global batch size:  1024 | lm loss: 1.819867E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29183/   51900 | consumed samples:     29883392 | elapsed time per iteration (ms): 37722.4 | learning rate: 9.739E-05 | global batch size:  1024 | lm loss: 1.845097E+00 | loss scale: 1.0 | grad norm: 0.089 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29184/   51900 | consumed samples:     29884416 | elapsed time per iteration (ms): 37686.4 | learning rate: 9.738E-05 | global batch size:  1024 | lm loss: 1.838680E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29185/   51900 | consumed samples:     29885440 | elapsed time per iteration (ms): 37507.8 | learning rate: 9.738E-05 | global batch size:  1024 | lm loss: 1.825497E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29186/   51900 | consumed samples:     29886464 | elapsed time per iteration (ms): 37742.0 | learning rate: 9.737E-05 | global batch size:  1024 | lm loss: 1.845146E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29187/   51900 | consumed samples:     29887488 | elapsed time per iteration (ms): 37717.8 | learning rate: 9.737E-05 | global batch size:  1024 | lm loss: 1.823470E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29188/   51900 | consumed samples:     29888512 | elapsed time per iteration (ms): 37718.3 | learning rate: 9.736E-05 | global batch size:  1024 | lm loss: 1.834913E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29189/   51900 | consumed samples:     29889536 | elapsed time per iteration (ms): 37619.2 | learning rate: 9.736E-05 | global batch size:  1024 | lm loss: 1.840163E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29190/   51900 | consumed samples:     29890560 | elapsed time per iteration (ms): 37565.4 | learning rate: 9.735E-05 | global batch size:  1024 | lm loss: 1.851137E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29191/   51900 | consumed samples:     29891584 | elapsed time per iteration (ms): 37650.9 | learning rate: 9.734E-05 | global batch size:  1024 | lm loss: 1.840681E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29192/   51900 | consumed samples:     29892608 | elapsed time per iteration (ms): 37594.3 | learning rate: 9.734E-05 | global batch size:  1024 | lm loss: 1.827898E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29193/   51900 | consumed samples:     29893632 | elapsed time per iteration (ms): 37824.8 | learning rate: 9.733E-05 | global batch size:  1024 | lm loss: 1.839523E+00 | loss scale: 1.0 | grad norm: 0.087 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29194/   51900 | consumed samples:     29894656 | elapsed time per iteration (ms): 37556.1 | learning rate: 9.733E-05 | global batch size:  1024 | lm loss: 1.835316E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29195/   51900 | consumed samples:     29895680 | elapsed time per iteration (ms): 37629.5 | learning rate: 9.732E-05 | global batch size:  1024 | lm loss: 1.823310E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29196/   51900 | consumed samples:     29896704 | elapsed time per iteration (ms): 37610.1 | learning rate: 9.732E-05 | global batch size:  1024 | lm loss: 1.830389E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29197/   51900 | consumed samples:     29897728 | elapsed time per iteration (ms): 37801.5 | learning rate: 9.731E-05 | global batch size:  1024 | lm loss: 1.848928E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29198/   51900 | consumed samples:     29898752 | elapsed time per iteration (ms): 37590.4 | learning rate: 9.730E-05 | global batch size:  1024 | lm loss: 1.860783E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29199/   51900 | consumed samples:     29899776 | elapsed time per iteration (ms): 37549.9 | learning rate: 9.730E-05 | global batch size:  1024 | lm loss: 1.840165E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29200/   51900 | consumed samples:     29900800 | elapsed time per iteration (ms): 37734.5 | learning rate: 9.729E-05 | global batch size:  1024 | lm loss: 1.845164E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29201/   51900 | consumed samples:     29901824 | elapsed time per iteration (ms): 37738.1 | learning rate: 9.729E-05 | global batch size:  1024 | lm loss: 1.838895E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29202/   51900 | consumed samples:     29902848 | elapsed time per iteration (ms): 37693.5 | learning rate: 9.728E-05 | global batch size:  1024 | lm loss: 1.840874E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29203/   51900 | consumed samples:     29903872 | elapsed time per iteration (ms): 37656.7 | learning rate: 9.728E-05 | global batch size:  1024 | lm loss: 1.823760E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29204/   51900 | consumed samples:     29904896 | elapsed time per iteration (ms): 37625.7 | learning rate: 9.727E-05 | global batch size:  1024 | lm loss: 1.839923E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29205/   51900 | consumed samples:     29905920 | elapsed time per iteration (ms): 37691.5 | learning rate: 9.727E-05 | global batch size:  1024 | lm loss: 1.839359E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29206/   51900 | consumed samples:     29906944 | elapsed time per iteration (ms): 37662.6 | learning rate: 9.726E-05 | global batch size:  1024 | lm loss: 1.840772E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29207/   51900 | consumed samples:     29907968 | elapsed time per iteration (ms): 37645.5 | learning rate: 9.725E-05 | global batch size:  1024 | lm loss: 1.821224E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29208/   51900 | consumed samples:     29908992 | elapsed time per iteration (ms): 37684.9 | learning rate: 9.725E-05 | global batch size:  1024 | lm loss: 1.842445E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29209/   51900 | consumed samples:     29910016 | elapsed time per iteration (ms): 37696.4 | learning rate: 9.724E-05 | global batch size:  1024 | lm loss: 1.841216E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29210/   51900 | consumed samples:     29911040 | elapsed time per iteration (ms): 37660.1 | learning rate: 9.724E-05 | global batch size:  1024 | lm loss: 1.824735E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29211/   51900 | consumed samples:     29912064 | elapsed time per iteration (ms): 37731.8 | learning rate: 9.723E-05 | global batch size:  1024 | lm loss: 1.848836E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29212/   51900 | consumed samples:     29913088 | elapsed time per iteration (ms): 37604.1 | learning rate: 9.723E-05 | global batch size:  1024 | lm loss: 1.850413E+00 | loss scale: 1.0 | grad norm: 0.095 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29213/   51900 | consumed samples:     29914112 | elapsed time per iteration (ms): 37546.9 | learning rate: 9.722E-05 | global batch size:  1024 | lm loss: 1.853193E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29214/   51900 | consumed samples:     29915136 | elapsed time per iteration (ms): 37618.1 | learning rate: 9.722E-05 | global batch size:  1024 | lm loss: 1.821826E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29215/   51900 | consumed samples:     29916160 | elapsed time per iteration (ms): 37706.1 | learning rate: 9.721E-05 | global batch size:  1024 | lm loss: 1.817717E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29216/   51900 | consumed samples:     29917184 | elapsed time per iteration (ms): 37594.8 | learning rate: 9.720E-05 | global batch size:  1024 | lm loss: 1.846698E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29217/   51900 | consumed samples:     29918208 | elapsed time per iteration (ms): 37710.3 | learning rate: 9.720E-05 | global batch size:  1024 | lm loss: 1.842184E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29218/   51900 | consumed samples:     29919232 | elapsed time per iteration (ms): 37551.1 | learning rate: 9.719E-05 | global batch size:  1024 | lm loss: 1.842766E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29219/   51900 | consumed samples:     29920256 | elapsed time per iteration (ms): 37726.2 | learning rate: 9.719E-05 | global batch size:  1024 | lm loss: 1.824332E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29220/   51900 | consumed samples:     29921280 | elapsed time per iteration (ms): 37748.1 | learning rate: 9.718E-05 | global batch size:  1024 | lm loss: 1.834116E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29221/   51900 | consumed samples:     29922304 | elapsed time per iteration (ms): 37664.1 | learning rate: 9.718E-05 | global batch size:  1024 | lm loss: 1.853824E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29222/   51900 | consumed samples:     29923328 | elapsed time per iteration (ms): 37588.4 | learning rate: 9.717E-05 | global batch size:  1024 | lm loss: 1.829548E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29223/   51900 | consumed samples:     29924352 | elapsed time per iteration (ms): 37669.3 | learning rate: 9.716E-05 | global batch size:  1024 | lm loss: 1.838392E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29224/   51900 | consumed samples:     29925376 | elapsed time per iteration (ms): 37740.0 | learning rate: 9.716E-05 | global batch size:  1024 | lm loss: 1.851418E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29225/   51900 | consumed samples:     29926400 | elapsed time per iteration (ms): 37634.4 | learning rate: 9.715E-05 | global batch size:  1024 | lm loss: 1.856383E+00 | loss scale: 1.0 | grad norm: 0.092 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29226/   51900 | consumed samples:     29927424 | elapsed time per iteration (ms): 37718.4 | learning rate: 9.715E-05 | global batch size:  1024 | lm loss: 1.834648E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29227/   51900 | consumed samples:     29928448 | elapsed time per iteration (ms): 37573.6 | learning rate: 9.714E-05 | global batch size:  1024 | lm loss: 1.828474E+00 | loss scale: 1.0 | grad norm: 0.087 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29228/   51900 | consumed samples:     29929472 | elapsed time per iteration (ms): 37681.7 | learning rate: 9.714E-05 | global batch size:  1024 | lm loss: 1.848773E+00 | loss scale: 1.0 | grad norm: 0.090 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29229/   51900 | consumed samples:     29930496 | elapsed time per iteration (ms): 37607.3 | learning rate: 9.713E-05 | global batch size:  1024 | lm loss: 1.829800E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29230/   51900 | consumed samples:     29931520 | elapsed time per iteration (ms): 37641.9 | learning rate: 9.713E-05 | global batch size:  1024 | lm loss: 1.845616E+00 | loss scale: 1.0 | grad norm: 0.097 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29231/   51900 | consumed samples:     29932544 | elapsed time per iteration (ms): 37680.8 | learning rate: 9.712E-05 | global batch size:  1024 | lm loss: 1.839505E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29232/   51900 | consumed samples:     29933568 | elapsed time per iteration (ms): 37642.0 | learning rate: 9.711E-05 | global batch size:  1024 | lm loss: 1.842336E+00 | loss scale: 1.0 | grad norm: 0.087 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29233/   51900 | consumed samples:     29934592 | elapsed time per iteration (ms): 37578.0 | learning rate: 9.711E-05 | global batch size:  1024 | lm loss: 1.842219E+00 | loss scale: 1.0 | grad norm: 0.089 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29234/   51900 | consumed samples:     29935616 | elapsed time per iteration (ms): 37642.6 | learning rate: 9.710E-05 | global batch size:  1024 | lm loss: 1.828428E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29235/   51900 | consumed samples:     29936640 | elapsed time per iteration (ms): 37695.7 | learning rate: 9.710E-05 | global batch size:  1024 | lm loss: 1.842132E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29236/   51900 | consumed samples:     29937664 | elapsed time per iteration (ms): 37663.3 | learning rate: 9.709E-05 | global batch size:  1024 | lm loss: 1.822962E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29237/   51900 | consumed samples:     29938688 | elapsed time per iteration (ms): 37647.0 | learning rate: 9.709E-05 | global batch size:  1024 | lm loss: 1.858264E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29238/   51900 | consumed samples:     29939712 | elapsed time per iteration (ms): 37656.8 | learning rate: 9.708E-05 | global batch size:  1024 | lm loss: 1.848208E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29239/   51900 | consumed samples:     29940736 | elapsed time per iteration (ms): 37542.6 | learning rate: 9.707E-05 | global batch size:  1024 | lm loss: 1.844407E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29240/   51900 | consumed samples:     29941760 | elapsed time per iteration (ms): 37683.4 | learning rate: 9.707E-05 | global batch size:  1024 | lm loss: 1.840109E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29241/   51900 | consumed samples:     29942784 | elapsed time per iteration (ms): 37750.9 | learning rate: 9.706E-05 | global batch size:  1024 | lm loss: 1.834607E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29242/   51900 | consumed samples:     29943808 | elapsed time per iteration (ms): 37618.2 | learning rate: 9.706E-05 | global batch size:  1024 | lm loss: 1.838164E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29243/   51900 | consumed samples:     29944832 | elapsed time per iteration (ms): 37638.6 | learning rate: 9.705E-05 | global batch size:  1024 | lm loss: 1.828942E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29244/   51900 | consumed samples:     29945856 | elapsed time per iteration (ms): 37525.6 | learning rate: 9.705E-05 | global batch size:  1024 | lm loss: 1.832773E+00 | loss scale: 1.0 | grad norm: 0.128 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29245/   51900 | consumed samples:     29946880 | elapsed time per iteration (ms): 37554.1 | learning rate: 9.704E-05 | global batch size:  1024 | lm loss: 1.859200E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29246/   51900 | consumed samples:     29947904 | elapsed time per iteration (ms): 37621.2 | learning rate: 9.704E-05 | global batch size:  1024 | lm loss: 1.854389E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29247/   51900 | consumed samples:     29948928 | elapsed time per iteration (ms): 37602.8 | learning rate: 9.703E-05 | global batch size:  1024 | lm loss: 1.865094E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29248/   51900 | consumed samples:     29949952 | elapsed time per iteration (ms): 37671.8 | learning rate: 9.702E-05 | global batch size:  1024 | lm loss: 1.829073E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29249/   51900 | consumed samples:     29950976 | elapsed time per iteration (ms): 37648.1 | learning rate: 9.702E-05 | global batch size:  1024 | lm loss: 1.840400E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29250/   51900 | consumed samples:     29952000 | elapsed time per iteration (ms): 37683.3 | learning rate: 9.701E-05 | global batch size:  1024 | lm loss: 1.842968E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29251/   51900 | consumed samples:     29953024 | elapsed time per iteration (ms): 37584.4 | learning rate: 9.701E-05 | global batch size:  1024 | lm loss: 1.832677E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29252/   51900 | consumed samples:     29954048 | elapsed time per iteration (ms): 37628.6 | learning rate: 9.700E-05 | global batch size:  1024 | lm loss: 1.846863E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29253/   51900 | consumed samples:     29955072 | elapsed time per iteration (ms): 37621.2 | learning rate: 9.700E-05 | global batch size:  1024 | lm loss: 1.828463E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29254/   51900 | consumed samples:     29956096 | elapsed time per iteration (ms): 37509.9 | learning rate: 9.699E-05 | global batch size:  1024 | lm loss: 1.836425E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29255/   51900 | consumed samples:     29957120 | elapsed time per iteration (ms): 37687.9 | learning rate: 9.699E-05 | global batch size:  1024 | lm loss: 1.842869E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29256/   51900 | consumed samples:     29958144 | elapsed time per iteration (ms): 37696.0 | learning rate: 9.698E-05 | global batch size:  1024 | lm loss: 1.853402E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29257/   51900 | consumed samples:     29959168 | elapsed time per iteration (ms): 37495.2 | learning rate: 9.697E-05 | global batch size:  1024 | lm loss: 1.834684E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29258/   51900 | consumed samples:     29960192 | elapsed time per iteration (ms): 37765.8 | learning rate: 9.697E-05 | global batch size:  1024 | lm loss: 1.837437E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29259/   51900 | consumed samples:     29961216 | elapsed time per iteration (ms): 37613.9 | learning rate: 9.696E-05 | global batch size:  1024 | lm loss: 1.827391E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29260/   51900 | consumed samples:     29962240 | elapsed time per iteration (ms): 37541.0 | learning rate: 9.696E-05 | global batch size:  1024 | lm loss: 1.820664E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29261/   51900 | consumed samples:     29963264 | elapsed time per iteration (ms): 37561.4 | learning rate: 9.695E-05 | global batch size:  1024 | lm loss: 1.829822E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29262/   51900 | consumed samples:     29964288 | elapsed time per iteration (ms): 37703.1 | learning rate: 9.695E-05 | global batch size:  1024 | lm loss: 1.830719E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29263/   51900 | consumed samples:     29965312 | elapsed time per iteration (ms): 37604.4 | learning rate: 9.694E-05 | global batch size:  1024 | lm loss: 1.826073E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29264/   51900 | consumed samples:     29966336 | elapsed time per iteration (ms): 37606.0 | learning rate: 9.693E-05 | global batch size:  1024 | lm loss: 1.852730E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29265/   51900 | consumed samples:     29967360 | elapsed time per iteration (ms): 37701.7 | learning rate: 9.693E-05 | global batch size:  1024 | lm loss: 1.834941E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29266/   51900 | consumed samples:     29968384 | elapsed time per iteration (ms): 37685.0 | learning rate: 9.692E-05 | global batch size:  1024 | lm loss: 1.831851E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29267/   51900 | consumed samples:     29969408 | elapsed time per iteration (ms): 37790.1 | learning rate: 9.692E-05 | global batch size:  1024 | lm loss: 1.837700E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29268/   51900 | consumed samples:     29970432 | elapsed time per iteration (ms): 37635.0 | learning rate: 9.691E-05 | global batch size:  1024 | lm loss: 1.827823E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29269/   51900 | consumed samples:     29971456 | elapsed time per iteration (ms): 37606.8 | learning rate: 9.691E-05 | global batch size:  1024 | lm loss: 1.825436E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29270/   51900 | consumed samples:     29972480 | elapsed time per iteration (ms): 37580.8 | learning rate: 9.690E-05 | global batch size:  1024 | lm loss: 1.853947E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29271/   51900 | consumed samples:     29973504 | elapsed time per iteration (ms): 37719.4 | learning rate: 9.690E-05 | global batch size:  1024 | lm loss: 1.857522E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29272/   51900 | consumed samples:     29974528 | elapsed time per iteration (ms): 37621.5 | learning rate: 9.689E-05 | global batch size:  1024 | lm loss: 1.836882E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29273/   51900 | consumed samples:     29975552 | elapsed time per iteration (ms): 37832.0 | learning rate: 9.688E-05 | global batch size:  1024 | lm loss: 1.839698E+00 | loss scale: 1.0 | grad norm: 0.096 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29274/   51900 | consumed samples:     29976576 | elapsed time per iteration (ms): 37660.6 | learning rate: 9.688E-05 | global batch size:  1024 | lm loss: 1.822434E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29275/   51900 | consumed samples:     29977600 | elapsed time per iteration (ms): 37600.5 | learning rate: 9.687E-05 | global batch size:  1024 | lm loss: 1.843314E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29276/   51900 | consumed samples:     29978624 | elapsed time per iteration (ms): 37654.1 | learning rate: 9.687E-05 | global batch size:  1024 | lm loss: 1.825313E+00 | loss scale: 1.0 | grad norm: 0.093 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29277/   51900 | consumed samples:     29979648 | elapsed time per iteration (ms): 37716.5 | learning rate: 9.686E-05 | global batch size:  1024 | lm loss: 1.840735E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29278/   51900 | consumed samples:     29980672 | elapsed time per iteration (ms): 37805.4 | learning rate: 9.686E-05 | global batch size:  1024 | lm loss: 1.841543E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29279/   51900 | consumed samples:     29981696 | elapsed time per iteration (ms): 37603.9 | learning rate: 9.685E-05 | global batch size:  1024 | lm loss: 1.825184E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29280/   51900 | consumed samples:     29982720 | elapsed time per iteration (ms): 37710.2 | learning rate: 9.685E-05 | global batch size:  1024 | lm loss: 1.852162E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29281/   51900 | consumed samples:     29983744 | elapsed time per iteration (ms): 37672.6 | learning rate: 9.684E-05 | global batch size:  1024 | lm loss: 1.839149E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29282/   51900 | consumed samples:     29984768 | elapsed time per iteration (ms): 37628.4 | learning rate: 9.683E-05 | global batch size:  1024 | lm loss: 1.813332E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29283/   51900 | consumed samples:     29985792 | elapsed time per iteration (ms): 37579.0 | learning rate: 9.683E-05 | global batch size:  1024 | lm loss: 1.840338E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29284/   51900 | consumed samples:     29986816 | elapsed time per iteration (ms): 37687.9 | learning rate: 9.682E-05 | global batch size:  1024 | lm loss: 1.848713E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29285/   51900 | consumed samples:     29987840 | elapsed time per iteration (ms): 37681.2 | learning rate: 9.682E-05 | global batch size:  1024 | lm loss: 1.810607E+00 | loss scale: 1.0 | grad norm: 0.089 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29286/   51900 | consumed samples:     29988864 | elapsed time per iteration (ms): 37738.4 | learning rate: 9.681E-05 | global batch size:  1024 | lm loss: 1.840695E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29287/   51900 | consumed samples:     29989888 | elapsed time per iteration (ms): 37662.4 | learning rate: 9.681E-05 | global batch size:  1024 | lm loss: 1.857380E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29288/   51900 | consumed samples:     29990912 | elapsed time per iteration (ms): 37668.7 | learning rate: 9.680E-05 | global batch size:  1024 | lm loss: 1.843162E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29289/   51900 | consumed samples:     29991936 | elapsed time per iteration (ms): 37653.5 | learning rate: 9.679E-05 | global batch size:  1024 | lm loss: 1.841497E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29290/   51900 | consumed samples:     29992960 | elapsed time per iteration (ms): 37602.7 | learning rate: 9.679E-05 | global batch size:  1024 | lm loss: 1.831777E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29291/   51900 | consumed samples:     29993984 | elapsed time per iteration (ms): 37597.9 | learning rate: 9.678E-05 | global batch size:  1024 | lm loss: 1.820611E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29292/   51900 | consumed samples:     29995008 | elapsed time per iteration (ms): 37493.4 | learning rate: 9.678E-05 | global batch size:  1024 | lm loss: 1.828997E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29293/   51900 | consumed samples:     29996032 | elapsed time per iteration (ms): 37700.1 | learning rate: 9.677E-05 | global batch size:  1024 | lm loss: 1.834744E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29294/   51900 | consumed samples:     29997056 | elapsed time per iteration (ms): 37659.3 | learning rate: 9.677E-05 | global batch size:  1024 | lm loss: 1.848913E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29295/   51900 | consumed samples:     29998080 | elapsed time per iteration (ms): 37569.6 | learning rate: 9.676E-05 | global batch size:  1024 | lm loss: 1.835926E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29296/   51900 | consumed samples:     29999104 | elapsed time per iteration (ms): 37649.4 | learning rate: 9.676E-05 | global batch size:  1024 | lm loss: 1.846292E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29297/   51900 | consumed samples:     30000128 | elapsed time per iteration (ms): 37533.0 | learning rate: 9.675E-05 | global batch size:  1024 | lm loss: 1.843791E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29298/   51900 | consumed samples:     30001152 | elapsed time per iteration (ms): 37756.6 | learning rate: 9.674E-05 | global batch size:  1024 | lm loss: 1.850841E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29299/   51900 | consumed samples:     30002176 | elapsed time per iteration (ms): 37590.5 | learning rate: 9.674E-05 | global batch size:  1024 | lm loss: 1.840618E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29300/   51900 | consumed samples:     30003200 | elapsed time per iteration (ms): 37489.7 | learning rate: 9.673E-05 | global batch size:  1024 | lm loss: 1.828767E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29301/   51900 | consumed samples:     30004224 | elapsed time per iteration (ms): 37588.0 | learning rate: 9.673E-05 | global batch size:  1024 | lm loss: 1.841937E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29302/   51900 | consumed samples:     30005248 | elapsed time per iteration (ms): 37631.2 | learning rate: 9.672E-05 | global batch size:  1024 | lm loss: 1.838029E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29303/   51900 | consumed samples:     30006272 | elapsed time per iteration (ms): 37630.3 | learning rate: 9.672E-05 | global batch size:  1024 | lm loss: 1.836899E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29304/   51900 | consumed samples:     30007296 | elapsed time per iteration (ms): 37607.3 | learning rate: 9.671E-05 | global batch size:  1024 | lm loss: 1.828700E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29305/   51900 | consumed samples:     30008320 | elapsed time per iteration (ms): 37631.7 | learning rate: 9.670E-05 | global batch size:  1024 | lm loss: 1.831320E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29306/   51900 | consumed samples:     30009344 | elapsed time per iteration (ms): 37785.1 | learning rate: 9.670E-05 | global batch size:  1024 | lm loss: 1.816001E+00 | loss scale: 1.0 | grad norm: 0.090 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29307/   51900 | consumed samples:     30010368 | elapsed time per iteration (ms): 37617.0 | learning rate: 9.669E-05 | global batch size:  1024 | lm loss: 1.842265E+00 | loss scale: 1.0 | grad norm: 0.089 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29308/   51900 | consumed samples:     30011392 | elapsed time per iteration (ms): 37675.4 | learning rate: 9.669E-05 | global batch size:  1024 | lm loss: 1.845488E+00 | loss scale: 1.0 | grad norm: 0.090 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29309/   51900 | consumed samples:     30012416 | elapsed time per iteration (ms): 37664.8 | learning rate: 9.668E-05 | global batch size:  1024 | lm loss: 1.842806E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29310/   51900 | consumed samples:     30013440 | elapsed time per iteration (ms): 37652.5 | learning rate: 9.668E-05 | global batch size:  1024 | lm loss: 1.843640E+00 | loss scale: 1.0 | grad norm: 0.091 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29311/   51900 | consumed samples:     30014464 | elapsed time per iteration (ms): 37646.4 | learning rate: 9.667E-05 | global batch size:  1024 | lm loss: 1.840734E+00 | loss scale: 1.0 | grad norm: 0.089 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29312/   51900 | consumed samples:     30015488 | elapsed time per iteration (ms): 37661.8 | learning rate: 9.667E-05 | global batch size:  1024 | lm loss: 1.829810E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29313/   51900 | consumed samples:     30016512 | elapsed time per iteration (ms): 37654.4 | learning rate: 9.666E-05 | global batch size:  1024 | lm loss: 1.855379E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29314/   51900 | consumed samples:     30017536 | elapsed time per iteration (ms): 37712.8 | learning rate: 9.665E-05 | global batch size:  1024 | lm loss: 1.828583E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29315/   51900 | consumed samples:     30018560 | elapsed time per iteration (ms): 37684.7 | learning rate: 9.665E-05 | global batch size:  1024 | lm loss: 1.836245E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29316/   51900 | consumed samples:     30019584 | elapsed time per iteration (ms): 37640.1 | learning rate: 9.664E-05 | global batch size:  1024 | lm loss: 1.855395E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29317/   51900 | consumed samples:     30020608 | elapsed time per iteration (ms): 37592.0 | learning rate: 9.664E-05 | global batch size:  1024 | lm loss: 1.834879E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29318/   51900 | consumed samples:     30021632 | elapsed time per iteration (ms): 37671.3 | learning rate: 9.663E-05 | global batch size:  1024 | lm loss: 1.844573E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29319/   51900 | consumed samples:     30022656 | elapsed time per iteration (ms): 37608.6 | learning rate: 9.663E-05 | global batch size:  1024 | lm loss: 1.848541E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29320/   51900 | consumed samples:     30023680 | elapsed time per iteration (ms): 37628.9 | learning rate: 9.662E-05 | global batch size:  1024 | lm loss: 1.844776E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29321/   51900 | consumed samples:     30024704 | elapsed time per iteration (ms): 37565.4 | learning rate: 9.662E-05 | global batch size:  1024 | lm loss: 1.837703E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29322/   51900 | consumed samples:     30025728 | elapsed time per iteration (ms): 37628.9 | learning rate: 9.661E-05 | global batch size:  1024 | lm loss: 1.815115E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29323/   51900 | consumed samples:     30026752 | elapsed time per iteration (ms): 37701.7 | learning rate: 9.660E-05 | global batch size:  1024 | lm loss: 1.836452E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29324/   51900 | consumed samples:     30027776 | elapsed time per iteration (ms): 37596.1 | learning rate: 9.660E-05 | global batch size:  1024 | lm loss: 1.825454E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29325/   51900 | consumed samples:     30028800 | elapsed time per iteration (ms): 37703.0 | learning rate: 9.659E-05 | global batch size:  1024 | lm loss: 1.856828E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29326/   51900 | consumed samples:     30029824 | elapsed time per iteration (ms): 37701.2 | learning rate: 9.659E-05 | global batch size:  1024 | lm loss: 1.834821E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29327/   51900 | consumed samples:     30030848 | elapsed time per iteration (ms): 37551.9 | learning rate: 9.658E-05 | global batch size:  1024 | lm loss: 1.836271E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29328/   51900 | consumed samples:     30031872 | elapsed time per iteration (ms): 37784.3 | learning rate: 9.658E-05 | global batch size:  1024 | lm loss: 1.832430E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29329/   51900 | consumed samples:     30032896 | elapsed time per iteration (ms): 37619.9 | learning rate: 9.657E-05 | global batch size:  1024 | lm loss: 1.827239E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29330/   51900 | consumed samples:     30033920 | elapsed time per iteration (ms): 37542.0 | learning rate: 9.656E-05 | global batch size:  1024 | lm loss: 1.829652E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29331/   51900 | consumed samples:     30034944 | elapsed time per iteration (ms): 37557.0 | learning rate: 9.656E-05 | global batch size:  1024 | lm loss: 1.840666E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29332/   51900 | consumed samples:     30035968 | elapsed time per iteration (ms): 37658.5 | learning rate: 9.655E-05 | global batch size:  1024 | lm loss: 1.825194E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29333/   51900 | consumed samples:     30036992 | elapsed time per iteration (ms): 37737.9 | learning rate: 9.655E-05 | global batch size:  1024 | lm loss: 1.841900E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29334/   51900 | consumed samples:     30038016 | elapsed time per iteration (ms): 37646.2 | learning rate: 9.654E-05 | global batch size:  1024 | lm loss: 1.822561E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29335/   51900 | consumed samples:     30039040 | elapsed time per iteration (ms): 37671.4 | learning rate: 9.654E-05 | global batch size:  1024 | lm loss: 1.838514E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29336/   51900 | consumed samples:     30040064 | elapsed time per iteration (ms): 37665.2 | learning rate: 9.653E-05 | global batch size:  1024 | lm loss: 1.840067E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29337/   51900 | consumed samples:     30041088 | elapsed time per iteration (ms): 37754.0 | learning rate: 9.653E-05 | global batch size:  1024 | lm loss: 1.829478E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29338/   51900 | consumed samples:     30042112 | elapsed time per iteration (ms): 37599.8 | learning rate: 9.652E-05 | global batch size:  1024 | lm loss: 1.825919E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29339/   51900 | consumed samples:     30043136 | elapsed time per iteration (ms): 37638.2 | learning rate: 9.651E-05 | global batch size:  1024 | lm loss: 1.816814E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29340/   51900 | consumed samples:     30044160 | elapsed time per iteration (ms): 37597.1 | learning rate: 9.651E-05 | global batch size:  1024 | lm loss: 1.829278E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29341/   51900 | consumed samples:     30045184 | elapsed time per iteration (ms): 37724.3 | learning rate: 9.650E-05 | global batch size:  1024 | lm loss: 1.845410E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29342/   51900 | consumed samples:     30046208 | elapsed time per iteration (ms): 37612.6 | learning rate: 9.650E-05 | global batch size:  1024 | lm loss: 1.830436E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29343/   51900 | consumed samples:     30047232 | elapsed time per iteration (ms): 37646.7 | learning rate: 9.649E-05 | global batch size:  1024 | lm loss: 1.846656E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29344/   51900 | consumed samples:     30048256 | elapsed time per iteration (ms): 37637.3 | learning rate: 9.649E-05 | global batch size:  1024 | lm loss: 1.845941E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29345/   51900 | consumed samples:     30049280 | elapsed time per iteration (ms): 37565.9 | learning rate: 9.648E-05 | global batch size:  1024 | lm loss: 1.829139E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29346/   51900 | consumed samples:     30050304 | elapsed time per iteration (ms): 37752.6 | learning rate: 9.648E-05 | global batch size:  1024 | lm loss: 1.839320E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29347/   51900 | consumed samples:     30051328 | elapsed time per iteration (ms): 37728.3 | learning rate: 9.647E-05 | global batch size:  1024 | lm loss: 1.844676E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29348/   51900 | consumed samples:     30052352 | elapsed time per iteration (ms): 37600.0 | learning rate: 9.646E-05 | global batch size:  1024 | lm loss: 1.829302E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29349/   51900 | consumed samples:     30053376 | elapsed time per iteration (ms): 37633.3 | learning rate: 9.646E-05 | global batch size:  1024 | lm loss: 1.836403E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29350/   51900 | consumed samples:     30054400 | elapsed time per iteration (ms): 37659.7 | learning rate: 9.645E-05 | global batch size:  1024 | lm loss: 1.860769E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29351/   51900 | consumed samples:     30055424 | elapsed time per iteration (ms): 37739.7 | learning rate: 9.645E-05 | global batch size:  1024 | lm loss: 1.820328E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29352/   51900 | consumed samples:     30056448 | elapsed time per iteration (ms): 37537.8 | learning rate: 9.644E-05 | global batch size:  1024 | lm loss: 1.839102E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29353/   51900 | consumed samples:     30057472 | elapsed time per iteration (ms): 37574.9 | learning rate: 9.644E-05 | global batch size:  1024 | lm loss: 1.813084E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29354/   51900 | consumed samples:     30058496 | elapsed time per iteration (ms): 37585.7 | learning rate: 9.643E-05 | global batch size:  1024 | lm loss: 1.837700E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29355/   51900 | consumed samples:     30059520 | elapsed time per iteration (ms): 37548.0 | learning rate: 9.642E-05 | global batch size:  1024 | lm loss: 1.829902E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29356/   51900 | consumed samples:     30060544 | elapsed time per iteration (ms): 37613.7 | learning rate: 9.642E-05 | global batch size:  1024 | lm loss: 1.820652E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29357/   51900 | consumed samples:     30061568 | elapsed time per iteration (ms): 37784.0 | learning rate: 9.641E-05 | global batch size:  1024 | lm loss: 1.835034E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29358/   51900 | consumed samples:     30062592 | elapsed time per iteration (ms): 37578.6 | learning rate: 9.641E-05 | global batch size:  1024 | lm loss: 1.846228E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29359/   51900 | consumed samples:     30063616 | elapsed time per iteration (ms): 37601.7 | learning rate: 9.640E-05 | global batch size:  1024 | lm loss: 1.846325E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29360/   51900 | consumed samples:     30064640 | elapsed time per iteration (ms): 37694.5 | learning rate: 9.640E-05 | global batch size:  1024 | lm loss: 1.846057E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29361/   51900 | consumed samples:     30065664 | elapsed time per iteration (ms): 37667.4 | learning rate: 9.639E-05 | global batch size:  1024 | lm loss: 1.844267E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29362/   51900 | consumed samples:     30066688 | elapsed time per iteration (ms): 37691.1 | learning rate: 9.639E-05 | global batch size:  1024 | lm loss: 1.839194E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29363/   51900 | consumed samples:     30067712 | elapsed time per iteration (ms): 37591.1 | learning rate: 9.638E-05 | global batch size:  1024 | lm loss: 1.840568E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29364/   51900 | consumed samples:     30068736 | elapsed time per iteration (ms): 37593.8 | learning rate: 9.637E-05 | global batch size:  1024 | lm loss: 1.839313E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29365/   51900 | consumed samples:     30069760 | elapsed time per iteration (ms): 37706.4 | learning rate: 9.637E-05 | global batch size:  1024 | lm loss: 1.844553E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29366/   51900 | consumed samples:     30070784 | elapsed time per iteration (ms): 37677.9 | learning rate: 9.636E-05 | global batch size:  1024 | lm loss: 1.833201E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29367/   51900 | consumed samples:     30071808 | elapsed time per iteration (ms): 37721.1 | learning rate: 9.636E-05 | global batch size:  1024 | lm loss: 1.831931E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29368/   51900 | consumed samples:     30072832 | elapsed time per iteration (ms): 37566.5 | learning rate: 9.635E-05 | global batch size:  1024 | lm loss: 1.849976E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29369/   51900 | consumed samples:     30073856 | elapsed time per iteration (ms): 37523.3 | learning rate: 9.635E-05 | global batch size:  1024 | lm loss: 1.852837E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29370/   51900 | consumed samples:     30074880 | elapsed time per iteration (ms): 37601.5 | learning rate: 9.634E-05 | global batch size:  1024 | lm loss: 1.851561E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29371/   51900 | consumed samples:     30075904 | elapsed time per iteration (ms): 37596.4 | learning rate: 9.634E-05 | global batch size:  1024 | lm loss: 1.832344E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29372/   51900 | consumed samples:     30076928 | elapsed time per iteration (ms): 37712.8 | learning rate: 9.633E-05 | global batch size:  1024 | lm loss: 1.853890E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29373/   51900 | consumed samples:     30077952 | elapsed time per iteration (ms): 37739.9 | learning rate: 9.632E-05 | global batch size:  1024 | lm loss: 1.830714E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29374/   51900 | consumed samples:     30078976 | elapsed time per iteration (ms): 37622.1 | learning rate: 9.632E-05 | global batch size:  1024 | lm loss: 1.847726E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29375/   51900 | consumed samples:     30080000 | elapsed time per iteration (ms): 37637.2 | learning rate: 9.631E-05 | global batch size:  1024 | lm loss: 1.841697E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29376/   51900 | consumed samples:     30081024 | elapsed time per iteration (ms): 37554.7 | learning rate: 9.631E-05 | global batch size:  1024 | lm loss: 1.856850E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29377/   51900 | consumed samples:     30082048 | elapsed time per iteration (ms): 37676.2 | learning rate: 9.630E-05 | global batch size:  1024 | lm loss: 1.858755E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29378/   51900 | consumed samples:     30083072 | elapsed time per iteration (ms): 37642.5 | learning rate: 9.630E-05 | global batch size:  1024 | lm loss: 1.838859E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29379/   51900 | consumed samples:     30084096 | elapsed time per iteration (ms): 37715.9 | learning rate: 9.629E-05 | global batch size:  1024 | lm loss: 1.845989E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29380/   51900 | consumed samples:     30085120 | elapsed time per iteration (ms): 37582.2 | learning rate: 9.628E-05 | global batch size:  1024 | lm loss: 1.854273E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29381/   51900 | consumed samples:     30086144 | elapsed time per iteration (ms): 37647.0 | learning rate: 9.628E-05 | global batch size:  1024 | lm loss: 1.836353E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29382/   51900 | consumed samples:     30087168 | elapsed time per iteration (ms): 37665.2 | learning rate: 9.627E-05 | global batch size:  1024 | lm loss: 1.838406E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29383/   51900 | consumed samples:     30088192 | elapsed time per iteration (ms): 37618.5 | learning rate: 9.627E-05 | global batch size:  1024 | lm loss: 1.832294E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29384/   51900 | consumed samples:     30089216 | elapsed time per iteration (ms): 37527.0 | learning rate: 9.626E-05 | global batch size:  1024 | lm loss: 1.838252E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29385/   51900 | consumed samples:     30090240 | elapsed time per iteration (ms): 37629.5 | learning rate: 9.626E-05 | global batch size:  1024 | lm loss: 1.831131E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29386/   51900 | consumed samples:     30091264 | elapsed time per iteration (ms): 37600.3 | learning rate: 9.625E-05 | global batch size:  1024 | lm loss: 1.821827E+00 | loss scale: 1.0 | grad norm: 0.088 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29387/   51900 | consumed samples:     30092288 | elapsed time per iteration (ms): 37636.6 | learning rate: 9.625E-05 | global batch size:  1024 | lm loss: 1.844296E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29388/   51900 | consumed samples:     30093312 | elapsed time per iteration (ms): 37580.7 | learning rate: 9.624E-05 | global batch size:  1024 | lm loss: 1.842281E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29389/   51900 | consumed samples:     30094336 | elapsed time per iteration (ms): 37593.9 | learning rate: 9.623E-05 | global batch size:  1024 | lm loss: 1.845409E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29390/   51900 | consumed samples:     30095360 | elapsed time per iteration (ms): 37574.0 | learning rate: 9.623E-05 | global batch size:  1024 | lm loss: 1.831545E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29391/   51900 | consumed samples:     30096384 | elapsed time per iteration (ms): 37643.6 | learning rate: 9.622E-05 | global batch size:  1024 | lm loss: 1.832991E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29392/   51900 | consumed samples:     30097408 | elapsed time per iteration (ms): 37657.2 | learning rate: 9.622E-05 | global batch size:  1024 | lm loss: 1.821660E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29393/   51900 | consumed samples:     30098432 | elapsed time per iteration (ms): 37665.8 | learning rate: 9.621E-05 | global batch size:  1024 | lm loss: 1.829002E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29394/   51900 | consumed samples:     30099456 | elapsed time per iteration (ms): 37727.3 | learning rate: 9.621E-05 | global batch size:  1024 | lm loss: 1.848245E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29395/   51900 | consumed samples:     30100480 | elapsed time per iteration (ms): 37706.5 | learning rate: 9.620E-05 | global batch size:  1024 | lm loss: 1.821225E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29396/   51900 | consumed samples:     30101504 | elapsed time per iteration (ms): 37568.4 | learning rate: 9.620E-05 | global batch size:  1024 | lm loss: 1.825692E+00 | loss scale: 1.0 | grad norm: 0.153 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29397/   51900 | consumed samples:     30102528 | elapsed time per iteration (ms): 37572.5 | learning rate: 9.619E-05 | global batch size:  1024 | lm loss: 1.827386E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29398/   51900 | consumed samples:     30103552 | elapsed time per iteration (ms): 37653.7 | learning rate: 9.618E-05 | global batch size:  1024 | lm loss: 1.845722E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29399/   51900 | consumed samples:     30104576 | elapsed time per iteration (ms): 37655.2 | learning rate: 9.618E-05 | global batch size:  1024 | lm loss: 1.841893E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29400/   51900 | consumed samples:     30105600 | elapsed time per iteration (ms): 37634.0 | learning rate: 9.617E-05 | global batch size:  1024 | lm loss: 1.843129E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29401/   51900 | consumed samples:     30106624 | elapsed time per iteration (ms): 37594.7 | learning rate: 9.617E-05 | global batch size:  1024 | lm loss: 1.841230E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29402/   51900 | consumed samples:     30107648 | elapsed time per iteration (ms): 37710.9 | learning rate: 9.616E-05 | global batch size:  1024 | lm loss: 1.854324E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29403/   51900 | consumed samples:     30108672 | elapsed time per iteration (ms): 37631.6 | learning rate: 9.616E-05 | global batch size:  1024 | lm loss: 1.818000E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29404/   51900 | consumed samples:     30109696 | elapsed time per iteration (ms): 37542.4 | learning rate: 9.615E-05 | global batch size:  1024 | lm loss: 1.843903E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29405/   51900 | consumed samples:     30110720 | elapsed time per iteration (ms): 37658.2 | learning rate: 9.614E-05 | global batch size:  1024 | lm loss: 1.842445E+00 | loss scale: 1.0 | grad norm: 0.094 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29406/   51900 | consumed samples:     30111744 | elapsed time per iteration (ms): 37682.3 | learning rate: 9.614E-05 | global batch size:  1024 | lm loss: 1.849439E+00 | loss scale: 1.0 | grad norm: 0.116 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29407/   51900 | consumed samples:     30112768 | elapsed time per iteration (ms): 37626.0 | learning rate: 9.613E-05 | global batch size:  1024 | lm loss: 1.851232E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29408/   51900 | consumed samples:     30113792 | elapsed time per iteration (ms): 37798.1 | learning rate: 9.613E-05 | global batch size:  1024 | lm loss: 1.835576E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29409/   51900 | consumed samples:     30114816 | elapsed time per iteration (ms): 37619.5 | learning rate: 9.612E-05 | global batch size:  1024 | lm loss: 1.823490E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29410/   51900 | consumed samples:     30115840 | elapsed time per iteration (ms): 37701.6 | learning rate: 9.612E-05 | global batch size:  1024 | lm loss: 1.844500E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29411/   51900 | consumed samples:     30116864 | elapsed time per iteration (ms): 37603.8 | learning rate: 9.611E-05 | global batch size:  1024 | lm loss: 1.832048E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29412/   51900 | consumed samples:     30117888 | elapsed time per iteration (ms): 37654.9 | learning rate: 9.611E-05 | global batch size:  1024 | lm loss: 1.844611E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29413/   51900 | consumed samples:     30118912 | elapsed time per iteration (ms): 37536.6 | learning rate: 9.610E-05 | global batch size:  1024 | lm loss: 1.829954E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29414/   51900 | consumed samples:     30119936 | elapsed time per iteration (ms): 37581.3 | learning rate: 9.609E-05 | global batch size:  1024 | lm loss: 1.824613E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29415/   51900 | consumed samples:     30120960 | elapsed time per iteration (ms): 37650.1 | learning rate: 9.609E-05 | global batch size:  1024 | lm loss: 1.825963E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29416/   51900 | consumed samples:     30121984 | elapsed time per iteration (ms): 37630.5 | learning rate: 9.608E-05 | global batch size:  1024 | lm loss: 1.840482E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29417/   51900 | consumed samples:     30123008 | elapsed time per iteration (ms): 37567.8 | learning rate: 9.608E-05 | global batch size:  1024 | lm loss: 1.844985E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29418/   51900 | consumed samples:     30124032 | elapsed time per iteration (ms): 37556.3 | learning rate: 9.607E-05 | global batch size:  1024 | lm loss: 1.863434E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29419/   51900 | consumed samples:     30125056 | elapsed time per iteration (ms): 37647.0 | learning rate: 9.607E-05 | global batch size:  1024 | lm loss: 1.816321E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29420/   51900 | consumed samples:     30126080 | elapsed time per iteration (ms): 37785.1 | learning rate: 9.606E-05 | global batch size:  1024 | lm loss: 1.834335E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29421/   51900 | consumed samples:     30127104 | elapsed time per iteration (ms): 37660.4 | learning rate: 9.606E-05 | global batch size:  1024 | lm loss: 1.835386E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29422/   51900 | consumed samples:     30128128 | elapsed time per iteration (ms): 37603.4 | learning rate: 9.605E-05 | global batch size:  1024 | lm loss: 1.827029E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29423/   51900 | consumed samples:     30129152 | elapsed time per iteration (ms): 37530.8 | learning rate: 9.604E-05 | global batch size:  1024 | lm loss: 1.816685E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29424/   51900 | consumed samples:     30130176 | elapsed time per iteration (ms): 37634.8 | learning rate: 9.604E-05 | global batch size:  1024 | lm loss: 1.817482E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29425/   51900 | consumed samples:     30131200 | elapsed time per iteration (ms): 37626.9 | learning rate: 9.603E-05 | global batch size:  1024 | lm loss: 1.841972E+00 | loss scale: 1.0 | grad norm: 0.090 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29426/   51900 | consumed samples:     30132224 | elapsed time per iteration (ms): 37802.9 | learning rate: 9.603E-05 | global batch size:  1024 | lm loss: 1.824815E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29427/   51900 | consumed samples:     30133248 | elapsed time per iteration (ms): 37703.1 | learning rate: 9.602E-05 | global batch size:  1024 | lm loss: 1.834624E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29428/   51900 | consumed samples:     30134272 | elapsed time per iteration (ms): 37619.1 | learning rate: 9.602E-05 | global batch size:  1024 | lm loss: 1.842466E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29429/   51900 | consumed samples:     30135296 | elapsed time per iteration (ms): 37673.5 | learning rate: 9.601E-05 | global batch size:  1024 | lm loss: 1.830557E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29430/   51900 | consumed samples:     30136320 | elapsed time per iteration (ms): 37771.9 | learning rate: 9.600E-05 | global batch size:  1024 | lm loss: 1.826300E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29431/   51900 | consumed samples:     30137344 | elapsed time per iteration (ms): 37747.4 | learning rate: 9.600E-05 | global batch size:  1024 | lm loss: 1.859381E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29432/   51900 | consumed samples:     30138368 | elapsed time per iteration (ms): 37541.7 | learning rate: 9.599E-05 | global batch size:  1024 | lm loss: 1.829092E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29433/   51900 | consumed samples:     30139392 | elapsed time per iteration (ms): 37654.4 | learning rate: 9.599E-05 | global batch size:  1024 | lm loss: 1.854559E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29434/   51900 | consumed samples:     30140416 | elapsed time per iteration (ms): 37617.9 | learning rate: 9.598E-05 | global batch size:  1024 | lm loss: 1.837127E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29435/   51900 | consumed samples:     30141440 | elapsed time per iteration (ms): 37632.9 | learning rate: 9.598E-05 | global batch size:  1024 | lm loss: 1.845133E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29436/   51900 | consumed samples:     30142464 | elapsed time per iteration (ms): 37627.6 | learning rate: 9.597E-05 | global batch size:  1024 | lm loss: 1.843581E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29437/   51900 | consumed samples:     30143488 | elapsed time per iteration (ms): 37695.5 | learning rate: 9.597E-05 | global batch size:  1024 | lm loss: 1.842511E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29438/   51900 | consumed samples:     30144512 | elapsed time per iteration (ms): 37649.8 | learning rate: 9.596E-05 | global batch size:  1024 | lm loss: 1.833069E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29439/   51900 | consumed samples:     30145536 | elapsed time per iteration (ms): 37655.8 | learning rate: 9.595E-05 | global batch size:  1024 | lm loss: 1.839993E+00 | loss scale: 1.0 | grad norm: 0.109 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29440/   51900 | consumed samples:     30146560 | elapsed time per iteration (ms): 37601.7 | learning rate: 9.595E-05 | global batch size:  1024 | lm loss: 1.835320E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29441/   51900 | consumed samples:     30147584 | elapsed time per iteration (ms): 37548.7 | learning rate: 9.594E-05 | global batch size:  1024 | lm loss: 1.837477E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29442/   51900 | consumed samples:     30148608 | elapsed time per iteration (ms): 37530.9 | learning rate: 9.594E-05 | global batch size:  1024 | lm loss: 1.840681E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29443/   51900 | consumed samples:     30149632 | elapsed time per iteration (ms): 37686.5 | learning rate: 9.593E-05 | global batch size:  1024 | lm loss: 1.845826E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29444/   51900 | consumed samples:     30150656 | elapsed time per iteration (ms): 37613.9 | learning rate: 9.593E-05 | global batch size:  1024 | lm loss: 1.843369E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29445/   51900 | consumed samples:     30151680 | elapsed time per iteration (ms): 37643.7 | learning rate: 9.592E-05 | global batch size:  1024 | lm loss: 1.853867E+00 | loss scale: 1.0 | grad norm: 0.271 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29446/   51900 | consumed samples:     30152704 | elapsed time per iteration (ms): 37639.9 | learning rate: 9.592E-05 | global batch size:  1024 | lm loss: 1.835307E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29447/   51900 | consumed samples:     30153728 | elapsed time per iteration (ms): 37522.8 | learning rate: 9.591E-05 | global batch size:  1024 | lm loss: 1.846036E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29448/   51900 | consumed samples:     30154752 | elapsed time per iteration (ms): 37615.6 | learning rate: 9.590E-05 | global batch size:  1024 | lm loss: 1.834363E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29449/   51900 | consumed samples:     30155776 | elapsed time per iteration (ms): 37607.7 | learning rate: 9.590E-05 | global batch size:  1024 | lm loss: 1.831953E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29450/   51900 | consumed samples:     30156800 | elapsed time per iteration (ms): 37734.3 | learning rate: 9.589E-05 | global batch size:  1024 | lm loss: 1.815953E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29451/   51900 | consumed samples:     30157824 | elapsed time per iteration (ms): 37688.6 | learning rate: 9.589E-05 | global batch size:  1024 | lm loss: 1.846651E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29452/   51900 | consumed samples:     30158848 | elapsed time per iteration (ms): 37683.2 | learning rate: 9.588E-05 | global batch size:  1024 | lm loss: 1.839592E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29453/   51900 | consumed samples:     30159872 | elapsed time per iteration (ms): 37599.7 | learning rate: 9.588E-05 | global batch size:  1024 | lm loss: 1.854702E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29454/   51900 | consumed samples:     30160896 | elapsed time per iteration (ms): 37625.8 | learning rate: 9.587E-05 | global batch size:  1024 | lm loss: 1.842849E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29455/   51900 | consumed samples:     30161920 | elapsed time per iteration (ms): 37534.8 | learning rate: 9.586E-05 | global batch size:  1024 | lm loss: 1.835291E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29456/   51900 | consumed samples:     30162944 | elapsed time per iteration (ms): 37689.8 | learning rate: 9.586E-05 | global batch size:  1024 | lm loss: 1.849292E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29457/   51900 | consumed samples:     30163968 | elapsed time per iteration (ms): 37537.4 | learning rate: 9.585E-05 | global batch size:  1024 | lm loss: 1.853522E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29458/   51900 | consumed samples:     30164992 | elapsed time per iteration (ms): 37599.5 | learning rate: 9.585E-05 | global batch size:  1024 | lm loss: 1.851047E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29459/   51900 | consumed samples:     30166016 | elapsed time per iteration (ms): 37643.7 | learning rate: 9.584E-05 | global batch size:  1024 | lm loss: 1.851198E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29460/   51900 | consumed samples:     30167040 | elapsed time per iteration (ms): 37644.7 | learning rate: 9.584E-05 | global batch size:  1024 | lm loss: 1.831301E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29461/   51900 | consumed samples:     30168064 | elapsed time per iteration (ms): 37644.5 | learning rate: 9.583E-05 | global batch size:  1024 | lm loss: 1.828995E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29462/   51900 | consumed samples:     30169088 | elapsed time per iteration (ms): 37561.1 | learning rate: 9.583E-05 | global batch size:  1024 | lm loss: 1.829522E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29463/   51900 | consumed samples:     30170112 | elapsed time per iteration (ms): 37698.2 | learning rate: 9.582E-05 | global batch size:  1024 | lm loss: 1.841172E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29464/   51900 | consumed samples:     30171136 | elapsed time per iteration (ms): 37682.4 | learning rate: 9.581E-05 | global batch size:  1024 | lm loss: 1.837570E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29465/   51900 | consumed samples:     30172160 | elapsed time per iteration (ms): 37665.1 | learning rate: 9.581E-05 | global batch size:  1024 | lm loss: 1.820773E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29466/   51900 | consumed samples:     30173184 | elapsed time per iteration (ms): 37605.5 | learning rate: 9.580E-05 | global batch size:  1024 | lm loss: 1.841960E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29467/   51900 | consumed samples:     30174208 | elapsed time per iteration (ms): 37658.4 | learning rate: 9.580E-05 | global batch size:  1024 | lm loss: 1.838613E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29468/   51900 | consumed samples:     30175232 | elapsed time per iteration (ms): 37732.1 | learning rate: 9.579E-05 | global batch size:  1024 | lm loss: 1.819481E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29469/   51900 | consumed samples:     30176256 | elapsed time per iteration (ms): 37703.7 | learning rate: 9.579E-05 | global batch size:  1024 | lm loss: 1.823993E+00 | loss scale: 1.0 | grad norm: 0.095 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29470/   51900 | consumed samples:     30177280 | elapsed time per iteration (ms): 37630.9 | learning rate: 9.578E-05 | global batch size:  1024 | lm loss: 1.848775E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29471/   51900 | consumed samples:     30178304 | elapsed time per iteration (ms): 37620.4 | learning rate: 9.578E-05 | global batch size:  1024 | lm loss: 1.838303E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29472/   51900 | consumed samples:     30179328 | elapsed time per iteration (ms): 37699.5 | learning rate: 9.577E-05 | global batch size:  1024 | lm loss: 1.842832E+00 | loss scale: 1.0 | grad norm: 0.065 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29473/   51900 | consumed samples:     30180352 | elapsed time per iteration (ms): 37623.5 | learning rate: 9.576E-05 | global batch size:  1024 | lm loss: 1.853133E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29474/   51900 | consumed samples:     30181376 | elapsed time per iteration (ms): 37661.0 | learning rate: 9.576E-05 | global batch size:  1024 | lm loss: 1.840711E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29475/   51900 | consumed samples:     30182400 | elapsed time per iteration (ms): 37589.7 | learning rate: 9.575E-05 | global batch size:  1024 | lm loss: 1.828718E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29476/   51900 | consumed samples:     30183424 | elapsed time per iteration (ms): 37605.8 | learning rate: 9.575E-05 | global batch size:  1024 | lm loss: 1.848526E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29477/   51900 | consumed samples:     30184448 | elapsed time per iteration (ms): 37588.3 | learning rate: 9.574E-05 | global batch size:  1024 | lm loss: 1.829301E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29478/   51900 | consumed samples:     30185472 | elapsed time per iteration (ms): 37665.6 | learning rate: 9.574E-05 | global batch size:  1024 | lm loss: 1.847574E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29479/   51900 | consumed samples:     30186496 | elapsed time per iteration (ms): 37698.3 | learning rate: 9.573E-05 | global batch size:  1024 | lm loss: 1.833232E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29480/   51900 | consumed samples:     30187520 | elapsed time per iteration (ms): 37589.9 | learning rate: 9.573E-05 | global batch size:  1024 | lm loss: 1.837832E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29481/   51900 | consumed samples:     30188544 | elapsed time per iteration (ms): 37708.3 | learning rate: 9.572E-05 | global batch size:  1024 | lm loss: 1.843770E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29482/   51900 | consumed samples:     30189568 | elapsed time per iteration (ms): 37656.0 | learning rate: 9.571E-05 | global batch size:  1024 | lm loss: 1.835717E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29483/   51900 | consumed samples:     30190592 | elapsed time per iteration (ms): 37620.4 | learning rate: 9.571E-05 | global batch size:  1024 | lm loss: 1.843896E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29484/   51900 | consumed samples:     30191616 | elapsed time per iteration (ms): 37760.7 | learning rate: 9.570E-05 | global batch size:  1024 | lm loss: 1.826520E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29485/   51900 | consumed samples:     30192640 | elapsed time per iteration (ms): 37662.9 | learning rate: 9.570E-05 | global batch size:  1024 | lm loss: 1.825606E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29486/   51900 | consumed samples:     30193664 | elapsed time per iteration (ms): 37707.7 | learning rate: 9.569E-05 | global batch size:  1024 | lm loss: 1.843774E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29487/   51900 | consumed samples:     30194688 | elapsed time per iteration (ms): 37612.4 | learning rate: 9.569E-05 | global batch size:  1024 | lm loss: 1.842597E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29488/   51900 | consumed samples:     30195712 | elapsed time per iteration (ms): 37643.3 | learning rate: 9.568E-05 | global batch size:  1024 | lm loss: 1.852019E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29489/   51900 | consumed samples:     30196736 | elapsed time per iteration (ms): 37631.1 | learning rate: 9.567E-05 | global batch size:  1024 | lm loss: 1.815368E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29490/   51900 | consumed samples:     30197760 | elapsed time per iteration (ms): 37617.5 | learning rate: 9.567E-05 | global batch size:  1024 | lm loss: 1.855277E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29491/   51900 | consumed samples:     30198784 | elapsed time per iteration (ms): 37823.0 | learning rate: 9.566E-05 | global batch size:  1024 | lm loss: 1.844139E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29492/   51900 | consumed samples:     30199808 | elapsed time per iteration (ms): 37543.0 | learning rate: 9.566E-05 | global batch size:  1024 | lm loss: 1.823113E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29493/   51900 | consumed samples:     30200832 | elapsed time per iteration (ms): 37589.6 | learning rate: 9.565E-05 | global batch size:  1024 | lm loss: 1.854819E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29494/   51900 | consumed samples:     30201856 | elapsed time per iteration (ms): 37678.4 | learning rate: 9.565E-05 | global batch size:  1024 | lm loss: 1.826215E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29495/   51900 | consumed samples:     30202880 | elapsed time per iteration (ms): 37608.6 | learning rate: 9.564E-05 | global batch size:  1024 | lm loss: 1.825197E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29496/   51900 | consumed samples:     30203904 | elapsed time per iteration (ms): 37594.0 | learning rate: 9.564E-05 | global batch size:  1024 | lm loss: 1.847612E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29497/   51900 | consumed samples:     30204928 | elapsed time per iteration (ms): 37576.6 | learning rate: 9.563E-05 | global batch size:  1024 | lm loss: 1.849912E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29498/   51900 | consumed samples:     30205952 | elapsed time per iteration (ms): 37692.1 | learning rate: 9.562E-05 | global batch size:  1024 | lm loss: 1.824142E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29499/   51900 | consumed samples:     30206976 | elapsed time per iteration (ms): 37586.7 | learning rate: 9.562E-05 | global batch size:  1024 | lm loss: 1.833470E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29500/   51900 | consumed samples:     30208000 | elapsed time per iteration (ms): 37696.6 | learning rate: 9.561E-05 | global batch size:  1024 | lm loss: 1.838627E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    save-checkpoint ................................: (161889.89, 161889.97)
 iteration    29501/   51900 | consumed samples:     30209024 | elapsed time per iteration (ms): 37195.2 | learning rate: 9.561E-05 | global batch size:  1024 | lm loss: 1.845265E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29502/   51900 | consumed samples:     30210048 | elapsed time per iteration (ms): 37707.8 | learning rate: 9.560E-05 | global batch size:  1024 | lm loss: 1.840669E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29503/   51900 | consumed samples:     30211072 | elapsed time per iteration (ms): 37515.0 | learning rate: 9.560E-05 | global batch size:  1024 | lm loss: 1.831928E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29504/   51900 | consumed samples:     30212096 | elapsed time per iteration (ms): 37766.3 | learning rate: 9.559E-05 | global batch size:  1024 | lm loss: 1.825774E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29505/   51900 | consumed samples:     30213120 | elapsed time per iteration (ms): 37741.2 | learning rate: 9.559E-05 | global batch size:  1024 | lm loss: 1.838681E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29506/   51900 | consumed samples:     30214144 | elapsed time per iteration (ms): 37781.6 | learning rate: 9.558E-05 | global batch size:  1024 | lm loss: 1.836276E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29507/   51900 | consumed samples:     30215168 | elapsed time per iteration (ms): 37523.3 | learning rate: 9.557E-05 | global batch size:  1024 | lm loss: 1.832692E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29508/   51900 | consumed samples:     30216192 | elapsed time per iteration (ms): 37582.9 | learning rate: 9.557E-05 | global batch size:  1024 | lm loss: 1.832663E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29509/   51900 | consumed samples:     30217216 | elapsed time per iteration (ms): 37663.6 | learning rate: 9.556E-05 | global batch size:  1024 | lm loss: 1.840395E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29510/   51900 | consumed samples:     30218240 | elapsed time per iteration (ms): 37680.0 | learning rate: 9.556E-05 | global batch size:  1024 | lm loss: 1.814648E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29511/   51900 | consumed samples:     30219264 | elapsed time per iteration (ms): 37664.1 | learning rate: 9.555E-05 | global batch size:  1024 | lm loss: 1.834571E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29512/   51900 | consumed samples:     30220288 | elapsed time per iteration (ms): 37757.6 | learning rate: 9.555E-05 | global batch size:  1024 | lm loss: 1.833361E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29513/   51900 | consumed samples:     30221312 | elapsed time per iteration (ms): 37663.3 | learning rate: 9.554E-05 | global batch size:  1024 | lm loss: 1.830610E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29514/   51900 | consumed samples:     30222336 | elapsed time per iteration (ms): 37586.8 | learning rate: 9.553E-05 | global batch size:  1024 | lm loss: 1.833261E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29515/   51900 | consumed samples:     30223360 | elapsed time per iteration (ms): 37765.6 | learning rate: 9.553E-05 | global batch size:  1024 | lm loss: 1.824595E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29516/   51900 | consumed samples:     30224384 | elapsed time per iteration (ms): 37573.7 | learning rate: 9.552E-05 | global batch size:  1024 | lm loss: 1.846700E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29517/   51900 | consumed samples:     30225408 | elapsed time per iteration (ms): 37604.0 | learning rate: 9.552E-05 | global batch size:  1024 | lm loss: 1.836573E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29518/   51900 | consumed samples:     30226432 | elapsed time per iteration (ms): 37778.8 | learning rate: 9.551E-05 | global batch size:  1024 | lm loss: 1.828819E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29519/   51900 | consumed samples:     30227456 | elapsed time per iteration (ms): 37610.1 | learning rate: 9.551E-05 | global batch size:  1024 | lm loss: 1.840200E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29520/   51900 | consumed samples:     30228480 | elapsed time per iteration (ms): 37668.8 | learning rate: 9.550E-05 | global batch size:  1024 | lm loss: 1.833839E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29521/   51900 | consumed samples:     30229504 | elapsed time per iteration (ms): 37564.6 | learning rate: 9.550E-05 | global batch size:  1024 | lm loss: 1.829004E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29522/   51900 | consumed samples:     30230528 | elapsed time per iteration (ms): 37572.2 | learning rate: 9.549E-05 | global batch size:  1024 | lm loss: 1.831515E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29523/   51900 | consumed samples:     30231552 | elapsed time per iteration (ms): 37595.1 | learning rate: 9.548E-05 | global batch size:  1024 | lm loss: 1.832923E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29524/   51900 | consumed samples:     30232576 | elapsed time per iteration (ms): 37675.5 | learning rate: 9.548E-05 | global batch size:  1024 | lm loss: 1.835143E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29525/   51900 | consumed samples:     30233600 | elapsed time per iteration (ms): 37690.9 | learning rate: 9.547E-05 | global batch size:  1024 | lm loss: 1.843408E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29526/   51900 | consumed samples:     30234624 | elapsed time per iteration (ms): 37605.0 | learning rate: 9.547E-05 | global batch size:  1024 | lm loss: 1.822652E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29527/   51900 | consumed samples:     30235648 | elapsed time per iteration (ms): 37589.9 | learning rate: 9.546E-05 | global batch size:  1024 | lm loss: 1.835129E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29528/   51900 | consumed samples:     30236672 | elapsed time per iteration (ms): 37584.9 | learning rate: 9.546E-05 | global batch size:  1024 | lm loss: 1.843932E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29529/   51900 | consumed samples:     30237696 | elapsed time per iteration (ms): 37587.3 | learning rate: 9.545E-05 | global batch size:  1024 | lm loss: 1.854107E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29530/   51900 | consumed samples:     30238720 | elapsed time per iteration (ms): 37665.1 | learning rate: 9.545E-05 | global batch size:  1024 | lm loss: 1.834052E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29531/   51900 | consumed samples:     30239744 | elapsed time per iteration (ms): 37651.3 | learning rate: 9.544E-05 | global batch size:  1024 | lm loss: 1.828518E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29532/   51900 | consumed samples:     30240768 | elapsed time per iteration (ms): 37717.2 | learning rate: 9.543E-05 | global batch size:  1024 | lm loss: 1.819431E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29533/   51900 | consumed samples:     30241792 | elapsed time per iteration (ms): 37834.2 | learning rate: 9.543E-05 | global batch size:  1024 | lm loss: 1.844152E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29534/   51900 | consumed samples:     30242816 | elapsed time per iteration (ms): 37613.5 | learning rate: 9.542E-05 | global batch size:  1024 | lm loss: 1.838706E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29535/   51900 | consumed samples:     30243840 | elapsed time per iteration (ms): 37497.8 | learning rate: 9.542E-05 | global batch size:  1024 | lm loss: 1.833970E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29536/   51900 | consumed samples:     30244864 | elapsed time per iteration (ms): 37759.5 | learning rate: 9.541E-05 | global batch size:  1024 | lm loss: 1.814077E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29537/   51900 | consumed samples:     30245888 | elapsed time per iteration (ms): 37667.9 | learning rate: 9.541E-05 | global batch size:  1024 | lm loss: 1.814923E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29538/   51900 | consumed samples:     30246912 | elapsed time per iteration (ms): 37673.1 | learning rate: 9.540E-05 | global batch size:  1024 | lm loss: 1.855882E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29539/   51900 | consumed samples:     30247936 | elapsed time per iteration (ms): 37634.3 | learning rate: 9.540E-05 | global batch size:  1024 | lm loss: 1.849173E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    29540/   51900 | consumed samples:     30248960 | elapsed time per iteration (ms): 37663.7 | learning rate: 9.539E-05 | global batch size:  1024 | lm loss: 1.847575E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
