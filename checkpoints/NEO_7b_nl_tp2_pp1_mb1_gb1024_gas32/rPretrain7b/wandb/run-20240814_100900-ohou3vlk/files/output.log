/data/xunjian_yin/mycode/MAP-NEO/Megatron-LM-NEO/megatron/checkpointing.py:422: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state_dict = torch.load(checkpoint_name, map_location='cpu')
/data/xunjian_yin/miniconda3/envs/apex1/lib/python3.10/site-packages/transformer_engine/pytorch/module/base.py:407: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state = torch.load(state, map_location='cuda')
/data/xunjian_yin/miniconda3/envs/apex1/lib/python3.10/site-packages/torch/distributed/c10d_logger.py:79: FutureWarning: `torch.distributed._all_gather_base` is a private function and will be deprecated. Please use `torch.distributed.all_gather_into_tensor` instead.
  return func(*args, **kwargs)
(min, max) time across ranks (ms):
    load-checkpoint ................................: (59678.58, 59678.66)
(min, max) time across ranks (ms):
    model-and-optimizer-setup ......................: (60685.56, 60798.21)
    train/valid/test-data-iterators-setup ..........: (10472.49, 14208.69)
/data/xunjian_yin/mycode/MAP-NEO/Megatron-LM-NEO/megatron/core/tensor_parallel/layers.py:396: FutureWarning: `torch.distributed._reduce_scatter_base` is a private function and will be deprecated. Please use `torch.distributed.reduce_scatter_tensor` instead.
  handle = torch.distributed._reduce_scatter_base(
/data/xunjian_yin/mycode/MAP-NEO/Megatron-LM-NEO/megatron/core/distributed/grad_buffer.py:104: FutureWarning: `torch.distributed._reduce_scatter_base` is a private function and will be deprecated. Please use `torch.distributed.reduce_scatter_tensor` instead.
  self.communication_handle = torch.distributed._reduce_scatter_base(
 iteration    20501/   51900 | consumed samples:     20993024 | elapsed time per iteration (ms): 46622.4 | learning rate: 1.455E-04 | global batch size:  1024 | lm loss: 1.894045E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
/data/xunjian_yin/mycode/MAP-NEO/Megatron-LM-NEO/megatron/training.py:533: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1720538438429/work/torch/csrc/tensor/python_tensor.cpp:78.)
  key, torch.cuda.FloatTensor([0.0])) + loss_dict[key]
 iteration    20502/   51900 | consumed samples:     20994048 | elapsed time per iteration (ms): 37570.4 | learning rate: 1.455E-04 | global batch size:  1024 | lm loss: 1.875348E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20503/   51900 | consumed samples:     20995072 | elapsed time per iteration (ms): 37645.3 | learning rate: 1.455E-04 | global batch size:  1024 | lm loss: 1.877137E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20504/   51900 | consumed samples:     20996096 | elapsed time per iteration (ms): 37730.8 | learning rate: 1.455E-04 | global batch size:  1024 | lm loss: 1.871170E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20505/   51900 | consumed samples:     20997120 | elapsed time per iteration (ms): 37586.0 | learning rate: 1.455E-04 | global batch size:  1024 | lm loss: 1.882091E+00 | loss scale: 1.0 | grad norm: 0.090 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20506/   51900 | consumed samples:     20998144 | elapsed time per iteration (ms): 37562.9 | learning rate: 1.455E-04 | global batch size:  1024 | lm loss: 1.880402E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20507/   51900 | consumed samples:     20999168 | elapsed time per iteration (ms): 37585.3 | learning rate: 1.455E-04 | global batch size:  1024 | lm loss: 1.893805E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20508/   51900 | consumed samples:     21000192 | elapsed time per iteration (ms): 37653.1 | learning rate: 1.455E-04 | global batch size:  1024 | lm loss: 1.872995E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20509/   51900 | consumed samples:     21001216 | elapsed time per iteration (ms): 37621.4 | learning rate: 1.455E-04 | global batch size:  1024 | lm loss: 1.900505E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20510/   51900 | consumed samples:     21002240 | elapsed time per iteration (ms): 37742.9 | learning rate: 1.455E-04 | global batch size:  1024 | lm loss: 1.884123E+00 | loss scale: 1.0 | grad norm: 0.090 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20511/   51900 | consumed samples:     21003264 | elapsed time per iteration (ms): 37742.4 | learning rate: 1.455E-04 | global batch size:  1024 | lm loss: 1.874313E+00 | loss scale: 1.0 | grad norm: 0.089 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20512/   51900 | consumed samples:     21004288 | elapsed time per iteration (ms): 37694.0 | learning rate: 1.455E-04 | global batch size:  1024 | lm loss: 1.869707E+00 | loss scale: 1.0 | grad norm: 0.088 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20513/   51900 | consumed samples:     21005312 | elapsed time per iteration (ms): 37538.2 | learning rate: 1.455E-04 | global batch size:  1024 | lm loss: 1.898023E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20514/   51900 | consumed samples:     21006336 | elapsed time per iteration (ms): 37609.3 | learning rate: 1.455E-04 | global batch size:  1024 | lm loss: 1.871320E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20515/   51900 | consumed samples:     21007360 | elapsed time per iteration (ms): 37634.0 | learning rate: 1.455E-04 | global batch size:  1024 | lm loss: 1.868277E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20516/   51900 | consumed samples:     21008384 | elapsed time per iteration (ms): 37687.0 | learning rate: 1.455E-04 | global batch size:  1024 | lm loss: 1.905127E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20517/   51900 | consumed samples:     21009408 | elapsed time per iteration (ms): 37665.6 | learning rate: 1.455E-04 | global batch size:  1024 | lm loss: 1.897750E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20518/   51900 | consumed samples:     21010432 | elapsed time per iteration (ms): 37515.5 | learning rate: 1.455E-04 | global batch size:  1024 | lm loss: 1.873012E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20519/   51900 | consumed samples:     21011456 | elapsed time per iteration (ms): 37649.5 | learning rate: 1.455E-04 | global batch size:  1024 | lm loss: 1.876107E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20520/   51900 | consumed samples:     21012480 | elapsed time per iteration (ms): 37586.4 | learning rate: 1.454E-04 | global batch size:  1024 | lm loss: 1.883039E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20521/   51900 | consumed samples:     21013504 | elapsed time per iteration (ms): 37632.5 | learning rate: 1.454E-04 | global batch size:  1024 | lm loss: 1.887611E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20522/   51900 | consumed samples:     21014528 | elapsed time per iteration (ms): 37584.4 | learning rate: 1.454E-04 | global batch size:  1024 | lm loss: 1.913866E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20523/   51900 | consumed samples:     21015552 | elapsed time per iteration (ms): 37554.2 | learning rate: 1.454E-04 | global batch size:  1024 | lm loss: 1.878522E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20524/   51900 | consumed samples:     21016576 | elapsed time per iteration (ms): 37614.4 | learning rate: 1.454E-04 | global batch size:  1024 | lm loss: 1.902410E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20525/   51900 | consumed samples:     21017600 | elapsed time per iteration (ms): 37713.3 | learning rate: 1.454E-04 | global batch size:  1024 | lm loss: 1.888126E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20526/   51900 | consumed samples:     21018624 | elapsed time per iteration (ms): 37656.5 | learning rate: 1.454E-04 | global batch size:  1024 | lm loss: 1.871030E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20527/   51900 | consumed samples:     21019648 | elapsed time per iteration (ms): 37726.0 | learning rate: 1.454E-04 | global batch size:  1024 | lm loss: 1.897019E+00 | loss scale: 1.0 | grad norm: 0.092 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20528/   51900 | consumed samples:     21020672 | elapsed time per iteration (ms): 37680.4 | learning rate: 1.454E-04 | global batch size:  1024 | lm loss: 1.868130E+00 | loss scale: 1.0 | grad norm: 0.098 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20529/   51900 | consumed samples:     21021696 | elapsed time per iteration (ms): 37585.5 | learning rate: 1.454E-04 | global batch size:  1024 | lm loss: 1.899690E+00 | loss scale: 1.0 | grad norm: 0.094 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20530/   51900 | consumed samples:     21022720 | elapsed time per iteration (ms): 37592.3 | learning rate: 1.454E-04 | global batch size:  1024 | lm loss: 1.891886E+00 | loss scale: 1.0 | grad norm: 0.088 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20531/   51900 | consumed samples:     21023744 | elapsed time per iteration (ms): 37590.5 | learning rate: 1.454E-04 | global batch size:  1024 | lm loss: 1.882616E+00 | loss scale: 1.0 | grad norm: 0.093 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20532/   51900 | consumed samples:     21024768 | elapsed time per iteration (ms): 37632.6 | learning rate: 1.454E-04 | global batch size:  1024 | lm loss: 1.885387E+00 | loss scale: 1.0 | grad norm: 0.093 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20533/   51900 | consumed samples:     21025792 | elapsed time per iteration (ms): 37683.5 | learning rate: 1.454E-04 | global batch size:  1024 | lm loss: 1.894419E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20534/   51900 | consumed samples:     21026816 | elapsed time per iteration (ms): 37641.0 | learning rate: 1.454E-04 | global batch size:  1024 | lm loss: 1.881533E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20535/   51900 | consumed samples:     21027840 | elapsed time per iteration (ms): 37622.8 | learning rate: 1.454E-04 | global batch size:  1024 | lm loss: 1.906236E+00 | loss scale: 1.0 | grad norm: 0.094 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20536/   51900 | consumed samples:     21028864 | elapsed time per iteration (ms): 37626.2 | learning rate: 1.454E-04 | global batch size:  1024 | lm loss: 1.867523E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20537/   51900 | consumed samples:     21029888 | elapsed time per iteration (ms): 37653.7 | learning rate: 1.454E-04 | global batch size:  1024 | lm loss: 1.887490E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20538/   51900 | consumed samples:     21030912 | elapsed time per iteration (ms): 37563.9 | learning rate: 1.454E-04 | global batch size:  1024 | lm loss: 1.881686E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20539/   51900 | consumed samples:     21031936 | elapsed time per iteration (ms): 37598.4 | learning rate: 1.453E-04 | global batch size:  1024 | lm loss: 1.888398E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20540/   51900 | consumed samples:     21032960 | elapsed time per iteration (ms): 37591.3 | learning rate: 1.453E-04 | global batch size:  1024 | lm loss: 1.891934E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20541/   51900 | consumed samples:     21033984 | elapsed time per iteration (ms): 37632.2 | learning rate: 1.453E-04 | global batch size:  1024 | lm loss: 1.879075E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20542/   51900 | consumed samples:     21035008 | elapsed time per iteration (ms): 37622.6 | learning rate: 1.453E-04 | global batch size:  1024 | lm loss: 1.865018E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20543/   51900 | consumed samples:     21036032 | elapsed time per iteration (ms): 37731.3 | learning rate: 1.453E-04 | global batch size:  1024 | lm loss: 1.866228E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20544/   51900 | consumed samples:     21037056 | elapsed time per iteration (ms): 37581.6 | learning rate: 1.453E-04 | global batch size:  1024 | lm loss: 1.887074E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20545/   51900 | consumed samples:     21038080 | elapsed time per iteration (ms): 37651.1 | learning rate: 1.453E-04 | global batch size:  1024 | lm loss: 1.888644E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20546/   51900 | consumed samples:     21039104 | elapsed time per iteration (ms): 37692.8 | learning rate: 1.453E-04 | global batch size:  1024 | lm loss: 1.867971E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20547/   51900 | consumed samples:     21040128 | elapsed time per iteration (ms): 37563.5 | learning rate: 1.453E-04 | global batch size:  1024 | lm loss: 1.877036E+00 | loss scale: 1.0 | grad norm: 0.092 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20548/   51900 | consumed samples:     21041152 | elapsed time per iteration (ms): 37679.3 | learning rate: 1.453E-04 | global batch size:  1024 | lm loss: 1.878168E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20549/   51900 | consumed samples:     21042176 | elapsed time per iteration (ms): 37649.0 | learning rate: 1.453E-04 | global batch size:  1024 | lm loss: 1.874603E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20550/   51900 | consumed samples:     21043200 | elapsed time per iteration (ms): 37614.1 | learning rate: 1.453E-04 | global batch size:  1024 | lm loss: 1.892876E+00 | loss scale: 1.0 | grad norm: 0.096 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20551/   51900 | consumed samples:     21044224 | elapsed time per iteration (ms): 37638.9 | learning rate: 1.453E-04 | global batch size:  1024 | lm loss: 1.883631E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20552/   51900 | consumed samples:     21045248 | elapsed time per iteration (ms): 37612.9 | learning rate: 1.453E-04 | global batch size:  1024 | lm loss: 1.891059E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20553/   51900 | consumed samples:     21046272 | elapsed time per iteration (ms): 37538.9 | learning rate: 1.453E-04 | global batch size:  1024 | lm loss: 1.882972E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20554/   51900 | consumed samples:     21047296 | elapsed time per iteration (ms): 37627.0 | learning rate: 1.453E-04 | global batch size:  1024 | lm loss: 1.886092E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20555/   51900 | consumed samples:     21048320 | elapsed time per iteration (ms): 37587.8 | learning rate: 1.453E-04 | global batch size:  1024 | lm loss: 1.881634E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20556/   51900 | consumed samples:     21049344 | elapsed time per iteration (ms): 37637.3 | learning rate: 1.453E-04 | global batch size:  1024 | lm loss: 1.877246E+00 | loss scale: 1.0 | grad norm: 0.089 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20557/   51900 | consumed samples:     21050368 | elapsed time per iteration (ms): 37748.3 | learning rate: 1.453E-04 | global batch size:  1024 | lm loss: 1.880666E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20558/   51900 | consumed samples:     21051392 | elapsed time per iteration (ms): 37650.6 | learning rate: 1.452E-04 | global batch size:  1024 | lm loss: 1.877537E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20559/   51900 | consumed samples:     21052416 | elapsed time per iteration (ms): 37599.8 | learning rate: 1.452E-04 | global batch size:  1024 | lm loss: 1.880258E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20560/   51900 | consumed samples:     21053440 | elapsed time per iteration (ms): 37575.2 | learning rate: 1.452E-04 | global batch size:  1024 | lm loss: 1.873801E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20561/   51900 | consumed samples:     21054464 | elapsed time per iteration (ms): 37730.4 | learning rate: 1.452E-04 | global batch size:  1024 | lm loss: 1.872884E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20562/   51900 | consumed samples:     21055488 | elapsed time per iteration (ms): 37589.7 | learning rate: 1.452E-04 | global batch size:  1024 | lm loss: 1.887351E+00 | loss scale: 1.0 | grad norm: 0.090 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20563/   51900 | consumed samples:     21056512 | elapsed time per iteration (ms): 37568.5 | learning rate: 1.452E-04 | global batch size:  1024 | lm loss: 1.903092E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20564/   51900 | consumed samples:     21057536 | elapsed time per iteration (ms): 37666.5 | learning rate: 1.452E-04 | global batch size:  1024 | lm loss: 1.890720E+00 | loss scale: 1.0 | grad norm: 0.096 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20565/   51900 | consumed samples:     21058560 | elapsed time per iteration (ms): 37635.7 | learning rate: 1.452E-04 | global batch size:  1024 | lm loss: 1.872348E+00 | loss scale: 1.0 | grad norm: 0.087 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20566/   51900 | consumed samples:     21059584 | elapsed time per iteration (ms): 37703.5 | learning rate: 1.452E-04 | global batch size:  1024 | lm loss: 1.875368E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20567/   51900 | consumed samples:     21060608 | elapsed time per iteration (ms): 37565.2 | learning rate: 1.452E-04 | global batch size:  1024 | lm loss: 1.896475E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20568/   51900 | consumed samples:     21061632 | elapsed time per iteration (ms): 37637.2 | learning rate: 1.452E-04 | global batch size:  1024 | lm loss: 1.879072E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20569/   51900 | consumed samples:     21062656 | elapsed time per iteration (ms): 37681.3 | learning rate: 1.452E-04 | global batch size:  1024 | lm loss: 1.885411E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20570/   51900 | consumed samples:     21063680 | elapsed time per iteration (ms): 37572.6 | learning rate: 1.452E-04 | global batch size:  1024 | lm loss: 1.881817E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20571/   51900 | consumed samples:     21064704 | elapsed time per iteration (ms): 37826.8 | learning rate: 1.452E-04 | global batch size:  1024 | lm loss: 1.908567E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20572/   51900 | consumed samples:     21065728 | elapsed time per iteration (ms): 37591.0 | learning rate: 1.452E-04 | global batch size:  1024 | lm loss: 1.879080E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20573/   51900 | consumed samples:     21066752 | elapsed time per iteration (ms): 37630.5 | learning rate: 1.452E-04 | global batch size:  1024 | lm loss: 1.876086E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20574/   51900 | consumed samples:     21067776 | elapsed time per iteration (ms): 37639.5 | learning rate: 1.452E-04 | global batch size:  1024 | lm loss: 1.876733E+00 | loss scale: 1.0 | grad norm: 0.088 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20575/   51900 | consumed samples:     21068800 | elapsed time per iteration (ms): 37654.2 | learning rate: 1.452E-04 | global batch size:  1024 | lm loss: 1.879554E+00 | loss scale: 1.0 | grad norm: 0.087 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20576/   51900 | consumed samples:     21069824 | elapsed time per iteration (ms): 37607.9 | learning rate: 1.452E-04 | global batch size:  1024 | lm loss: 1.885761E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20577/   51900 | consumed samples:     21070848 | elapsed time per iteration (ms): 37633.3 | learning rate: 1.451E-04 | global batch size:  1024 | lm loss: 1.883574E+00 | loss scale: 1.0 | grad norm: 0.091 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20578/   51900 | consumed samples:     21071872 | elapsed time per iteration (ms): 37647.9 | learning rate: 1.451E-04 | global batch size:  1024 | lm loss: 1.873269E+00 | loss scale: 1.0 | grad norm: 0.092 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20579/   51900 | consumed samples:     21072896 | elapsed time per iteration (ms): 37683.5 | learning rate: 1.451E-04 | global batch size:  1024 | lm loss: 1.884200E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20580/   51900 | consumed samples:     21073920 | elapsed time per iteration (ms): 37626.2 | learning rate: 1.451E-04 | global batch size:  1024 | lm loss: 1.873761E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20581/   51900 | consumed samples:     21074944 | elapsed time per iteration (ms): 37667.7 | learning rate: 1.451E-04 | global batch size:  1024 | lm loss: 1.868598E+00 | loss scale: 1.0 | grad norm: 0.091 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20582/   51900 | consumed samples:     21075968 | elapsed time per iteration (ms): 37595.1 | learning rate: 1.451E-04 | global batch size:  1024 | lm loss: 1.882262E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20583/   51900 | consumed samples:     21076992 | elapsed time per iteration (ms): 37626.8 | learning rate: 1.451E-04 | global batch size:  1024 | lm loss: 1.901222E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20584/   51900 | consumed samples:     21078016 | elapsed time per iteration (ms): 37624.5 | learning rate: 1.451E-04 | global batch size:  1024 | lm loss: 1.873286E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20585/   51900 | consumed samples:     21079040 | elapsed time per iteration (ms): 37601.8 | learning rate: 1.451E-04 | global batch size:  1024 | lm loss: 1.888511E+00 | loss scale: 1.0 | grad norm: 0.090 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20586/   51900 | consumed samples:     21080064 | elapsed time per iteration (ms): 37598.0 | learning rate: 1.451E-04 | global batch size:  1024 | lm loss: 1.884158E+00 | loss scale: 1.0 | grad norm: 0.093 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20587/   51900 | consumed samples:     21081088 | elapsed time per iteration (ms): 37642.7 | learning rate: 1.451E-04 | global batch size:  1024 | lm loss: 1.891209E+00 | loss scale: 1.0 | grad norm: 0.093 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20588/   51900 | consumed samples:     21082112 | elapsed time per iteration (ms): 37678.7 | learning rate: 1.451E-04 | global batch size:  1024 | lm loss: 1.890068E+00 | loss scale: 1.0 | grad norm: 0.092 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20589/   51900 | consumed samples:     21083136 | elapsed time per iteration (ms): 37668.5 | learning rate: 1.451E-04 | global batch size:  1024 | lm loss: 1.900406E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20590/   51900 | consumed samples:     21084160 | elapsed time per iteration (ms): 37529.1 | learning rate: 1.451E-04 | global batch size:  1024 | lm loss: 1.885636E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20591/   51900 | consumed samples:     21085184 | elapsed time per iteration (ms): 37753.1 | learning rate: 1.451E-04 | global batch size:  1024 | lm loss: 1.889305E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20592/   51900 | consumed samples:     21086208 | elapsed time per iteration (ms): 37654.4 | learning rate: 1.451E-04 | global batch size:  1024 | lm loss: 1.884957E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20593/   51900 | consumed samples:     21087232 | elapsed time per iteration (ms): 37674.7 | learning rate: 1.451E-04 | global batch size:  1024 | lm loss: 1.892839E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20594/   51900 | consumed samples:     21088256 | elapsed time per iteration (ms): 37598.4 | learning rate: 1.451E-04 | global batch size:  1024 | lm loss: 1.874875E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20595/   51900 | consumed samples:     21089280 | elapsed time per iteration (ms): 37633.1 | learning rate: 1.451E-04 | global batch size:  1024 | lm loss: 1.884258E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20596/   51900 | consumed samples:     21090304 | elapsed time per iteration (ms): 37665.6 | learning rate: 1.451E-04 | global batch size:  1024 | lm loss: 1.879830E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20597/   51900 | consumed samples:     21091328 | elapsed time per iteration (ms): 37649.6 | learning rate: 1.450E-04 | global batch size:  1024 | lm loss: 1.884988E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20598/   51900 | consumed samples:     21092352 | elapsed time per iteration (ms): 37568.8 | learning rate: 1.450E-04 | global batch size:  1024 | lm loss: 1.902581E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20599/   51900 | consumed samples:     21093376 | elapsed time per iteration (ms): 37629.6 | learning rate: 1.450E-04 | global batch size:  1024 | lm loss: 1.892948E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20600/   51900 | consumed samples:     21094400 | elapsed time per iteration (ms): 37579.1 | learning rate: 1.450E-04 | global batch size:  1024 | lm loss: 1.895808E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20601/   51900 | consumed samples:     21095424 | elapsed time per iteration (ms): 37629.8 | learning rate: 1.450E-04 | global batch size:  1024 | lm loss: 1.879263E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20602/   51900 | consumed samples:     21096448 | elapsed time per iteration (ms): 37661.9 | learning rate: 1.450E-04 | global batch size:  1024 | lm loss: 1.885283E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20603/   51900 | consumed samples:     21097472 | elapsed time per iteration (ms): 37621.7 | learning rate: 1.450E-04 | global batch size:  1024 | lm loss: 1.893282E+00 | loss scale: 1.0 | grad norm: 0.092 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20604/   51900 | consumed samples:     21098496 | elapsed time per iteration (ms): 37567.3 | learning rate: 1.450E-04 | global batch size:  1024 | lm loss: 1.883790E+00 | loss scale: 1.0 | grad norm: 0.097 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20605/   51900 | consumed samples:     21099520 | elapsed time per iteration (ms): 37512.1 | learning rate: 1.450E-04 | global batch size:  1024 | lm loss: 1.887302E+00 | loss scale: 1.0 | grad norm: 0.103 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20606/   51900 | consumed samples:     21100544 | elapsed time per iteration (ms): 37559.9 | learning rate: 1.450E-04 | global batch size:  1024 | lm loss: 1.894059E+00 | loss scale: 1.0 | grad norm: 0.095 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20607/   51900 | consumed samples:     21101568 | elapsed time per iteration (ms): 37650.4 | learning rate: 1.450E-04 | global batch size:  1024 | lm loss: 1.890701E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20608/   51900 | consumed samples:     21102592 | elapsed time per iteration (ms): 37646.6 | learning rate: 1.450E-04 | global batch size:  1024 | lm loss: 1.912543E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20609/   51900 | consumed samples:     21103616 | elapsed time per iteration (ms): 37609.8 | learning rate: 1.450E-04 | global batch size:  1024 | lm loss: 1.882467E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20610/   51900 | consumed samples:     21104640 | elapsed time per iteration (ms): 37545.7 | learning rate: 1.450E-04 | global batch size:  1024 | lm loss: 1.891629E+00 | loss scale: 1.0 | grad norm: 0.089 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20611/   51900 | consumed samples:     21105664 | elapsed time per iteration (ms): 37682.2 | learning rate: 1.450E-04 | global batch size:  1024 | lm loss: 1.873233E+00 | loss scale: 1.0 | grad norm: 0.091 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20612/   51900 | consumed samples:     21106688 | elapsed time per iteration (ms): 37624.3 | learning rate: 1.450E-04 | global batch size:  1024 | lm loss: 1.869225E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20613/   51900 | consumed samples:     21107712 | elapsed time per iteration (ms): 37530.5 | learning rate: 1.450E-04 | global batch size:  1024 | lm loss: 1.880601E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20614/   51900 | consumed samples:     21108736 | elapsed time per iteration (ms): 37549.5 | learning rate: 1.450E-04 | global batch size:  1024 | lm loss: 1.882457E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20615/   51900 | consumed samples:     21109760 | elapsed time per iteration (ms): 37592.1 | learning rate: 1.450E-04 | global batch size:  1024 | lm loss: 1.880102E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20616/   51900 | consumed samples:     21110784 | elapsed time per iteration (ms): 37612.1 | learning rate: 1.449E-04 | global batch size:  1024 | lm loss: 1.892540E+00 | loss scale: 1.0 | grad norm: 0.092 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20617/   51900 | consumed samples:     21111808 | elapsed time per iteration (ms): 37656.6 | learning rate: 1.449E-04 | global batch size:  1024 | lm loss: 1.894499E+00 | loss scale: 1.0 | grad norm: 0.089 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20618/   51900 | consumed samples:     21112832 | elapsed time per iteration (ms): 37632.3 | learning rate: 1.449E-04 | global batch size:  1024 | lm loss: 1.879984E+00 | loss scale: 1.0 | grad norm: 0.093 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20619/   51900 | consumed samples:     21113856 | elapsed time per iteration (ms): 37660.9 | learning rate: 1.449E-04 | global batch size:  1024 | lm loss: 1.860954E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20620/   51900 | consumed samples:     21114880 | elapsed time per iteration (ms): 37715.2 | learning rate: 1.449E-04 | global batch size:  1024 | lm loss: 1.887089E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20621/   51900 | consumed samples:     21115904 | elapsed time per iteration (ms): 37646.5 | learning rate: 1.449E-04 | global batch size:  1024 | lm loss: 1.884110E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20622/   51900 | consumed samples:     21116928 | elapsed time per iteration (ms): 37609.6 | learning rate: 1.449E-04 | global batch size:  1024 | lm loss: 1.901857E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20623/   51900 | consumed samples:     21117952 | elapsed time per iteration (ms): 37597.4 | learning rate: 1.449E-04 | global batch size:  1024 | lm loss: 1.893340E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20624/   51900 | consumed samples:     21118976 | elapsed time per iteration (ms): 37591.8 | learning rate: 1.449E-04 | global batch size:  1024 | lm loss: 1.887995E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20625/   51900 | consumed samples:     21120000 | elapsed time per iteration (ms): 37758.3 | learning rate: 1.449E-04 | global batch size:  1024 | lm loss: 1.878780E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20626/   51900 | consumed samples:     21121024 | elapsed time per iteration (ms): 37643.1 | learning rate: 1.449E-04 | global batch size:  1024 | lm loss: 1.892045E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20627/   51900 | consumed samples:     21122048 | elapsed time per iteration (ms): 37636.6 | learning rate: 1.449E-04 | global batch size:  1024 | lm loss: 1.861124E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20628/   51900 | consumed samples:     21123072 | elapsed time per iteration (ms): 37605.3 | learning rate: 1.449E-04 | global batch size:  1024 | lm loss: 1.881991E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20629/   51900 | consumed samples:     21124096 | elapsed time per iteration (ms): 37631.0 | learning rate: 1.449E-04 | global batch size:  1024 | lm loss: 1.886369E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20630/   51900 | consumed samples:     21125120 | elapsed time per iteration (ms): 37652.0 | learning rate: 1.449E-04 | global batch size:  1024 | lm loss: 1.882818E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20631/   51900 | consumed samples:     21126144 | elapsed time per iteration (ms): 37647.9 | learning rate: 1.449E-04 | global batch size:  1024 | lm loss: 1.877172E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20632/   51900 | consumed samples:     21127168 | elapsed time per iteration (ms): 37569.6 | learning rate: 1.449E-04 | global batch size:  1024 | lm loss: 1.883595E+00 | loss scale: 1.0 | grad norm: 0.095 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20633/   51900 | consumed samples:     21128192 | elapsed time per iteration (ms): 37690.1 | learning rate: 1.449E-04 | global batch size:  1024 | lm loss: 1.890711E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20634/   51900 | consumed samples:     21129216 | elapsed time per iteration (ms): 37695.1 | learning rate: 1.449E-04 | global batch size:  1024 | lm loss: 1.885029E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20635/   51900 | consumed samples:     21130240 | elapsed time per iteration (ms): 37670.7 | learning rate: 1.448E-04 | global batch size:  1024 | lm loss: 1.892652E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20636/   51900 | consumed samples:     21131264 | elapsed time per iteration (ms): 37586.4 | learning rate: 1.448E-04 | global batch size:  1024 | lm loss: 1.891506E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20637/   51900 | consumed samples:     21132288 | elapsed time per iteration (ms): 37730.5 | learning rate: 1.448E-04 | global batch size:  1024 | lm loss: 1.869682E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20638/   51900 | consumed samples:     21133312 | elapsed time per iteration (ms): 37516.4 | learning rate: 1.448E-04 | global batch size:  1024 | lm loss: 1.902195E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20639/   51900 | consumed samples:     21134336 | elapsed time per iteration (ms): 37631.7 | learning rate: 1.448E-04 | global batch size:  1024 | lm loss: 1.876391E+00 | loss scale: 1.0 | grad norm: 0.088 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20640/   51900 | consumed samples:     21135360 | elapsed time per iteration (ms): 37582.7 | learning rate: 1.448E-04 | global batch size:  1024 | lm loss: 1.902730E+00 | loss scale: 1.0 | grad norm: 0.090 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20641/   51900 | consumed samples:     21136384 | elapsed time per iteration (ms): 37661.2 | learning rate: 1.448E-04 | global batch size:  1024 | lm loss: 1.894173E+00 | loss scale: 1.0 | grad norm: 0.098 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20642/   51900 | consumed samples:     21137408 | elapsed time per iteration (ms): 37673.1 | learning rate: 1.448E-04 | global batch size:  1024 | lm loss: 1.895191E+00 | loss scale: 1.0 | grad norm: 0.106 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20643/   51900 | consumed samples:     21138432 | elapsed time per iteration (ms): 37651.1 | learning rate: 1.448E-04 | global batch size:  1024 | lm loss: 1.906706E+00 | loss scale: 1.0 | grad norm: 0.106 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20644/   51900 | consumed samples:     21139456 | elapsed time per iteration (ms): 37555.2 | learning rate: 1.448E-04 | global batch size:  1024 | lm loss: 1.890234E+00 | loss scale: 1.0 | grad norm: 0.094 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20645/   51900 | consumed samples:     21140480 | elapsed time per iteration (ms): 37512.6 | learning rate: 1.448E-04 | global batch size:  1024 | lm loss: 1.865099E+00 | loss scale: 1.0 | grad norm: 0.092 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20646/   51900 | consumed samples:     21141504 | elapsed time per iteration (ms): 37655.2 | learning rate: 1.448E-04 | global batch size:  1024 | lm loss: 1.878665E+00 | loss scale: 1.0 | grad norm: 0.093 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20647/   51900 | consumed samples:     21142528 | elapsed time per iteration (ms): 37567.3 | learning rate: 1.448E-04 | global batch size:  1024 | lm loss: 1.891520E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20648/   51900 | consumed samples:     21143552 | elapsed time per iteration (ms): 37612.2 | learning rate: 1.448E-04 | global batch size:  1024 | lm loss: 1.871338E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20649/   51900 | consumed samples:     21144576 | elapsed time per iteration (ms): 37663.9 | learning rate: 1.448E-04 | global batch size:  1024 | lm loss: 1.885777E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20650/   51900 | consumed samples:     21145600 | elapsed time per iteration (ms): 37682.6 | learning rate: 1.448E-04 | global batch size:  1024 | lm loss: 1.882825E+00 | loss scale: 1.0 | grad norm: 0.089 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20651/   51900 | consumed samples:     21146624 | elapsed time per iteration (ms): 37557.6 | learning rate: 1.448E-04 | global batch size:  1024 | lm loss: 1.882191E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20652/   51900 | consumed samples:     21147648 | elapsed time per iteration (ms): 37613.5 | learning rate: 1.448E-04 | global batch size:  1024 | lm loss: 1.874939E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20653/   51900 | consumed samples:     21148672 | elapsed time per iteration (ms): 37554.0 | learning rate: 1.448E-04 | global batch size:  1024 | lm loss: 1.883395E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20654/   51900 | consumed samples:     21149696 | elapsed time per iteration (ms): 37612.2 | learning rate: 1.447E-04 | global batch size:  1024 | lm loss: 1.875902E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20655/   51900 | consumed samples:     21150720 | elapsed time per iteration (ms): 37674.1 | learning rate: 1.447E-04 | global batch size:  1024 | lm loss: 1.868893E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20656/   51900 | consumed samples:     21151744 | elapsed time per iteration (ms): 37551.7 | learning rate: 1.447E-04 | global batch size:  1024 | lm loss: 1.883323E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20657/   51900 | consumed samples:     21152768 | elapsed time per iteration (ms): 37501.6 | learning rate: 1.447E-04 | global batch size:  1024 | lm loss: 1.874861E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20658/   51900 | consumed samples:     21153792 | elapsed time per iteration (ms): 37511.2 | learning rate: 1.447E-04 | global batch size:  1024 | lm loss: 1.880481E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20659/   51900 | consumed samples:     21154816 | elapsed time per iteration (ms): 37565.8 | learning rate: 1.447E-04 | global batch size:  1024 | lm loss: 1.880834E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20660/   51900 | consumed samples:     21155840 | elapsed time per iteration (ms): 37715.7 | learning rate: 1.447E-04 | global batch size:  1024 | lm loss: 1.875341E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20661/   51900 | consumed samples:     21156864 | elapsed time per iteration (ms): 37544.0 | learning rate: 1.447E-04 | global batch size:  1024 | lm loss: 1.885122E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20662/   51900 | consumed samples:     21157888 | elapsed time per iteration (ms): 37639.0 | learning rate: 1.447E-04 | global batch size:  1024 | lm loss: 1.884062E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20663/   51900 | consumed samples:     21158912 | elapsed time per iteration (ms): 37567.4 | learning rate: 1.447E-04 | global batch size:  1024 | lm loss: 1.897468E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20664/   51900 | consumed samples:     21159936 | elapsed time per iteration (ms): 37685.0 | learning rate: 1.447E-04 | global batch size:  1024 | lm loss: 1.885553E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20665/   51900 | consumed samples:     21160960 | elapsed time per iteration (ms): 37569.4 | learning rate: 1.447E-04 | global batch size:  1024 | lm loss: 1.873202E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20666/   51900 | consumed samples:     21161984 | elapsed time per iteration (ms): 37599.3 | learning rate: 1.447E-04 | global batch size:  1024 | lm loss: 1.880922E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20667/   51900 | consumed samples:     21163008 | elapsed time per iteration (ms): 37567.8 | learning rate: 1.447E-04 | global batch size:  1024 | lm loss: 1.872635E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20668/   51900 | consumed samples:     21164032 | elapsed time per iteration (ms): 37654.1 | learning rate: 1.447E-04 | global batch size:  1024 | lm loss: 1.871232E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20669/   51900 | consumed samples:     21165056 | elapsed time per iteration (ms): 37517.7 | learning rate: 1.447E-04 | global batch size:  1024 | lm loss: 1.887550E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20670/   51900 | consumed samples:     21166080 | elapsed time per iteration (ms): 37591.3 | learning rate: 1.447E-04 | global batch size:  1024 | lm loss: 1.892117E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20671/   51900 | consumed samples:     21167104 | elapsed time per iteration (ms): 37650.0 | learning rate: 1.447E-04 | global batch size:  1024 | lm loss: 1.895935E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20672/   51900 | consumed samples:     21168128 | elapsed time per iteration (ms): 37602.8 | learning rate: 1.447E-04 | global batch size:  1024 | lm loss: 1.888078E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20673/   51900 | consumed samples:     21169152 | elapsed time per iteration (ms): 37583.7 | learning rate: 1.446E-04 | global batch size:  1024 | lm loss: 1.880419E+00 | loss scale: 1.0 | grad norm: 0.093 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20674/   51900 | consumed samples:     21170176 | elapsed time per iteration (ms): 37547.8 | learning rate: 1.446E-04 | global batch size:  1024 | lm loss: 1.872398E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20675/   51900 | consumed samples:     21171200 | elapsed time per iteration (ms): 37586.5 | learning rate: 1.446E-04 | global batch size:  1024 | lm loss: 1.857036E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20676/   51900 | consumed samples:     21172224 | elapsed time per iteration (ms): 37492.3 | learning rate: 1.446E-04 | global batch size:  1024 | lm loss: 1.879946E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20677/   51900 | consumed samples:     21173248 | elapsed time per iteration (ms): 37521.2 | learning rate: 1.446E-04 | global batch size:  1024 | lm loss: 1.884530E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20678/   51900 | consumed samples:     21174272 | elapsed time per iteration (ms): 37459.8 | learning rate: 1.446E-04 | global batch size:  1024 | lm loss: 1.880304E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20679/   51900 | consumed samples:     21175296 | elapsed time per iteration (ms): 37589.1 | learning rate: 1.446E-04 | global batch size:  1024 | lm loss: 1.900311E+00 | loss scale: 1.0 | grad norm: 0.098 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20680/   51900 | consumed samples:     21176320 | elapsed time per iteration (ms): 37588.2 | learning rate: 1.446E-04 | global batch size:  1024 | lm loss: 1.873815E+00 | loss scale: 1.0 | grad norm: 0.099 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20681/   51900 | consumed samples:     21177344 | elapsed time per iteration (ms): 37547.3 | learning rate: 1.446E-04 | global batch size:  1024 | lm loss: 1.866603E+00 | loss scale: 1.0 | grad norm: 0.096 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20682/   51900 | consumed samples:     21178368 | elapsed time per iteration (ms): 37635.3 | learning rate: 1.446E-04 | global batch size:  1024 | lm loss: 1.892994E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20683/   51900 | consumed samples:     21179392 | elapsed time per iteration (ms): 37553.5 | learning rate: 1.446E-04 | global batch size:  1024 | lm loss: 1.882719E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20684/   51900 | consumed samples:     21180416 | elapsed time per iteration (ms): 37699.8 | learning rate: 1.446E-04 | global batch size:  1024 | lm loss: 1.896906E+00 | loss scale: 1.0 | grad norm: 0.091 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20685/   51900 | consumed samples:     21181440 | elapsed time per iteration (ms): 37603.8 | learning rate: 1.446E-04 | global batch size:  1024 | lm loss: 1.880950E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20686/   51900 | consumed samples:     21182464 | elapsed time per iteration (ms): 37767.5 | learning rate: 1.446E-04 | global batch size:  1024 | lm loss: 1.884920E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20687/   51900 | consumed samples:     21183488 | elapsed time per iteration (ms): 37584.5 | learning rate: 1.446E-04 | global batch size:  1024 | lm loss: 1.891244E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20688/   51900 | consumed samples:     21184512 | elapsed time per iteration (ms): 37588.3 | learning rate: 1.446E-04 | global batch size:  1024 | lm loss: 1.871035E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20689/   51900 | consumed samples:     21185536 | elapsed time per iteration (ms): 37431.1 | learning rate: 1.446E-04 | global batch size:  1024 | lm loss: 1.868974E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20690/   51900 | consumed samples:     21186560 | elapsed time per iteration (ms): 37594.4 | learning rate: 1.446E-04 | global batch size:  1024 | lm loss: 1.882186E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20691/   51900 | consumed samples:     21187584 | elapsed time per iteration (ms): 37600.4 | learning rate: 1.446E-04 | global batch size:  1024 | lm loss: 1.883017E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20692/   51900 | consumed samples:     21188608 | elapsed time per iteration (ms): 37661.8 | learning rate: 1.445E-04 | global batch size:  1024 | lm loss: 1.887596E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20693/   51900 | consumed samples:     21189632 | elapsed time per iteration (ms): 37492.7 | learning rate: 1.445E-04 | global batch size:  1024 | lm loss: 1.872337E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20694/   51900 | consumed samples:     21190656 | elapsed time per iteration (ms): 37574.1 | learning rate: 1.445E-04 | global batch size:  1024 | lm loss: 1.874033E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20695/   51900 | consumed samples:     21191680 | elapsed time per iteration (ms): 37565.4 | learning rate: 1.445E-04 | global batch size:  1024 | lm loss: 1.886215E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20696/   51900 | consumed samples:     21192704 | elapsed time per iteration (ms): 37579.8 | learning rate: 1.445E-04 | global batch size:  1024 | lm loss: 1.888147E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20697/   51900 | consumed samples:     21193728 | elapsed time per iteration (ms): 37673.8 | learning rate: 1.445E-04 | global batch size:  1024 | lm loss: 1.890676E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20698/   51900 | consumed samples:     21194752 | elapsed time per iteration (ms): 37589.9 | learning rate: 1.445E-04 | global batch size:  1024 | lm loss: 1.883368E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20699/   51900 | consumed samples:     21195776 | elapsed time per iteration (ms): 37571.7 | learning rate: 1.445E-04 | global batch size:  1024 | lm loss: 1.869272E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20700/   51900 | consumed samples:     21196800 | elapsed time per iteration (ms): 37637.6 | learning rate: 1.445E-04 | global batch size:  1024 | lm loss: 1.885164E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20701/   51900 | consumed samples:     21197824 | elapsed time per iteration (ms): 37633.0 | learning rate: 1.445E-04 | global batch size:  1024 | lm loss: 1.878484E+00 | loss scale: 1.0 | grad norm: 0.090 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20702/   51900 | consumed samples:     21198848 | elapsed time per iteration (ms): 37612.2 | learning rate: 1.445E-04 | global batch size:  1024 | lm loss: 1.899101E+00 | loss scale: 1.0 | grad norm: 0.099 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20703/   51900 | consumed samples:     21199872 | elapsed time per iteration (ms): 37570.9 | learning rate: 1.445E-04 | global batch size:  1024 | lm loss: 1.879344E+00 | loss scale: 1.0 | grad norm: 0.098 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20704/   51900 | consumed samples:     21200896 | elapsed time per iteration (ms): 37541.5 | learning rate: 1.445E-04 | global batch size:  1024 | lm loss: 1.870321E+00 | loss scale: 1.0 | grad norm: 0.088 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20705/   51900 | consumed samples:     21201920 | elapsed time per iteration (ms): 37607.1 | learning rate: 1.445E-04 | global batch size:  1024 | lm loss: 1.877662E+00 | loss scale: 1.0 | grad norm: 0.089 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20706/   51900 | consumed samples:     21202944 | elapsed time per iteration (ms): 37632.1 | learning rate: 1.445E-04 | global batch size:  1024 | lm loss: 1.883843E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20707/   51900 | consumed samples:     21203968 | elapsed time per iteration (ms): 37590.7 | learning rate: 1.445E-04 | global batch size:  1024 | lm loss: 1.880828E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20708/   51900 | consumed samples:     21204992 | elapsed time per iteration (ms): 37590.7 | learning rate: 1.445E-04 | global batch size:  1024 | lm loss: 1.876163E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20709/   51900 | consumed samples:     21206016 | elapsed time per iteration (ms): 37658.7 | learning rate: 1.445E-04 | global batch size:  1024 | lm loss: 1.862384E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20710/   51900 | consumed samples:     21207040 | elapsed time per iteration (ms): 37649.0 | learning rate: 1.445E-04 | global batch size:  1024 | lm loss: 1.887296E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20711/   51900 | consumed samples:     21208064 | elapsed time per iteration (ms): 37592.0 | learning rate: 1.444E-04 | global batch size:  1024 | lm loss: 1.876781E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20712/   51900 | consumed samples:     21209088 | elapsed time per iteration (ms): 37668.7 | learning rate: 1.444E-04 | global batch size:  1024 | lm loss: 1.874972E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20713/   51900 | consumed samples:     21210112 | elapsed time per iteration (ms): 37503.8 | learning rate: 1.444E-04 | global batch size:  1024 | lm loss: 1.874719E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20714/   51900 | consumed samples:     21211136 | elapsed time per iteration (ms): 37573.7 | learning rate: 1.444E-04 | global batch size:  1024 | lm loss: 1.905197E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20715/   51900 | consumed samples:     21212160 | elapsed time per iteration (ms): 37618.1 | learning rate: 1.444E-04 | global batch size:  1024 | lm loss: 1.892564E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20716/   51900 | consumed samples:     21213184 | elapsed time per iteration (ms): 37693.9 | learning rate: 1.444E-04 | global batch size:  1024 | lm loss: 1.887849E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20717/   51900 | consumed samples:     21214208 | elapsed time per iteration (ms): 37631.7 | learning rate: 1.444E-04 | global batch size:  1024 | lm loss: 1.895572E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20718/   51900 | consumed samples:     21215232 | elapsed time per iteration (ms): 37566.9 | learning rate: 1.444E-04 | global batch size:  1024 | lm loss: 1.900098E+00 | loss scale: 1.0 | grad norm: 0.091 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20719/   51900 | consumed samples:     21216256 | elapsed time per iteration (ms): 37631.2 | learning rate: 1.444E-04 | global batch size:  1024 | lm loss: 1.887170E+00 | loss scale: 1.0 | grad norm: 0.093 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20720/   51900 | consumed samples:     21217280 | elapsed time per iteration (ms): 37641.6 | learning rate: 1.444E-04 | global batch size:  1024 | lm loss: 1.888137E+00 | loss scale: 1.0 | grad norm: 0.096 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20721/   51900 | consumed samples:     21218304 | elapsed time per iteration (ms): 37639.5 | learning rate: 1.444E-04 | global batch size:  1024 | lm loss: 1.898354E+00 | loss scale: 1.0 | grad norm: 0.095 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20722/   51900 | consumed samples:     21219328 | elapsed time per iteration (ms): 37598.4 | learning rate: 1.444E-04 | global batch size:  1024 | lm loss: 1.866994E+00 | loss scale: 1.0 | grad norm: 0.100 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20723/   51900 | consumed samples:     21220352 | elapsed time per iteration (ms): 37583.8 | learning rate: 1.444E-04 | global batch size:  1024 | lm loss: 1.881763E+00 | loss scale: 1.0 | grad norm: 0.101 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20724/   51900 | consumed samples:     21221376 | elapsed time per iteration (ms): 37727.2 | learning rate: 1.444E-04 | global batch size:  1024 | lm loss: 1.888610E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20725/   51900 | consumed samples:     21222400 | elapsed time per iteration (ms): 37531.8 | learning rate: 1.444E-04 | global batch size:  1024 | lm loss: 1.876304E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20726/   51900 | consumed samples:     21223424 | elapsed time per iteration (ms): 37579.7 | learning rate: 1.444E-04 | global batch size:  1024 | lm loss: 1.882878E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20727/   51900 | consumed samples:     21224448 | elapsed time per iteration (ms): 37617.3 | learning rate: 1.444E-04 | global batch size:  1024 | lm loss: 1.896857E+00 | loss scale: 1.0 | grad norm: 0.094 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20728/   51900 | consumed samples:     21225472 | elapsed time per iteration (ms): 37531.2 | learning rate: 1.444E-04 | global batch size:  1024 | lm loss: 1.871013E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20729/   51900 | consumed samples:     21226496 | elapsed time per iteration (ms): 37626.3 | learning rate: 1.444E-04 | global batch size:  1024 | lm loss: 1.892887E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20730/   51900 | consumed samples:     21227520 | elapsed time per iteration (ms): 37623.5 | learning rate: 1.443E-04 | global batch size:  1024 | lm loss: 1.882777E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20731/   51900 | consumed samples:     21228544 | elapsed time per iteration (ms): 37626.9 | learning rate: 1.443E-04 | global batch size:  1024 | lm loss: 1.886069E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20732/   51900 | consumed samples:     21229568 | elapsed time per iteration (ms): 37591.3 | learning rate: 1.443E-04 | global batch size:  1024 | lm loss: 1.874703E+00 | loss scale: 1.0 | grad norm: 0.094 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20733/   51900 | consumed samples:     21230592 | elapsed time per iteration (ms): 37720.6 | learning rate: 1.443E-04 | global batch size:  1024 | lm loss: 1.880351E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20734/   51900 | consumed samples:     21231616 | elapsed time per iteration (ms): 37722.1 | learning rate: 1.443E-04 | global batch size:  1024 | lm loss: 1.871421E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20735/   51900 | consumed samples:     21232640 | elapsed time per iteration (ms): 37519.8 | learning rate: 1.443E-04 | global batch size:  1024 | lm loss: 1.881137E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20736/   51900 | consumed samples:     21233664 | elapsed time per iteration (ms): 37679.4 | learning rate: 1.443E-04 | global batch size:  1024 | lm loss: 1.871120E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20737/   51900 | consumed samples:     21234688 | elapsed time per iteration (ms): 37566.7 | learning rate: 1.443E-04 | global batch size:  1024 | lm loss: 1.893798E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20738/   51900 | consumed samples:     21235712 | elapsed time per iteration (ms): 37635.1 | learning rate: 1.443E-04 | global batch size:  1024 | lm loss: 1.864390E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20739/   51900 | consumed samples:     21236736 | elapsed time per iteration (ms): 37679.6 | learning rate: 1.443E-04 | global batch size:  1024 | lm loss: 1.871129E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20740/   51900 | consumed samples:     21237760 | elapsed time per iteration (ms): 37532.5 | learning rate: 1.443E-04 | global batch size:  1024 | lm loss: 1.871643E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20741/   51900 | consumed samples:     21238784 | elapsed time per iteration (ms): 37412.2 | learning rate: 1.443E-04 | global batch size:  1024 | lm loss: 1.886419E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20742/   51900 | consumed samples:     21239808 | elapsed time per iteration (ms): 37665.0 | learning rate: 1.443E-04 | global batch size:  1024 | lm loss: 1.886081E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20743/   51900 | consumed samples:     21240832 | elapsed time per iteration (ms): 37562.1 | learning rate: 1.443E-04 | global batch size:  1024 | lm loss: 1.872603E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20744/   51900 | consumed samples:     21241856 | elapsed time per iteration (ms): 37602.0 | learning rate: 1.443E-04 | global batch size:  1024 | lm loss: 1.890152E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20745/   51900 | consumed samples:     21242880 | elapsed time per iteration (ms): 37532.4 | learning rate: 1.443E-04 | global batch size:  1024 | lm loss: 1.891147E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20746/   51900 | consumed samples:     21243904 | elapsed time per iteration (ms): 37662.1 | learning rate: 1.443E-04 | global batch size:  1024 | lm loss: 1.877863E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20747/   51900 | consumed samples:     21244928 | elapsed time per iteration (ms): 37599.7 | learning rate: 1.443E-04 | global batch size:  1024 | lm loss: 1.895186E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20748/   51900 | consumed samples:     21245952 | elapsed time per iteration (ms): 37544.9 | learning rate: 1.443E-04 | global batch size:  1024 | lm loss: 1.883183E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20749/   51900 | consumed samples:     21246976 | elapsed time per iteration (ms): 37682.5 | learning rate: 1.443E-04 | global batch size:  1024 | lm loss: 1.873362E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20750/   51900 | consumed samples:     21248000 | elapsed time per iteration (ms): 37632.0 | learning rate: 1.442E-04 | global batch size:  1024 | lm loss: 1.911291E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20751/   51900 | consumed samples:     21249024 | elapsed time per iteration (ms): 37631.5 | learning rate: 1.442E-04 | global batch size:  1024 | lm loss: 1.888834E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20752/   51900 | consumed samples:     21250048 | elapsed time per iteration (ms): 37582.0 | learning rate: 1.442E-04 | global batch size:  1024 | lm loss: 1.879990E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20753/   51900 | consumed samples:     21251072 | elapsed time per iteration (ms): 37554.0 | learning rate: 1.442E-04 | global batch size:  1024 | lm loss: 1.882397E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20754/   51900 | consumed samples:     21252096 | elapsed time per iteration (ms): 37542.7 | learning rate: 1.442E-04 | global batch size:  1024 | lm loss: 1.904437E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20755/   51900 | consumed samples:     21253120 | elapsed time per iteration (ms): 37632.3 | learning rate: 1.442E-04 | global batch size:  1024 | lm loss: 1.876283E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20756/   51900 | consumed samples:     21254144 | elapsed time per iteration (ms): 37618.6 | learning rate: 1.442E-04 | global batch size:  1024 | lm loss: 1.889983E+00 | loss scale: 1.0 | grad norm: 0.094 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20757/   51900 | consumed samples:     21255168 | elapsed time per iteration (ms): 37535.6 | learning rate: 1.442E-04 | global batch size:  1024 | lm loss: 1.901741E+00 | loss scale: 1.0 | grad norm: 0.105 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20758/   51900 | consumed samples:     21256192 | elapsed time per iteration (ms): 37641.8 | learning rate: 1.442E-04 | global batch size:  1024 | lm loss: 1.893016E+00 | loss scale: 1.0 | grad norm: 0.110 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20759/   51900 | consumed samples:     21257216 | elapsed time per iteration (ms): 37709.2 | learning rate: 1.442E-04 | global batch size:  1024 | lm loss: 1.901396E+00 | loss scale: 1.0 | grad norm: 0.098 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20760/   51900 | consumed samples:     21258240 | elapsed time per iteration (ms): 37598.0 | learning rate: 1.442E-04 | global batch size:  1024 | lm loss: 1.876232E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20761/   51900 | consumed samples:     21259264 | elapsed time per iteration (ms): 37673.2 | learning rate: 1.442E-04 | global batch size:  1024 | lm loss: 1.886220E+00 | loss scale: 1.0 | grad norm: 0.090 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20762/   51900 | consumed samples:     21260288 | elapsed time per iteration (ms): 37561.3 | learning rate: 1.442E-04 | global batch size:  1024 | lm loss: 1.875632E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20763/   51900 | consumed samples:     21261312 | elapsed time per iteration (ms): 37627.8 | learning rate: 1.442E-04 | global batch size:  1024 | lm loss: 1.881794E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20764/   51900 | consumed samples:     21262336 | elapsed time per iteration (ms): 37658.6 | learning rate: 1.442E-04 | global batch size:  1024 | lm loss: 1.870036E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20765/   51900 | consumed samples:     21263360 | elapsed time per iteration (ms): 37714.1 | learning rate: 1.442E-04 | global batch size:  1024 | lm loss: 1.902431E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20766/   51900 | consumed samples:     21264384 | elapsed time per iteration (ms): 37628.1 | learning rate: 1.442E-04 | global batch size:  1024 | lm loss: 1.885167E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20767/   51900 | consumed samples:     21265408 | elapsed time per iteration (ms): 37560.0 | learning rate: 1.442E-04 | global batch size:  1024 | lm loss: 1.890365E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20768/   51900 | consumed samples:     21266432 | elapsed time per iteration (ms): 37626.3 | learning rate: 1.442E-04 | global batch size:  1024 | lm loss: 1.874366E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20769/   51900 | consumed samples:     21267456 | elapsed time per iteration (ms): 37625.0 | learning rate: 1.441E-04 | global batch size:  1024 | lm loss: 1.888651E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20770/   51900 | consumed samples:     21268480 | elapsed time per iteration (ms): 37552.9 | learning rate: 1.441E-04 | global batch size:  1024 | lm loss: 1.889760E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20771/   51900 | consumed samples:     21269504 | elapsed time per iteration (ms): 37651.3 | learning rate: 1.441E-04 | global batch size:  1024 | lm loss: 1.895765E+00 | loss scale: 1.0 | grad norm: 0.087 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20772/   51900 | consumed samples:     21270528 | elapsed time per iteration (ms): 37822.2 | learning rate: 1.441E-04 | global batch size:  1024 | lm loss: 1.876551E+00 | loss scale: 1.0 | grad norm: 0.087 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20773/   51900 | consumed samples:     21271552 | elapsed time per iteration (ms): 37703.8 | learning rate: 1.441E-04 | global batch size:  1024 | lm loss: 1.898665E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20774/   51900 | consumed samples:     21272576 | elapsed time per iteration (ms): 37718.2 | learning rate: 1.441E-04 | global batch size:  1024 | lm loss: 1.865720E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20775/   51900 | consumed samples:     21273600 | elapsed time per iteration (ms): 37607.8 | learning rate: 1.441E-04 | global batch size:  1024 | lm loss: 1.893500E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20776/   51900 | consumed samples:     21274624 | elapsed time per iteration (ms): 37685.6 | learning rate: 1.441E-04 | global batch size:  1024 | lm loss: 1.908938E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20777/   51900 | consumed samples:     21275648 | elapsed time per iteration (ms): 37653.7 | learning rate: 1.441E-04 | global batch size:  1024 | lm loss: 1.885388E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20778/   51900 | consumed samples:     21276672 | elapsed time per iteration (ms): 37702.7 | learning rate: 1.441E-04 | global batch size:  1024 | lm loss: 1.884317E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20779/   51900 | consumed samples:     21277696 | elapsed time per iteration (ms): 37559.3 | learning rate: 1.441E-04 | global batch size:  1024 | lm loss: 1.875928E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20780/   51900 | consumed samples:     21278720 | elapsed time per iteration (ms): 37605.8 | learning rate: 1.441E-04 | global batch size:  1024 | lm loss: 1.874519E+00 | loss scale: 1.0 | grad norm: 0.092 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20781/   51900 | consumed samples:     21279744 | elapsed time per iteration (ms): 37750.1 | learning rate: 1.441E-04 | global batch size:  1024 | lm loss: 1.869246E+00 | loss scale: 1.0 | grad norm: 0.088 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20782/   51900 | consumed samples:     21280768 | elapsed time per iteration (ms): 37586.4 | learning rate: 1.441E-04 | global batch size:  1024 | lm loss: 1.889004E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20783/   51900 | consumed samples:     21281792 | elapsed time per iteration (ms): 37605.9 | learning rate: 1.441E-04 | global batch size:  1024 | lm loss: 1.883540E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20784/   51900 | consumed samples:     21282816 | elapsed time per iteration (ms): 37638.9 | learning rate: 1.441E-04 | global batch size:  1024 | lm loss: 1.886158E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20785/   51900 | consumed samples:     21283840 | elapsed time per iteration (ms): 37626.5 | learning rate: 1.441E-04 | global batch size:  1024 | lm loss: 1.883317E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20786/   51900 | consumed samples:     21284864 | elapsed time per iteration (ms): 37566.1 | learning rate: 1.441E-04 | global batch size:  1024 | lm loss: 1.887596E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20787/   51900 | consumed samples:     21285888 | elapsed time per iteration (ms): 37671.9 | learning rate: 1.441E-04 | global batch size:  1024 | lm loss: 1.887596E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20788/   51900 | consumed samples:     21286912 | elapsed time per iteration (ms): 37725.8 | learning rate: 1.440E-04 | global batch size:  1024 | lm loss: 1.880959E+00 | loss scale: 1.0 | grad norm: 0.092 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20789/   51900 | consumed samples:     21287936 | elapsed time per iteration (ms): 37649.4 | learning rate: 1.440E-04 | global batch size:  1024 | lm loss: 1.888655E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20790/   51900 | consumed samples:     21288960 | elapsed time per iteration (ms): 37603.6 | learning rate: 1.440E-04 | global batch size:  1024 | lm loss: 1.871026E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20791/   51900 | consumed samples:     21289984 | elapsed time per iteration (ms): 37570.2 | learning rate: 1.440E-04 | global batch size:  1024 | lm loss: 1.882845E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20792/   51900 | consumed samples:     21291008 | elapsed time per iteration (ms): 37714.7 | learning rate: 1.440E-04 | global batch size:  1024 | lm loss: 1.874736E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20793/   51900 | consumed samples:     21292032 | elapsed time per iteration (ms): 37680.3 | learning rate: 1.440E-04 | global batch size:  1024 | lm loss: 1.880152E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20794/   51900 | consumed samples:     21293056 | elapsed time per iteration (ms): 37582.5 | learning rate: 1.440E-04 | global batch size:  1024 | lm loss: 1.876441E+00 | loss scale: 1.0 | grad norm: 0.087 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20795/   51900 | consumed samples:     21294080 | elapsed time per iteration (ms): 37652.6 | learning rate: 1.440E-04 | global batch size:  1024 | lm loss: 1.871064E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20796/   51900 | consumed samples:     21295104 | elapsed time per iteration (ms): 37606.1 | learning rate: 1.440E-04 | global batch size:  1024 | lm loss: 1.876906E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20797/   51900 | consumed samples:     21296128 | elapsed time per iteration (ms): 37602.6 | learning rate: 1.440E-04 | global batch size:  1024 | lm loss: 1.886501E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20798/   51900 | consumed samples:     21297152 | elapsed time per iteration (ms): 37620.2 | learning rate: 1.440E-04 | global batch size:  1024 | lm loss: 1.885425E+00 | loss scale: 1.0 | grad norm: 0.093 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20799/   51900 | consumed samples:     21298176 | elapsed time per iteration (ms): 37613.5 | learning rate: 1.440E-04 | global batch size:  1024 | lm loss: 1.897356E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20800/   51900 | consumed samples:     21299200 | elapsed time per iteration (ms): 37554.1 | learning rate: 1.440E-04 | global batch size:  1024 | lm loss: 1.885104E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20801/   51900 | consumed samples:     21300224 | elapsed time per iteration (ms): 37624.5 | learning rate: 1.440E-04 | global batch size:  1024 | lm loss: 1.872396E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20802/   51900 | consumed samples:     21301248 | elapsed time per iteration (ms): 37688.7 | learning rate: 1.440E-04 | global batch size:  1024 | lm loss: 1.887506E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20803/   51900 | consumed samples:     21302272 | elapsed time per iteration (ms): 37738.6 | learning rate: 1.440E-04 | global batch size:  1024 | lm loss: 1.877025E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20804/   51900 | consumed samples:     21303296 | elapsed time per iteration (ms): 37587.5 | learning rate: 1.440E-04 | global batch size:  1024 | lm loss: 1.897437E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20805/   51900 | consumed samples:     21304320 | elapsed time per iteration (ms): 37625.4 | learning rate: 1.440E-04 | global batch size:  1024 | lm loss: 1.887987E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20806/   51900 | consumed samples:     21305344 | elapsed time per iteration (ms): 37655.5 | learning rate: 1.440E-04 | global batch size:  1024 | lm loss: 1.901579E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20807/   51900 | consumed samples:     21306368 | elapsed time per iteration (ms): 37631.8 | learning rate: 1.439E-04 | global batch size:  1024 | lm loss: 1.859599E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20808/   51900 | consumed samples:     21307392 | elapsed time per iteration (ms): 37555.7 | learning rate: 1.439E-04 | global batch size:  1024 | lm loss: 1.880301E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20809/   51900 | consumed samples:     21308416 | elapsed time per iteration (ms): 37546.1 | learning rate: 1.439E-04 | global batch size:  1024 | lm loss: 1.863724E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20810/   51900 | consumed samples:     21309440 | elapsed time per iteration (ms): 37633.8 | learning rate: 1.439E-04 | global batch size:  1024 | lm loss: 1.862727E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20811/   51900 | consumed samples:     21310464 | elapsed time per iteration (ms): 37599.6 | learning rate: 1.439E-04 | global batch size:  1024 | lm loss: 1.876314E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20812/   51900 | consumed samples:     21311488 | elapsed time per iteration (ms): 37772.8 | learning rate: 1.439E-04 | global batch size:  1024 | lm loss: 1.880656E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20813/   51900 | consumed samples:     21312512 | elapsed time per iteration (ms): 37625.4 | learning rate: 1.439E-04 | global batch size:  1024 | lm loss: 1.876601E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20814/   51900 | consumed samples:     21313536 | elapsed time per iteration (ms): 37730.1 | learning rate: 1.439E-04 | global batch size:  1024 | lm loss: 1.881938E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20815/   51900 | consumed samples:     21314560 | elapsed time per iteration (ms): 37651.1 | learning rate: 1.439E-04 | global batch size:  1024 | lm loss: 1.873424E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20816/   51900 | consumed samples:     21315584 | elapsed time per iteration (ms): 37639.1 | learning rate: 1.439E-04 | global batch size:  1024 | lm loss: 1.877265E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20817/   51900 | consumed samples:     21316608 | elapsed time per iteration (ms): 37682.7 | learning rate: 1.439E-04 | global batch size:  1024 | lm loss: 1.884310E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20818/   51900 | consumed samples:     21317632 | elapsed time per iteration (ms): 37632.9 | learning rate: 1.439E-04 | global batch size:  1024 | lm loss: 1.886797E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20819/   51900 | consumed samples:     21318656 | elapsed time per iteration (ms): 37615.2 | learning rate: 1.439E-04 | global batch size:  1024 | lm loss: 1.884292E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20820/   51900 | consumed samples:     21319680 | elapsed time per iteration (ms): 37693.6 | learning rate: 1.439E-04 | global batch size:  1024 | lm loss: 1.885367E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20821/   51900 | consumed samples:     21320704 | elapsed time per iteration (ms): 37569.3 | learning rate: 1.439E-04 | global batch size:  1024 | lm loss: 1.873224E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20822/   51900 | consumed samples:     21321728 | elapsed time per iteration (ms): 37602.4 | learning rate: 1.439E-04 | global batch size:  1024 | lm loss: 1.868616E+00 | loss scale: 1.0 | grad norm: 0.089 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20823/   51900 | consumed samples:     21322752 | elapsed time per iteration (ms): 37530.3 | learning rate: 1.439E-04 | global batch size:  1024 | lm loss: 1.882134E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20824/   51900 | consumed samples:     21323776 | elapsed time per iteration (ms): 37685.5 | learning rate: 1.439E-04 | global batch size:  1024 | lm loss: 1.876041E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20825/   51900 | consumed samples:     21324800 | elapsed time per iteration (ms): 37696.0 | learning rate: 1.439E-04 | global batch size:  1024 | lm loss: 1.872283E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20826/   51900 | consumed samples:     21325824 | elapsed time per iteration (ms): 37644.7 | learning rate: 1.438E-04 | global batch size:  1024 | lm loss: 1.865784E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20827/   51900 | consumed samples:     21326848 | elapsed time per iteration (ms): 37681.7 | learning rate: 1.438E-04 | global batch size:  1024 | lm loss: 1.887934E+00 | loss scale: 1.0 | grad norm: 0.101 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20828/   51900 | consumed samples:     21327872 | elapsed time per iteration (ms): 37587.7 | learning rate: 1.438E-04 | global batch size:  1024 | lm loss: 1.883592E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20829/   51900 | consumed samples:     21328896 | elapsed time per iteration (ms): 37756.6 | learning rate: 1.438E-04 | global batch size:  1024 | lm loss: 1.878289E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20830/   51900 | consumed samples:     21329920 | elapsed time per iteration (ms): 37605.4 | learning rate: 1.438E-04 | global batch size:  1024 | lm loss: 1.884180E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20831/   51900 | consumed samples:     21330944 | elapsed time per iteration (ms): 37591.9 | learning rate: 1.438E-04 | global batch size:  1024 | lm loss: 1.875222E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20832/   51900 | consumed samples:     21331968 | elapsed time per iteration (ms): 37666.0 | learning rate: 1.438E-04 | global batch size:  1024 | lm loss: 1.869711E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20833/   51900 | consumed samples:     21332992 | elapsed time per iteration (ms): 37551.6 | learning rate: 1.438E-04 | global batch size:  1024 | lm loss: 1.900008E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20834/   51900 | consumed samples:     21334016 | elapsed time per iteration (ms): 37622.4 | learning rate: 1.438E-04 | global batch size:  1024 | lm loss: 1.889064E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20835/   51900 | consumed samples:     21335040 | elapsed time per iteration (ms): 37758.7 | learning rate: 1.438E-04 | global batch size:  1024 | lm loss: 1.877534E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20836/   51900 | consumed samples:     21336064 | elapsed time per iteration (ms): 37583.1 | learning rate: 1.438E-04 | global batch size:  1024 | lm loss: 1.873646E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20837/   51900 | consumed samples:     21337088 | elapsed time per iteration (ms): 37651.2 | learning rate: 1.438E-04 | global batch size:  1024 | lm loss: 1.886987E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20838/   51900 | consumed samples:     21338112 | elapsed time per iteration (ms): 37587.7 | learning rate: 1.438E-04 | global batch size:  1024 | lm loss: 1.873160E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20839/   51900 | consumed samples:     21339136 | elapsed time per iteration (ms): 37705.4 | learning rate: 1.438E-04 | global batch size:  1024 | lm loss: 1.868406E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20840/   51900 | consumed samples:     21340160 | elapsed time per iteration (ms): 37648.8 | learning rate: 1.438E-04 | global batch size:  1024 | lm loss: 1.870074E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20841/   51900 | consumed samples:     21341184 | elapsed time per iteration (ms): 37530.2 | learning rate: 1.438E-04 | global batch size:  1024 | lm loss: 1.877115E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20842/   51900 | consumed samples:     21342208 | elapsed time per iteration (ms): 37559.1 | learning rate: 1.438E-04 | global batch size:  1024 | lm loss: 1.908549E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20843/   51900 | consumed samples:     21343232 | elapsed time per iteration (ms): 37562.8 | learning rate: 1.438E-04 | global batch size:  1024 | lm loss: 1.883484E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20844/   51900 | consumed samples:     21344256 | elapsed time per iteration (ms): 37646.9 | learning rate: 1.438E-04 | global batch size:  1024 | lm loss: 1.879790E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20845/   51900 | consumed samples:     21345280 | elapsed time per iteration (ms): 37563.2 | learning rate: 1.437E-04 | global batch size:  1024 | lm loss: 1.867127E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20846/   51900 | consumed samples:     21346304 | elapsed time per iteration (ms): 37682.9 | learning rate: 1.437E-04 | global batch size:  1024 | lm loss: 1.871619E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20847/   51900 | consumed samples:     21347328 | elapsed time per iteration (ms): 37734.9 | learning rate: 1.437E-04 | global batch size:  1024 | lm loss: 1.877027E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20848/   51900 | consumed samples:     21348352 | elapsed time per iteration (ms): 37661.7 | learning rate: 1.437E-04 | global batch size:  1024 | lm loss: 1.878681E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20849/   51900 | consumed samples:     21349376 | elapsed time per iteration (ms): 37525.8 | learning rate: 1.437E-04 | global batch size:  1024 | lm loss: 1.888998E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20850/   51900 | consumed samples:     21350400 | elapsed time per iteration (ms): 37572.4 | learning rate: 1.437E-04 | global batch size:  1024 | lm loss: 1.865370E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20851/   51900 | consumed samples:     21351424 | elapsed time per iteration (ms): 37608.7 | learning rate: 1.437E-04 | global batch size:  1024 | lm loss: 1.885850E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20852/   51900 | consumed samples:     21352448 | elapsed time per iteration (ms): 37602.1 | learning rate: 1.437E-04 | global batch size:  1024 | lm loss: 1.871310E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20853/   51900 | consumed samples:     21353472 | elapsed time per iteration (ms): 37567.3 | learning rate: 1.437E-04 | global batch size:  1024 | lm loss: 1.882065E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20854/   51900 | consumed samples:     21354496 | elapsed time per iteration (ms): 37667.1 | learning rate: 1.437E-04 | global batch size:  1024 | lm loss: 1.903028E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20855/   51900 | consumed samples:     21355520 | elapsed time per iteration (ms): 37577.0 | learning rate: 1.437E-04 | global batch size:  1024 | lm loss: 1.881173E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20856/   51900 | consumed samples:     21356544 | elapsed time per iteration (ms): 37527.2 | learning rate: 1.437E-04 | global batch size:  1024 | lm loss: 1.874250E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20857/   51900 | consumed samples:     21357568 | elapsed time per iteration (ms): 37586.5 | learning rate: 1.437E-04 | global batch size:  1024 | lm loss: 1.899819E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20858/   51900 | consumed samples:     21358592 | elapsed time per iteration (ms): 37546.3 | learning rate: 1.437E-04 | global batch size:  1024 | lm loss: 1.883373E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20859/   51900 | consumed samples:     21359616 | elapsed time per iteration (ms): 37652.2 | learning rate: 1.437E-04 | global batch size:  1024 | lm loss: 1.890101E+00 | loss scale: 1.0 | grad norm: 0.087 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20860/   51900 | consumed samples:     21360640 | elapsed time per iteration (ms): 37544.2 | learning rate: 1.437E-04 | global batch size:  1024 | lm loss: 1.885058E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20861/   51900 | consumed samples:     21361664 | elapsed time per iteration (ms): 37767.3 | learning rate: 1.437E-04 | global batch size:  1024 | lm loss: 1.888876E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20862/   51900 | consumed samples:     21362688 | elapsed time per iteration (ms): 37596.3 | learning rate: 1.437E-04 | global batch size:  1024 | lm loss: 1.876858E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20863/   51900 | consumed samples:     21363712 | elapsed time per iteration (ms): 37538.7 | learning rate: 1.437E-04 | global batch size:  1024 | lm loss: 1.901493E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20864/   51900 | consumed samples:     21364736 | elapsed time per iteration (ms): 37598.1 | learning rate: 1.436E-04 | global batch size:  1024 | lm loss: 1.874693E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20865/   51900 | consumed samples:     21365760 | elapsed time per iteration (ms): 37622.4 | learning rate: 1.436E-04 | global batch size:  1024 | lm loss: 1.895186E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20866/   51900 | consumed samples:     21366784 | elapsed time per iteration (ms): 37586.4 | learning rate: 1.436E-04 | global batch size:  1024 | lm loss: 1.873024E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20867/   51900 | consumed samples:     21367808 | elapsed time per iteration (ms): 37720.0 | learning rate: 1.436E-04 | global batch size:  1024 | lm loss: 1.871819E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20868/   51900 | consumed samples:     21368832 | elapsed time per iteration (ms): 37583.0 | learning rate: 1.436E-04 | global batch size:  1024 | lm loss: 1.872675E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20869/   51900 | consumed samples:     21369856 | elapsed time per iteration (ms): 37508.3 | learning rate: 1.436E-04 | global batch size:  1024 | lm loss: 1.870703E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20870/   51900 | consumed samples:     21370880 | elapsed time per iteration (ms): 37540.8 | learning rate: 1.436E-04 | global batch size:  1024 | lm loss: 1.870138E+00 | loss scale: 1.0 | grad norm: 0.091 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20871/   51900 | consumed samples:     21371904 | elapsed time per iteration (ms): 37566.2 | learning rate: 1.436E-04 | global batch size:  1024 | lm loss: 1.883996E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20872/   51900 | consumed samples:     21372928 | elapsed time per iteration (ms): 37577.7 | learning rate: 1.436E-04 | global batch size:  1024 | lm loss: 1.887949E+00 | loss scale: 1.0 | grad norm: 0.095 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20873/   51900 | consumed samples:     21373952 | elapsed time per iteration (ms): 37689.4 | learning rate: 1.436E-04 | global batch size:  1024 | lm loss: 1.880366E+00 | loss scale: 1.0 | grad norm: 0.096 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20874/   51900 | consumed samples:     21374976 | elapsed time per iteration (ms): 37817.0 | learning rate: 1.436E-04 | global batch size:  1024 | lm loss: 1.875000E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20875/   51900 | consumed samples:     21376000 | elapsed time per iteration (ms): 37664.8 | learning rate: 1.436E-04 | global batch size:  1024 | lm loss: 1.888499E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20876/   51900 | consumed samples:     21377024 | elapsed time per iteration (ms): 37663.2 | learning rate: 1.436E-04 | global batch size:  1024 | lm loss: 1.888739E+00 | loss scale: 1.0 | grad norm: 0.087 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20877/   51900 | consumed samples:     21378048 | elapsed time per iteration (ms): 37732.9 | learning rate: 1.436E-04 | global batch size:  1024 | lm loss: 1.885800E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20878/   51900 | consumed samples:     21379072 | elapsed time per iteration (ms): 37573.7 | learning rate: 1.436E-04 | global batch size:  1024 | lm loss: 1.863574E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20879/   51900 | consumed samples:     21380096 | elapsed time per iteration (ms): 37689.6 | learning rate: 1.436E-04 | global batch size:  1024 | lm loss: 1.888075E+00 | loss scale: 1.0 | grad norm: 0.093 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20880/   51900 | consumed samples:     21381120 | elapsed time per iteration (ms): 37641.0 | learning rate: 1.436E-04 | global batch size:  1024 | lm loss: 1.866390E+00 | loss scale: 1.0 | grad norm: 0.091 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20881/   51900 | consumed samples:     21382144 | elapsed time per iteration (ms): 37689.8 | learning rate: 1.436E-04 | global batch size:  1024 | lm loss: 1.897080E+00 | loss scale: 1.0 | grad norm: 0.096 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20882/   51900 | consumed samples:     21383168 | elapsed time per iteration (ms): 37663.0 | learning rate: 1.436E-04 | global batch size:  1024 | lm loss: 1.882192E+00 | loss scale: 1.0 | grad norm: 0.100 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20883/   51900 | consumed samples:     21384192 | elapsed time per iteration (ms): 37669.2 | learning rate: 1.435E-04 | global batch size:  1024 | lm loss: 1.873422E+00 | loss scale: 1.0 | grad norm: 0.092 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20884/   51900 | consumed samples:     21385216 | elapsed time per iteration (ms): 37679.1 | learning rate: 1.435E-04 | global batch size:  1024 | lm loss: 1.878095E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20885/   51900 | consumed samples:     21386240 | elapsed time per iteration (ms): 37639.0 | learning rate: 1.435E-04 | global batch size:  1024 | lm loss: 1.869760E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20886/   51900 | consumed samples:     21387264 | elapsed time per iteration (ms): 37695.0 | learning rate: 1.435E-04 | global batch size:  1024 | lm loss: 1.887531E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20887/   51900 | consumed samples:     21388288 | elapsed time per iteration (ms): 37564.7 | learning rate: 1.435E-04 | global batch size:  1024 | lm loss: 1.876329E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20888/   51900 | consumed samples:     21389312 | elapsed time per iteration (ms): 37551.3 | learning rate: 1.435E-04 | global batch size:  1024 | lm loss: 1.876096E+00 | loss scale: 1.0 | grad norm: 0.087 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20889/   51900 | consumed samples:     21390336 | elapsed time per iteration (ms): 37617.4 | learning rate: 1.435E-04 | global batch size:  1024 | lm loss: 1.882015E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20890/   51900 | consumed samples:     21391360 | elapsed time per iteration (ms): 37636.4 | learning rate: 1.435E-04 | global batch size:  1024 | lm loss: 1.862622E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20891/   51900 | consumed samples:     21392384 | elapsed time per iteration (ms): 37764.4 | learning rate: 1.435E-04 | global batch size:  1024 | lm loss: 1.858562E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20892/   51900 | consumed samples:     21393408 | elapsed time per iteration (ms): 37559.4 | learning rate: 1.435E-04 | global batch size:  1024 | lm loss: 1.887321E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20893/   51900 | consumed samples:     21394432 | elapsed time per iteration (ms): 37604.0 | learning rate: 1.435E-04 | global batch size:  1024 | lm loss: 1.868577E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20894/   51900 | consumed samples:     21395456 | elapsed time per iteration (ms): 37562.3 | learning rate: 1.435E-04 | global batch size:  1024 | lm loss: 1.889587E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20895/   51900 | consumed samples:     21396480 | elapsed time per iteration (ms): 37717.8 | learning rate: 1.435E-04 | global batch size:  1024 | lm loss: 1.888481E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20896/   51900 | consumed samples:     21397504 | elapsed time per iteration (ms): 37668.9 | learning rate: 1.435E-04 | global batch size:  1024 | lm loss: 1.879936E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20897/   51900 | consumed samples:     21398528 | elapsed time per iteration (ms): 37647.0 | learning rate: 1.435E-04 | global batch size:  1024 | lm loss: 1.875965E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20898/   51900 | consumed samples:     21399552 | elapsed time per iteration (ms): 37545.9 | learning rate: 1.435E-04 | global batch size:  1024 | lm loss: 1.876124E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20899/   51900 | consumed samples:     21400576 | elapsed time per iteration (ms): 37625.6 | learning rate: 1.435E-04 | global batch size:  1024 | lm loss: 1.883021E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20900/   51900 | consumed samples:     21401600 | elapsed time per iteration (ms): 37680.3 | learning rate: 1.435E-04 | global batch size:  1024 | lm loss: 1.881881E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20901/   51900 | consumed samples:     21402624 | elapsed time per iteration (ms): 37570.8 | learning rate: 1.435E-04 | global batch size:  1024 | lm loss: 1.886284E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20902/   51900 | consumed samples:     21403648 | elapsed time per iteration (ms): 37667.3 | learning rate: 1.434E-04 | global batch size:  1024 | lm loss: 1.892999E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20903/   51900 | consumed samples:     21404672 | elapsed time per iteration (ms): 37494.8 | learning rate: 1.434E-04 | global batch size:  1024 | lm loss: 1.897017E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20904/   51900 | consumed samples:     21405696 | elapsed time per iteration (ms): 37655.4 | learning rate: 1.434E-04 | global batch size:  1024 | lm loss: 1.867121E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20905/   51900 | consumed samples:     21406720 | elapsed time per iteration (ms): 37603.1 | learning rate: 1.434E-04 | global batch size:  1024 | lm loss: 1.895580E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20906/   51900 | consumed samples:     21407744 | elapsed time per iteration (ms): 37738.0 | learning rate: 1.434E-04 | global batch size:  1024 | lm loss: 1.883560E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20907/   51900 | consumed samples:     21408768 | elapsed time per iteration (ms): 37627.4 | learning rate: 1.434E-04 | global batch size:  1024 | lm loss: 1.882344E+00 | loss scale: 1.0 | grad norm: 0.090 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20908/   51900 | consumed samples:     21409792 | elapsed time per iteration (ms): 37582.2 | learning rate: 1.434E-04 | global batch size:  1024 | lm loss: 1.882470E+00 | loss scale: 1.0 | grad norm: 0.090 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20909/   51900 | consumed samples:     21410816 | elapsed time per iteration (ms): 37563.2 | learning rate: 1.434E-04 | global batch size:  1024 | lm loss: 1.874866E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20910/   51900 | consumed samples:     21411840 | elapsed time per iteration (ms): 37583.3 | learning rate: 1.434E-04 | global batch size:  1024 | lm loss: 1.871027E+00 | loss scale: 1.0 | grad norm: 0.087 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20911/   51900 | consumed samples:     21412864 | elapsed time per iteration (ms): 37574.5 | learning rate: 1.434E-04 | global batch size:  1024 | lm loss: 1.884271E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20912/   51900 | consumed samples:     21413888 | elapsed time per iteration (ms): 37630.8 | learning rate: 1.434E-04 | global batch size:  1024 | lm loss: 1.888448E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20913/   51900 | consumed samples:     21414912 | elapsed time per iteration (ms): 37716.8 | learning rate: 1.434E-04 | global batch size:  1024 | lm loss: 1.884130E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20914/   51900 | consumed samples:     21415936 | elapsed time per iteration (ms): 37702.2 | learning rate: 1.434E-04 | global batch size:  1024 | lm loss: 1.880016E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20915/   51900 | consumed samples:     21416960 | elapsed time per iteration (ms): 37694.7 | learning rate: 1.434E-04 | global batch size:  1024 | lm loss: 1.909727E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20916/   51900 | consumed samples:     21417984 | elapsed time per iteration (ms): 37624.4 | learning rate: 1.434E-04 | global batch size:  1024 | lm loss: 1.889510E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20917/   51900 | consumed samples:     21419008 | elapsed time per iteration (ms): 37630.5 | learning rate: 1.434E-04 | global batch size:  1024 | lm loss: 1.861048E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20918/   51900 | consumed samples:     21420032 | elapsed time per iteration (ms): 37586.6 | learning rate: 1.434E-04 | global batch size:  1024 | lm loss: 1.891986E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20919/   51900 | consumed samples:     21421056 | elapsed time per iteration (ms): 37701.1 | learning rate: 1.434E-04 | global batch size:  1024 | lm loss: 1.896276E+00 | loss scale: 1.0 | grad norm: 0.089 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20920/   51900 | consumed samples:     21422080 | elapsed time per iteration (ms): 37653.0 | learning rate: 1.434E-04 | global batch size:  1024 | lm loss: 1.878602E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20921/   51900 | consumed samples:     21423104 | elapsed time per iteration (ms): 37632.8 | learning rate: 1.433E-04 | global batch size:  1024 | lm loss: 1.880115E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20922/   51900 | consumed samples:     21424128 | elapsed time per iteration (ms): 37623.9 | learning rate: 1.433E-04 | global batch size:  1024 | lm loss: 1.858830E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20923/   51900 | consumed samples:     21425152 | elapsed time per iteration (ms): 37594.4 | learning rate: 1.433E-04 | global batch size:  1024 | lm loss: 1.865783E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20924/   51900 | consumed samples:     21426176 | elapsed time per iteration (ms): 37642.7 | learning rate: 1.433E-04 | global batch size:  1024 | lm loss: 1.876588E+00 | loss scale: 1.0 | grad norm: 0.090 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20925/   51900 | consumed samples:     21427200 | elapsed time per iteration (ms): 37670.8 | learning rate: 1.433E-04 | global batch size:  1024 | lm loss: 1.880443E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20926/   51900 | consumed samples:     21428224 | elapsed time per iteration (ms): 37639.8 | learning rate: 1.433E-04 | global batch size:  1024 | lm loss: 1.893099E+00 | loss scale: 1.0 | grad norm: 0.089 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20927/   51900 | consumed samples:     21429248 | elapsed time per iteration (ms): 37612.2 | learning rate: 1.433E-04 | global batch size:  1024 | lm loss: 1.877484E+00 | loss scale: 1.0 | grad norm: 0.094 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20928/   51900 | consumed samples:     21430272 | elapsed time per iteration (ms): 37571.8 | learning rate: 1.433E-04 | global batch size:  1024 | lm loss: 1.889713E+00 | loss scale: 1.0 | grad norm: 0.097 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20929/   51900 | consumed samples:     21431296 | elapsed time per iteration (ms): 37682.0 | learning rate: 1.433E-04 | global batch size:  1024 | lm loss: 1.892692E+00 | loss scale: 1.0 | grad norm: 0.099 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20930/   51900 | consumed samples:     21432320 | elapsed time per iteration (ms): 37518.5 | learning rate: 1.433E-04 | global batch size:  1024 | lm loss: 1.880313E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20931/   51900 | consumed samples:     21433344 | elapsed time per iteration (ms): 37578.6 | learning rate: 1.433E-04 | global batch size:  1024 | lm loss: 1.877941E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20932/   51900 | consumed samples:     21434368 | elapsed time per iteration (ms): 37702.3 | learning rate: 1.433E-04 | global batch size:  1024 | lm loss: 1.897125E+00 | loss scale: 1.0 | grad norm: 0.155 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20933/   51900 | consumed samples:     21435392 | elapsed time per iteration (ms): 37583.8 | learning rate: 1.433E-04 | global batch size:  1024 | lm loss: 1.889179E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20934/   51900 | consumed samples:     21436416 | elapsed time per iteration (ms): 37545.2 | learning rate: 1.433E-04 | global batch size:  1024 | lm loss: 1.877773E+00 | loss scale: 1.0 | grad norm: 0.155 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20935/   51900 | consumed samples:     21437440 | elapsed time per iteration (ms): 37574.5 | learning rate: 1.433E-04 | global batch size:  1024 | lm loss: 1.877490E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20936/   51900 | consumed samples:     21438464 | elapsed time per iteration (ms): 37656.7 | learning rate: 1.433E-04 | global batch size:  1024 | lm loss: 1.897107E+00 | loss scale: 1.0 | grad norm: 0.118 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20937/   51900 | consumed samples:     21439488 | elapsed time per iteration (ms): 37730.5 | learning rate: 1.433E-04 | global batch size:  1024 | lm loss: 1.875373E+00 | loss scale: 1.0 | grad norm: 0.094 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20938/   51900 | consumed samples:     21440512 | elapsed time per iteration (ms): 37709.7 | learning rate: 1.433E-04 | global batch size:  1024 | lm loss: 1.896644E+00 | loss scale: 1.0 | grad norm: 0.152 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20939/   51900 | consumed samples:     21441536 | elapsed time per iteration (ms): 37663.3 | learning rate: 1.433E-04 | global batch size:  1024 | lm loss: 1.892529E+00 | loss scale: 1.0 | grad norm: 0.095 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20940/   51900 | consumed samples:     21442560 | elapsed time per iteration (ms): 37584.5 | learning rate: 1.432E-04 | global batch size:  1024 | lm loss: 1.891224E+00 | loss scale: 1.0 | grad norm: 0.193 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20941/   51900 | consumed samples:     21443584 | elapsed time per iteration (ms): 37643.9 | learning rate: 1.432E-04 | global batch size:  1024 | lm loss: 1.881774E+00 | loss scale: 1.0 | grad norm: 0.145 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20942/   51900 | consumed samples:     21444608 | elapsed time per iteration (ms): 37670.0 | learning rate: 1.432E-04 | global batch size:  1024 | lm loss: 1.902424E+00 | loss scale: 1.0 | grad norm: 0.142 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20943/   51900 | consumed samples:     21445632 | elapsed time per iteration (ms): 37582.5 | learning rate: 1.432E-04 | global batch size:  1024 | lm loss: 1.885324E+00 | loss scale: 1.0 | grad norm: 0.102 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20944/   51900 | consumed samples:     21446656 | elapsed time per iteration (ms): 37614.4 | learning rate: 1.432E-04 | global batch size:  1024 | lm loss: 1.896193E+00 | loss scale: 1.0 | grad norm: 0.100 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20945/   51900 | consumed samples:     21447680 | elapsed time per iteration (ms): 37650.6 | learning rate: 1.432E-04 | global batch size:  1024 | lm loss: 1.889587E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20946/   51900 | consumed samples:     21448704 | elapsed time per iteration (ms): 37649.5 | learning rate: 1.432E-04 | global batch size:  1024 | lm loss: 1.883309E+00 | loss scale: 1.0 | grad norm: 0.087 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20947/   51900 | consumed samples:     21449728 | elapsed time per iteration (ms): 37581.0 | learning rate: 1.432E-04 | global batch size:  1024 | lm loss: 1.892032E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20948/   51900 | consumed samples:     21450752 | elapsed time per iteration (ms): 37637.3 | learning rate: 1.432E-04 | global batch size:  1024 | lm loss: 1.885043E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20949/   51900 | consumed samples:     21451776 | elapsed time per iteration (ms): 37653.9 | learning rate: 1.432E-04 | global batch size:  1024 | lm loss: 1.870037E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20950/   51900 | consumed samples:     21452800 | elapsed time per iteration (ms): 37564.5 | learning rate: 1.432E-04 | global batch size:  1024 | lm loss: 1.870388E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20951/   51900 | consumed samples:     21453824 | elapsed time per iteration (ms): 37740.6 | learning rate: 1.432E-04 | global batch size:  1024 | lm loss: 1.882379E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20952/   51900 | consumed samples:     21454848 | elapsed time per iteration (ms): 37629.6 | learning rate: 1.432E-04 | global batch size:  1024 | lm loss: 1.879926E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20953/   51900 | consumed samples:     21455872 | elapsed time per iteration (ms): 37707.6 | learning rate: 1.432E-04 | global batch size:  1024 | lm loss: 1.887021E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20954/   51900 | consumed samples:     21456896 | elapsed time per iteration (ms): 37665.3 | learning rate: 1.432E-04 | global batch size:  1024 | lm loss: 1.884151E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20955/   51900 | consumed samples:     21457920 | elapsed time per iteration (ms): 37623.0 | learning rate: 1.432E-04 | global batch size:  1024 | lm loss: 1.877706E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20956/   51900 | consumed samples:     21458944 | elapsed time per iteration (ms): 37645.4 | learning rate: 1.432E-04 | global batch size:  1024 | lm loss: 1.888672E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20957/   51900 | consumed samples:     21459968 | elapsed time per iteration (ms): 37735.7 | learning rate: 1.432E-04 | global batch size:  1024 | lm loss: 1.896974E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20958/   51900 | consumed samples:     21460992 | elapsed time per iteration (ms): 37627.9 | learning rate: 1.432E-04 | global batch size:  1024 | lm loss: 1.881315E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20959/   51900 | consumed samples:     21462016 | elapsed time per iteration (ms): 37620.9 | learning rate: 1.431E-04 | global batch size:  1024 | lm loss: 1.888821E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20960/   51900 | consumed samples:     21463040 | elapsed time per iteration (ms): 37570.0 | learning rate: 1.431E-04 | global batch size:  1024 | lm loss: 1.873787E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20961/   51900 | consumed samples:     21464064 | elapsed time per iteration (ms): 37649.7 | learning rate: 1.431E-04 | global batch size:  1024 | lm loss: 1.877735E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20962/   51900 | consumed samples:     21465088 | elapsed time per iteration (ms): 37656.9 | learning rate: 1.431E-04 | global batch size:  1024 | lm loss: 1.891995E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20963/   51900 | consumed samples:     21466112 | elapsed time per iteration (ms): 37547.5 | learning rate: 1.431E-04 | global batch size:  1024 | lm loss: 1.900595E+00 | loss scale: 1.0 | grad norm: 0.065 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20964/   51900 | consumed samples:     21467136 | elapsed time per iteration (ms): 37601.4 | learning rate: 1.431E-04 | global batch size:  1024 | lm loss: 1.880311E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20965/   51900 | consumed samples:     21468160 | elapsed time per iteration (ms): 37721.0 | learning rate: 1.431E-04 | global batch size:  1024 | lm loss: 1.882852E+00 | loss scale: 1.0 | grad norm: 0.063 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20966/   51900 | consumed samples:     21469184 | elapsed time per iteration (ms): 37675.7 | learning rate: 1.431E-04 | global batch size:  1024 | lm loss: 1.881063E+00 | loss scale: 1.0 | grad norm: 0.064 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20967/   51900 | consumed samples:     21470208 | elapsed time per iteration (ms): 37591.4 | learning rate: 1.431E-04 | global batch size:  1024 | lm loss: 1.870628E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20968/   51900 | consumed samples:     21471232 | elapsed time per iteration (ms): 37591.3 | learning rate: 1.431E-04 | global batch size:  1024 | lm loss: 1.865289E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20969/   51900 | consumed samples:     21472256 | elapsed time per iteration (ms): 37615.9 | learning rate: 1.431E-04 | global batch size:  1024 | lm loss: 1.869940E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20970/   51900 | consumed samples:     21473280 | elapsed time per iteration (ms): 37652.0 | learning rate: 1.431E-04 | global batch size:  1024 | lm loss: 1.895212E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20971/   51900 | consumed samples:     21474304 | elapsed time per iteration (ms): 37561.0 | learning rate: 1.431E-04 | global batch size:  1024 | lm loss: 1.889423E+00 | loss scale: 1.0 | grad norm: 0.095 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20972/   51900 | consumed samples:     21475328 | elapsed time per iteration (ms): 37697.8 | learning rate: 1.431E-04 | global batch size:  1024 | lm loss: 1.892136E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20973/   51900 | consumed samples:     21476352 | elapsed time per iteration (ms): 37577.6 | learning rate: 1.431E-04 | global batch size:  1024 | lm loss: 1.905239E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20974/   51900 | consumed samples:     21477376 | elapsed time per iteration (ms): 37604.9 | learning rate: 1.431E-04 | global batch size:  1024 | lm loss: 1.886114E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20975/   51900 | consumed samples:     21478400 | elapsed time per iteration (ms): 37576.3 | learning rate: 1.431E-04 | global batch size:  1024 | lm loss: 1.874388E+00 | loss scale: 1.0 | grad norm: 0.143 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20976/   51900 | consumed samples:     21479424 | elapsed time per iteration (ms): 37728.5 | learning rate: 1.431E-04 | global batch size:  1024 | lm loss: 1.892752E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20977/   51900 | consumed samples:     21480448 | elapsed time per iteration (ms): 37552.1 | learning rate: 1.431E-04 | global batch size:  1024 | lm loss: 1.886998E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20978/   51900 | consumed samples:     21481472 | elapsed time per iteration (ms): 37660.2 | learning rate: 1.430E-04 | global batch size:  1024 | lm loss: 1.889485E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20979/   51900 | consumed samples:     21482496 | elapsed time per iteration (ms): 37645.6 | learning rate: 1.430E-04 | global batch size:  1024 | lm loss: 1.895716E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20980/   51900 | consumed samples:     21483520 | elapsed time per iteration (ms): 37601.5 | learning rate: 1.430E-04 | global batch size:  1024 | lm loss: 1.871664E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20981/   51900 | consumed samples:     21484544 | elapsed time per iteration (ms): 37648.9 | learning rate: 1.430E-04 | global batch size:  1024 | lm loss: 1.886279E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20982/   51900 | consumed samples:     21485568 | elapsed time per iteration (ms): 37639.9 | learning rate: 1.430E-04 | global batch size:  1024 | lm loss: 1.899730E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20983/   51900 | consumed samples:     21486592 | elapsed time per iteration (ms): 37596.3 | learning rate: 1.430E-04 | global batch size:  1024 | lm loss: 1.869941E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20984/   51900 | consumed samples:     21487616 | elapsed time per iteration (ms): 37740.0 | learning rate: 1.430E-04 | global batch size:  1024 | lm loss: 1.896333E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20985/   51900 | consumed samples:     21488640 | elapsed time per iteration (ms): 37645.2 | learning rate: 1.430E-04 | global batch size:  1024 | lm loss: 1.887163E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20986/   51900 | consumed samples:     21489664 | elapsed time per iteration (ms): 37747.7 | learning rate: 1.430E-04 | global batch size:  1024 | lm loss: 1.877154E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20987/   51900 | consumed samples:     21490688 | elapsed time per iteration (ms): 37565.4 | learning rate: 1.430E-04 | global batch size:  1024 | lm loss: 1.882130E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20988/   51900 | consumed samples:     21491712 | elapsed time per iteration (ms): 37645.7 | learning rate: 1.430E-04 | global batch size:  1024 | lm loss: 1.885163E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20989/   51900 | consumed samples:     21492736 | elapsed time per iteration (ms): 37814.1 | learning rate: 1.430E-04 | global batch size:  1024 | lm loss: 1.871718E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20990/   51900 | consumed samples:     21493760 | elapsed time per iteration (ms): 37587.6 | learning rate: 1.430E-04 | global batch size:  1024 | lm loss: 1.887085E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20991/   51900 | consumed samples:     21494784 | elapsed time per iteration (ms): 37607.3 | learning rate: 1.430E-04 | global batch size:  1024 | lm loss: 1.869151E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20992/   51900 | consumed samples:     21495808 | elapsed time per iteration (ms): 37677.0 | learning rate: 1.430E-04 | global batch size:  1024 | lm loss: 1.886798E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20993/   51900 | consumed samples:     21496832 | elapsed time per iteration (ms): 37611.5 | learning rate: 1.430E-04 | global batch size:  1024 | lm loss: 1.878064E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20994/   51900 | consumed samples:     21497856 | elapsed time per iteration (ms): 37731.9 | learning rate: 1.430E-04 | global batch size:  1024 | lm loss: 1.854582E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20995/   51900 | consumed samples:     21498880 | elapsed time per iteration (ms): 37671.9 | learning rate: 1.430E-04 | global batch size:  1024 | lm loss: 1.868772E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20996/   51900 | consumed samples:     21499904 | elapsed time per iteration (ms): 37608.2 | learning rate: 1.430E-04 | global batch size:  1024 | lm loss: 1.884468E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20997/   51900 | consumed samples:     21500928 | elapsed time per iteration (ms): 37635.1 | learning rate: 1.429E-04 | global batch size:  1024 | lm loss: 1.884287E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20998/   51900 | consumed samples:     21501952 | elapsed time per iteration (ms): 37558.3 | learning rate: 1.429E-04 | global batch size:  1024 | lm loss: 1.881545E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    20999/   51900 | consumed samples:     21502976 | elapsed time per iteration (ms): 37530.5 | learning rate: 1.429E-04 | global batch size:  1024 | lm loss: 1.873896E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
