/data/xunjian_yin/mycode/MAP-NEO/Megatron-LM-NEO/megatron/checkpointing.py:422: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state_dict = torch.load(checkpoint_name, map_location='cpu')
/data/xunjian_yin/miniconda3/envs/apex1/lib/python3.10/site-packages/transformer_engine/pytorch/module/base.py:407: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state = torch.load(state, map_location='cuda')
/data/xunjian_yin/miniconda3/envs/apex1/lib/python3.10/site-packages/torch/distributed/c10d_logger.py:79: FutureWarning: `torch.distributed._all_gather_base` is a private function and will be deprecated. Please use `torch.distributed.all_gather_into_tensor` instead.
  return func(*args, **kwargs)
(min, max) time across ranks (ms):
    load-checkpoint ................................: (74274.22, 74274.31)
(min, max) time across ranks (ms):
    model-and-optimizer-setup ......................: (75324.88, 75677.02)
    train/valid/test-data-iterators-setup ..........: (117053.09, 120934.48)
/data/xunjian_yin/mycode/MAP-NEO/Megatron-LM-NEO/megatron/core/tensor_parallel/layers.py:396: FutureWarning: `torch.distributed._reduce_scatter_base` is a private function and will be deprecated. Please use `torch.distributed.reduce_scatter_tensor` instead.
  handle = torch.distributed._reduce_scatter_base(
/data/xunjian_yin/mycode/MAP-NEO/Megatron-LM-NEO/megatron/core/distributed/grad_buffer.py:104: FutureWarning: `torch.distributed._reduce_scatter_base` is a private function and will be deprecated. Please use `torch.distributed.reduce_scatter_tensor` instead.
  self.communication_handle = torch.distributed._reduce_scatter_base(
/data/xunjian_yin/mycode/MAP-NEO/Megatron-LM-NEO/megatron/training.py:533: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1720538438429/work/torch/csrc/tensor/python_tensor.cpp:78.)
  key, torch.cuda.FloatTensor([0.0])) + loss_dict[key]
 iteration    34001/   51900 | consumed samples:     34817024 | elapsed time per iteration (ms): 47542.0 | learning rate: 7.135E-05 | global batch size:  1024 | lm loss: 1.809775E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34002/   51900 | consumed samples:     34818048 | elapsed time per iteration (ms): 37615.8 | learning rate: 7.134E-05 | global batch size:  1024 | lm loss: 1.818066E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34003/   51900 | consumed samples:     34819072 | elapsed time per iteration (ms): 37527.7 | learning rate: 7.134E-05 | global batch size:  1024 | lm loss: 1.802626E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34004/   51900 | consumed samples:     34820096 | elapsed time per iteration (ms): 37678.0 | learning rate: 7.133E-05 | global batch size:  1024 | lm loss: 1.836882E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34005/   51900 | consumed samples:     34821120 | elapsed time per iteration (ms): 37668.0 | learning rate: 7.133E-05 | global batch size:  1024 | lm loss: 1.829568E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34006/   51900 | consumed samples:     34822144 | elapsed time per iteration (ms): 37735.4 | learning rate: 7.132E-05 | global batch size:  1024 | lm loss: 1.831574E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34007/   51900 | consumed samples:     34823168 | elapsed time per iteration (ms): 37717.7 | learning rate: 7.132E-05 | global batch size:  1024 | lm loss: 1.821078E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34008/   51900 | consumed samples:     34824192 | elapsed time per iteration (ms): 37691.5 | learning rate: 7.131E-05 | global batch size:  1024 | lm loss: 1.837778E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34009/   51900 | consumed samples:     34825216 | elapsed time per iteration (ms): 37725.7 | learning rate: 7.131E-05 | global batch size:  1024 | lm loss: 1.837860E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34010/   51900 | consumed samples:     34826240 | elapsed time per iteration (ms): 37707.6 | learning rate: 7.130E-05 | global batch size:  1024 | lm loss: 1.811153E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34011/   51900 | consumed samples:     34827264 | elapsed time per iteration (ms): 37657.8 | learning rate: 7.130E-05 | global batch size:  1024 | lm loss: 1.830041E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34012/   51900 | consumed samples:     34828288 | elapsed time per iteration (ms): 37761.0 | learning rate: 7.129E-05 | global batch size:  1024 | lm loss: 1.825409E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34013/   51900 | consumed samples:     34829312 | elapsed time per iteration (ms): 37670.8 | learning rate: 7.129E-05 | global batch size:  1024 | lm loss: 1.819664E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34014/   51900 | consumed samples:     34830336 | elapsed time per iteration (ms): 37742.1 | learning rate: 7.128E-05 | global batch size:  1024 | lm loss: 1.822583E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34015/   51900 | consumed samples:     34831360 | elapsed time per iteration (ms): 37729.4 | learning rate: 7.128E-05 | global batch size:  1024 | lm loss: 1.809456E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34016/   51900 | consumed samples:     34832384 | elapsed time per iteration (ms): 37621.7 | learning rate: 7.127E-05 | global batch size:  1024 | lm loss: 1.815654E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34017/   51900 | consumed samples:     34833408 | elapsed time per iteration (ms): 37757.6 | learning rate: 7.127E-05 | global batch size:  1024 | lm loss: 1.829547E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34018/   51900 | consumed samples:     34834432 | elapsed time per iteration (ms): 37710.6 | learning rate: 7.126E-05 | global batch size:  1024 | lm loss: 1.826681E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34019/   51900 | consumed samples:     34835456 | elapsed time per iteration (ms): 37630.3 | learning rate: 7.125E-05 | global batch size:  1024 | lm loss: 1.833855E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34020/   51900 | consumed samples:     34836480 | elapsed time per iteration (ms): 37639.2 | learning rate: 7.125E-05 | global batch size:  1024 | lm loss: 1.810711E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34021/   51900 | consumed samples:     34837504 | elapsed time per iteration (ms): 37672.6 | learning rate: 7.124E-05 | global batch size:  1024 | lm loss: 1.820692E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34022/   51900 | consumed samples:     34838528 | elapsed time per iteration (ms): 37715.7 | learning rate: 7.124E-05 | global batch size:  1024 | lm loss: 1.804815E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34023/   51900 | consumed samples:     34839552 | elapsed time per iteration (ms): 37684.6 | learning rate: 7.123E-05 | global batch size:  1024 | lm loss: 1.805743E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34024/   51900 | consumed samples:     34840576 | elapsed time per iteration (ms): 37613.4 | learning rate: 7.123E-05 | global batch size:  1024 | lm loss: 1.806614E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34025/   51900 | consumed samples:     34841600 | elapsed time per iteration (ms): 37639.8 | learning rate: 7.122E-05 | global batch size:  1024 | lm loss: 1.817850E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34026/   51900 | consumed samples:     34842624 | elapsed time per iteration (ms): 37652.7 | learning rate: 7.122E-05 | global batch size:  1024 | lm loss: 1.806774E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34027/   51900 | consumed samples:     34843648 | elapsed time per iteration (ms): 37785.9 | learning rate: 7.121E-05 | global batch size:  1024 | lm loss: 1.821160E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34028/   51900 | consumed samples:     34844672 | elapsed time per iteration (ms): 37841.6 | learning rate: 7.121E-05 | global batch size:  1024 | lm loss: 1.816101E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34029/   51900 | consumed samples:     34845696 | elapsed time per iteration (ms): 37807.0 | learning rate: 7.120E-05 | global batch size:  1024 | lm loss: 1.820947E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34030/   51900 | consumed samples:     34846720 | elapsed time per iteration (ms): 37724.4 | learning rate: 7.120E-05 | global batch size:  1024 | lm loss: 1.817911E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34031/   51900 | consumed samples:     34847744 | elapsed time per iteration (ms): 37693.9 | learning rate: 7.119E-05 | global batch size:  1024 | lm loss: 1.819371E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34032/   51900 | consumed samples:     34848768 | elapsed time per iteration (ms): 37641.1 | learning rate: 7.119E-05 | global batch size:  1024 | lm loss: 1.815056E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34033/   51900 | consumed samples:     34849792 | elapsed time per iteration (ms): 37800.5 | learning rate: 7.118E-05 | global batch size:  1024 | lm loss: 1.813419E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34034/   51900 | consumed samples:     34850816 | elapsed time per iteration (ms): 37688.5 | learning rate: 7.118E-05 | global batch size:  1024 | lm loss: 1.801363E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34035/   51900 | consumed samples:     34851840 | elapsed time per iteration (ms): 37648.8 | learning rate: 7.117E-05 | global batch size:  1024 | lm loss: 1.817044E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34036/   51900 | consumed samples:     34852864 | elapsed time per iteration (ms): 37649.6 | learning rate: 7.117E-05 | global batch size:  1024 | lm loss: 1.822374E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34037/   51900 | consumed samples:     34853888 | elapsed time per iteration (ms): 37671.9 | learning rate: 7.116E-05 | global batch size:  1024 | lm loss: 1.795508E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34038/   51900 | consumed samples:     34854912 | elapsed time per iteration (ms): 37651.1 | learning rate: 7.116E-05 | global batch size:  1024 | lm loss: 1.805106E+00 | loss scale: 1.0 | grad norm: 0.064 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34039/   51900 | consumed samples:     34855936 | elapsed time per iteration (ms): 37755.7 | learning rate: 7.115E-05 | global batch size:  1024 | lm loss: 1.832139E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34040/   51900 | consumed samples:     34856960 | elapsed time per iteration (ms): 37699.9 | learning rate: 7.115E-05 | global batch size:  1024 | lm loss: 1.816234E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34041/   51900 | consumed samples:     34857984 | elapsed time per iteration (ms): 37816.9 | learning rate: 7.114E-05 | global batch size:  1024 | lm loss: 1.822503E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34042/   51900 | consumed samples:     34859008 | elapsed time per iteration (ms): 37642.9 | learning rate: 7.114E-05 | global batch size:  1024 | lm loss: 1.802906E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34043/   51900 | consumed samples:     34860032 | elapsed time per iteration (ms): 37587.5 | learning rate: 7.113E-05 | global batch size:  1024 | lm loss: 1.825336E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34044/   51900 | consumed samples:     34861056 | elapsed time per iteration (ms): 37680.6 | learning rate: 7.113E-05 | global batch size:  1024 | lm loss: 1.833104E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34045/   51900 | consumed samples:     34862080 | elapsed time per iteration (ms): 37761.8 | learning rate: 7.112E-05 | global batch size:  1024 | lm loss: 1.819283E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34046/   51900 | consumed samples:     34863104 | elapsed time per iteration (ms): 37597.7 | learning rate: 7.112E-05 | global batch size:  1024 | lm loss: 1.808918E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34047/   51900 | consumed samples:     34864128 | elapsed time per iteration (ms): 37631.2 | learning rate: 7.111E-05 | global batch size:  1024 | lm loss: 1.824045E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34048/   51900 | consumed samples:     34865152 | elapsed time per iteration (ms): 37614.0 | learning rate: 7.111E-05 | global batch size:  1024 | lm loss: 1.792657E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34049/   51900 | consumed samples:     34866176 | elapsed time per iteration (ms): 37728.1 | learning rate: 7.110E-05 | global batch size:  1024 | lm loss: 1.829429E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34050/   51900 | consumed samples:     34867200 | elapsed time per iteration (ms): 37689.1 | learning rate: 7.110E-05 | global batch size:  1024 | lm loss: 1.818054E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34051/   51900 | consumed samples:     34868224 | elapsed time per iteration (ms): 37673.3 | learning rate: 7.109E-05 | global batch size:  1024 | lm loss: 1.807940E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34052/   51900 | consumed samples:     34869248 | elapsed time per iteration (ms): 37785.1 | learning rate: 7.109E-05 | global batch size:  1024 | lm loss: 1.816984E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34053/   51900 | consumed samples:     34870272 | elapsed time per iteration (ms): 37737.3 | learning rate: 7.108E-05 | global batch size:  1024 | lm loss: 1.820445E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34054/   51900 | consumed samples:     34871296 | elapsed time per iteration (ms): 37665.1 | learning rate: 7.108E-05 | global batch size:  1024 | lm loss: 1.820775E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34055/   51900 | consumed samples:     34872320 | elapsed time per iteration (ms): 37720.4 | learning rate: 7.107E-05 | global batch size:  1024 | lm loss: 1.850116E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34056/   51900 | consumed samples:     34873344 | elapsed time per iteration (ms): 37693.4 | learning rate: 7.107E-05 | global batch size:  1024 | lm loss: 1.816057E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34057/   51900 | consumed samples:     34874368 | elapsed time per iteration (ms): 37673.5 | learning rate: 7.106E-05 | global batch size:  1024 | lm loss: 1.827643E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34058/   51900 | consumed samples:     34875392 | elapsed time per iteration (ms): 37754.0 | learning rate: 7.106E-05 | global batch size:  1024 | lm loss: 1.798284E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34059/   51900 | consumed samples:     34876416 | elapsed time per iteration (ms): 37737.7 | learning rate: 7.105E-05 | global batch size:  1024 | lm loss: 1.808197E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34060/   51900 | consumed samples:     34877440 | elapsed time per iteration (ms): 37684.8 | learning rate: 7.105E-05 | global batch size:  1024 | lm loss: 1.831828E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34061/   51900 | consumed samples:     34878464 | elapsed time per iteration (ms): 37642.1 | learning rate: 7.104E-05 | global batch size:  1024 | lm loss: 1.829915E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34062/   51900 | consumed samples:     34879488 | elapsed time per iteration (ms): 37771.2 | learning rate: 7.104E-05 | global batch size:  1024 | lm loss: 1.825401E+00 | loss scale: 1.0 | grad norm: 0.065 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34063/   51900 | consumed samples:     34880512 | elapsed time per iteration (ms): 37695.8 | learning rate: 7.103E-05 | global batch size:  1024 | lm loss: 1.794139E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34064/   51900 | consumed samples:     34881536 | elapsed time per iteration (ms): 37592.3 | learning rate: 7.102E-05 | global batch size:  1024 | lm loss: 1.834222E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34065/   51900 | consumed samples:     34882560 | elapsed time per iteration (ms): 37684.2 | learning rate: 7.102E-05 | global batch size:  1024 | lm loss: 1.823167E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34066/   51900 | consumed samples:     34883584 | elapsed time per iteration (ms): 37681.2 | learning rate: 7.101E-05 | global batch size:  1024 | lm loss: 1.815655E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34067/   51900 | consumed samples:     34884608 | elapsed time per iteration (ms): 37526.8 | learning rate: 7.101E-05 | global batch size:  1024 | lm loss: 1.819366E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34068/   51900 | consumed samples:     34885632 | elapsed time per iteration (ms): 37702.5 | learning rate: 7.100E-05 | global batch size:  1024 | lm loss: 1.835092E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34069/   51900 | consumed samples:     34886656 | elapsed time per iteration (ms): 37647.5 | learning rate: 7.100E-05 | global batch size:  1024 | lm loss: 1.804722E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34070/   51900 | consumed samples:     34887680 | elapsed time per iteration (ms): 37716.1 | learning rate: 7.099E-05 | global batch size:  1024 | lm loss: 1.811651E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34071/   51900 | consumed samples:     34888704 | elapsed time per iteration (ms): 37682.5 | learning rate: 7.099E-05 | global batch size:  1024 | lm loss: 1.803024E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34072/   51900 | consumed samples:     34889728 | elapsed time per iteration (ms): 37696.2 | learning rate: 7.098E-05 | global batch size:  1024 | lm loss: 1.820773E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34073/   51900 | consumed samples:     34890752 | elapsed time per iteration (ms): 37678.4 | learning rate: 7.098E-05 | global batch size:  1024 | lm loss: 1.821622E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34074/   51900 | consumed samples:     34891776 | elapsed time per iteration (ms): 37703.8 | learning rate: 7.097E-05 | global batch size:  1024 | lm loss: 1.824457E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34075/   51900 | consumed samples:     34892800 | elapsed time per iteration (ms): 37644.7 | learning rate: 7.097E-05 | global batch size:  1024 | lm loss: 1.809535E+00 | loss scale: 1.0 | grad norm: 0.101 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34076/   51900 | consumed samples:     34893824 | elapsed time per iteration (ms): 37708.3 | learning rate: 7.096E-05 | global batch size:  1024 | lm loss: 1.826110E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34077/   51900 | consumed samples:     34894848 | elapsed time per iteration (ms): 37656.1 | learning rate: 7.096E-05 | global batch size:  1024 | lm loss: 1.836441E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34078/   51900 | consumed samples:     34895872 | elapsed time per iteration (ms): 37630.6 | learning rate: 7.095E-05 | global batch size:  1024 | lm loss: 1.798263E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34079/   51900 | consumed samples:     34896896 | elapsed time per iteration (ms): 37772.3 | learning rate: 7.095E-05 | global batch size:  1024 | lm loss: 1.821475E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34080/   51900 | consumed samples:     34897920 | elapsed time per iteration (ms): 37593.6 | learning rate: 7.094E-05 | global batch size:  1024 | lm loss: 1.826100E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34081/   51900 | consumed samples:     34898944 | elapsed time per iteration (ms): 37822.7 | learning rate: 7.094E-05 | global batch size:  1024 | lm loss: 1.824136E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34082/   51900 | consumed samples:     34899968 | elapsed time per iteration (ms): 37671.0 | learning rate: 7.093E-05 | global batch size:  1024 | lm loss: 1.832772E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34083/   51900 | consumed samples:     34900992 | elapsed time per iteration (ms): 37778.6 | learning rate: 7.093E-05 | global batch size:  1024 | lm loss: 1.813546E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34084/   51900 | consumed samples:     34902016 | elapsed time per iteration (ms): 37792.8 | learning rate: 7.092E-05 | global batch size:  1024 | lm loss: 1.836502E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34085/   51900 | consumed samples:     34903040 | elapsed time per iteration (ms): 37565.5 | learning rate: 7.092E-05 | global batch size:  1024 | lm loss: 1.811920E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34086/   51900 | consumed samples:     34904064 | elapsed time per iteration (ms): 37640.9 | learning rate: 7.091E-05 | global batch size:  1024 | lm loss: 1.819380E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34087/   51900 | consumed samples:     34905088 | elapsed time per iteration (ms): 37580.6 | learning rate: 7.091E-05 | global batch size:  1024 | lm loss: 1.809542E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34088/   51900 | consumed samples:     34906112 | elapsed time per iteration (ms): 37774.8 | learning rate: 7.090E-05 | global batch size:  1024 | lm loss: 1.795911E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34089/   51900 | consumed samples:     34907136 | elapsed time per iteration (ms): 37758.0 | learning rate: 7.090E-05 | global batch size:  1024 | lm loss: 1.818655E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34090/   51900 | consumed samples:     34908160 | elapsed time per iteration (ms): 37598.7 | learning rate: 7.089E-05 | global batch size:  1024 | lm loss: 1.811886E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34091/   51900 | consumed samples:     34909184 | elapsed time per iteration (ms): 37615.4 | learning rate: 7.089E-05 | global batch size:  1024 | lm loss: 1.829550E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34092/   51900 | consumed samples:     34910208 | elapsed time per iteration (ms): 37757.7 | learning rate: 7.088E-05 | global batch size:  1024 | lm loss: 1.816708E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34093/   51900 | consumed samples:     34911232 | elapsed time per iteration (ms): 37734.0 | learning rate: 7.088E-05 | global batch size:  1024 | lm loss: 1.835650E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34094/   51900 | consumed samples:     34912256 | elapsed time per iteration (ms): 37763.1 | learning rate: 7.087E-05 | global batch size:  1024 | lm loss: 1.807666E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34095/   51900 | consumed samples:     34913280 | elapsed time per iteration (ms): 37791.7 | learning rate: 7.087E-05 | global batch size:  1024 | lm loss: 1.827583E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34096/   51900 | consumed samples:     34914304 | elapsed time per iteration (ms): 37800.5 | learning rate: 7.086E-05 | global batch size:  1024 | lm loss: 1.823635E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34097/   51900 | consumed samples:     34915328 | elapsed time per iteration (ms): 37669.7 | learning rate: 7.086E-05 | global batch size:  1024 | lm loss: 1.795287E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34098/   51900 | consumed samples:     34916352 | elapsed time per iteration (ms): 37621.9 | learning rate: 7.085E-05 | global batch size:  1024 | lm loss: 1.820602E+00 | loss scale: 1.0 | grad norm: 0.065 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34099/   51900 | consumed samples:     34917376 | elapsed time per iteration (ms): 37759.5 | learning rate: 7.085E-05 | global batch size:  1024 | lm loss: 1.813420E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34100/   51900 | consumed samples:     34918400 | elapsed time per iteration (ms): 37716.0 | learning rate: 7.084E-05 | global batch size:  1024 | lm loss: 1.828393E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34101/   51900 | consumed samples:     34919424 | elapsed time per iteration (ms): 37630.5 | learning rate: 7.084E-05 | global batch size:  1024 | lm loss: 1.814058E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34102/   51900 | consumed samples:     34920448 | elapsed time per iteration (ms): 37709.4 | learning rate: 7.083E-05 | global batch size:  1024 | lm loss: 1.818825E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34103/   51900 | consumed samples:     34921472 | elapsed time per iteration (ms): 37785.4 | learning rate: 7.083E-05 | global batch size:  1024 | lm loss: 1.809609E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34104/   51900 | consumed samples:     34922496 | elapsed time per iteration (ms): 37785.0 | learning rate: 7.082E-05 | global batch size:  1024 | lm loss: 1.827579E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34105/   51900 | consumed samples:     34923520 | elapsed time per iteration (ms): 37687.7 | learning rate: 7.082E-05 | global batch size:  1024 | lm loss: 1.818674E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34106/   51900 | consumed samples:     34924544 | elapsed time per iteration (ms): 37657.6 | learning rate: 7.081E-05 | global batch size:  1024 | lm loss: 1.815210E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34107/   51900 | consumed samples:     34925568 | elapsed time per iteration (ms): 37785.5 | learning rate: 7.081E-05 | global batch size:  1024 | lm loss: 1.824354E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34108/   51900 | consumed samples:     34926592 | elapsed time per iteration (ms): 37754.4 | learning rate: 7.080E-05 | global batch size:  1024 | lm loss: 1.808358E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34109/   51900 | consumed samples:     34927616 | elapsed time per iteration (ms): 37680.7 | learning rate: 7.080E-05 | global batch size:  1024 | lm loss: 1.831843E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34110/   51900 | consumed samples:     34928640 | elapsed time per iteration (ms): 37674.3 | learning rate: 7.079E-05 | global batch size:  1024 | lm loss: 1.826157E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34111/   51900 | consumed samples:     34929664 | elapsed time per iteration (ms): 37630.0 | learning rate: 7.078E-05 | global batch size:  1024 | lm loss: 1.809470E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34112/   51900 | consumed samples:     34930688 | elapsed time per iteration (ms): 37728.4 | learning rate: 7.078E-05 | global batch size:  1024 | lm loss: 1.814114E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34113/   51900 | consumed samples:     34931712 | elapsed time per iteration (ms): 37782.8 | learning rate: 7.077E-05 | global batch size:  1024 | lm loss: 1.832264E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34114/   51900 | consumed samples:     34932736 | elapsed time per iteration (ms): 37681.6 | learning rate: 7.077E-05 | global batch size:  1024 | lm loss: 1.841776E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34115/   51900 | consumed samples:     34933760 | elapsed time per iteration (ms): 37689.7 | learning rate: 7.076E-05 | global batch size:  1024 | lm loss: 1.826539E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34116/   51900 | consumed samples:     34934784 | elapsed time per iteration (ms): 37625.3 | learning rate: 7.076E-05 | global batch size:  1024 | lm loss: 1.800086E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34117/   51900 | consumed samples:     34935808 | elapsed time per iteration (ms): 37703.7 | learning rate: 7.075E-05 | global batch size:  1024 | lm loss: 1.824224E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34118/   51900 | consumed samples:     34936832 | elapsed time per iteration (ms): 37672.5 | learning rate: 7.075E-05 | global batch size:  1024 | lm loss: 1.807153E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34119/   51900 | consumed samples:     34937856 | elapsed time per iteration (ms): 37739.6 | learning rate: 7.074E-05 | global batch size:  1024 | lm loss: 1.825374E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34120/   51900 | consumed samples:     34938880 | elapsed time per iteration (ms): 37880.9 | learning rate: 7.074E-05 | global batch size:  1024 | lm loss: 1.820429E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34121/   51900 | consumed samples:     34939904 | elapsed time per iteration (ms): 37680.5 | learning rate: 7.073E-05 | global batch size:  1024 | lm loss: 1.805569E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34122/   51900 | consumed samples:     34940928 | elapsed time per iteration (ms): 37704.6 | learning rate: 7.073E-05 | global batch size:  1024 | lm loss: 1.807156E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34123/   51900 | consumed samples:     34941952 | elapsed time per iteration (ms): 37693.3 | learning rate: 7.072E-05 | global batch size:  1024 | lm loss: 1.801072E+00 | loss scale: 1.0 | grad norm: 0.098 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34124/   51900 | consumed samples:     34942976 | elapsed time per iteration (ms): 37705.7 | learning rate: 7.072E-05 | global batch size:  1024 | lm loss: 1.828514E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34125/   51900 | consumed samples:     34944000 | elapsed time per iteration (ms): 37711.8 | learning rate: 7.071E-05 | global batch size:  1024 | lm loss: 1.809854E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34126/   51900 | consumed samples:     34945024 | elapsed time per iteration (ms): 37607.8 | learning rate: 7.071E-05 | global batch size:  1024 | lm loss: 1.816577E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34127/   51900 | consumed samples:     34946048 | elapsed time per iteration (ms): 37728.6 | learning rate: 7.070E-05 | global batch size:  1024 | lm loss: 1.821168E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34128/   51900 | consumed samples:     34947072 | elapsed time per iteration (ms): 37697.9 | learning rate: 7.070E-05 | global batch size:  1024 | lm loss: 1.819952E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34129/   51900 | consumed samples:     34948096 | elapsed time per iteration (ms): 37734.3 | learning rate: 7.069E-05 | global batch size:  1024 | lm loss: 1.815902E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34130/   51900 | consumed samples:     34949120 | elapsed time per iteration (ms): 37779.7 | learning rate: 7.069E-05 | global batch size:  1024 | lm loss: 1.801512E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34131/   51900 | consumed samples:     34950144 | elapsed time per iteration (ms): 37663.3 | learning rate: 7.068E-05 | global batch size:  1024 | lm loss: 1.804941E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34132/   51900 | consumed samples:     34951168 | elapsed time per iteration (ms): 37701.7 | learning rate: 7.068E-05 | global batch size:  1024 | lm loss: 1.821535E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34133/   51900 | consumed samples:     34952192 | elapsed time per iteration (ms): 37726.5 | learning rate: 7.067E-05 | global batch size:  1024 | lm loss: 1.809502E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34134/   51900 | consumed samples:     34953216 | elapsed time per iteration (ms): 37690.0 | learning rate: 7.067E-05 | global batch size:  1024 | lm loss: 1.826366E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34135/   51900 | consumed samples:     34954240 | elapsed time per iteration (ms): 37743.8 | learning rate: 7.066E-05 | global batch size:  1024 | lm loss: 1.819729E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34136/   51900 | consumed samples:     34955264 | elapsed time per iteration (ms): 37741.5 | learning rate: 7.066E-05 | global batch size:  1024 | lm loss: 1.835465E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34137/   51900 | consumed samples:     34956288 | elapsed time per iteration (ms): 37604.3 | learning rate: 7.065E-05 | global batch size:  1024 | lm loss: 1.816882E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34138/   51900 | consumed samples:     34957312 | elapsed time per iteration (ms): 37710.1 | learning rate: 7.065E-05 | global batch size:  1024 | lm loss: 1.805157E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34139/   51900 | consumed samples:     34958336 | elapsed time per iteration (ms): 37636.6 | learning rate: 7.064E-05 | global batch size:  1024 | lm loss: 1.827162E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34140/   51900 | consumed samples:     34959360 | elapsed time per iteration (ms): 37771.5 | learning rate: 7.064E-05 | global batch size:  1024 | lm loss: 1.818507E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34141/   51900 | consumed samples:     34960384 | elapsed time per iteration (ms): 37750.8 | learning rate: 7.063E-05 | global batch size:  1024 | lm loss: 1.814849E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34142/   51900 | consumed samples:     34961408 | elapsed time per iteration (ms): 37738.3 | learning rate: 7.063E-05 | global batch size:  1024 | lm loss: 1.824398E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34143/   51900 | consumed samples:     34962432 | elapsed time per iteration (ms): 37828.3 | learning rate: 7.062E-05 | global batch size:  1024 | lm loss: 1.814276E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34144/   51900 | consumed samples:     34963456 | elapsed time per iteration (ms): 37758.5 | learning rate: 7.062E-05 | global batch size:  1024 | lm loss: 1.815097E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34145/   51900 | consumed samples:     34964480 | elapsed time per iteration (ms): 37706.8 | learning rate: 7.061E-05 | global batch size:  1024 | lm loss: 1.815835E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34146/   51900 | consumed samples:     34965504 | elapsed time per iteration (ms): 37614.3 | learning rate: 7.061E-05 | global batch size:  1024 | lm loss: 1.815378E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34147/   51900 | consumed samples:     34966528 | elapsed time per iteration (ms): 37669.5 | learning rate: 7.060E-05 | global batch size:  1024 | lm loss: 1.815034E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34148/   51900 | consumed samples:     34967552 | elapsed time per iteration (ms): 37805.2 | learning rate: 7.060E-05 | global batch size:  1024 | lm loss: 1.807251E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34149/   51900 | consumed samples:     34968576 | elapsed time per iteration (ms): 37714.7 | learning rate: 7.059E-05 | global batch size:  1024 | lm loss: 1.816245E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34150/   51900 | consumed samples:     34969600 | elapsed time per iteration (ms): 37640.4 | learning rate: 7.059E-05 | global batch size:  1024 | lm loss: 1.806273E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34151/   51900 | consumed samples:     34970624 | elapsed time per iteration (ms): 37643.4 | learning rate: 7.058E-05 | global batch size:  1024 | lm loss: 1.817827E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34152/   51900 | consumed samples:     34971648 | elapsed time per iteration (ms): 37660.5 | learning rate: 7.058E-05 | global batch size:  1024 | lm loss: 1.831202E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34153/   51900 | consumed samples:     34972672 | elapsed time per iteration (ms): 37617.5 | learning rate: 7.057E-05 | global batch size:  1024 | lm loss: 1.821250E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34154/   51900 | consumed samples:     34973696 | elapsed time per iteration (ms): 37649.5 | learning rate: 7.057E-05 | global batch size:  1024 | lm loss: 1.832190E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34155/   51900 | consumed samples:     34974720 | elapsed time per iteration (ms): 37580.5 | learning rate: 7.056E-05 | global batch size:  1024 | lm loss: 1.827690E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34156/   51900 | consumed samples:     34975744 | elapsed time per iteration (ms): 37837.3 | learning rate: 7.056E-05 | global batch size:  1024 | lm loss: 1.807315E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34157/   51900 | consumed samples:     34976768 | elapsed time per iteration (ms): 37679.4 | learning rate: 7.055E-05 | global batch size:  1024 | lm loss: 1.814169E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34158/   51900 | consumed samples:     34977792 | elapsed time per iteration (ms): 37771.4 | learning rate: 7.055E-05 | global batch size:  1024 | lm loss: 1.838079E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34159/   51900 | consumed samples:     34978816 | elapsed time per iteration (ms): 37760.9 | learning rate: 7.054E-05 | global batch size:  1024 | lm loss: 1.835857E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34160/   51900 | consumed samples:     34979840 | elapsed time per iteration (ms): 37692.2 | learning rate: 7.054E-05 | global batch size:  1024 | lm loss: 1.829004E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34161/   51900 | consumed samples:     34980864 | elapsed time per iteration (ms): 37617.1 | learning rate: 7.053E-05 | global batch size:  1024 | lm loss: 1.814452E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34162/   51900 | consumed samples:     34981888 | elapsed time per iteration (ms): 37715.1 | learning rate: 7.053E-05 | global batch size:  1024 | lm loss: 1.812336E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34163/   51900 | consumed samples:     34982912 | elapsed time per iteration (ms): 37655.0 | learning rate: 7.052E-05 | global batch size:  1024 | lm loss: 1.816945E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34164/   51900 | consumed samples:     34983936 | elapsed time per iteration (ms): 37680.5 | learning rate: 7.051E-05 | global batch size:  1024 | lm loss: 1.820419E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34165/   51900 | consumed samples:     34984960 | elapsed time per iteration (ms): 37656.1 | learning rate: 7.051E-05 | global batch size:  1024 | lm loss: 1.822434E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34166/   51900 | consumed samples:     34985984 | elapsed time per iteration (ms): 37646.9 | learning rate: 7.050E-05 | global batch size:  1024 | lm loss: 1.832948E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34167/   51900 | consumed samples:     34987008 | elapsed time per iteration (ms): 37574.9 | learning rate: 7.050E-05 | global batch size:  1024 | lm loss: 1.825520E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34168/   51900 | consumed samples:     34988032 | elapsed time per iteration (ms): 37655.7 | learning rate: 7.049E-05 | global batch size:  1024 | lm loss: 1.816826E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34169/   51900 | consumed samples:     34989056 | elapsed time per iteration (ms): 37660.7 | learning rate: 7.049E-05 | global batch size:  1024 | lm loss: 1.805421E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34170/   51900 | consumed samples:     34990080 | elapsed time per iteration (ms): 37649.5 | learning rate: 7.048E-05 | global batch size:  1024 | lm loss: 1.809570E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34171/   51900 | consumed samples:     34991104 | elapsed time per iteration (ms): 37775.7 | learning rate: 7.048E-05 | global batch size:  1024 | lm loss: 1.813660E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34172/   51900 | consumed samples:     34992128 | elapsed time per iteration (ms): 37759.4 | learning rate: 7.047E-05 | global batch size:  1024 | lm loss: 1.828696E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34173/   51900 | consumed samples:     34993152 | elapsed time per iteration (ms): 37555.7 | learning rate: 7.047E-05 | global batch size:  1024 | lm loss: 1.810738E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34174/   51900 | consumed samples:     34994176 | elapsed time per iteration (ms): 37620.4 | learning rate: 7.046E-05 | global batch size:  1024 | lm loss: 1.823259E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34175/   51900 | consumed samples:     34995200 | elapsed time per iteration (ms): 37717.2 | learning rate: 7.046E-05 | global batch size:  1024 | lm loss: 1.820333E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34176/   51900 | consumed samples:     34996224 | elapsed time per iteration (ms): 37756.7 | learning rate: 7.045E-05 | global batch size:  1024 | lm loss: 1.817630E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34177/   51900 | consumed samples:     34997248 | elapsed time per iteration (ms): 37607.7 | learning rate: 7.045E-05 | global batch size:  1024 | lm loss: 1.818938E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34178/   51900 | consumed samples:     34998272 | elapsed time per iteration (ms): 37643.9 | learning rate: 7.044E-05 | global batch size:  1024 | lm loss: 1.814667E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34179/   51900 | consumed samples:     34999296 | elapsed time per iteration (ms): 37670.9 | learning rate: 7.044E-05 | global batch size:  1024 | lm loss: 1.829043E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34180/   51900 | consumed samples:     35000320 | elapsed time per iteration (ms): 37641.9 | learning rate: 7.043E-05 | global batch size:  1024 | lm loss: 1.810065E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34181/   51900 | consumed samples:     35001344 | elapsed time per iteration (ms): 37718.4 | learning rate: 7.043E-05 | global batch size:  1024 | lm loss: 1.822680E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34182/   51900 | consumed samples:     35002368 | elapsed time per iteration (ms): 37687.4 | learning rate: 7.042E-05 | global batch size:  1024 | lm loss: 1.813792E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34183/   51900 | consumed samples:     35003392 | elapsed time per iteration (ms): 37611.9 | learning rate: 7.042E-05 | global batch size:  1024 | lm loss: 1.811257E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34184/   51900 | consumed samples:     35004416 | elapsed time per iteration (ms): 37724.2 | learning rate: 7.041E-05 | global batch size:  1024 | lm loss: 1.821151E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34185/   51900 | consumed samples:     35005440 | elapsed time per iteration (ms): 37669.7 | learning rate: 7.041E-05 | global batch size:  1024 | lm loss: 1.815142E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34186/   51900 | consumed samples:     35006464 | elapsed time per iteration (ms): 37747.1 | learning rate: 7.040E-05 | global batch size:  1024 | lm loss: 1.813681E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34187/   51900 | consumed samples:     35007488 | elapsed time per iteration (ms): 37717.5 | learning rate: 7.040E-05 | global batch size:  1024 | lm loss: 1.817135E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34188/   51900 | consumed samples:     35008512 | elapsed time per iteration (ms): 37691.9 | learning rate: 7.039E-05 | global batch size:  1024 | lm loss: 1.826158E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34189/   51900 | consumed samples:     35009536 | elapsed time per iteration (ms): 37588.5 | learning rate: 7.039E-05 | global batch size:  1024 | lm loss: 1.829717E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34190/   51900 | consumed samples:     35010560 | elapsed time per iteration (ms): 37682.3 | learning rate: 7.038E-05 | global batch size:  1024 | lm loss: 1.810673E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34191/   51900 | consumed samples:     35011584 | elapsed time per iteration (ms): 37745.9 | learning rate: 7.038E-05 | global batch size:  1024 | lm loss: 1.811871E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34192/   51900 | consumed samples:     35012608 | elapsed time per iteration (ms): 37706.1 | learning rate: 7.037E-05 | global batch size:  1024 | lm loss: 1.816833E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34193/   51900 | consumed samples:     35013632 | elapsed time per iteration (ms): 37697.1 | learning rate: 7.037E-05 | global batch size:  1024 | lm loss: 1.790001E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34194/   51900 | consumed samples:     35014656 | elapsed time per iteration (ms): 37673.7 | learning rate: 7.036E-05 | global batch size:  1024 | lm loss: 1.822899E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34195/   51900 | consumed samples:     35015680 | elapsed time per iteration (ms): 37667.7 | learning rate: 7.036E-05 | global batch size:  1024 | lm loss: 1.813716E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34196/   51900 | consumed samples:     35016704 | elapsed time per iteration (ms): 37564.0 | learning rate: 7.035E-05 | global batch size:  1024 | lm loss: 1.826941E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34197/   51900 | consumed samples:     35017728 | elapsed time per iteration (ms): 37683.9 | learning rate: 7.035E-05 | global batch size:  1024 | lm loss: 1.804055E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34198/   51900 | consumed samples:     35018752 | elapsed time per iteration (ms): 37688.9 | learning rate: 7.034E-05 | global batch size:  1024 | lm loss: 1.826694E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34199/   51900 | consumed samples:     35019776 | elapsed time per iteration (ms): 37660.9 | learning rate: 7.034E-05 | global batch size:  1024 | lm loss: 1.825250E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34200/   51900 | consumed samples:     35020800 | elapsed time per iteration (ms): 37676.7 | learning rate: 7.033E-05 | global batch size:  1024 | lm loss: 1.791619E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34201/   51900 | consumed samples:     35021824 | elapsed time per iteration (ms): 37613.3 | learning rate: 7.033E-05 | global batch size:  1024 | lm loss: 1.815807E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34202/   51900 | consumed samples:     35022848 | elapsed time per iteration (ms): 37635.2 | learning rate: 7.032E-05 | global batch size:  1024 | lm loss: 1.820358E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34203/   51900 | consumed samples:     35023872 | elapsed time per iteration (ms): 37763.9 | learning rate: 7.032E-05 | global batch size:  1024 | lm loss: 1.815988E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34204/   51900 | consumed samples:     35024896 | elapsed time per iteration (ms): 37693.8 | learning rate: 7.031E-05 | global batch size:  1024 | lm loss: 1.817677E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34205/   51900 | consumed samples:     35025920 | elapsed time per iteration (ms): 37664.1 | learning rate: 7.031E-05 | global batch size:  1024 | lm loss: 1.820029E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34206/   51900 | consumed samples:     35026944 | elapsed time per iteration (ms): 37706.8 | learning rate: 7.030E-05 | global batch size:  1024 | lm loss: 1.801984E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34207/   51900 | consumed samples:     35027968 | elapsed time per iteration (ms): 37685.6 | learning rate: 7.030E-05 | global batch size:  1024 | lm loss: 1.810286E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34208/   51900 | consumed samples:     35028992 | elapsed time per iteration (ms): 37795.2 | learning rate: 7.029E-05 | global batch size:  1024 | lm loss: 1.803418E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34209/   51900 | consumed samples:     35030016 | elapsed time per iteration (ms): 37603.5 | learning rate: 7.029E-05 | global batch size:  1024 | lm loss: 1.799222E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34210/   51900 | consumed samples:     35031040 | elapsed time per iteration (ms): 37604.0 | learning rate: 7.028E-05 | global batch size:  1024 | lm loss: 1.797861E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34211/   51900 | consumed samples:     35032064 | elapsed time per iteration (ms): 37740.2 | learning rate: 7.028E-05 | global batch size:  1024 | lm loss: 1.805938E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34212/   51900 | consumed samples:     35033088 | elapsed time per iteration (ms): 37575.1 | learning rate: 7.027E-05 | global batch size:  1024 | lm loss: 1.817523E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34213/   51900 | consumed samples:     35034112 | elapsed time per iteration (ms): 37602.8 | learning rate: 7.027E-05 | global batch size:  1024 | lm loss: 1.815960E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34214/   51900 | consumed samples:     35035136 | elapsed time per iteration (ms): 37714.3 | learning rate: 7.026E-05 | global batch size:  1024 | lm loss: 1.813884E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34215/   51900 | consumed samples:     35036160 | elapsed time per iteration (ms): 37551.9 | learning rate: 7.026E-05 | global batch size:  1024 | lm loss: 1.814795E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34216/   51900 | consumed samples:     35037184 | elapsed time per iteration (ms): 37715.9 | learning rate: 7.025E-05 | global batch size:  1024 | lm loss: 1.801521E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34217/   51900 | consumed samples:     35038208 | elapsed time per iteration (ms): 37725.3 | learning rate: 7.025E-05 | global batch size:  1024 | lm loss: 1.827958E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34218/   51900 | consumed samples:     35039232 | elapsed time per iteration (ms): 37763.2 | learning rate: 7.024E-05 | global batch size:  1024 | lm loss: 1.815988E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34219/   51900 | consumed samples:     35040256 | elapsed time per iteration (ms): 37678.7 | learning rate: 7.024E-05 | global batch size:  1024 | lm loss: 1.819501E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34220/   51900 | consumed samples:     35041280 | elapsed time per iteration (ms): 37617.4 | learning rate: 7.023E-05 | global batch size:  1024 | lm loss: 1.824058E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34221/   51900 | consumed samples:     35042304 | elapsed time per iteration (ms): 37703.0 | learning rate: 7.022E-05 | global batch size:  1024 | lm loss: 1.796284E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34222/   51900 | consumed samples:     35043328 | elapsed time per iteration (ms): 37682.0 | learning rate: 7.022E-05 | global batch size:  1024 | lm loss: 1.833216E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34223/   51900 | consumed samples:     35044352 | elapsed time per iteration (ms): 37639.8 | learning rate: 7.021E-05 | global batch size:  1024 | lm loss: 1.816732E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34224/   51900 | consumed samples:     35045376 | elapsed time per iteration (ms): 37625.3 | learning rate: 7.021E-05 | global batch size:  1024 | lm loss: 1.824156E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34225/   51900 | consumed samples:     35046400 | elapsed time per iteration (ms): 37632.8 | learning rate: 7.020E-05 | global batch size:  1024 | lm loss: 1.830001E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34226/   51900 | consumed samples:     35047424 | elapsed time per iteration (ms): 37567.5 | learning rate: 7.020E-05 | global batch size:  1024 | lm loss: 1.820128E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34227/   51900 | consumed samples:     35048448 | elapsed time per iteration (ms): 37598.5 | learning rate: 7.019E-05 | global batch size:  1024 | lm loss: 1.816157E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34228/   51900 | consumed samples:     35049472 | elapsed time per iteration (ms): 37719.7 | learning rate: 7.019E-05 | global batch size:  1024 | lm loss: 1.805740E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34229/   51900 | consumed samples:     35050496 | elapsed time per iteration (ms): 37687.5 | learning rate: 7.018E-05 | global batch size:  1024 | lm loss: 1.818342E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34230/   51900 | consumed samples:     35051520 | elapsed time per iteration (ms): 37811.1 | learning rate: 7.018E-05 | global batch size:  1024 | lm loss: 1.819461E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34231/   51900 | consumed samples:     35052544 | elapsed time per iteration (ms): 37772.5 | learning rate: 7.017E-05 | global batch size:  1024 | lm loss: 1.806944E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34232/   51900 | consumed samples:     35053568 | elapsed time per iteration (ms): 37597.2 | learning rate: 7.017E-05 | global batch size:  1024 | lm loss: 1.817784E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34233/   51900 | consumed samples:     35054592 | elapsed time per iteration (ms): 37654.3 | learning rate: 7.016E-05 | global batch size:  1024 | lm loss: 1.814609E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34234/   51900 | consumed samples:     35055616 | elapsed time per iteration (ms): 37531.2 | learning rate: 7.016E-05 | global batch size:  1024 | lm loss: 1.805587E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34235/   51900 | consumed samples:     35056640 | elapsed time per iteration (ms): 37571.2 | learning rate: 7.015E-05 | global batch size:  1024 | lm loss: 1.822522E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34236/   51900 | consumed samples:     35057664 | elapsed time per iteration (ms): 37564.3 | learning rate: 7.015E-05 | global batch size:  1024 | lm loss: 1.815485E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34237/   51900 | consumed samples:     35058688 | elapsed time per iteration (ms): 37687.9 | learning rate: 7.014E-05 | global batch size:  1024 | lm loss: 1.825351E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34238/   51900 | consumed samples:     35059712 | elapsed time per iteration (ms): 37693.4 | learning rate: 7.014E-05 | global batch size:  1024 | lm loss: 1.822961E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34239/   51900 | consumed samples:     35060736 | elapsed time per iteration (ms): 37586.6 | learning rate: 7.013E-05 | global batch size:  1024 | lm loss: 1.818936E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34240/   51900 | consumed samples:     35061760 | elapsed time per iteration (ms): 37595.9 | learning rate: 7.013E-05 | global batch size:  1024 | lm loss: 1.831954E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34241/   51900 | consumed samples:     35062784 | elapsed time per iteration (ms): 37724.4 | learning rate: 7.012E-05 | global batch size:  1024 | lm loss: 1.825095E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34242/   51900 | consumed samples:     35063808 | elapsed time per iteration (ms): 37775.1 | learning rate: 7.012E-05 | global batch size:  1024 | lm loss: 1.830872E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34243/   51900 | consumed samples:     35064832 | elapsed time per iteration (ms): 37663.1 | learning rate: 7.011E-05 | global batch size:  1024 | lm loss: 1.826180E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34244/   51900 | consumed samples:     35065856 | elapsed time per iteration (ms): 37705.2 | learning rate: 7.011E-05 | global batch size:  1024 | lm loss: 1.814361E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34245/   51900 | consumed samples:     35066880 | elapsed time per iteration (ms): 37685.2 | learning rate: 7.010E-05 | global batch size:  1024 | lm loss: 1.817991E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34246/   51900 | consumed samples:     35067904 | elapsed time per iteration (ms): 37627.9 | learning rate: 7.010E-05 | global batch size:  1024 | lm loss: 1.817453E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34247/   51900 | consumed samples:     35068928 | elapsed time per iteration (ms): 37671.7 | learning rate: 7.009E-05 | global batch size:  1024 | lm loss: 1.831896E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34248/   51900 | consumed samples:     35069952 | elapsed time per iteration (ms): 37686.5 | learning rate: 7.009E-05 | global batch size:  1024 | lm loss: 1.804177E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34249/   51900 | consumed samples:     35070976 | elapsed time per iteration (ms): 37795.5 | learning rate: 7.008E-05 | global batch size:  1024 | lm loss: 1.824979E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34250/   51900 | consumed samples:     35072000 | elapsed time per iteration (ms): 37582.9 | learning rate: 7.008E-05 | global batch size:  1024 | lm loss: 1.825026E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34251/   51900 | consumed samples:     35073024 | elapsed time per iteration (ms): 37736.5 | learning rate: 7.007E-05 | global batch size:  1024 | lm loss: 1.816443E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34252/   51900 | consumed samples:     35074048 | elapsed time per iteration (ms): 37627.3 | learning rate: 7.007E-05 | global batch size:  1024 | lm loss: 1.821738E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34253/   51900 | consumed samples:     35075072 | elapsed time per iteration (ms): 37802.2 | learning rate: 7.006E-05 | global batch size:  1024 | lm loss: 1.817554E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34254/   51900 | consumed samples:     35076096 | elapsed time per iteration (ms): 37671.4 | learning rate: 7.006E-05 | global batch size:  1024 | lm loss: 1.820150E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34255/   51900 | consumed samples:     35077120 | elapsed time per iteration (ms): 37666.7 | learning rate: 7.005E-05 | global batch size:  1024 | lm loss: 1.828207E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34256/   51900 | consumed samples:     35078144 | elapsed time per iteration (ms): 37678.7 | learning rate: 7.005E-05 | global batch size:  1024 | lm loss: 1.823050E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34257/   51900 | consumed samples:     35079168 | elapsed time per iteration (ms): 37595.9 | learning rate: 7.004E-05 | global batch size:  1024 | lm loss: 1.839335E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34258/   51900 | consumed samples:     35080192 | elapsed time per iteration (ms): 37727.7 | learning rate: 7.004E-05 | global batch size:  1024 | lm loss: 1.822598E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34259/   51900 | consumed samples:     35081216 | elapsed time per iteration (ms): 37626.6 | learning rate: 7.003E-05 | global batch size:  1024 | lm loss: 1.820914E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34260/   51900 | consumed samples:     35082240 | elapsed time per iteration (ms): 37606.5 | learning rate: 7.003E-05 | global batch size:  1024 | lm loss: 1.815842E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34261/   51900 | consumed samples:     35083264 | elapsed time per iteration (ms): 37648.2 | learning rate: 7.002E-05 | global batch size:  1024 | lm loss: 1.801005E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34262/   51900 | consumed samples:     35084288 | elapsed time per iteration (ms): 37615.5 | learning rate: 7.002E-05 | global batch size:  1024 | lm loss: 1.836568E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34263/   51900 | consumed samples:     35085312 | elapsed time per iteration (ms): 37710.9 | learning rate: 7.001E-05 | global batch size:  1024 | lm loss: 1.825969E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34264/   51900 | consumed samples:     35086336 | elapsed time per iteration (ms): 37592.6 | learning rate: 7.001E-05 | global batch size:  1024 | lm loss: 1.836718E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34265/   51900 | consumed samples:     35087360 | elapsed time per iteration (ms): 37762.4 | learning rate: 7.000E-05 | global batch size:  1024 | lm loss: 1.807712E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34266/   51900 | consumed samples:     35088384 | elapsed time per iteration (ms): 37678.4 | learning rate: 7.000E-05 | global batch size:  1024 | lm loss: 1.802969E+00 | loss scale: 1.0 | grad norm: 0.113 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34267/   51900 | consumed samples:     35089408 | elapsed time per iteration (ms): 37661.3 | learning rate: 6.999E-05 | global batch size:  1024 | lm loss: 1.831567E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34268/   51900 | consumed samples:     35090432 | elapsed time per iteration (ms): 37704.1 | learning rate: 6.999E-05 | global batch size:  1024 | lm loss: 1.805881E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34269/   51900 | consumed samples:     35091456 | elapsed time per iteration (ms): 37637.2 | learning rate: 6.998E-05 | global batch size:  1024 | lm loss: 1.830450E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34270/   51900 | consumed samples:     35092480 | elapsed time per iteration (ms): 37615.4 | learning rate: 6.998E-05 | global batch size:  1024 | lm loss: 1.819538E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34271/   51900 | consumed samples:     35093504 | elapsed time per iteration (ms): 37712.5 | learning rate: 6.997E-05 | global batch size:  1024 | lm loss: 1.825021E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34272/   51900 | consumed samples:     35094528 | elapsed time per iteration (ms): 37744.3 | learning rate: 6.997E-05 | global batch size:  1024 | lm loss: 1.815955E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34273/   51900 | consumed samples:     35095552 | elapsed time per iteration (ms): 37619.7 | learning rate: 6.996E-05 | global batch size:  1024 | lm loss: 1.822951E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34274/   51900 | consumed samples:     35096576 | elapsed time per iteration (ms): 37691.7 | learning rate: 6.996E-05 | global batch size:  1024 | lm loss: 1.820079E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34275/   51900 | consumed samples:     35097600 | elapsed time per iteration (ms): 37739.8 | learning rate: 6.995E-05 | global batch size:  1024 | lm loss: 1.806157E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34276/   51900 | consumed samples:     35098624 | elapsed time per iteration (ms): 37574.1 | learning rate: 6.995E-05 | global batch size:  1024 | lm loss: 1.808462E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34277/   51900 | consumed samples:     35099648 | elapsed time per iteration (ms): 37630.3 | learning rate: 6.994E-05 | global batch size:  1024 | lm loss: 1.807389E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34278/   51900 | consumed samples:     35100672 | elapsed time per iteration (ms): 37629.7 | learning rate: 6.994E-05 | global batch size:  1024 | lm loss: 1.832559E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34279/   51900 | consumed samples:     35101696 | elapsed time per iteration (ms): 37697.8 | learning rate: 6.993E-05 | global batch size:  1024 | lm loss: 1.836010E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34280/   51900 | consumed samples:     35102720 | elapsed time per iteration (ms): 37654.7 | learning rate: 6.993E-05 | global batch size:  1024 | lm loss: 1.812915E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34281/   51900 | consumed samples:     35103744 | elapsed time per iteration (ms): 37613.9 | learning rate: 6.992E-05 | global batch size:  1024 | lm loss: 1.839278E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34282/   51900 | consumed samples:     35104768 | elapsed time per iteration (ms): 37570.7 | learning rate: 6.992E-05 | global batch size:  1024 | lm loss: 1.806529E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34283/   51900 | consumed samples:     35105792 | elapsed time per iteration (ms): 37625.8 | learning rate: 6.991E-05 | global batch size:  1024 | lm loss: 1.807942E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34284/   51900 | consumed samples:     35106816 | elapsed time per iteration (ms): 37663.7 | learning rate: 6.991E-05 | global batch size:  1024 | lm loss: 1.836906E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34285/   51900 | consumed samples:     35107840 | elapsed time per iteration (ms): 37628.0 | learning rate: 6.990E-05 | global batch size:  1024 | lm loss: 1.825145E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34286/   51900 | consumed samples:     35108864 | elapsed time per iteration (ms): 37626.3 | learning rate: 6.989E-05 | global batch size:  1024 | lm loss: 1.790388E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34287/   51900 | consumed samples:     35109888 | elapsed time per iteration (ms): 37627.3 | learning rate: 6.989E-05 | global batch size:  1024 | lm loss: 1.820100E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34288/   51900 | consumed samples:     35110912 | elapsed time per iteration (ms): 37643.5 | learning rate: 6.988E-05 | global batch size:  1024 | lm loss: 1.804490E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34289/   51900 | consumed samples:     35111936 | elapsed time per iteration (ms): 37612.5 | learning rate: 6.988E-05 | global batch size:  1024 | lm loss: 1.817779E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34290/   51900 | consumed samples:     35112960 | elapsed time per iteration (ms): 37620.7 | learning rate: 6.987E-05 | global batch size:  1024 | lm loss: 1.798511E+00 | loss scale: 1.0 | grad norm: 0.088 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34291/   51900 | consumed samples:     35113984 | elapsed time per iteration (ms): 37578.5 | learning rate: 6.987E-05 | global batch size:  1024 | lm loss: 1.820964E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34292/   51900 | consumed samples:     35115008 | elapsed time per iteration (ms): 37601.1 | learning rate: 6.986E-05 | global batch size:  1024 | lm loss: 1.820929E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34293/   51900 | consumed samples:     35116032 | elapsed time per iteration (ms): 37586.8 | learning rate: 6.986E-05 | global batch size:  1024 | lm loss: 1.813866E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34294/   51900 | consumed samples:     35117056 | elapsed time per iteration (ms): 37719.5 | learning rate: 6.985E-05 | global batch size:  1024 | lm loss: 1.807672E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34295/   51900 | consumed samples:     35118080 | elapsed time per iteration (ms): 37603.2 | learning rate: 6.985E-05 | global batch size:  1024 | lm loss: 1.812326E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34296/   51900 | consumed samples:     35119104 | elapsed time per iteration (ms): 37752.0 | learning rate: 6.984E-05 | global batch size:  1024 | lm loss: 1.807831E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34297/   51900 | consumed samples:     35120128 | elapsed time per iteration (ms): 37591.5 | learning rate: 6.984E-05 | global batch size:  1024 | lm loss: 1.819802E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34298/   51900 | consumed samples:     35121152 | elapsed time per iteration (ms): 37972.7 | learning rate: 6.983E-05 | global batch size:  1024 | lm loss: 1.827309E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34299/   51900 | consumed samples:     35122176 | elapsed time per iteration (ms): 37781.8 | learning rate: 6.983E-05 | global batch size:  1024 | lm loss: 1.832272E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34300/   51900 | consumed samples:     35123200 | elapsed time per iteration (ms): 37661.7 | learning rate: 6.982E-05 | global batch size:  1024 | lm loss: 1.817139E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34301/   51900 | consumed samples:     35124224 | elapsed time per iteration (ms): 37745.0 | learning rate: 6.982E-05 | global batch size:  1024 | lm loss: 1.827647E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34302/   51900 | consumed samples:     35125248 | elapsed time per iteration (ms): 37526.7 | learning rate: 6.981E-05 | global batch size:  1024 | lm loss: 1.820478E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34303/   51900 | consumed samples:     35126272 | elapsed time per iteration (ms): 37664.6 | learning rate: 6.981E-05 | global batch size:  1024 | lm loss: 1.830251E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34304/   51900 | consumed samples:     35127296 | elapsed time per iteration (ms): 37698.3 | learning rate: 6.980E-05 | global batch size:  1024 | lm loss: 1.827496E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34305/   51900 | consumed samples:     35128320 | elapsed time per iteration (ms): 37476.3 | learning rate: 6.980E-05 | global batch size:  1024 | lm loss: 1.802014E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34306/   51900 | consumed samples:     35129344 | elapsed time per iteration (ms): 37651.5 | learning rate: 6.979E-05 | global batch size:  1024 | lm loss: 1.830755E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34307/   51900 | consumed samples:     35130368 | elapsed time per iteration (ms): 37680.7 | learning rate: 6.979E-05 | global batch size:  1024 | lm loss: 1.821082E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34308/   51900 | consumed samples:     35131392 | elapsed time per iteration (ms): 37535.0 | learning rate: 6.978E-05 | global batch size:  1024 | lm loss: 1.806178E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34309/   51900 | consumed samples:     35132416 | elapsed time per iteration (ms): 37616.4 | learning rate: 6.978E-05 | global batch size:  1024 | lm loss: 1.810128E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34310/   51900 | consumed samples:     35133440 | elapsed time per iteration (ms): 37605.5 | learning rate: 6.977E-05 | global batch size:  1024 | lm loss: 1.810276E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34311/   51900 | consumed samples:     35134464 | elapsed time per iteration (ms): 37642.4 | learning rate: 6.977E-05 | global batch size:  1024 | lm loss: 1.818857E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34312/   51900 | consumed samples:     35135488 | elapsed time per iteration (ms): 37679.4 | learning rate: 6.976E-05 | global batch size:  1024 | lm loss: 1.819849E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34313/   51900 | consumed samples:     35136512 | elapsed time per iteration (ms): 37663.0 | learning rate: 6.976E-05 | global batch size:  1024 | lm loss: 1.822577E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34314/   51900 | consumed samples:     35137536 | elapsed time per iteration (ms): 37666.4 | learning rate: 6.975E-05 | global batch size:  1024 | lm loss: 1.843942E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34315/   51900 | consumed samples:     35138560 | elapsed time per iteration (ms): 37641.7 | learning rate: 6.975E-05 | global batch size:  1024 | lm loss: 1.799661E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34316/   51900 | consumed samples:     35139584 | elapsed time per iteration (ms): 37692.9 | learning rate: 6.974E-05 | global batch size:  1024 | lm loss: 1.817837E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34317/   51900 | consumed samples:     35140608 | elapsed time per iteration (ms): 37688.4 | learning rate: 6.974E-05 | global batch size:  1024 | lm loss: 1.814247E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34318/   51900 | consumed samples:     35141632 | elapsed time per iteration (ms): 37698.7 | learning rate: 6.973E-05 | global batch size:  1024 | lm loss: 1.834731E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34319/   51900 | consumed samples:     35142656 | elapsed time per iteration (ms): 37691.1 | learning rate: 6.973E-05 | global batch size:  1024 | lm loss: 1.821372E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34320/   51900 | consumed samples:     35143680 | elapsed time per iteration (ms): 37652.9 | learning rate: 6.972E-05 | global batch size:  1024 | lm loss: 1.810123E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34321/   51900 | consumed samples:     35144704 | elapsed time per iteration (ms): 37609.1 | learning rate: 6.972E-05 | global batch size:  1024 | lm loss: 1.799236E+00 | loss scale: 1.0 | grad norm: 0.088 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34322/   51900 | consumed samples:     35145728 | elapsed time per iteration (ms): 37760.4 | learning rate: 6.971E-05 | global batch size:  1024 | lm loss: 1.816110E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34323/   51900 | consumed samples:     35146752 | elapsed time per iteration (ms): 37697.6 | learning rate: 6.971E-05 | global batch size:  1024 | lm loss: 1.819099E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34324/   51900 | consumed samples:     35147776 | elapsed time per iteration (ms): 37622.4 | learning rate: 6.970E-05 | global batch size:  1024 | lm loss: 1.823913E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34325/   51900 | consumed samples:     35148800 | elapsed time per iteration (ms): 37705.0 | learning rate: 6.970E-05 | global batch size:  1024 | lm loss: 1.795783E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34326/   51900 | consumed samples:     35149824 | elapsed time per iteration (ms): 37725.2 | learning rate: 6.969E-05 | global batch size:  1024 | lm loss: 1.824586E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34327/   51900 | consumed samples:     35150848 | elapsed time per iteration (ms): 37729.4 | learning rate: 6.969E-05 | global batch size:  1024 | lm loss: 1.816893E+00 | loss scale: 1.0 | grad norm: 0.088 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34328/   51900 | consumed samples:     35151872 | elapsed time per iteration (ms): 37764.0 | learning rate: 6.968E-05 | global batch size:  1024 | lm loss: 1.819011E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34329/   51900 | consumed samples:     35152896 | elapsed time per iteration (ms): 37599.0 | learning rate: 6.968E-05 | global batch size:  1024 | lm loss: 1.808832E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34330/   51900 | consumed samples:     35153920 | elapsed time per iteration (ms): 37652.0 | learning rate: 6.967E-05 | global batch size:  1024 | lm loss: 1.823455E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34331/   51900 | consumed samples:     35154944 | elapsed time per iteration (ms): 37603.2 | learning rate: 6.967E-05 | global batch size:  1024 | lm loss: 1.830792E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34332/   51900 | consumed samples:     35155968 | elapsed time per iteration (ms): 37624.0 | learning rate: 6.966E-05 | global batch size:  1024 | lm loss: 1.819862E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34333/   51900 | consumed samples:     35156992 | elapsed time per iteration (ms): 37663.4 | learning rate: 6.966E-05 | global batch size:  1024 | lm loss: 1.811319E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34334/   51900 | consumed samples:     35158016 | elapsed time per iteration (ms): 37645.0 | learning rate: 6.965E-05 | global batch size:  1024 | lm loss: 1.811948E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34335/   51900 | consumed samples:     35159040 | elapsed time per iteration (ms): 37755.5 | learning rate: 6.965E-05 | global batch size:  1024 | lm loss: 1.808077E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34336/   51900 | consumed samples:     35160064 | elapsed time per iteration (ms): 37646.5 | learning rate: 6.964E-05 | global batch size:  1024 | lm loss: 1.803707E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34337/   51900 | consumed samples:     35161088 | elapsed time per iteration (ms): 37712.5 | learning rate: 6.964E-05 | global batch size:  1024 | lm loss: 1.822930E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34338/   51900 | consumed samples:     35162112 | elapsed time per iteration (ms): 37611.0 | learning rate: 6.963E-05 | global batch size:  1024 | lm loss: 1.810449E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34339/   51900 | consumed samples:     35163136 | elapsed time per iteration (ms): 37740.4 | learning rate: 6.963E-05 | global batch size:  1024 | lm loss: 1.824599E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34340/   51900 | consumed samples:     35164160 | elapsed time per iteration (ms): 37616.4 | learning rate: 6.962E-05 | global batch size:  1024 | lm loss: 1.829140E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34341/   51900 | consumed samples:     35165184 | elapsed time per iteration (ms): 37623.6 | learning rate: 6.962E-05 | global batch size:  1024 | lm loss: 1.825131E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34342/   51900 | consumed samples:     35166208 | elapsed time per iteration (ms): 37839.1 | learning rate: 6.961E-05 | global batch size:  1024 | lm loss: 1.817448E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34343/   51900 | consumed samples:     35167232 | elapsed time per iteration (ms): 37644.4 | learning rate: 6.961E-05 | global batch size:  1024 | lm loss: 1.804641E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34344/   51900 | consumed samples:     35168256 | elapsed time per iteration (ms): 37598.9 | learning rate: 6.960E-05 | global batch size:  1024 | lm loss: 1.810040E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34345/   51900 | consumed samples:     35169280 | elapsed time per iteration (ms): 37673.0 | learning rate: 6.960E-05 | global batch size:  1024 | lm loss: 1.835830E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34346/   51900 | consumed samples:     35170304 | elapsed time per iteration (ms): 37664.4 | learning rate: 6.959E-05 | global batch size:  1024 | lm loss: 1.818370E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34347/   51900 | consumed samples:     35171328 | elapsed time per iteration (ms): 37698.3 | learning rate: 6.959E-05 | global batch size:  1024 | lm loss: 1.811068E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34348/   51900 | consumed samples:     35172352 | elapsed time per iteration (ms): 37702.4 | learning rate: 6.958E-05 | global batch size:  1024 | lm loss: 1.824411E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34349/   51900 | consumed samples:     35173376 | elapsed time per iteration (ms): 37637.7 | learning rate: 6.958E-05 | global batch size:  1024 | lm loss: 1.826573E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34350/   51900 | consumed samples:     35174400 | elapsed time per iteration (ms): 37663.4 | learning rate: 6.957E-05 | global batch size:  1024 | lm loss: 1.812040E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34351/   51900 | consumed samples:     35175424 | elapsed time per iteration (ms): 37700.1 | learning rate: 6.957E-05 | global batch size:  1024 | lm loss: 1.807218E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34352/   51900 | consumed samples:     35176448 | elapsed time per iteration (ms): 37606.4 | learning rate: 6.956E-05 | global batch size:  1024 | lm loss: 1.821030E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34353/   51900 | consumed samples:     35177472 | elapsed time per iteration (ms): 37630.7 | learning rate: 6.956E-05 | global batch size:  1024 | lm loss: 1.821525E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34354/   51900 | consumed samples:     35178496 | elapsed time per iteration (ms): 37721.7 | learning rate: 6.955E-05 | global batch size:  1024 | lm loss: 1.819780E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34355/   51900 | consumed samples:     35179520 | elapsed time per iteration (ms): 37722.3 | learning rate: 6.955E-05 | global batch size:  1024 | lm loss: 1.809312E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34356/   51900 | consumed samples:     35180544 | elapsed time per iteration (ms): 37718.9 | learning rate: 6.954E-05 | global batch size:  1024 | lm loss: 1.820555E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34357/   51900 | consumed samples:     35181568 | elapsed time per iteration (ms): 37678.7 | learning rate: 6.954E-05 | global batch size:  1024 | lm loss: 1.823193E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34358/   51900 | consumed samples:     35182592 | elapsed time per iteration (ms): 37783.2 | learning rate: 6.953E-05 | global batch size:  1024 | lm loss: 1.824751E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34359/   51900 | consumed samples:     35183616 | elapsed time per iteration (ms): 37722.7 | learning rate: 6.953E-05 | global batch size:  1024 | lm loss: 1.827085E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34360/   51900 | consumed samples:     35184640 | elapsed time per iteration (ms): 37697.5 | learning rate: 6.952E-05 | global batch size:  1024 | lm loss: 1.816219E+00 | loss scale: 1.0 | grad norm: 0.141 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34361/   51900 | consumed samples:     35185664 | elapsed time per iteration (ms): 37752.3 | learning rate: 6.951E-05 | global batch size:  1024 | lm loss: 1.798861E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34362/   51900 | consumed samples:     35186688 | elapsed time per iteration (ms): 37718.0 | learning rate: 6.951E-05 | global batch size:  1024 | lm loss: 1.826406E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34363/   51900 | consumed samples:     35187712 | elapsed time per iteration (ms): 37653.5 | learning rate: 6.950E-05 | global batch size:  1024 | lm loss: 1.814404E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34364/   51900 | consumed samples:     35188736 | elapsed time per iteration (ms): 37642.4 | learning rate: 6.950E-05 | global batch size:  1024 | lm loss: 1.820950E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34365/   51900 | consumed samples:     35189760 | elapsed time per iteration (ms): 37727.2 | learning rate: 6.949E-05 | global batch size:  1024 | lm loss: 1.805060E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34366/   51900 | consumed samples:     35190784 | elapsed time per iteration (ms): 37643.7 | learning rate: 6.949E-05 | global batch size:  1024 | lm loss: 1.826962E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34367/   51900 | consumed samples:     35191808 | elapsed time per iteration (ms): 37689.3 | learning rate: 6.948E-05 | global batch size:  1024 | lm loss: 1.811081E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34368/   51900 | consumed samples:     35192832 | elapsed time per iteration (ms): 37603.3 | learning rate: 6.948E-05 | global batch size:  1024 | lm loss: 1.822993E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34369/   51900 | consumed samples:     35193856 | elapsed time per iteration (ms): 37631.5 | learning rate: 6.947E-05 | global batch size:  1024 | lm loss: 1.812973E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34370/   51900 | consumed samples:     35194880 | elapsed time per iteration (ms): 37690.1 | learning rate: 6.947E-05 | global batch size:  1024 | lm loss: 1.821558E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34371/   51900 | consumed samples:     35195904 | elapsed time per iteration (ms): 37607.5 | learning rate: 6.946E-05 | global batch size:  1024 | lm loss: 1.821378E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34372/   51900 | consumed samples:     35196928 | elapsed time per iteration (ms): 37693.8 | learning rate: 6.946E-05 | global batch size:  1024 | lm loss: 1.807217E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34373/   51900 | consumed samples:     35197952 | elapsed time per iteration (ms): 37814.1 | learning rate: 6.945E-05 | global batch size:  1024 | lm loss: 1.811727E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34374/   51900 | consumed samples:     35198976 | elapsed time per iteration (ms): 37731.5 | learning rate: 6.945E-05 | global batch size:  1024 | lm loss: 1.831001E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34375/   51900 | consumed samples:     35200000 | elapsed time per iteration (ms): 37611.5 | learning rate: 6.944E-05 | global batch size:  1024 | lm loss: 1.804911E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34376/   51900 | consumed samples:     35201024 | elapsed time per iteration (ms): 37775.8 | learning rate: 6.944E-05 | global batch size:  1024 | lm loss: 1.817997E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34377/   51900 | consumed samples:     35202048 | elapsed time per iteration (ms): 37660.5 | learning rate: 6.943E-05 | global batch size:  1024 | lm loss: 1.811129E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34378/   51900 | consumed samples:     35203072 | elapsed time per iteration (ms): 37677.1 | learning rate: 6.943E-05 | global batch size:  1024 | lm loss: 1.816330E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34379/   51900 | consumed samples:     35204096 | elapsed time per iteration (ms): 37761.9 | learning rate: 6.942E-05 | global batch size:  1024 | lm loss: 1.803251E+00 | loss scale: 1.0 | grad norm: 0.063 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34380/   51900 | consumed samples:     35205120 | elapsed time per iteration (ms): 37569.5 | learning rate: 6.942E-05 | global batch size:  1024 | lm loss: 1.800982E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34381/   51900 | consumed samples:     35206144 | elapsed time per iteration (ms): 37613.7 | learning rate: 6.941E-05 | global batch size:  1024 | lm loss: 1.826149E+00 | loss scale: 1.0 | grad norm: 0.065 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34382/   51900 | consumed samples:     35207168 | elapsed time per iteration (ms): 37576.0 | learning rate: 6.941E-05 | global batch size:  1024 | lm loss: 1.825390E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34383/   51900 | consumed samples:     35208192 | elapsed time per iteration (ms): 37715.7 | learning rate: 6.940E-05 | global batch size:  1024 | lm loss: 1.796078E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34384/   51900 | consumed samples:     35209216 | elapsed time per iteration (ms): 37773.4 | learning rate: 6.940E-05 | global batch size:  1024 | lm loss: 1.817006E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34385/   51900 | consumed samples:     35210240 | elapsed time per iteration (ms): 37623.1 | learning rate: 6.939E-05 | global batch size:  1024 | lm loss: 1.827003E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34386/   51900 | consumed samples:     35211264 | elapsed time per iteration (ms): 37595.9 | learning rate: 6.939E-05 | global batch size:  1024 | lm loss: 1.816418E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34387/   51900 | consumed samples:     35212288 | elapsed time per iteration (ms): 37706.5 | learning rate: 6.938E-05 | global batch size:  1024 | lm loss: 1.815732E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34388/   51900 | consumed samples:     35213312 | elapsed time per iteration (ms): 37662.2 | learning rate: 6.938E-05 | global batch size:  1024 | lm loss: 1.811427E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34389/   51900 | consumed samples:     35214336 | elapsed time per iteration (ms): 37702.7 | learning rate: 6.937E-05 | global batch size:  1024 | lm loss: 1.835553E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34390/   51900 | consumed samples:     35215360 | elapsed time per iteration (ms): 37629.6 | learning rate: 6.937E-05 | global batch size:  1024 | lm loss: 1.822630E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34391/   51900 | consumed samples:     35216384 | elapsed time per iteration (ms): 37659.9 | learning rate: 6.936E-05 | global batch size:  1024 | lm loss: 1.823719E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34392/   51900 | consumed samples:     35217408 | elapsed time per iteration (ms): 37541.3 | learning rate: 6.936E-05 | global batch size:  1024 | lm loss: 1.833745E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34393/   51900 | consumed samples:     35218432 | elapsed time per iteration (ms): 37691.5 | learning rate: 6.935E-05 | global batch size:  1024 | lm loss: 1.819552E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34394/   51900 | consumed samples:     35219456 | elapsed time per iteration (ms): 37682.0 | learning rate: 6.935E-05 | global batch size:  1024 | lm loss: 1.820827E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34395/   51900 | consumed samples:     35220480 | elapsed time per iteration (ms): 37644.0 | learning rate: 6.934E-05 | global batch size:  1024 | lm loss: 1.810535E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34396/   51900 | consumed samples:     35221504 | elapsed time per iteration (ms): 37576.7 | learning rate: 6.934E-05 | global batch size:  1024 | lm loss: 1.812964E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34397/   51900 | consumed samples:     35222528 | elapsed time per iteration (ms): 37569.4 | learning rate: 6.933E-05 | global batch size:  1024 | lm loss: 1.817888E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34398/   51900 | consumed samples:     35223552 | elapsed time per iteration (ms): 37596.8 | learning rate: 6.933E-05 | global batch size:  1024 | lm loss: 1.810793E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34399/   51900 | consumed samples:     35224576 | elapsed time per iteration (ms): 37665.3 | learning rate: 6.932E-05 | global batch size:  1024 | lm loss: 1.807240E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34400/   51900 | consumed samples:     35225600 | elapsed time per iteration (ms): 37581.4 | learning rate: 6.932E-05 | global batch size:  1024 | lm loss: 1.815493E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34401/   51900 | consumed samples:     35226624 | elapsed time per iteration (ms): 37688.6 | learning rate: 6.931E-05 | global batch size:  1024 | lm loss: 1.814024E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34402/   51900 | consumed samples:     35227648 | elapsed time per iteration (ms): 37532.2 | learning rate: 6.931E-05 | global batch size:  1024 | lm loss: 1.824042E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34403/   51900 | consumed samples:     35228672 | elapsed time per iteration (ms): 37663.7 | learning rate: 6.930E-05 | global batch size:  1024 | lm loss: 1.821476E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34404/   51900 | consumed samples:     35229696 | elapsed time per iteration (ms): 37635.2 | learning rate: 6.930E-05 | global batch size:  1024 | lm loss: 1.818506E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34405/   51900 | consumed samples:     35230720 | elapsed time per iteration (ms): 37726.6 | learning rate: 6.929E-05 | global batch size:  1024 | lm loss: 1.806950E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34406/   51900 | consumed samples:     35231744 | elapsed time per iteration (ms): 37640.0 | learning rate: 6.929E-05 | global batch size:  1024 | lm loss: 1.827646E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34407/   51900 | consumed samples:     35232768 | elapsed time per iteration (ms): 37761.6 | learning rate: 6.928E-05 | global batch size:  1024 | lm loss: 1.823459E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34408/   51900 | consumed samples:     35233792 | elapsed time per iteration (ms): 37603.1 | learning rate: 6.928E-05 | global batch size:  1024 | lm loss: 1.825559E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34409/   51900 | consumed samples:     35234816 | elapsed time per iteration (ms): 37665.8 | learning rate: 6.927E-05 | global batch size:  1024 | lm loss: 1.810037E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34410/   51900 | consumed samples:     35235840 | elapsed time per iteration (ms): 37732.4 | learning rate: 6.927E-05 | global batch size:  1024 | lm loss: 1.822663E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34411/   51900 | consumed samples:     35236864 | elapsed time per iteration (ms): 37741.0 | learning rate: 6.926E-05 | global batch size:  1024 | lm loss: 1.810071E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34412/   51900 | consumed samples:     35237888 | elapsed time per iteration (ms): 37784.4 | learning rate: 6.926E-05 | global batch size:  1024 | lm loss: 1.809467E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34413/   51900 | consumed samples:     35238912 | elapsed time per iteration (ms): 37715.5 | learning rate: 6.925E-05 | global batch size:  1024 | lm loss: 1.825013E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34414/   51900 | consumed samples:     35239936 | elapsed time per iteration (ms): 37716.9 | learning rate: 6.925E-05 | global batch size:  1024 | lm loss: 1.815801E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34415/   51900 | consumed samples:     35240960 | elapsed time per iteration (ms): 37634.0 | learning rate: 6.924E-05 | global batch size:  1024 | lm loss: 1.808381E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34416/   51900 | consumed samples:     35241984 | elapsed time per iteration (ms): 37637.8 | learning rate: 6.924E-05 | global batch size:  1024 | lm loss: 1.821750E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34417/   51900 | consumed samples:     35243008 | elapsed time per iteration (ms): 37733.9 | learning rate: 6.923E-05 | global batch size:  1024 | lm loss: 1.822700E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34418/   51900 | consumed samples:     35244032 | elapsed time per iteration (ms): 37741.6 | learning rate: 6.923E-05 | global batch size:  1024 | lm loss: 1.823528E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34419/   51900 | consumed samples:     35245056 | elapsed time per iteration (ms): 37655.6 | learning rate: 6.922E-05 | global batch size:  1024 | lm loss: 1.826667E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34420/   51900 | consumed samples:     35246080 | elapsed time per iteration (ms): 37724.3 | learning rate: 6.922E-05 | global batch size:  1024 | lm loss: 1.829717E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34421/   51900 | consumed samples:     35247104 | elapsed time per iteration (ms): 37708.4 | learning rate: 6.921E-05 | global batch size:  1024 | lm loss: 1.829458E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34422/   51900 | consumed samples:     35248128 | elapsed time per iteration (ms): 37618.2 | learning rate: 6.921E-05 | global batch size:  1024 | lm loss: 1.814118E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34423/   51900 | consumed samples:     35249152 | elapsed time per iteration (ms): 37780.0 | learning rate: 6.920E-05 | global batch size:  1024 | lm loss: 1.793419E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34424/   51900 | consumed samples:     35250176 | elapsed time per iteration (ms): 37516.1 | learning rate: 6.920E-05 | global batch size:  1024 | lm loss: 1.815316E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34425/   51900 | consumed samples:     35251200 | elapsed time per iteration (ms): 37676.2 | learning rate: 6.919E-05 | global batch size:  1024 | lm loss: 1.825553E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34426/   51900 | consumed samples:     35252224 | elapsed time per iteration (ms): 37734.8 | learning rate: 6.919E-05 | global batch size:  1024 | lm loss: 1.826900E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34427/   51900 | consumed samples:     35253248 | elapsed time per iteration (ms): 37708.5 | learning rate: 6.918E-05 | global batch size:  1024 | lm loss: 1.839011E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34428/   51900 | consumed samples:     35254272 | elapsed time per iteration (ms): 37759.9 | learning rate: 6.918E-05 | global batch size:  1024 | lm loss: 1.823217E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34429/   51900 | consumed samples:     35255296 | elapsed time per iteration (ms): 37723.8 | learning rate: 6.917E-05 | global batch size:  1024 | lm loss: 1.799045E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34430/   51900 | consumed samples:     35256320 | elapsed time per iteration (ms): 37668.1 | learning rate: 6.917E-05 | global batch size:  1024 | lm loss: 1.806755E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34431/   51900 | consumed samples:     35257344 | elapsed time per iteration (ms): 37612.9 | learning rate: 6.916E-05 | global batch size:  1024 | lm loss: 1.810912E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34432/   51900 | consumed samples:     35258368 | elapsed time per iteration (ms): 37646.2 | learning rate: 6.916E-05 | global batch size:  1024 | lm loss: 1.813692E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34433/   51900 | consumed samples:     35259392 | elapsed time per iteration (ms): 37719.7 | learning rate: 6.915E-05 | global batch size:  1024 | lm loss: 1.815564E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34434/   51900 | consumed samples:     35260416 | elapsed time per iteration (ms): 37681.2 | learning rate: 6.915E-05 | global batch size:  1024 | lm loss: 1.809053E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34435/   51900 | consumed samples:     35261440 | elapsed time per iteration (ms): 37666.6 | learning rate: 6.914E-05 | global batch size:  1024 | lm loss: 1.827450E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34436/   51900 | consumed samples:     35262464 | elapsed time per iteration (ms): 37644.3 | learning rate: 6.914E-05 | global batch size:  1024 | lm loss: 1.818023E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34437/   51900 | consumed samples:     35263488 | elapsed time per iteration (ms): 37667.9 | learning rate: 6.913E-05 | global batch size:  1024 | lm loss: 1.813565E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34438/   51900 | consumed samples:     35264512 | elapsed time per iteration (ms): 37802.1 | learning rate: 6.913E-05 | global batch size:  1024 | lm loss: 1.809542E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34439/   51900 | consumed samples:     35265536 | elapsed time per iteration (ms): 37596.6 | learning rate: 6.912E-05 | global batch size:  1024 | lm loss: 1.818940E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34440/   51900 | consumed samples:     35266560 | elapsed time per iteration (ms): 37576.8 | learning rate: 6.912E-05 | global batch size:  1024 | lm loss: 1.806418E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34441/   51900 | consumed samples:     35267584 | elapsed time per iteration (ms): 37580.1 | learning rate: 6.911E-05 | global batch size:  1024 | lm loss: 1.807750E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34442/   51900 | consumed samples:     35268608 | elapsed time per iteration (ms): 37662.1 | learning rate: 6.911E-05 | global batch size:  1024 | lm loss: 1.808641E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34443/   51900 | consumed samples:     35269632 | elapsed time per iteration (ms): 37678.8 | learning rate: 6.910E-05 | global batch size:  1024 | lm loss: 1.812295E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34444/   51900 | consumed samples:     35270656 | elapsed time per iteration (ms): 37786.8 | learning rate: 6.910E-05 | global batch size:  1024 | lm loss: 1.819195E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34445/   51900 | consumed samples:     35271680 | elapsed time per iteration (ms): 37612.7 | learning rate: 6.909E-05 | global batch size:  1024 | lm loss: 1.818367E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34446/   51900 | consumed samples:     35272704 | elapsed time per iteration (ms): 37689.8 | learning rate: 6.909E-05 | global batch size:  1024 | lm loss: 1.795324E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34447/   51900 | consumed samples:     35273728 | elapsed time per iteration (ms): 37627.6 | learning rate: 6.908E-05 | global batch size:  1024 | lm loss: 1.821717E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34448/   51900 | consumed samples:     35274752 | elapsed time per iteration (ms): 37569.8 | learning rate: 6.908E-05 | global batch size:  1024 | lm loss: 1.827257E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34449/   51900 | consumed samples:     35275776 | elapsed time per iteration (ms): 37647.1 | learning rate: 6.907E-05 | global batch size:  1024 | lm loss: 1.810671E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34450/   51900 | consumed samples:     35276800 | elapsed time per iteration (ms): 37658.4 | learning rate: 6.907E-05 | global batch size:  1024 | lm loss: 1.815277E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34451/   51900 | consumed samples:     35277824 | elapsed time per iteration (ms): 37676.4 | learning rate: 6.906E-05 | global batch size:  1024 | lm loss: 1.824009E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34452/   51900 | consumed samples:     35278848 | elapsed time per iteration (ms): 37782.8 | learning rate: 6.906E-05 | global batch size:  1024 | lm loss: 1.820354E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34453/   51900 | consumed samples:     35279872 | elapsed time per iteration (ms): 37757.9 | learning rate: 6.905E-05 | global batch size:  1024 | lm loss: 1.837862E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34454/   51900 | consumed samples:     35280896 | elapsed time per iteration (ms): 37649.4 | learning rate: 6.904E-05 | global batch size:  1024 | lm loss: 1.821773E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34455/   51900 | consumed samples:     35281920 | elapsed time per iteration (ms): 37702.3 | learning rate: 6.904E-05 | global batch size:  1024 | lm loss: 1.805167E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34456/   51900 | consumed samples:     35282944 | elapsed time per iteration (ms): 37742.5 | learning rate: 6.903E-05 | global batch size:  1024 | lm loss: 1.808169E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34457/   51900 | consumed samples:     35283968 | elapsed time per iteration (ms): 37705.0 | learning rate: 6.903E-05 | global batch size:  1024 | lm loss: 1.798605E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34458/   51900 | consumed samples:     35284992 | elapsed time per iteration (ms): 37761.5 | learning rate: 6.902E-05 | global batch size:  1024 | lm loss: 1.818522E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34459/   51900 | consumed samples:     35286016 | elapsed time per iteration (ms): 37668.7 | learning rate: 6.902E-05 | global batch size:  1024 | lm loss: 1.815959E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34460/   51900 | consumed samples:     35287040 | elapsed time per iteration (ms): 37666.2 | learning rate: 6.901E-05 | global batch size:  1024 | lm loss: 1.809756E+00 | loss scale: 1.0 | grad norm: 0.107 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34461/   51900 | consumed samples:     35288064 | elapsed time per iteration (ms): 37758.0 | learning rate: 6.901E-05 | global batch size:  1024 | lm loss: 1.814504E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34462/   51900 | consumed samples:     35289088 | elapsed time per iteration (ms): 37580.2 | learning rate: 6.900E-05 | global batch size:  1024 | lm loss: 1.814679E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34463/   51900 | consumed samples:     35290112 | elapsed time per iteration (ms): 37603.9 | learning rate: 6.900E-05 | global batch size:  1024 | lm loss: 1.793682E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34464/   51900 | consumed samples:     35291136 | elapsed time per iteration (ms): 37683.8 | learning rate: 6.899E-05 | global batch size:  1024 | lm loss: 1.809889E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34465/   51900 | consumed samples:     35292160 | elapsed time per iteration (ms): 37694.8 | learning rate: 6.899E-05 | global batch size:  1024 | lm loss: 1.796509E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34466/   51900 | consumed samples:     35293184 | elapsed time per iteration (ms): 37708.7 | learning rate: 6.898E-05 | global batch size:  1024 | lm loss: 1.825968E+00 | loss scale: 1.0 | grad norm: 0.087 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34467/   51900 | consumed samples:     35294208 | elapsed time per iteration (ms): 37670.2 | learning rate: 6.898E-05 | global batch size:  1024 | lm loss: 1.815419E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34468/   51900 | consumed samples:     35295232 | elapsed time per iteration (ms): 37556.1 | learning rate: 6.897E-05 | global batch size:  1024 | lm loss: 1.816728E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34469/   51900 | consumed samples:     35296256 | elapsed time per iteration (ms): 37682.7 | learning rate: 6.897E-05 | global batch size:  1024 | lm loss: 1.818710E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34470/   51900 | consumed samples:     35297280 | elapsed time per iteration (ms): 37609.4 | learning rate: 6.896E-05 | global batch size:  1024 | lm loss: 1.811482E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34471/   51900 | consumed samples:     35298304 | elapsed time per iteration (ms): 37631.0 | learning rate: 6.896E-05 | global batch size:  1024 | lm loss: 1.815445E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34472/   51900 | consumed samples:     35299328 | elapsed time per iteration (ms): 37721.4 | learning rate: 6.895E-05 | global batch size:  1024 | lm loss: 1.819285E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34473/   51900 | consumed samples:     35300352 | elapsed time per iteration (ms): 37532.9 | learning rate: 6.895E-05 | global batch size:  1024 | lm loss: 1.810553E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34474/   51900 | consumed samples:     35301376 | elapsed time per iteration (ms): 37678.4 | learning rate: 6.894E-05 | global batch size:  1024 | lm loss: 1.812487E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34475/   51900 | consumed samples:     35302400 | elapsed time per iteration (ms): 37671.5 | learning rate: 6.894E-05 | global batch size:  1024 | lm loss: 1.837806E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34476/   51900 | consumed samples:     35303424 | elapsed time per iteration (ms): 37794.9 | learning rate: 6.893E-05 | global batch size:  1024 | lm loss: 1.824640E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34477/   51900 | consumed samples:     35304448 | elapsed time per iteration (ms): 37750.8 | learning rate: 6.893E-05 | global batch size:  1024 | lm loss: 1.825850E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34478/   51900 | consumed samples:     35305472 | elapsed time per iteration (ms): 37767.4 | learning rate: 6.892E-05 | global batch size:  1024 | lm loss: 1.800175E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34479/   51900 | consumed samples:     35306496 | elapsed time per iteration (ms): 37664.3 | learning rate: 6.892E-05 | global batch size:  1024 | lm loss: 1.806786E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34480/   51900 | consumed samples:     35307520 | elapsed time per iteration (ms): 37715.9 | learning rate: 6.891E-05 | global batch size:  1024 | lm loss: 1.829164E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34481/   51900 | consumed samples:     35308544 | elapsed time per iteration (ms): 37623.2 | learning rate: 6.891E-05 | global batch size:  1024 | lm loss: 1.818638E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34482/   51900 | consumed samples:     35309568 | elapsed time per iteration (ms): 37737.4 | learning rate: 6.890E-05 | global batch size:  1024 | lm loss: 1.805863E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34483/   51900 | consumed samples:     35310592 | elapsed time per iteration (ms): 37676.2 | learning rate: 6.890E-05 | global batch size:  1024 | lm loss: 1.814535E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34484/   51900 | consumed samples:     35311616 | elapsed time per iteration (ms): 37728.3 | learning rate: 6.889E-05 | global batch size:  1024 | lm loss: 1.818779E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34485/   51900 | consumed samples:     35312640 | elapsed time per iteration (ms): 37709.0 | learning rate: 6.889E-05 | global batch size:  1024 | lm loss: 1.828020E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34486/   51900 | consumed samples:     35313664 | elapsed time per iteration (ms): 37652.5 | learning rate: 6.888E-05 | global batch size:  1024 | lm loss: 1.813089E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34487/   51900 | consumed samples:     35314688 | elapsed time per iteration (ms): 37610.7 | learning rate: 6.888E-05 | global batch size:  1024 | lm loss: 1.810738E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34488/   51900 | consumed samples:     35315712 | elapsed time per iteration (ms): 37558.9 | learning rate: 6.887E-05 | global batch size:  1024 | lm loss: 1.823349E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34489/   51900 | consumed samples:     35316736 | elapsed time per iteration (ms): 37617.8 | learning rate: 6.887E-05 | global batch size:  1024 | lm loss: 1.801510E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34490/   51900 | consumed samples:     35317760 | elapsed time per iteration (ms): 37648.1 | learning rate: 6.886E-05 | global batch size:  1024 | lm loss: 1.814182E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34491/   51900 | consumed samples:     35318784 | elapsed time per iteration (ms): 37705.5 | learning rate: 6.886E-05 | global batch size:  1024 | lm loss: 1.821757E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34492/   51900 | consumed samples:     35319808 | elapsed time per iteration (ms): 37735.3 | learning rate: 6.885E-05 | global batch size:  1024 | lm loss: 1.826462E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34493/   51900 | consumed samples:     35320832 | elapsed time per iteration (ms): 37710.8 | learning rate: 6.885E-05 | global batch size:  1024 | lm loss: 1.820748E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34494/   51900 | consumed samples:     35321856 | elapsed time per iteration (ms): 37754.4 | learning rate: 6.884E-05 | global batch size:  1024 | lm loss: 1.820092E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34495/   51900 | consumed samples:     35322880 | elapsed time per iteration (ms): 37681.5 | learning rate: 6.884E-05 | global batch size:  1024 | lm loss: 1.794843E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34496/   51900 | consumed samples:     35323904 | elapsed time per iteration (ms): 37685.7 | learning rate: 6.883E-05 | global batch size:  1024 | lm loss: 1.819794E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34497/   51900 | consumed samples:     35324928 | elapsed time per iteration (ms): 37694.5 | learning rate: 6.883E-05 | global batch size:  1024 | lm loss: 1.811398E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34498/   51900 | consumed samples:     35325952 | elapsed time per iteration (ms): 37651.4 | learning rate: 6.882E-05 | global batch size:  1024 | lm loss: 1.823186E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34499/   51900 | consumed samples:     35326976 | elapsed time per iteration (ms): 37817.0 | learning rate: 6.882E-05 | global batch size:  1024 | lm loss: 1.807057E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34500/   51900 | consumed samples:     35328000 | elapsed time per iteration (ms): 37725.8 | learning rate: 6.881E-05 | global batch size:  1024 | lm loss: 1.840029E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    save-checkpoint ................................: (141082.46, 141082.53)
 iteration    34501/   51900 | consumed samples:     35329024 | elapsed time per iteration (ms): 37251.4 | learning rate: 6.881E-05 | global batch size:  1024 | lm loss: 1.811950E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34502/   51900 | consumed samples:     35330048 | elapsed time per iteration (ms): 37764.3 | learning rate: 6.880E-05 | global batch size:  1024 | lm loss: 1.822245E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34503/   51900 | consumed samples:     35331072 | elapsed time per iteration (ms): 37682.8 | learning rate: 6.880E-05 | global batch size:  1024 | lm loss: 1.796560E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34504/   51900 | consumed samples:     35332096 | elapsed time per iteration (ms): 37582.9 | learning rate: 6.879E-05 | global batch size:  1024 | lm loss: 1.838249E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34505/   51900 | consumed samples:     35333120 | elapsed time per iteration (ms): 37583.8 | learning rate: 6.879E-05 | global batch size:  1024 | lm loss: 1.793086E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34506/   51900 | consumed samples:     35334144 | elapsed time per iteration (ms): 37711.5 | learning rate: 6.878E-05 | global batch size:  1024 | lm loss: 1.811799E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34507/   51900 | consumed samples:     35335168 | elapsed time per iteration (ms): 37613.9 | learning rate: 6.878E-05 | global batch size:  1024 | lm loss: 1.818571E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34508/   51900 | consumed samples:     35336192 | elapsed time per iteration (ms): 37593.0 | learning rate: 6.877E-05 | global batch size:  1024 | lm loss: 1.823247E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34509/   51900 | consumed samples:     35337216 | elapsed time per iteration (ms): 37706.4 | learning rate: 6.877E-05 | global batch size:  1024 | lm loss: 1.812199E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34510/   51900 | consumed samples:     35338240 | elapsed time per iteration (ms): 37587.9 | learning rate: 6.876E-05 | global batch size:  1024 | lm loss: 1.821156E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34511/   51900 | consumed samples:     35339264 | elapsed time per iteration (ms): 37651.1 | learning rate: 6.876E-05 | global batch size:  1024 | lm loss: 1.821833E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34512/   51900 | consumed samples:     35340288 | elapsed time per iteration (ms): 37691.4 | learning rate: 6.875E-05 | global batch size:  1024 | lm loss: 1.804164E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34513/   51900 | consumed samples:     35341312 | elapsed time per iteration (ms): 37580.7 | learning rate: 6.875E-05 | global batch size:  1024 | lm loss: 1.815922E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34514/   51900 | consumed samples:     35342336 | elapsed time per iteration (ms): 37614.7 | learning rate: 6.874E-05 | global batch size:  1024 | lm loss: 1.822523E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34515/   51900 | consumed samples:     35343360 | elapsed time per iteration (ms): 37563.7 | learning rate: 6.874E-05 | global batch size:  1024 | lm loss: 1.822267E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34516/   51900 | consumed samples:     35344384 | elapsed time per iteration (ms): 37625.1 | learning rate: 6.873E-05 | global batch size:  1024 | lm loss: 1.794859E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34517/   51900 | consumed samples:     35345408 | elapsed time per iteration (ms): 37728.2 | learning rate: 6.873E-05 | global batch size:  1024 | lm loss: 1.822353E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34518/   51900 | consumed samples:     35346432 | elapsed time per iteration (ms): 37662.4 | learning rate: 6.872E-05 | global batch size:  1024 | lm loss: 1.821922E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34519/   51900 | consumed samples:     35347456 | elapsed time per iteration (ms): 37744.9 | learning rate: 6.872E-05 | global batch size:  1024 | lm loss: 1.805485E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34520/   51900 | consumed samples:     35348480 | elapsed time per iteration (ms): 37611.0 | learning rate: 6.871E-05 | global batch size:  1024 | lm loss: 1.807495E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34521/   51900 | consumed samples:     35349504 | elapsed time per iteration (ms): 37721.6 | learning rate: 6.871E-05 | global batch size:  1024 | lm loss: 1.812461E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34522/   51900 | consumed samples:     35350528 | elapsed time per iteration (ms): 37777.5 | learning rate: 6.870E-05 | global batch size:  1024 | lm loss: 1.817811E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34523/   51900 | consumed samples:     35351552 | elapsed time per iteration (ms): 37703.5 | learning rate: 6.870E-05 | global batch size:  1024 | lm loss: 1.816554E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34524/   51900 | consumed samples:     35352576 | elapsed time per iteration (ms): 37627.5 | learning rate: 6.869E-05 | global batch size:  1024 | lm loss: 1.822284E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34525/   51900 | consumed samples:     35353600 | elapsed time per iteration (ms): 37646.2 | learning rate: 6.869E-05 | global batch size:  1024 | lm loss: 1.814383E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34526/   51900 | consumed samples:     35354624 | elapsed time per iteration (ms): 37680.5 | learning rate: 6.868E-05 | global batch size:  1024 | lm loss: 1.797750E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34527/   51900 | consumed samples:     35355648 | elapsed time per iteration (ms): 37740.9 | learning rate: 6.868E-05 | global batch size:  1024 | lm loss: 1.819260E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34528/   51900 | consumed samples:     35356672 | elapsed time per iteration (ms): 37701.6 | learning rate: 6.867E-05 | global batch size:  1024 | lm loss: 1.803545E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34529/   51900 | consumed samples:     35357696 | elapsed time per iteration (ms): 37528.8 | learning rate: 6.867E-05 | global batch size:  1024 | lm loss: 1.838671E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34530/   51900 | consumed samples:     35358720 | elapsed time per iteration (ms): 37699.6 | learning rate: 6.866E-05 | global batch size:  1024 | lm loss: 1.800259E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34531/   51900 | consumed samples:     35359744 | elapsed time per iteration (ms): 37661.7 | learning rate: 6.866E-05 | global batch size:  1024 | lm loss: 1.814381E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34532/   51900 | consumed samples:     35360768 | elapsed time per iteration (ms): 37611.4 | learning rate: 6.865E-05 | global batch size:  1024 | lm loss: 1.824408E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34533/   51900 | consumed samples:     35361792 | elapsed time per iteration (ms): 37658.0 | learning rate: 6.865E-05 | global batch size:  1024 | lm loss: 1.810372E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34534/   51900 | consumed samples:     35362816 | elapsed time per iteration (ms): 37682.2 | learning rate: 6.864E-05 | global batch size:  1024 | lm loss: 1.823634E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34535/   51900 | consumed samples:     35363840 | elapsed time per iteration (ms): 37635.0 | learning rate: 6.864E-05 | global batch size:  1024 | lm loss: 1.829493E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34536/   51900 | consumed samples:     35364864 | elapsed time per iteration (ms): 37654.5 | learning rate: 6.863E-05 | global batch size:  1024 | lm loss: 1.803330E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34537/   51900 | consumed samples:     35365888 | elapsed time per iteration (ms): 37681.3 | learning rate: 6.863E-05 | global batch size:  1024 | lm loss: 1.806517E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34538/   51900 | consumed samples:     35366912 | elapsed time per iteration (ms): 37674.9 | learning rate: 6.862E-05 | global batch size:  1024 | lm loss: 1.813839E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34539/   51900 | consumed samples:     35367936 | elapsed time per iteration (ms): 37643.1 | learning rate: 6.862E-05 | global batch size:  1024 | lm loss: 1.808358E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34540/   51900 | consumed samples:     35368960 | elapsed time per iteration (ms): 37618.1 | learning rate: 6.861E-05 | global batch size:  1024 | lm loss: 1.835994E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34541/   51900 | consumed samples:     35369984 | elapsed time per iteration (ms): 37664.2 | learning rate: 6.861E-05 | global batch size:  1024 | lm loss: 1.833401E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34542/   51900 | consumed samples:     35371008 | elapsed time per iteration (ms): 37614.8 | learning rate: 6.860E-05 | global batch size:  1024 | lm loss: 1.812895E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34543/   51900 | consumed samples:     35372032 | elapsed time per iteration (ms): 37630.8 | learning rate: 6.860E-05 | global batch size:  1024 | lm loss: 1.801851E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34544/   51900 | consumed samples:     35373056 | elapsed time per iteration (ms): 37642.0 | learning rate: 6.859E-05 | global batch size:  1024 | lm loss: 1.816390E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34545/   51900 | consumed samples:     35374080 | elapsed time per iteration (ms): 37698.1 | learning rate: 6.859E-05 | global batch size:  1024 | lm loss: 1.802297E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34546/   51900 | consumed samples:     35375104 | elapsed time per iteration (ms): 37626.5 | learning rate: 6.858E-05 | global batch size:  1024 | lm loss: 1.809454E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34547/   51900 | consumed samples:     35376128 | elapsed time per iteration (ms): 37530.2 | learning rate: 6.858E-05 | global batch size:  1024 | lm loss: 1.814577E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34548/   51900 | consumed samples:     35377152 | elapsed time per iteration (ms): 37650.5 | learning rate: 6.857E-05 | global batch size:  1024 | lm loss: 1.806615E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34549/   51900 | consumed samples:     35378176 | elapsed time per iteration (ms): 37684.5 | learning rate: 6.857E-05 | global batch size:  1024 | lm loss: 1.816707E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34550/   51900 | consumed samples:     35379200 | elapsed time per iteration (ms): 37692.2 | learning rate: 6.856E-05 | global batch size:  1024 | lm loss: 1.817829E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34551/   51900 | consumed samples:     35380224 | elapsed time per iteration (ms): 37707.9 | learning rate: 6.856E-05 | global batch size:  1024 | lm loss: 1.814470E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34552/   51900 | consumed samples:     35381248 | elapsed time per iteration (ms): 37611.0 | learning rate: 6.855E-05 | global batch size:  1024 | lm loss: 1.816938E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34553/   51900 | consumed samples:     35382272 | elapsed time per iteration (ms): 37790.0 | learning rate: 6.855E-05 | global batch size:  1024 | lm loss: 1.811136E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34554/   51900 | consumed samples:     35383296 | elapsed time per iteration (ms): 37709.3 | learning rate: 6.854E-05 | global batch size:  1024 | lm loss: 1.835423E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34555/   51900 | consumed samples:     35384320 | elapsed time per iteration (ms): 37575.5 | learning rate: 6.854E-05 | global batch size:  1024 | lm loss: 1.834525E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34556/   51900 | consumed samples:     35385344 | elapsed time per iteration (ms): 37723.0 | learning rate: 6.853E-05 | global batch size:  1024 | lm loss: 1.833144E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34557/   51900 | consumed samples:     35386368 | elapsed time per iteration (ms): 37665.1 | learning rate: 6.853E-05 | global batch size:  1024 | lm loss: 1.816935E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34558/   51900 | consumed samples:     35387392 | elapsed time per iteration (ms): 37693.2 | learning rate: 6.852E-05 | global batch size:  1024 | lm loss: 1.809908E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34559/   51900 | consumed samples:     35388416 | elapsed time per iteration (ms): 37718.3 | learning rate: 6.852E-05 | global batch size:  1024 | lm loss: 1.812734E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34560/   51900 | consumed samples:     35389440 | elapsed time per iteration (ms): 37695.2 | learning rate: 6.851E-05 | global batch size:  1024 | lm loss: 1.818300E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34561/   51900 | consumed samples:     35390464 | elapsed time per iteration (ms): 37641.4 | learning rate: 6.851E-05 | global batch size:  1024 | lm loss: 1.817100E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34562/   51900 | consumed samples:     35391488 | elapsed time per iteration (ms): 37639.9 | learning rate: 6.850E-05 | global batch size:  1024 | lm loss: 1.803188E+00 | loss scale: 1.0 | grad norm: 0.065 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34563/   51900 | consumed samples:     35392512 | elapsed time per iteration (ms): 37656.1 | learning rate: 6.850E-05 | global batch size:  1024 | lm loss: 1.817240E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34564/   51900 | consumed samples:     35393536 | elapsed time per iteration (ms): 37657.6 | learning rate: 6.849E-05 | global batch size:  1024 | lm loss: 1.822064E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34565/   51900 | consumed samples:     35394560 | elapsed time per iteration (ms): 37666.8 | learning rate: 6.849E-05 | global batch size:  1024 | lm loss: 1.796287E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34566/   51900 | consumed samples:     35395584 | elapsed time per iteration (ms): 37616.1 | learning rate: 6.848E-05 | global batch size:  1024 | lm loss: 1.829229E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34567/   51900 | consumed samples:     35396608 | elapsed time per iteration (ms): 37632.6 | learning rate: 6.848E-05 | global batch size:  1024 | lm loss: 1.789245E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34568/   51900 | consumed samples:     35397632 | elapsed time per iteration (ms): 37714.8 | learning rate: 6.847E-05 | global batch size:  1024 | lm loss: 1.823285E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34569/   51900 | consumed samples:     35398656 | elapsed time per iteration (ms): 37626.4 | learning rate: 6.847E-05 | global batch size:  1024 | lm loss: 1.814834E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34570/   51900 | consumed samples:     35399680 | elapsed time per iteration (ms): 37696.8 | learning rate: 6.846E-05 | global batch size:  1024 | lm loss: 1.836683E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34571/   51900 | consumed samples:     35400704 | elapsed time per iteration (ms): 37708.2 | learning rate: 6.846E-05 | global batch size:  1024 | lm loss: 1.801244E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34572/   51900 | consumed samples:     35401728 | elapsed time per iteration (ms): 37603.2 | learning rate: 6.845E-05 | global batch size:  1024 | lm loss: 1.803201E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34573/   51900 | consumed samples:     35402752 | elapsed time per iteration (ms): 37602.8 | learning rate: 6.845E-05 | global batch size:  1024 | lm loss: 1.824616E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34574/   51900 | consumed samples:     35403776 | elapsed time per iteration (ms): 37625.5 | learning rate: 6.844E-05 | global batch size:  1024 | lm loss: 1.820317E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34575/   51900 | consumed samples:     35404800 | elapsed time per iteration (ms): 37662.6 | learning rate: 6.844E-05 | global batch size:  1024 | lm loss: 1.819876E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34576/   51900 | consumed samples:     35405824 | elapsed time per iteration (ms): 37702.8 | learning rate: 6.843E-05 | global batch size:  1024 | lm loss: 1.805978E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34577/   51900 | consumed samples:     35406848 | elapsed time per iteration (ms): 37676.3 | learning rate: 6.843E-05 | global batch size:  1024 | lm loss: 1.832534E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34578/   51900 | consumed samples:     35407872 | elapsed time per iteration (ms): 37667.5 | learning rate: 6.842E-05 | global batch size:  1024 | lm loss: 1.827798E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34579/   51900 | consumed samples:     35408896 | elapsed time per iteration (ms): 37599.4 | learning rate: 6.842E-05 | global batch size:  1024 | lm loss: 1.816607E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34580/   51900 | consumed samples:     35409920 | elapsed time per iteration (ms): 37716.2 | learning rate: 6.841E-05 | global batch size:  1024 | lm loss: 1.823437E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34581/   51900 | consumed samples:     35410944 | elapsed time per iteration (ms): 37764.1 | learning rate: 6.841E-05 | global batch size:  1024 | lm loss: 1.824245E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34582/   51900 | consumed samples:     35411968 | elapsed time per iteration (ms): 37636.1 | learning rate: 6.840E-05 | global batch size:  1024 | lm loss: 1.813021E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34583/   51900 | consumed samples:     35412992 | elapsed time per iteration (ms): 37582.0 | learning rate: 6.840E-05 | global batch size:  1024 | lm loss: 1.824803E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34584/   51900 | consumed samples:     35414016 | elapsed time per iteration (ms): 37640.2 | learning rate: 6.839E-05 | global batch size:  1024 | lm loss: 1.806206E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34585/   51900 | consumed samples:     35415040 | elapsed time per iteration (ms): 37665.0 | learning rate: 6.839E-05 | global batch size:  1024 | lm loss: 1.814548E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34586/   51900 | consumed samples:     35416064 | elapsed time per iteration (ms): 37577.7 | learning rate: 6.838E-05 | global batch size:  1024 | lm loss: 1.812123E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34587/   51900 | consumed samples:     35417088 | elapsed time per iteration (ms): 37631.5 | learning rate: 6.838E-05 | global batch size:  1024 | lm loss: 1.820540E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34588/   51900 | consumed samples:     35418112 | elapsed time per iteration (ms): 37651.4 | learning rate: 6.837E-05 | global batch size:  1024 | lm loss: 1.805531E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34589/   51900 | consumed samples:     35419136 | elapsed time per iteration (ms): 37605.0 | learning rate: 6.837E-05 | global batch size:  1024 | lm loss: 1.832770E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34590/   51900 | consumed samples:     35420160 | elapsed time per iteration (ms): 37681.6 | learning rate: 6.836E-05 | global batch size:  1024 | lm loss: 1.811213E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34591/   51900 | consumed samples:     35421184 | elapsed time per iteration (ms): 37709.6 | learning rate: 6.836E-05 | global batch size:  1024 | lm loss: 1.830968E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34592/   51900 | consumed samples:     35422208 | elapsed time per iteration (ms): 37811.8 | learning rate: 6.835E-05 | global batch size:  1024 | lm loss: 1.806526E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34593/   51900 | consumed samples:     35423232 | elapsed time per iteration (ms): 37654.3 | learning rate: 6.835E-05 | global batch size:  1024 | lm loss: 1.816463E+00 | loss scale: 1.0 | grad norm: 0.065 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34594/   51900 | consumed samples:     35424256 | elapsed time per iteration (ms): 37637.8 | learning rate: 6.834E-05 | global batch size:  1024 | lm loss: 1.826197E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34595/   51900 | consumed samples:     35425280 | elapsed time per iteration (ms): 37837.6 | learning rate: 6.834E-05 | global batch size:  1024 | lm loss: 1.825837E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34596/   51900 | consumed samples:     35426304 | elapsed time per iteration (ms): 37654.9 | learning rate: 6.833E-05 | global batch size:  1024 | lm loss: 1.832691E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34597/   51900 | consumed samples:     35427328 | elapsed time per iteration (ms): 37653.4 | learning rate: 6.833E-05 | global batch size:  1024 | lm loss: 1.810759E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34598/   51900 | consumed samples:     35428352 | elapsed time per iteration (ms): 37648.3 | learning rate: 6.832E-05 | global batch size:  1024 | lm loss: 1.818355E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34599/   51900 | consumed samples:     35429376 | elapsed time per iteration (ms): 37661.6 | learning rate: 6.832E-05 | global batch size:  1024 | lm loss: 1.817058E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34600/   51900 | consumed samples:     35430400 | elapsed time per iteration (ms): 37638.7 | learning rate: 6.831E-05 | global batch size:  1024 | lm loss: 1.832389E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34601/   51900 | consumed samples:     35431424 | elapsed time per iteration (ms): 37786.3 | learning rate: 6.831E-05 | global batch size:  1024 | lm loss: 1.810631E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34602/   51900 | consumed samples:     35432448 | elapsed time per iteration (ms): 37616.7 | learning rate: 6.830E-05 | global batch size:  1024 | lm loss: 1.801943E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34603/   51900 | consumed samples:     35433472 | elapsed time per iteration (ms): 37725.2 | learning rate: 6.829E-05 | global batch size:  1024 | lm loss: 1.827297E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34604/   51900 | consumed samples:     35434496 | elapsed time per iteration (ms): 37626.4 | learning rate: 6.829E-05 | global batch size:  1024 | lm loss: 1.802337E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34605/   51900 | consumed samples:     35435520 | elapsed time per iteration (ms): 37664.0 | learning rate: 6.828E-05 | global batch size:  1024 | lm loss: 1.813334E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34606/   51900 | consumed samples:     35436544 | elapsed time per iteration (ms): 37794.9 | learning rate: 6.828E-05 | global batch size:  1024 | lm loss: 1.817734E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34607/   51900 | consumed samples:     35437568 | elapsed time per iteration (ms): 37601.6 | learning rate: 6.827E-05 | global batch size:  1024 | lm loss: 1.790043E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34608/   51900 | consumed samples:     35438592 | elapsed time per iteration (ms): 37740.2 | learning rate: 6.827E-05 | global batch size:  1024 | lm loss: 1.820899E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34609/   51900 | consumed samples:     35439616 | elapsed time per iteration (ms): 37744.9 | learning rate: 6.826E-05 | global batch size:  1024 | lm loss: 1.825972E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34610/   51900 | consumed samples:     35440640 | elapsed time per iteration (ms): 37547.2 | learning rate: 6.826E-05 | global batch size:  1024 | lm loss: 1.814939E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34611/   51900 | consumed samples:     35441664 | elapsed time per iteration (ms): 37578.4 | learning rate: 6.825E-05 | global batch size:  1024 | lm loss: 1.806390E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34612/   51900 | consumed samples:     35442688 | elapsed time per iteration (ms): 37647.0 | learning rate: 6.825E-05 | global batch size:  1024 | lm loss: 1.819141E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34613/   51900 | consumed samples:     35443712 | elapsed time per iteration (ms): 37598.7 | learning rate: 6.824E-05 | global batch size:  1024 | lm loss: 1.814551E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34614/   51900 | consumed samples:     35444736 | elapsed time per iteration (ms): 37565.8 | learning rate: 6.824E-05 | global batch size:  1024 | lm loss: 1.809739E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34615/   51900 | consumed samples:     35445760 | elapsed time per iteration (ms): 37588.0 | learning rate: 6.823E-05 | global batch size:  1024 | lm loss: 1.828562E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34616/   51900 | consumed samples:     35446784 | elapsed time per iteration (ms): 37621.5 | learning rate: 6.823E-05 | global batch size:  1024 | lm loss: 1.801722E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34617/   51900 | consumed samples:     35447808 | elapsed time per iteration (ms): 37706.9 | learning rate: 6.822E-05 | global batch size:  1024 | lm loss: 1.821352E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34618/   51900 | consumed samples:     35448832 | elapsed time per iteration (ms): 37732.7 | learning rate: 6.822E-05 | global batch size:  1024 | lm loss: 1.820819E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34619/   51900 | consumed samples:     35449856 | elapsed time per iteration (ms): 37725.1 | learning rate: 6.821E-05 | global batch size:  1024 | lm loss: 1.819572E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34620/   51900 | consumed samples:     35450880 | elapsed time per iteration (ms): 37843.1 | learning rate: 6.821E-05 | global batch size:  1024 | lm loss: 1.810050E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34621/   51900 | consumed samples:     35451904 | elapsed time per iteration (ms): 37593.0 | learning rate: 6.820E-05 | global batch size:  1024 | lm loss: 1.804674E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34622/   51900 | consumed samples:     35452928 | elapsed time per iteration (ms): 37693.9 | learning rate: 6.820E-05 | global batch size:  1024 | lm loss: 1.798440E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34623/   51900 | consumed samples:     35453952 | elapsed time per iteration (ms): 37622.8 | learning rate: 6.819E-05 | global batch size:  1024 | lm loss: 1.813181E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34624/   51900 | consumed samples:     35454976 | elapsed time per iteration (ms): 37629.2 | learning rate: 6.819E-05 | global batch size:  1024 | lm loss: 1.816887E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34625/   51900 | consumed samples:     35456000 | elapsed time per iteration (ms): 37677.5 | learning rate: 6.818E-05 | global batch size:  1024 | lm loss: 1.795773E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34626/   51900 | consumed samples:     35457024 | elapsed time per iteration (ms): 37558.1 | learning rate: 6.818E-05 | global batch size:  1024 | lm loss: 1.829882E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34627/   51900 | consumed samples:     35458048 | elapsed time per iteration (ms): 37759.0 | learning rate: 6.817E-05 | global batch size:  1024 | lm loss: 1.804829E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34628/   51900 | consumed samples:     35459072 | elapsed time per iteration (ms): 37594.4 | learning rate: 6.817E-05 | global batch size:  1024 | lm loss: 1.806376E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34629/   51900 | consumed samples:     35460096 | elapsed time per iteration (ms): 37674.5 | learning rate: 6.816E-05 | global batch size:  1024 | lm loss: 1.820321E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34630/   51900 | consumed samples:     35461120 | elapsed time per iteration (ms): 37674.4 | learning rate: 6.816E-05 | global batch size:  1024 | lm loss: 1.820372E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34631/   51900 | consumed samples:     35462144 | elapsed time per iteration (ms): 37727.3 | learning rate: 6.815E-05 | global batch size:  1024 | lm loss: 1.812043E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34632/   51900 | consumed samples:     35463168 | elapsed time per iteration (ms): 37639.1 | learning rate: 6.815E-05 | global batch size:  1024 | lm loss: 1.799437E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34633/   51900 | consumed samples:     35464192 | elapsed time per iteration (ms): 37690.8 | learning rate: 6.814E-05 | global batch size:  1024 | lm loss: 1.822626E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34634/   51900 | consumed samples:     35465216 | elapsed time per iteration (ms): 37627.6 | learning rate: 6.814E-05 | global batch size:  1024 | lm loss: 1.828669E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34635/   51900 | consumed samples:     35466240 | elapsed time per iteration (ms): 37647.6 | learning rate: 6.813E-05 | global batch size:  1024 | lm loss: 1.824634E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34636/   51900 | consumed samples:     35467264 | elapsed time per iteration (ms): 37711.8 | learning rate: 6.813E-05 | global batch size:  1024 | lm loss: 1.826476E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34637/   51900 | consumed samples:     35468288 | elapsed time per iteration (ms): 37698.4 | learning rate: 6.812E-05 | global batch size:  1024 | lm loss: 1.814998E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34638/   51900 | consumed samples:     35469312 | elapsed time per iteration (ms): 37656.9 | learning rate: 6.812E-05 | global batch size:  1024 | lm loss: 1.828844E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34639/   51900 | consumed samples:     35470336 | elapsed time per iteration (ms): 37682.3 | learning rate: 6.811E-05 | global batch size:  1024 | lm loss: 1.837965E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34640/   51900 | consumed samples:     35471360 | elapsed time per iteration (ms): 37719.7 | learning rate: 6.811E-05 | global batch size:  1024 | lm loss: 1.808246E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34641/   51900 | consumed samples:     35472384 | elapsed time per iteration (ms): 37727.7 | learning rate: 6.810E-05 | global batch size:  1024 | lm loss: 1.824561E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34642/   51900 | consumed samples:     35473408 | elapsed time per iteration (ms): 37622.1 | learning rate: 6.810E-05 | global batch size:  1024 | lm loss: 1.827285E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34643/   51900 | consumed samples:     35474432 | elapsed time per iteration (ms): 37651.2 | learning rate: 6.809E-05 | global batch size:  1024 | lm loss: 1.802981E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34644/   51900 | consumed samples:     35475456 | elapsed time per iteration (ms): 37764.3 | learning rate: 6.809E-05 | global batch size:  1024 | lm loss: 1.820992E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34645/   51900 | consumed samples:     35476480 | elapsed time per iteration (ms): 37649.0 | learning rate: 6.808E-05 | global batch size:  1024 | lm loss: 1.825020E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34646/   51900 | consumed samples:     35477504 | elapsed time per iteration (ms): 37651.6 | learning rate: 6.808E-05 | global batch size:  1024 | lm loss: 1.818794E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34647/   51900 | consumed samples:     35478528 | elapsed time per iteration (ms): 37747.5 | learning rate: 6.807E-05 | global batch size:  1024 | lm loss: 1.823663E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34648/   51900 | consumed samples:     35479552 | elapsed time per iteration (ms): 37556.0 | learning rate: 6.807E-05 | global batch size:  1024 | lm loss: 1.816241E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34649/   51900 | consumed samples:     35480576 | elapsed time per iteration (ms): 37752.3 | learning rate: 6.806E-05 | global batch size:  1024 | lm loss: 1.825379E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34650/   51900 | consumed samples:     35481600 | elapsed time per iteration (ms): 37641.4 | learning rate: 6.806E-05 | global batch size:  1024 | lm loss: 1.838096E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34651/   51900 | consumed samples:     35482624 | elapsed time per iteration (ms): 37746.9 | learning rate: 6.805E-05 | global batch size:  1024 | lm loss: 1.809882E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34652/   51900 | consumed samples:     35483648 | elapsed time per iteration (ms): 37711.6 | learning rate: 6.805E-05 | global batch size:  1024 | lm loss: 1.792762E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34653/   51900 | consumed samples:     35484672 | elapsed time per iteration (ms): 37682.0 | learning rate: 6.804E-05 | global batch size:  1024 | lm loss: 1.817379E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34654/   51900 | consumed samples:     35485696 | elapsed time per iteration (ms): 37797.1 | learning rate: 6.804E-05 | global batch size:  1024 | lm loss: 1.823795E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34655/   51900 | consumed samples:     35486720 | elapsed time per iteration (ms): 37749.1 | learning rate: 6.803E-05 | global batch size:  1024 | lm loss: 1.812479E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34656/   51900 | consumed samples:     35487744 | elapsed time per iteration (ms): 37660.9 | learning rate: 6.803E-05 | global batch size:  1024 | lm loss: 1.817326E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34657/   51900 | consumed samples:     35488768 | elapsed time per iteration (ms): 37678.8 | learning rate: 6.802E-05 | global batch size:  1024 | lm loss: 1.809571E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34658/   51900 | consumed samples:     35489792 | elapsed time per iteration (ms): 37584.0 | learning rate: 6.802E-05 | global batch size:  1024 | lm loss: 1.828479E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34659/   51900 | consumed samples:     35490816 | elapsed time per iteration (ms): 37689.9 | learning rate: 6.801E-05 | global batch size:  1024 | lm loss: 1.806044E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34660/   51900 | consumed samples:     35491840 | elapsed time per iteration (ms): 37653.5 | learning rate: 6.801E-05 | global batch size:  1024 | lm loss: 1.815940E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34661/   51900 | consumed samples:     35492864 | elapsed time per iteration (ms): 37674.8 | learning rate: 6.800E-05 | global batch size:  1024 | lm loss: 1.831764E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34662/   51900 | consumed samples:     35493888 | elapsed time per iteration (ms): 37622.9 | learning rate: 6.800E-05 | global batch size:  1024 | lm loss: 1.830323E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34663/   51900 | consumed samples:     35494912 | elapsed time per iteration (ms): 37757.4 | learning rate: 6.799E-05 | global batch size:  1024 | lm loss: 1.833520E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34664/   51900 | consumed samples:     35495936 | elapsed time per iteration (ms): 37606.1 | learning rate: 6.799E-05 | global batch size:  1024 | lm loss: 1.804947E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34665/   51900 | consumed samples:     35496960 | elapsed time per iteration (ms): 37686.0 | learning rate: 6.798E-05 | global batch size:  1024 | lm loss: 1.820411E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34666/   51900 | consumed samples:     35497984 | elapsed time per iteration (ms): 37780.9 | learning rate: 6.798E-05 | global batch size:  1024 | lm loss: 1.820781E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34667/   51900 | consumed samples:     35499008 | elapsed time per iteration (ms): 37663.8 | learning rate: 6.797E-05 | global batch size:  1024 | lm loss: 1.823587E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34668/   51900 | consumed samples:     35500032 | elapsed time per iteration (ms): 37749.0 | learning rate: 6.797E-05 | global batch size:  1024 | lm loss: 1.803859E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34669/   51900 | consumed samples:     35501056 | elapsed time per iteration (ms): 37661.1 | learning rate: 6.796E-05 | global batch size:  1024 | lm loss: 1.813304E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34670/   51900 | consumed samples:     35502080 | elapsed time per iteration (ms): 37699.4 | learning rate: 6.796E-05 | global batch size:  1024 | lm loss: 1.802393E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34671/   51900 | consumed samples:     35503104 | elapsed time per iteration (ms): 37651.2 | learning rate: 6.795E-05 | global batch size:  1024 | lm loss: 1.818837E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34672/   51900 | consumed samples:     35504128 | elapsed time per iteration (ms): 37710.8 | learning rate: 6.795E-05 | global batch size:  1024 | lm loss: 1.809680E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34673/   51900 | consumed samples:     35505152 | elapsed time per iteration (ms): 37600.8 | learning rate: 6.794E-05 | global batch size:  1024 | lm loss: 1.827282E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34674/   51900 | consumed samples:     35506176 | elapsed time per iteration (ms): 37695.6 | learning rate: 6.794E-05 | global batch size:  1024 | lm loss: 1.819005E+00 | loss scale: 1.0 | grad norm: 0.065 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34675/   51900 | consumed samples:     35507200 | elapsed time per iteration (ms): 37706.4 | learning rate: 6.793E-05 | global batch size:  1024 | lm loss: 1.804250E+00 | loss scale: 1.0 | grad norm: 0.065 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34676/   51900 | consumed samples:     35508224 | elapsed time per iteration (ms): 37580.9 | learning rate: 6.793E-05 | global batch size:  1024 | lm loss: 1.796040E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34677/   51900 | consumed samples:     35509248 | elapsed time per iteration (ms): 37569.8 | learning rate: 6.792E-05 | global batch size:  1024 | lm loss: 1.828828E+00 | loss scale: 1.0 | grad norm: 0.065 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34678/   51900 | consumed samples:     35510272 | elapsed time per iteration (ms): 37760.1 | learning rate: 6.792E-05 | global batch size:  1024 | lm loss: 1.846426E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34679/   51900 | consumed samples:     35511296 | elapsed time per iteration (ms): 37698.0 | learning rate: 6.791E-05 | global batch size:  1024 | lm loss: 1.816961E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34680/   51900 | consumed samples:     35512320 | elapsed time per iteration (ms): 37624.1 | learning rate: 6.791E-05 | global batch size:  1024 | lm loss: 1.816651E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34681/   51900 | consumed samples:     35513344 | elapsed time per iteration (ms): 37713.6 | learning rate: 6.790E-05 | global batch size:  1024 | lm loss: 1.809049E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34682/   51900 | consumed samples:     35514368 | elapsed time per iteration (ms): 37717.3 | learning rate: 6.790E-05 | global batch size:  1024 | lm loss: 1.803386E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34683/   51900 | consumed samples:     35515392 | elapsed time per iteration (ms): 37590.7 | learning rate: 6.789E-05 | global batch size:  1024 | lm loss: 1.828208E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34684/   51900 | consumed samples:     35516416 | elapsed time per iteration (ms): 37729.2 | learning rate: 6.789E-05 | global batch size:  1024 | lm loss: 1.810185E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34685/   51900 | consumed samples:     35517440 | elapsed time per iteration (ms): 37693.4 | learning rate: 6.788E-05 | global batch size:  1024 | lm loss: 1.815219E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34686/   51900 | consumed samples:     35518464 | elapsed time per iteration (ms): 37635.8 | learning rate: 6.788E-05 | global batch size:  1024 | lm loss: 1.804925E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34687/   51900 | consumed samples:     35519488 | elapsed time per iteration (ms): 37651.5 | learning rate: 6.787E-05 | global batch size:  1024 | lm loss: 1.830061E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34688/   51900 | consumed samples:     35520512 | elapsed time per iteration (ms): 37614.4 | learning rate: 6.787E-05 | global batch size:  1024 | lm loss: 1.823265E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34689/   51900 | consumed samples:     35521536 | elapsed time per iteration (ms): 37659.0 | learning rate: 6.786E-05 | global batch size:  1024 | lm loss: 1.822182E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34690/   51900 | consumed samples:     35522560 | elapsed time per iteration (ms): 37592.7 | learning rate: 6.786E-05 | global batch size:  1024 | lm loss: 1.810079E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34691/   51900 | consumed samples:     35523584 | elapsed time per iteration (ms): 37592.5 | learning rate: 6.785E-05 | global batch size:  1024 | lm loss: 1.835848E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34692/   51900 | consumed samples:     35524608 | elapsed time per iteration (ms): 37651.1 | learning rate: 6.785E-05 | global batch size:  1024 | lm loss: 1.803389E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34693/   51900 | consumed samples:     35525632 | elapsed time per iteration (ms): 37738.5 | learning rate: 6.784E-05 | global batch size:  1024 | lm loss: 1.810648E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34694/   51900 | consumed samples:     35526656 | elapsed time per iteration (ms): 37699.4 | learning rate: 6.784E-05 | global batch size:  1024 | lm loss: 1.816820E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34695/   51900 | consumed samples:     35527680 | elapsed time per iteration (ms): 37668.6 | learning rate: 6.783E-05 | global batch size:  1024 | lm loss: 1.816272E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34696/   51900 | consumed samples:     35528704 | elapsed time per iteration (ms): 37669.2 | learning rate: 6.783E-05 | global batch size:  1024 | lm loss: 1.781126E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34697/   51900 | consumed samples:     35529728 | elapsed time per iteration (ms): 37630.7 | learning rate: 6.782E-05 | global batch size:  1024 | lm loss: 1.814227E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34698/   51900 | consumed samples:     35530752 | elapsed time per iteration (ms): 37707.3 | learning rate: 6.782E-05 | global batch size:  1024 | lm loss: 1.812665E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34699/   51900 | consumed samples:     35531776 | elapsed time per iteration (ms): 37627.2 | learning rate: 6.781E-05 | global batch size:  1024 | lm loss: 1.791173E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34700/   51900 | consumed samples:     35532800 | elapsed time per iteration (ms): 37557.9 | learning rate: 6.781E-05 | global batch size:  1024 | lm loss: 1.808319E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34701/   51900 | consumed samples:     35533824 | elapsed time per iteration (ms): 37521.4 | learning rate: 6.780E-05 | global batch size:  1024 | lm loss: 1.818063E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34702/   51900 | consumed samples:     35534848 | elapsed time per iteration (ms): 37576.1 | learning rate: 6.780E-05 | global batch size:  1024 | lm loss: 1.804410E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34703/   51900 | consumed samples:     35535872 | elapsed time per iteration (ms): 37584.7 | learning rate: 6.779E-05 | global batch size:  1024 | lm loss: 1.833112E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34704/   51900 | consumed samples:     35536896 | elapsed time per iteration (ms): 37631.7 | learning rate: 6.779E-05 | global batch size:  1024 | lm loss: 1.817613E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34705/   51900 | consumed samples:     35537920 | elapsed time per iteration (ms): 37605.1 | learning rate: 6.778E-05 | global batch size:  1024 | lm loss: 1.823493E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34706/   51900 | consumed samples:     35538944 | elapsed time per iteration (ms): 37631.5 | learning rate: 6.778E-05 | global batch size:  1024 | lm loss: 1.835453E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34707/   51900 | consumed samples:     35539968 | elapsed time per iteration (ms): 37667.6 | learning rate: 6.777E-05 | global batch size:  1024 | lm loss: 1.808709E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34708/   51900 | consumed samples:     35540992 | elapsed time per iteration (ms): 37859.5 | learning rate: 6.777E-05 | global batch size:  1024 | lm loss: 1.822874E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34709/   51900 | consumed samples:     35542016 | elapsed time per iteration (ms): 37707.3 | learning rate: 6.776E-05 | global batch size:  1024 | lm loss: 1.834019E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34710/   51900 | consumed samples:     35543040 | elapsed time per iteration (ms): 37720.6 | learning rate: 6.776E-05 | global batch size:  1024 | lm loss: 1.822479E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34711/   51900 | consumed samples:     35544064 | elapsed time per iteration (ms): 37754.1 | learning rate: 6.775E-05 | global batch size:  1024 | lm loss: 1.786783E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34712/   51900 | consumed samples:     35545088 | elapsed time per iteration (ms): 37718.1 | learning rate: 6.775E-05 | global batch size:  1024 | lm loss: 1.824517E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34713/   51900 | consumed samples:     35546112 | elapsed time per iteration (ms): 37596.3 | learning rate: 6.774E-05 | global batch size:  1024 | lm loss: 1.828491E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34714/   51900 | consumed samples:     35547136 | elapsed time per iteration (ms): 37684.9 | learning rate: 6.774E-05 | global batch size:  1024 | lm loss: 1.815069E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34715/   51900 | consumed samples:     35548160 | elapsed time per iteration (ms): 37600.9 | learning rate: 6.773E-05 | global batch size:  1024 | lm loss: 1.818211E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34716/   51900 | consumed samples:     35549184 | elapsed time per iteration (ms): 37625.0 | learning rate: 6.773E-05 | global batch size:  1024 | lm loss: 1.812561E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34717/   51900 | consumed samples:     35550208 | elapsed time per iteration (ms): 37691.9 | learning rate: 6.772E-05 | global batch size:  1024 | lm loss: 1.825572E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34718/   51900 | consumed samples:     35551232 | elapsed time per iteration (ms): 37725.1 | learning rate: 6.772E-05 | global batch size:  1024 | lm loss: 1.805094E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34719/   51900 | consumed samples:     35552256 | elapsed time per iteration (ms): 37592.0 | learning rate: 6.771E-05 | global batch size:  1024 | lm loss: 1.817396E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34720/   51900 | consumed samples:     35553280 | elapsed time per iteration (ms): 37649.3 | learning rate: 6.771E-05 | global batch size:  1024 | lm loss: 1.808051E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34721/   51900 | consumed samples:     35554304 | elapsed time per iteration (ms): 37539.3 | learning rate: 6.770E-05 | global batch size:  1024 | lm loss: 1.816670E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34722/   51900 | consumed samples:     35555328 | elapsed time per iteration (ms): 37695.8 | learning rate: 6.770E-05 | global batch size:  1024 | lm loss: 1.809267E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34723/   51900 | consumed samples:     35556352 | elapsed time per iteration (ms): 37803.0 | learning rate: 6.769E-05 | global batch size:  1024 | lm loss: 1.833865E+00 | loss scale: 1.0 | grad norm: 0.090 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34724/   51900 | consumed samples:     35557376 | elapsed time per iteration (ms): 37636.0 | learning rate: 6.769E-05 | global batch size:  1024 | lm loss: 1.808622E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34725/   51900 | consumed samples:     35558400 | elapsed time per iteration (ms): 37670.3 | learning rate: 6.768E-05 | global batch size:  1024 | lm loss: 1.824888E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34726/   51900 | consumed samples:     35559424 | elapsed time per iteration (ms): 37716.7 | learning rate: 6.768E-05 | global batch size:  1024 | lm loss: 1.811412E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34727/   51900 | consumed samples:     35560448 | elapsed time per iteration (ms): 37803.8 | learning rate: 6.767E-05 | global batch size:  1024 | lm loss: 1.814404E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34728/   51900 | consumed samples:     35561472 | elapsed time per iteration (ms): 37657.7 | learning rate: 6.767E-05 | global batch size:  1024 | lm loss: 1.820731E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34729/   51900 | consumed samples:     35562496 | elapsed time per iteration (ms): 37718.1 | learning rate: 6.766E-05 | global batch size:  1024 | lm loss: 1.823003E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34730/   51900 | consumed samples:     35563520 | elapsed time per iteration (ms): 37581.6 | learning rate: 6.766E-05 | global batch size:  1024 | lm loss: 1.816981E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34731/   51900 | consumed samples:     35564544 | elapsed time per iteration (ms): 37589.7 | learning rate: 6.765E-05 | global batch size:  1024 | lm loss: 1.823573E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34732/   51900 | consumed samples:     35565568 | elapsed time per iteration (ms): 37563.1 | learning rate: 6.765E-05 | global batch size:  1024 | lm loss: 1.813518E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34733/   51900 | consumed samples:     35566592 | elapsed time per iteration (ms): 37702.3 | learning rate: 6.764E-05 | global batch size:  1024 | lm loss: 1.793986E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34734/   51900 | consumed samples:     35567616 | elapsed time per iteration (ms): 37791.7 | learning rate: 6.764E-05 | global batch size:  1024 | lm loss: 1.806489E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34735/   51900 | consumed samples:     35568640 | elapsed time per iteration (ms): 37613.1 | learning rate: 6.763E-05 | global batch size:  1024 | lm loss: 1.814576E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34736/   51900 | consumed samples:     35569664 | elapsed time per iteration (ms): 37640.7 | learning rate: 6.763E-05 | global batch size:  1024 | lm loss: 1.825518E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34737/   51900 | consumed samples:     35570688 | elapsed time per iteration (ms): 37780.1 | learning rate: 6.762E-05 | global batch size:  1024 | lm loss: 1.811628E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34738/   51900 | consumed samples:     35571712 | elapsed time per iteration (ms): 37615.6 | learning rate: 6.762E-05 | global batch size:  1024 | lm loss: 1.784854E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34739/   51900 | consumed samples:     35572736 | elapsed time per iteration (ms): 37637.9 | learning rate: 6.761E-05 | global batch size:  1024 | lm loss: 1.827741E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34740/   51900 | consumed samples:     35573760 | elapsed time per iteration (ms): 37645.1 | learning rate: 6.761E-05 | global batch size:  1024 | lm loss: 1.835491E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34741/   51900 | consumed samples:     35574784 | elapsed time per iteration (ms): 37780.7 | learning rate: 6.760E-05 | global batch size:  1024 | lm loss: 1.788850E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34742/   51900 | consumed samples:     35575808 | elapsed time per iteration (ms): 37636.5 | learning rate: 6.760E-05 | global batch size:  1024 | lm loss: 1.812832E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34743/   51900 | consumed samples:     35576832 | elapsed time per iteration (ms): 37646.4 | learning rate: 6.759E-05 | global batch size:  1024 | lm loss: 1.805423E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34744/   51900 | consumed samples:     35577856 | elapsed time per iteration (ms): 37639.9 | learning rate: 6.759E-05 | global batch size:  1024 | lm loss: 1.807994E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34745/   51900 | consumed samples:     35578880 | elapsed time per iteration (ms): 37611.3 | learning rate: 6.758E-05 | global batch size:  1024 | lm loss: 1.829048E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34746/   51900 | consumed samples:     35579904 | elapsed time per iteration (ms): 37754.9 | learning rate: 6.758E-05 | global batch size:  1024 | lm loss: 1.820435E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34747/   51900 | consumed samples:     35580928 | elapsed time per iteration (ms): 37726.8 | learning rate: 6.757E-05 | global batch size:  1024 | lm loss: 1.816754E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34748/   51900 | consumed samples:     35581952 | elapsed time per iteration (ms): 37722.0 | learning rate: 6.757E-05 | global batch size:  1024 | lm loss: 1.814801E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34749/   51900 | consumed samples:     35582976 | elapsed time per iteration (ms): 37717.1 | learning rate: 6.756E-05 | global batch size:  1024 | lm loss: 1.822402E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34750/   51900 | consumed samples:     35584000 | elapsed time per iteration (ms): 37543.5 | learning rate: 6.756E-05 | global batch size:  1024 | lm loss: 1.826536E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34751/   51900 | consumed samples:     35585024 | elapsed time per iteration (ms): 37617.2 | learning rate: 6.755E-05 | global batch size:  1024 | lm loss: 1.817698E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34752/   51900 | consumed samples:     35586048 | elapsed time per iteration (ms): 37684.3 | learning rate: 6.755E-05 | global batch size:  1024 | lm loss: 1.817246E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34753/   51900 | consumed samples:     35587072 | elapsed time per iteration (ms): 37651.3 | learning rate: 6.754E-05 | global batch size:  1024 | lm loss: 1.811380E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34754/   51900 | consumed samples:     35588096 | elapsed time per iteration (ms): 37589.8 | learning rate: 6.754E-05 | global batch size:  1024 | lm loss: 1.801946E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34755/   51900 | consumed samples:     35589120 | elapsed time per iteration (ms): 37631.6 | learning rate: 6.753E-05 | global batch size:  1024 | lm loss: 1.805139E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34756/   51900 | consumed samples:     35590144 | elapsed time per iteration (ms): 37596.1 | learning rate: 6.753E-05 | global batch size:  1024 | lm loss: 1.814490E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34757/   51900 | consumed samples:     35591168 | elapsed time per iteration (ms): 37772.1 | learning rate: 6.752E-05 | global batch size:  1024 | lm loss: 1.807212E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34758/   51900 | consumed samples:     35592192 | elapsed time per iteration (ms): 37770.3 | learning rate: 6.752E-05 | global batch size:  1024 | lm loss: 1.823780E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34759/   51900 | consumed samples:     35593216 | elapsed time per iteration (ms): 37736.0 | learning rate: 6.751E-05 | global batch size:  1024 | lm loss: 1.822087E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34760/   51900 | consumed samples:     35594240 | elapsed time per iteration (ms): 37656.6 | learning rate: 6.751E-05 | global batch size:  1024 | lm loss: 1.815654E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34761/   51900 | consumed samples:     35595264 | elapsed time per iteration (ms): 37649.4 | learning rate: 6.750E-05 | global batch size:  1024 | lm loss: 1.818333E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34762/   51900 | consumed samples:     35596288 | elapsed time per iteration (ms): 37653.1 | learning rate: 6.750E-05 | global batch size:  1024 | lm loss: 1.831634E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34763/   51900 | consumed samples:     35597312 | elapsed time per iteration (ms): 37737.4 | learning rate: 6.749E-05 | global batch size:  1024 | lm loss: 1.817857E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34764/   51900 | consumed samples:     35598336 | elapsed time per iteration (ms): 37693.8 | learning rate: 6.749E-05 | global batch size:  1024 | lm loss: 1.817364E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34765/   51900 | consumed samples:     35599360 | elapsed time per iteration (ms): 37726.4 | learning rate: 6.748E-05 | global batch size:  1024 | lm loss: 1.813433E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34766/   51900 | consumed samples:     35600384 | elapsed time per iteration (ms): 37710.8 | learning rate: 6.748E-05 | global batch size:  1024 | lm loss: 1.807938E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34767/   51900 | consumed samples:     35601408 | elapsed time per iteration (ms): 37708.1 | learning rate: 6.747E-05 | global batch size:  1024 | lm loss: 1.812350E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34768/   51900 | consumed samples:     35602432 | elapsed time per iteration (ms): 37711.4 | learning rate: 6.747E-05 | global batch size:  1024 | lm loss: 1.815347E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34769/   51900 | consumed samples:     35603456 | elapsed time per iteration (ms): 37646.7 | learning rate: 6.746E-05 | global batch size:  1024 | lm loss: 1.821030E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34770/   51900 | consumed samples:     35604480 | elapsed time per iteration (ms): 37739.9 | learning rate: 6.746E-05 | global batch size:  1024 | lm loss: 1.792866E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34771/   51900 | consumed samples:     35605504 | elapsed time per iteration (ms): 37679.2 | learning rate: 6.745E-05 | global batch size:  1024 | lm loss: 1.827697E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34772/   51900 | consumed samples:     35606528 | elapsed time per iteration (ms): 37560.2 | learning rate: 6.745E-05 | global batch size:  1024 | lm loss: 1.822545E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34773/   51900 | consumed samples:     35607552 | elapsed time per iteration (ms): 37745.8 | learning rate: 6.744E-05 | global batch size:  1024 | lm loss: 1.820120E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34774/   51900 | consumed samples:     35608576 | elapsed time per iteration (ms): 37667.7 | learning rate: 6.744E-05 | global batch size:  1024 | lm loss: 1.798914E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34775/   51900 | consumed samples:     35609600 | elapsed time per iteration (ms): 37594.0 | learning rate: 6.743E-05 | global batch size:  1024 | lm loss: 1.823372E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34776/   51900 | consumed samples:     35610624 | elapsed time per iteration (ms): 37601.4 | learning rate: 6.743E-05 | global batch size:  1024 | lm loss: 1.824305E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34777/   51900 | consumed samples:     35611648 | elapsed time per iteration (ms): 37484.8 | learning rate: 6.742E-05 | global batch size:  1024 | lm loss: 1.810723E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34778/   51900 | consumed samples:     35612672 | elapsed time per iteration (ms): 37642.9 | learning rate: 6.742E-05 | global batch size:  1024 | lm loss: 1.808023E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34779/   51900 | consumed samples:     35613696 | elapsed time per iteration (ms): 37594.3 | learning rate: 6.741E-05 | global batch size:  1024 | lm loss: 1.828374E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34780/   51900 | consumed samples:     35614720 | elapsed time per iteration (ms): 37668.6 | learning rate: 6.741E-05 | global batch size:  1024 | lm loss: 1.800479E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34781/   51900 | consumed samples:     35615744 | elapsed time per iteration (ms): 37569.1 | learning rate: 6.740E-05 | global batch size:  1024 | lm loss: 1.823209E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34782/   51900 | consumed samples:     35616768 | elapsed time per iteration (ms): 37513.5 | learning rate: 6.740E-05 | global batch size:  1024 | lm loss: 1.796146E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34783/   51900 | consumed samples:     35617792 | elapsed time per iteration (ms): 37717.3 | learning rate: 6.739E-05 | global batch size:  1024 | lm loss: 1.799335E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34784/   51900 | consumed samples:     35618816 | elapsed time per iteration (ms): 37784.9 | learning rate: 6.739E-05 | global batch size:  1024 | lm loss: 1.822012E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34785/   51900 | consumed samples:     35619840 | elapsed time per iteration (ms): 37575.4 | learning rate: 6.738E-05 | global batch size:  1024 | lm loss: 1.807283E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34786/   51900 | consumed samples:     35620864 | elapsed time per iteration (ms): 37614.2 | learning rate: 6.738E-05 | global batch size:  1024 | lm loss: 1.812319E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34787/   51900 | consumed samples:     35621888 | elapsed time per iteration (ms): 37681.5 | learning rate: 6.737E-05 | global batch size:  1024 | lm loss: 1.811763E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34788/   51900 | consumed samples:     35622912 | elapsed time per iteration (ms): 37744.8 | learning rate: 6.737E-05 | global batch size:  1024 | lm loss: 1.799770E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34789/   51900 | consumed samples:     35623936 | elapsed time per iteration (ms): 37621.6 | learning rate: 6.736E-05 | global batch size:  1024 | lm loss: 1.809178E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34790/   51900 | consumed samples:     35624960 | elapsed time per iteration (ms): 37568.2 | learning rate: 6.736E-05 | global batch size:  1024 | lm loss: 1.825971E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34791/   51900 | consumed samples:     35625984 | elapsed time per iteration (ms): 37667.7 | learning rate: 6.735E-05 | global batch size:  1024 | lm loss: 1.815586E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34792/   51900 | consumed samples:     35627008 | elapsed time per iteration (ms): 37632.0 | learning rate: 6.735E-05 | global batch size:  1024 | lm loss: 1.821845E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34793/   51900 | consumed samples:     35628032 | elapsed time per iteration (ms): 37587.0 | learning rate: 6.734E-05 | global batch size:  1024 | lm loss: 1.786455E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34794/   51900 | consumed samples:     35629056 | elapsed time per iteration (ms): 37559.2 | learning rate: 6.734E-05 | global batch size:  1024 | lm loss: 1.810261E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34795/   51900 | consumed samples:     35630080 | elapsed time per iteration (ms): 37591.8 | learning rate: 6.733E-05 | global batch size:  1024 | lm loss: 1.792251E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34796/   51900 | consumed samples:     35631104 | elapsed time per iteration (ms): 37649.2 | learning rate: 6.733E-05 | global batch size:  1024 | lm loss: 1.813315E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34797/   51900 | consumed samples:     35632128 | elapsed time per iteration (ms): 37758.6 | learning rate: 6.732E-05 | global batch size:  1024 | lm loss: 1.808909E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34798/   51900 | consumed samples:     35633152 | elapsed time per iteration (ms): 37705.0 | learning rate: 6.732E-05 | global batch size:  1024 | lm loss: 1.813619E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34799/   51900 | consumed samples:     35634176 | elapsed time per iteration (ms): 37647.2 | learning rate: 6.731E-05 | global batch size:  1024 | lm loss: 1.798236E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34800/   51900 | consumed samples:     35635200 | elapsed time per iteration (ms): 37559.5 | learning rate: 6.731E-05 | global batch size:  1024 | lm loss: 1.813975E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34801/   51900 | consumed samples:     35636224 | elapsed time per iteration (ms): 37674.9 | learning rate: 6.730E-05 | global batch size:  1024 | lm loss: 1.789048E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34802/   51900 | consumed samples:     35637248 | elapsed time per iteration (ms): 37666.2 | learning rate: 6.730E-05 | global batch size:  1024 | lm loss: 1.804546E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34803/   51900 | consumed samples:     35638272 | elapsed time per iteration (ms): 37728.1 | learning rate: 6.729E-05 | global batch size:  1024 | lm loss: 1.826340E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34804/   51900 | consumed samples:     35639296 | elapsed time per iteration (ms): 37625.8 | learning rate: 6.729E-05 | global batch size:  1024 | lm loss: 1.816128E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34805/   51900 | consumed samples:     35640320 | elapsed time per iteration (ms): 37780.2 | learning rate: 6.728E-05 | global batch size:  1024 | lm loss: 1.828483E+00 | loss scale: 1.0 | grad norm: 0.125 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34806/   51900 | consumed samples:     35641344 | elapsed time per iteration (ms): 37669.4 | learning rate: 6.728E-05 | global batch size:  1024 | lm loss: 1.805539E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34807/   51900 | consumed samples:     35642368 | elapsed time per iteration (ms): 37758.3 | learning rate: 6.727E-05 | global batch size:  1024 | lm loss: 1.810803E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34808/   51900 | consumed samples:     35643392 | elapsed time per iteration (ms): 37693.3 | learning rate: 6.727E-05 | global batch size:  1024 | lm loss: 1.804724E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34809/   51900 | consumed samples:     35644416 | elapsed time per iteration (ms): 37716.7 | learning rate: 6.726E-05 | global batch size:  1024 | lm loss: 1.807297E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34810/   51900 | consumed samples:     35645440 | elapsed time per iteration (ms): 37735.8 | learning rate: 6.726E-05 | global batch size:  1024 | lm loss: 1.806858E+00 | loss scale: 1.0 | grad norm: 0.088 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34811/   51900 | consumed samples:     35646464 | elapsed time per iteration (ms): 37657.7 | learning rate: 6.725E-05 | global batch size:  1024 | lm loss: 1.810678E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34812/   51900 | consumed samples:     35647488 | elapsed time per iteration (ms): 37786.4 | learning rate: 6.725E-05 | global batch size:  1024 | lm loss: 1.832816E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34813/   51900 | consumed samples:     35648512 | elapsed time per iteration (ms): 37688.2 | learning rate: 6.724E-05 | global batch size:  1024 | lm loss: 1.817689E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34814/   51900 | consumed samples:     35649536 | elapsed time per iteration (ms): 37550.1 | learning rate: 6.724E-05 | global batch size:  1024 | lm loss: 1.806278E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34815/   51900 | consumed samples:     35650560 | elapsed time per iteration (ms): 37626.0 | learning rate: 6.723E-05 | global batch size:  1024 | lm loss: 1.810300E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34816/   51900 | consumed samples:     35651584 | elapsed time per iteration (ms): 37636.6 | learning rate: 6.723E-05 | global batch size:  1024 | lm loss: 1.830102E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34817/   51900 | consumed samples:     35652608 | elapsed time per iteration (ms): 37669.0 | learning rate: 6.722E-05 | global batch size:  1024 | lm loss: 1.818937E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34818/   51900 | consumed samples:     35653632 | elapsed time per iteration (ms): 37714.9 | learning rate: 6.722E-05 | global batch size:  1024 | lm loss: 1.820594E+00 | loss scale: 1.0 | grad norm: 0.094 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34819/   51900 | consumed samples:     35654656 | elapsed time per iteration (ms): 37601.9 | learning rate: 6.721E-05 | global batch size:  1024 | lm loss: 1.827133E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34820/   51900 | consumed samples:     35655680 | elapsed time per iteration (ms): 37750.4 | learning rate: 6.721E-05 | global batch size:  1024 | lm loss: 1.806925E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34821/   51900 | consumed samples:     35656704 | elapsed time per iteration (ms): 37738.5 | learning rate: 6.720E-05 | global batch size:  1024 | lm loss: 1.807680E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34822/   51900 | consumed samples:     35657728 | elapsed time per iteration (ms): 37614.4 | learning rate: 6.720E-05 | global batch size:  1024 | lm loss: 1.818810E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34823/   51900 | consumed samples:     35658752 | elapsed time per iteration (ms): 37690.0 | learning rate: 6.719E-05 | global batch size:  1024 | lm loss: 1.807920E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34824/   51900 | consumed samples:     35659776 | elapsed time per iteration (ms): 37644.5 | learning rate: 6.719E-05 | global batch size:  1024 | lm loss: 1.798084E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34825/   51900 | consumed samples:     35660800 | elapsed time per iteration (ms): 37637.0 | learning rate: 6.718E-05 | global batch size:  1024 | lm loss: 1.813022E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34826/   51900 | consumed samples:     35661824 | elapsed time per iteration (ms): 37650.5 | learning rate: 6.718E-05 | global batch size:  1024 | lm loss: 1.823731E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34827/   51900 | consumed samples:     35662848 | elapsed time per iteration (ms): 37695.7 | learning rate: 6.717E-05 | global batch size:  1024 | lm loss: 1.822707E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34828/   51900 | consumed samples:     35663872 | elapsed time per iteration (ms): 37657.1 | learning rate: 6.717E-05 | global batch size:  1024 | lm loss: 1.832186E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34829/   51900 | consumed samples:     35664896 | elapsed time per iteration (ms): 37569.0 | learning rate: 6.716E-05 | global batch size:  1024 | lm loss: 1.796189E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34830/   51900 | consumed samples:     35665920 | elapsed time per iteration (ms): 37601.4 | learning rate: 6.716E-05 | global batch size:  1024 | lm loss: 1.789725E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34831/   51900 | consumed samples:     35666944 | elapsed time per iteration (ms): 37745.0 | learning rate: 6.715E-05 | global batch size:  1024 | lm loss: 1.808658E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34832/   51900 | consumed samples:     35667968 | elapsed time per iteration (ms): 37715.7 | learning rate: 6.715E-05 | global batch size:  1024 | lm loss: 1.812113E+00 | loss scale: 1.0 | grad norm: 0.088 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34833/   51900 | consumed samples:     35668992 | elapsed time per iteration (ms): 37691.5 | learning rate: 6.714E-05 | global batch size:  1024 | lm loss: 1.809801E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34834/   51900 | consumed samples:     35670016 | elapsed time per iteration (ms): 37614.2 | learning rate: 6.714E-05 | global batch size:  1024 | lm loss: 1.801747E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34835/   51900 | consumed samples:     35671040 | elapsed time per iteration (ms): 37737.3 | learning rate: 6.713E-05 | global batch size:  1024 | lm loss: 1.800110E+00 | loss scale: 1.0 | grad norm: 0.105 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34836/   51900 | consumed samples:     35672064 | elapsed time per iteration (ms): 37804.7 | learning rate: 6.713E-05 | global batch size:  1024 | lm loss: 1.823712E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34837/   51900 | consumed samples:     35673088 | elapsed time per iteration (ms): 37666.6 | learning rate: 6.712E-05 | global batch size:  1024 | lm loss: 1.821234E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34838/   51900 | consumed samples:     35674112 | elapsed time per iteration (ms): 37693.3 | learning rate: 6.712E-05 | global batch size:  1024 | lm loss: 1.813043E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34839/   51900 | consumed samples:     35675136 | elapsed time per iteration (ms): 37650.9 | learning rate: 6.711E-05 | global batch size:  1024 | lm loss: 1.815998E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34840/   51900 | consumed samples:     35676160 | elapsed time per iteration (ms): 37606.7 | learning rate: 6.711E-05 | global batch size:  1024 | lm loss: 1.822690E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34841/   51900 | consumed samples:     35677184 | elapsed time per iteration (ms): 37726.0 | learning rate: 6.710E-05 | global batch size:  1024 | lm loss: 1.820529E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34842/   51900 | consumed samples:     35678208 | elapsed time per iteration (ms): 37645.7 | learning rate: 6.710E-05 | global batch size:  1024 | lm loss: 1.828266E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34843/   51900 | consumed samples:     35679232 | elapsed time per iteration (ms): 37865.4 | learning rate: 6.709E-05 | global batch size:  1024 | lm loss: 1.812243E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34844/   51900 | consumed samples:     35680256 | elapsed time per iteration (ms): 37656.8 | learning rate: 6.709E-05 | global batch size:  1024 | lm loss: 1.820403E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34845/   51900 | consumed samples:     35681280 | elapsed time per iteration (ms): 37715.1 | learning rate: 6.708E-05 | global batch size:  1024 | lm loss: 1.812093E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34846/   51900 | consumed samples:     35682304 | elapsed time per iteration (ms): 37677.0 | learning rate: 6.708E-05 | global batch size:  1024 | lm loss: 1.814763E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34847/   51900 | consumed samples:     35683328 | elapsed time per iteration (ms): 37635.9 | learning rate: 6.707E-05 | global batch size:  1024 | lm loss: 1.824527E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34848/   51900 | consumed samples:     35684352 | elapsed time per iteration (ms): 37789.4 | learning rate: 6.707E-05 | global batch size:  1024 | lm loss: 1.828535E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34849/   51900 | consumed samples:     35685376 | elapsed time per iteration (ms): 37566.9 | learning rate: 6.706E-05 | global batch size:  1024 | lm loss: 1.814069E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34850/   51900 | consumed samples:     35686400 | elapsed time per iteration (ms): 37624.2 | learning rate: 6.706E-05 | global batch size:  1024 | lm loss: 1.804941E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34851/   51900 | consumed samples:     35687424 | elapsed time per iteration (ms): 37681.8 | learning rate: 6.705E-05 | global batch size:  1024 | lm loss: 1.815583E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34852/   51900 | consumed samples:     35688448 | elapsed time per iteration (ms): 37715.4 | learning rate: 6.705E-05 | global batch size:  1024 | lm loss: 1.807082E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34853/   51900 | consumed samples:     35689472 | elapsed time per iteration (ms): 37671.9 | learning rate: 6.704E-05 | global batch size:  1024 | lm loss: 1.811138E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34854/   51900 | consumed samples:     35690496 | elapsed time per iteration (ms): 37822.4 | learning rate: 6.704E-05 | global batch size:  1024 | lm loss: 1.827017E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34855/   51900 | consumed samples:     35691520 | elapsed time per iteration (ms): 37709.7 | learning rate: 6.703E-05 | global batch size:  1024 | lm loss: 1.815385E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34856/   51900 | consumed samples:     35692544 | elapsed time per iteration (ms): 37632.3 | learning rate: 6.703E-05 | global batch size:  1024 | lm loss: 1.806151E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34857/   51900 | consumed samples:     35693568 | elapsed time per iteration (ms): 37602.5 | learning rate: 6.703E-05 | global batch size:  1024 | lm loss: 1.830547E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34858/   51900 | consumed samples:     35694592 | elapsed time per iteration (ms): 37634.1 | learning rate: 6.702E-05 | global batch size:  1024 | lm loss: 1.827702E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34859/   51900 | consumed samples:     35695616 | elapsed time per iteration (ms): 37712.9 | learning rate: 6.702E-05 | global batch size:  1024 | lm loss: 1.821146E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34860/   51900 | consumed samples:     35696640 | elapsed time per iteration (ms): 37612.0 | learning rate: 6.701E-05 | global batch size:  1024 | lm loss: 1.831081E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34861/   51900 | consumed samples:     35697664 | elapsed time per iteration (ms): 37661.3 | learning rate: 6.701E-05 | global batch size:  1024 | lm loss: 1.808821E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34862/   51900 | consumed samples:     35698688 | elapsed time per iteration (ms): 37748.7 | learning rate: 6.700E-05 | global batch size:  1024 | lm loss: 1.816559E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34863/   51900 | consumed samples:     35699712 | elapsed time per iteration (ms): 37670.0 | learning rate: 6.700E-05 | global batch size:  1024 | lm loss: 1.831898E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34864/   51900 | consumed samples:     35700736 | elapsed time per iteration (ms): 37657.7 | learning rate: 6.699E-05 | global batch size:  1024 | lm loss: 1.812369E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34865/   51900 | consumed samples:     35701760 | elapsed time per iteration (ms): 37750.6 | learning rate: 6.699E-05 | global batch size:  1024 | lm loss: 1.825387E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34866/   51900 | consumed samples:     35702784 | elapsed time per iteration (ms): 37748.2 | learning rate: 6.698E-05 | global batch size:  1024 | lm loss: 1.800705E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34867/   51900 | consumed samples:     35703808 | elapsed time per iteration (ms): 37666.2 | learning rate: 6.698E-05 | global batch size:  1024 | lm loss: 1.825793E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34868/   51900 | consumed samples:     35704832 | elapsed time per iteration (ms): 37732.0 | learning rate: 6.697E-05 | global batch size:  1024 | lm loss: 1.826769E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34869/   51900 | consumed samples:     35705856 | elapsed time per iteration (ms): 37721.6 | learning rate: 6.697E-05 | global batch size:  1024 | lm loss: 1.805619E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34870/   51900 | consumed samples:     35706880 | elapsed time per iteration (ms): 37714.2 | learning rate: 6.696E-05 | global batch size:  1024 | lm loss: 1.806487E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34871/   51900 | consumed samples:     35707904 | elapsed time per iteration (ms): 37682.5 | learning rate: 6.696E-05 | global batch size:  1024 | lm loss: 1.805364E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34872/   51900 | consumed samples:     35708928 | elapsed time per iteration (ms): 37596.3 | learning rate: 6.695E-05 | global batch size:  1024 | lm loss: 1.815484E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34873/   51900 | consumed samples:     35709952 | elapsed time per iteration (ms): 37766.1 | learning rate: 6.695E-05 | global batch size:  1024 | lm loss: 1.829113E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34874/   51900 | consumed samples:     35710976 | elapsed time per iteration (ms): 37577.9 | learning rate: 6.694E-05 | global batch size:  1024 | lm loss: 1.816612E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34875/   51900 | consumed samples:     35712000 | elapsed time per iteration (ms): 37748.8 | learning rate: 6.694E-05 | global batch size:  1024 | lm loss: 1.825324E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34876/   51900 | consumed samples:     35713024 | elapsed time per iteration (ms): 37712.7 | learning rate: 6.693E-05 | global batch size:  1024 | lm loss: 1.819086E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34877/   51900 | consumed samples:     35714048 | elapsed time per iteration (ms): 37653.0 | learning rate: 6.693E-05 | global batch size:  1024 | lm loss: 1.789376E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34878/   51900 | consumed samples:     35715072 | elapsed time per iteration (ms): 37754.7 | learning rate: 6.692E-05 | global batch size:  1024 | lm loss: 1.819326E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34879/   51900 | consumed samples:     35716096 | elapsed time per iteration (ms): 37759.4 | learning rate: 6.692E-05 | global batch size:  1024 | lm loss: 1.820484E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34880/   51900 | consumed samples:     35717120 | elapsed time per iteration (ms): 37742.1 | learning rate: 6.691E-05 | global batch size:  1024 | lm loss: 1.814009E+00 | loss scale: 1.0 | grad norm: 0.062 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34881/   51900 | consumed samples:     35718144 | elapsed time per iteration (ms): 37614.3 | learning rate: 6.691E-05 | global batch size:  1024 | lm loss: 1.805204E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34882/   51900 | consumed samples:     35719168 | elapsed time per iteration (ms): 37682.4 | learning rate: 6.690E-05 | global batch size:  1024 | lm loss: 1.811003E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34883/   51900 | consumed samples:     35720192 | elapsed time per iteration (ms): 37747.6 | learning rate: 6.690E-05 | global batch size:  1024 | lm loss: 1.822331E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34884/   51900 | consumed samples:     35721216 | elapsed time per iteration (ms): 37663.8 | learning rate: 6.689E-05 | global batch size:  1024 | lm loss: 1.825880E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34885/   51900 | consumed samples:     35722240 | elapsed time per iteration (ms): 37565.9 | learning rate: 6.689E-05 | global batch size:  1024 | lm loss: 1.821564E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34886/   51900 | consumed samples:     35723264 | elapsed time per iteration (ms): 37640.9 | learning rate: 6.688E-05 | global batch size:  1024 | lm loss: 1.826757E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34887/   51900 | consumed samples:     35724288 | elapsed time per iteration (ms): 37633.0 | learning rate: 6.688E-05 | global batch size:  1024 | lm loss: 1.816117E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34888/   51900 | consumed samples:     35725312 | elapsed time per iteration (ms): 37624.7 | learning rate: 6.687E-05 | global batch size:  1024 | lm loss: 1.821334E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34889/   51900 | consumed samples:     35726336 | elapsed time per iteration (ms): 37667.2 | learning rate: 6.687E-05 | global batch size:  1024 | lm loss: 1.837253E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34890/   51900 | consumed samples:     35727360 | elapsed time per iteration (ms): 37827.1 | learning rate: 6.686E-05 | global batch size:  1024 | lm loss: 1.827823E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34891/   51900 | consumed samples:     35728384 | elapsed time per iteration (ms): 37744.3 | learning rate: 6.686E-05 | global batch size:  1024 | lm loss: 1.824020E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34892/   51900 | consumed samples:     35729408 | elapsed time per iteration (ms): 37743.4 | learning rate: 6.685E-05 | global batch size:  1024 | lm loss: 1.815293E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34893/   51900 | consumed samples:     35730432 | elapsed time per iteration (ms): 37728.0 | learning rate: 6.685E-05 | global batch size:  1024 | lm loss: 1.796434E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34894/   51900 | consumed samples:     35731456 | elapsed time per iteration (ms): 37724.9 | learning rate: 6.684E-05 | global batch size:  1024 | lm loss: 1.818987E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34895/   51900 | consumed samples:     35732480 | elapsed time per iteration (ms): 37746.5 | learning rate: 6.684E-05 | global batch size:  1024 | lm loss: 1.822179E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34896/   51900 | consumed samples:     35733504 | elapsed time per iteration (ms): 37653.6 | learning rate: 6.683E-05 | global batch size:  1024 | lm loss: 1.813430E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34897/   51900 | consumed samples:     35734528 | elapsed time per iteration (ms): 37729.1 | learning rate: 6.683E-05 | global batch size:  1024 | lm loss: 1.821735E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34898/   51900 | consumed samples:     35735552 | elapsed time per iteration (ms): 37722.3 | learning rate: 6.682E-05 | global batch size:  1024 | lm loss: 1.828641E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34899/   51900 | consumed samples:     35736576 | elapsed time per iteration (ms): 37572.9 | learning rate: 6.682E-05 | global batch size:  1024 | lm loss: 1.817883E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34900/   51900 | consumed samples:     35737600 | elapsed time per iteration (ms): 37642.6 | learning rate: 6.681E-05 | global batch size:  1024 | lm loss: 1.797177E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34901/   51900 | consumed samples:     35738624 | elapsed time per iteration (ms): 37647.7 | learning rate: 6.681E-05 | global batch size:  1024 | lm loss: 1.814170E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34902/   51900 | consumed samples:     35739648 | elapsed time per iteration (ms): 37681.8 | learning rate: 6.680E-05 | global batch size:  1024 | lm loss: 1.819672E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34903/   51900 | consumed samples:     35740672 | elapsed time per iteration (ms): 37690.3 | learning rate: 6.680E-05 | global batch size:  1024 | lm loss: 1.835749E+00 | loss scale: 1.0 | grad norm: 0.090 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34904/   51900 | consumed samples:     35741696 | elapsed time per iteration (ms): 37641.2 | learning rate: 6.679E-05 | global batch size:  1024 | lm loss: 1.800485E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34905/   51900 | consumed samples:     35742720 | elapsed time per iteration (ms): 37709.6 | learning rate: 6.679E-05 | global batch size:  1024 | lm loss: 1.822119E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34906/   51900 | consumed samples:     35743744 | elapsed time per iteration (ms): 37638.0 | learning rate: 6.678E-05 | global batch size:  1024 | lm loss: 1.808758E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34907/   51900 | consumed samples:     35744768 | elapsed time per iteration (ms): 37645.0 | learning rate: 6.678E-05 | global batch size:  1024 | lm loss: 1.802360E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34908/   51900 | consumed samples:     35745792 | elapsed time per iteration (ms): 37732.9 | learning rate: 6.677E-05 | global batch size:  1024 | lm loss: 1.820825E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34909/   51900 | consumed samples:     35746816 | elapsed time per iteration (ms): 37670.5 | learning rate: 6.677E-05 | global batch size:  1024 | lm loss: 1.807161E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34910/   51900 | consumed samples:     35747840 | elapsed time per iteration (ms): 37716.5 | learning rate: 6.676E-05 | global batch size:  1024 | lm loss: 1.816766E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34911/   51900 | consumed samples:     35748864 | elapsed time per iteration (ms): 37820.4 | learning rate: 6.676E-05 | global batch size:  1024 | lm loss: 1.790462E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34912/   51900 | consumed samples:     35749888 | elapsed time per iteration (ms): 37736.4 | learning rate: 6.675E-05 | global batch size:  1024 | lm loss: 1.798561E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34913/   51900 | consumed samples:     35750912 | elapsed time per iteration (ms): 37618.3 | learning rate: 6.675E-05 | global batch size:  1024 | lm loss: 1.794636E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34914/   51900 | consumed samples:     35751936 | elapsed time per iteration (ms): 37735.1 | learning rate: 6.674E-05 | global batch size:  1024 | lm loss: 1.824612E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34915/   51900 | consumed samples:     35752960 | elapsed time per iteration (ms): 37746.0 | learning rate: 6.674E-05 | global batch size:  1024 | lm loss: 1.813296E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34916/   51900 | consumed samples:     35753984 | elapsed time per iteration (ms): 37711.3 | learning rate: 6.673E-05 | global batch size:  1024 | lm loss: 1.831000E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34917/   51900 | consumed samples:     35755008 | elapsed time per iteration (ms): 37739.3 | learning rate: 6.673E-05 | global batch size:  1024 | lm loss: 1.806013E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34918/   51900 | consumed samples:     35756032 | elapsed time per iteration (ms): 37684.8 | learning rate: 6.672E-05 | global batch size:  1024 | lm loss: 1.836118E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34919/   51900 | consumed samples:     35757056 | elapsed time per iteration (ms): 37699.6 | learning rate: 6.672E-05 | global batch size:  1024 | lm loss: 1.814477E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34920/   51900 | consumed samples:     35758080 | elapsed time per iteration (ms): 37729.1 | learning rate: 6.671E-05 | global batch size:  1024 | lm loss: 1.812978E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34921/   51900 | consumed samples:     35759104 | elapsed time per iteration (ms): 37690.9 | learning rate: 6.671E-05 | global batch size:  1024 | lm loss: 1.815039E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34922/   51900 | consumed samples:     35760128 | elapsed time per iteration (ms): 37634.3 | learning rate: 6.670E-05 | global batch size:  1024 | lm loss: 1.819946E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34923/   51900 | consumed samples:     35761152 | elapsed time per iteration (ms): 37586.3 | learning rate: 6.670E-05 | global batch size:  1024 | lm loss: 1.795335E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34924/   51900 | consumed samples:     35762176 | elapsed time per iteration (ms): 37638.9 | learning rate: 6.669E-05 | global batch size:  1024 | lm loss: 1.818952E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34925/   51900 | consumed samples:     35763200 | elapsed time per iteration (ms): 37658.9 | learning rate: 6.669E-05 | global batch size:  1024 | lm loss: 1.806401E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34926/   51900 | consumed samples:     35764224 | elapsed time per iteration (ms): 37722.5 | learning rate: 6.668E-05 | global batch size:  1024 | lm loss: 1.814890E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34927/   51900 | consumed samples:     35765248 | elapsed time per iteration (ms): 37774.8 | learning rate: 6.668E-05 | global batch size:  1024 | lm loss: 1.805858E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34928/   51900 | consumed samples:     35766272 | elapsed time per iteration (ms): 37684.8 | learning rate: 6.667E-05 | global batch size:  1024 | lm loss: 1.820943E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34929/   51900 | consumed samples:     35767296 | elapsed time per iteration (ms): 37651.6 | learning rate: 6.667E-05 | global batch size:  1024 | lm loss: 1.814516E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34930/   51900 | consumed samples:     35768320 | elapsed time per iteration (ms): 37686.9 | learning rate: 6.666E-05 | global batch size:  1024 | lm loss: 1.816919E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34931/   51900 | consumed samples:     35769344 | elapsed time per iteration (ms): 37665.2 | learning rate: 6.666E-05 | global batch size:  1024 | lm loss: 1.809110E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34932/   51900 | consumed samples:     35770368 | elapsed time per iteration (ms): 37634.4 | learning rate: 6.665E-05 | global batch size:  1024 | lm loss: 1.835590E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34933/   51900 | consumed samples:     35771392 | elapsed time per iteration (ms): 37740.8 | learning rate: 6.665E-05 | global batch size:  1024 | lm loss: 1.800719E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34934/   51900 | consumed samples:     35772416 | elapsed time per iteration (ms): 37655.5 | learning rate: 6.664E-05 | global batch size:  1024 | lm loss: 1.795880E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34935/   51900 | consumed samples:     35773440 | elapsed time per iteration (ms): 37698.6 | learning rate: 6.664E-05 | global batch size:  1024 | lm loss: 1.822555E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34936/   51900 | consumed samples:     35774464 | elapsed time per iteration (ms): 37677.9 | learning rate: 6.663E-05 | global batch size:  1024 | lm loss: 1.826709E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34937/   51900 | consumed samples:     35775488 | elapsed time per iteration (ms): 37565.1 | learning rate: 6.663E-05 | global batch size:  1024 | lm loss: 1.813779E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34938/   51900 | consumed samples:     35776512 | elapsed time per iteration (ms): 37693.7 | learning rate: 6.662E-05 | global batch size:  1024 | lm loss: 1.808575E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34939/   51900 | consumed samples:     35777536 | elapsed time per iteration (ms): 37627.0 | learning rate: 6.662E-05 | global batch size:  1024 | lm loss: 1.810883E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34940/   51900 | consumed samples:     35778560 | elapsed time per iteration (ms): 37656.6 | learning rate: 6.661E-05 | global batch size:  1024 | lm loss: 1.803475E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34941/   51900 | consumed samples:     35779584 | elapsed time per iteration (ms): 37563.9 | learning rate: 6.661E-05 | global batch size:  1024 | lm loss: 1.833493E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34942/   51900 | consumed samples:     35780608 | elapsed time per iteration (ms): 37700.0 | learning rate: 6.660E-05 | global batch size:  1024 | lm loss: 1.817426E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34943/   51900 | consumed samples:     35781632 | elapsed time per iteration (ms): 37695.7 | learning rate: 6.660E-05 | global batch size:  1024 | lm loss: 1.813023E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34944/   51900 | consumed samples:     35782656 | elapsed time per iteration (ms): 37657.0 | learning rate: 6.659E-05 | global batch size:  1024 | lm loss: 1.823375E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34945/   51900 | consumed samples:     35783680 | elapsed time per iteration (ms): 37641.2 | learning rate: 6.659E-05 | global batch size:  1024 | lm loss: 1.786802E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34946/   51900 | consumed samples:     35784704 | elapsed time per iteration (ms): 37589.2 | learning rate: 6.658E-05 | global batch size:  1024 | lm loss: 1.826002E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34947/   51900 | consumed samples:     35785728 | elapsed time per iteration (ms): 37595.1 | learning rate: 6.658E-05 | global batch size:  1024 | lm loss: 1.818379E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34948/   51900 | consumed samples:     35786752 | elapsed time per iteration (ms): 37659.9 | learning rate: 6.657E-05 | global batch size:  1024 | lm loss: 1.813051E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34949/   51900 | consumed samples:     35787776 | elapsed time per iteration (ms): 37586.2 | learning rate: 6.657E-05 | global batch size:  1024 | lm loss: 1.812753E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34950/   51900 | consumed samples:     35788800 | elapsed time per iteration (ms): 37641.6 | learning rate: 6.656E-05 | global batch size:  1024 | lm loss: 1.831159E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34951/   51900 | consumed samples:     35789824 | elapsed time per iteration (ms): 37708.6 | learning rate: 6.656E-05 | global batch size:  1024 | lm loss: 1.817942E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34952/   51900 | consumed samples:     35790848 | elapsed time per iteration (ms): 37701.4 | learning rate: 6.655E-05 | global batch size:  1024 | lm loss: 1.825899E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34953/   51900 | consumed samples:     35791872 | elapsed time per iteration (ms): 37745.7 | learning rate: 6.655E-05 | global batch size:  1024 | lm loss: 1.799842E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34954/   51900 | consumed samples:     35792896 | elapsed time per iteration (ms): 37681.8 | learning rate: 6.654E-05 | global batch size:  1024 | lm loss: 1.816387E+00 | loss scale: 1.0 | grad norm: 0.107 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34955/   51900 | consumed samples:     35793920 | elapsed time per iteration (ms): 37678.0 | learning rate: 6.654E-05 | global batch size:  1024 | lm loss: 1.804995E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34956/   51900 | consumed samples:     35794944 | elapsed time per iteration (ms): 37687.9 | learning rate: 6.653E-05 | global batch size:  1024 | lm loss: 1.823817E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34957/   51900 | consumed samples:     35795968 | elapsed time per iteration (ms): 37703.5 | learning rate: 6.653E-05 | global batch size:  1024 | lm loss: 1.834004E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34958/   51900 | consumed samples:     35796992 | elapsed time per iteration (ms): 37625.9 | learning rate: 6.652E-05 | global batch size:  1024 | lm loss: 1.817086E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34959/   51900 | consumed samples:     35798016 | elapsed time per iteration (ms): 37745.3 | learning rate: 6.652E-05 | global batch size:  1024 | lm loss: 1.812842E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34960/   51900 | consumed samples:     35799040 | elapsed time per iteration (ms): 37644.4 | learning rate: 6.651E-05 | global batch size:  1024 | lm loss: 1.811806E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34961/   51900 | consumed samples:     35800064 | elapsed time per iteration (ms): 37687.6 | learning rate: 6.651E-05 | global batch size:  1024 | lm loss: 1.801028E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34962/   51900 | consumed samples:     35801088 | elapsed time per iteration (ms): 37654.5 | learning rate: 6.650E-05 | global batch size:  1024 | lm loss: 1.804559E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34963/   51900 | consumed samples:     35802112 | elapsed time per iteration (ms): 37589.4 | learning rate: 6.650E-05 | global batch size:  1024 | lm loss: 1.821786E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34964/   51900 | consumed samples:     35803136 | elapsed time per iteration (ms): 37605.2 | learning rate: 6.649E-05 | global batch size:  1024 | lm loss: 1.801388E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34965/   51900 | consumed samples:     35804160 | elapsed time per iteration (ms): 37737.3 | learning rate: 6.649E-05 | global batch size:  1024 | lm loss: 1.850335E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34966/   51900 | consumed samples:     35805184 | elapsed time per iteration (ms): 37721.6 | learning rate: 6.648E-05 | global batch size:  1024 | lm loss: 1.822222E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34967/   51900 | consumed samples:     35806208 | elapsed time per iteration (ms): 37637.7 | learning rate: 6.648E-05 | global batch size:  1024 | lm loss: 1.815276E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34968/   51900 | consumed samples:     35807232 | elapsed time per iteration (ms): 37712.3 | learning rate: 6.647E-05 | global batch size:  1024 | lm loss: 1.821783E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34969/   51900 | consumed samples:     35808256 | elapsed time per iteration (ms): 37610.7 | learning rate: 6.647E-05 | global batch size:  1024 | lm loss: 1.821144E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34970/   51900 | consumed samples:     35809280 | elapsed time per iteration (ms): 37634.7 | learning rate: 6.646E-05 | global batch size:  1024 | lm loss: 1.834325E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34971/   51900 | consumed samples:     35810304 | elapsed time per iteration (ms): 37590.3 | learning rate: 6.646E-05 | global batch size:  1024 | lm loss: 1.815820E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34972/   51900 | consumed samples:     35811328 | elapsed time per iteration (ms): 37737.1 | learning rate: 6.645E-05 | global batch size:  1024 | lm loss: 1.800735E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34973/   51900 | consumed samples:     35812352 | elapsed time per iteration (ms): 37703.4 | learning rate: 6.645E-05 | global batch size:  1024 | lm loss: 1.808813E+00 | loss scale: 1.0 | grad norm: 0.192 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34974/   51900 | consumed samples:     35813376 | elapsed time per iteration (ms): 37725.1 | learning rate: 6.644E-05 | global batch size:  1024 | lm loss: 1.806755E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34975/   51900 | consumed samples:     35814400 | elapsed time per iteration (ms): 37658.8 | learning rate: 6.644E-05 | global batch size:  1024 | lm loss: 1.813057E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34976/   51900 | consumed samples:     35815424 | elapsed time per iteration (ms): 37651.8 | learning rate: 6.643E-05 | global batch size:  1024 | lm loss: 1.820371E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34977/   51900 | consumed samples:     35816448 | elapsed time per iteration (ms): 37694.9 | learning rate: 6.643E-05 | global batch size:  1024 | lm loss: 1.817833E+00 | loss scale: 1.0 | grad norm: 0.088 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34978/   51900 | consumed samples:     35817472 | elapsed time per iteration (ms): 37689.2 | learning rate: 6.642E-05 | global batch size:  1024 | lm loss: 1.819964E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34979/   51900 | consumed samples:     35818496 | elapsed time per iteration (ms): 37626.2 | learning rate: 6.642E-05 | global batch size:  1024 | lm loss: 1.807768E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34980/   51900 | consumed samples:     35819520 | elapsed time per iteration (ms): 37588.3 | learning rate: 6.641E-05 | global batch size:  1024 | lm loss: 1.821628E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34981/   51900 | consumed samples:     35820544 | elapsed time per iteration (ms): 37653.3 | learning rate: 6.641E-05 | global batch size:  1024 | lm loss: 1.811589E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34982/   51900 | consumed samples:     35821568 | elapsed time per iteration (ms): 37707.0 | learning rate: 6.640E-05 | global batch size:  1024 | lm loss: 1.811724E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34983/   51900 | consumed samples:     35822592 | elapsed time per iteration (ms): 37616.2 | learning rate: 6.640E-05 | global batch size:  1024 | lm loss: 1.825215E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34984/   51900 | consumed samples:     35823616 | elapsed time per iteration (ms): 37702.7 | learning rate: 6.639E-05 | global batch size:  1024 | lm loss: 1.817967E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34985/   51900 | consumed samples:     35824640 | elapsed time per iteration (ms): 37618.1 | learning rate: 6.639E-05 | global batch size:  1024 | lm loss: 1.804269E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34986/   51900 | consumed samples:     35825664 | elapsed time per iteration (ms): 37674.7 | learning rate: 6.638E-05 | global batch size:  1024 | lm loss: 1.824764E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34987/   51900 | consumed samples:     35826688 | elapsed time per iteration (ms): 37695.7 | learning rate: 6.638E-05 | global batch size:  1024 | lm loss: 1.805373E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34988/   51900 | consumed samples:     35827712 | elapsed time per iteration (ms): 37673.8 | learning rate: 6.637E-05 | global batch size:  1024 | lm loss: 1.814113E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34989/   51900 | consumed samples:     35828736 | elapsed time per iteration (ms): 37612.9 | learning rate: 6.637E-05 | global batch size:  1024 | lm loss: 1.799666E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34990/   51900 | consumed samples:     35829760 | elapsed time per iteration (ms): 37619.6 | learning rate: 6.636E-05 | global batch size:  1024 | lm loss: 1.810156E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34991/   51900 | consumed samples:     35830784 | elapsed time per iteration (ms): 37758.3 | learning rate: 6.636E-05 | global batch size:  1024 | lm loss: 1.804259E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34992/   51900 | consumed samples:     35831808 | elapsed time per iteration (ms): 37628.8 | learning rate: 6.635E-05 | global batch size:  1024 | lm loss: 1.807896E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34993/   51900 | consumed samples:     35832832 | elapsed time per iteration (ms): 37726.7 | learning rate: 6.635E-05 | global batch size:  1024 | lm loss: 1.818820E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34994/   51900 | consumed samples:     35833856 | elapsed time per iteration (ms): 37720.8 | learning rate: 6.634E-05 | global batch size:  1024 | lm loss: 1.835451E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34995/   51900 | consumed samples:     35834880 | elapsed time per iteration (ms): 37636.5 | learning rate: 6.634E-05 | global batch size:  1024 | lm loss: 1.820016E+00 | loss scale: 1.0 | grad norm: 0.065 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34996/   51900 | consumed samples:     35835904 | elapsed time per iteration (ms): 37584.6 | learning rate: 6.633E-05 | global batch size:  1024 | lm loss: 1.815903E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34997/   51900 | consumed samples:     35836928 | elapsed time per iteration (ms): 37677.8 | learning rate: 6.633E-05 | global batch size:  1024 | lm loss: 1.815924E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34998/   51900 | consumed samples:     35837952 | elapsed time per iteration (ms): 37703.7 | learning rate: 6.632E-05 | global batch size:  1024 | lm loss: 1.815533E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    34999/   51900 | consumed samples:     35838976 | elapsed time per iteration (ms): 37584.0 | learning rate: 6.632E-05 | global batch size:  1024 | lm loss: 1.806193E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35000/   51900 | consumed samples:     35840000 | elapsed time per iteration (ms): 37621.4 | learning rate: 6.631E-05 | global batch size:  1024 | lm loss: 1.803912E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    save-checkpoint ................................: (152893.63, 152894.07)
 iteration    35001/   51900 | consumed samples:     35841024 | elapsed time per iteration (ms): 37200.0 | learning rate: 6.631E-05 | global batch size:  1024 | lm loss: 1.805087E+00 | loss scale: 1.0 | grad norm: 0.064 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35002/   51900 | consumed samples:     35842048 | elapsed time per iteration (ms): 37565.7 | learning rate: 6.630E-05 | global batch size:  1024 | lm loss: 1.820491E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35003/   51900 | consumed samples:     35843072 | elapsed time per iteration (ms): 37740.3 | learning rate: 6.630E-05 | global batch size:  1024 | lm loss: 1.809099E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35004/   51900 | consumed samples:     35844096 | elapsed time per iteration (ms): 37738.5 | learning rate: 6.630E-05 | global batch size:  1024 | lm loss: 1.793301E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35005/   51900 | consumed samples:     35845120 | elapsed time per iteration (ms): 37732.1 | learning rate: 6.629E-05 | global batch size:  1024 | lm loss: 1.808222E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35006/   51900 | consumed samples:     35846144 | elapsed time per iteration (ms): 37638.9 | learning rate: 6.629E-05 | global batch size:  1024 | lm loss: 1.799397E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35007/   51900 | consumed samples:     35847168 | elapsed time per iteration (ms): 37618.8 | learning rate: 6.628E-05 | global batch size:  1024 | lm loss: 1.809163E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35008/   51900 | consumed samples:     35848192 | elapsed time per iteration (ms): 37676.9 | learning rate: 6.628E-05 | global batch size:  1024 | lm loss: 1.809272E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35009/   51900 | consumed samples:     35849216 | elapsed time per iteration (ms): 37698.0 | learning rate: 6.627E-05 | global batch size:  1024 | lm loss: 1.815934E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35010/   51900 | consumed samples:     35850240 | elapsed time per iteration (ms): 37660.0 | learning rate: 6.627E-05 | global batch size:  1024 | lm loss: 1.817598E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35011/   51900 | consumed samples:     35851264 | elapsed time per iteration (ms): 37775.3 | learning rate: 6.626E-05 | global batch size:  1024 | lm loss: 1.815753E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35012/   51900 | consumed samples:     35852288 | elapsed time per iteration (ms): 37574.0 | learning rate: 6.626E-05 | global batch size:  1024 | lm loss: 1.813492E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35013/   51900 | consumed samples:     35853312 | elapsed time per iteration (ms): 37712.4 | learning rate: 6.625E-05 | global batch size:  1024 | lm loss: 1.810429E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35014/   51900 | consumed samples:     35854336 | elapsed time per iteration (ms): 37676.7 | learning rate: 6.625E-05 | global batch size:  1024 | lm loss: 1.826489E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35015/   51900 | consumed samples:     35855360 | elapsed time per iteration (ms): 37653.3 | learning rate: 6.624E-05 | global batch size:  1024 | lm loss: 1.821002E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35016/   51900 | consumed samples:     35856384 | elapsed time per iteration (ms): 37650.6 | learning rate: 6.624E-05 | global batch size:  1024 | lm loss: 1.821445E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35017/   51900 | consumed samples:     35857408 | elapsed time per iteration (ms): 37734.7 | learning rate: 6.623E-05 | global batch size:  1024 | lm loss: 1.798262E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35018/   51900 | consumed samples:     35858432 | elapsed time per iteration (ms): 37639.1 | learning rate: 6.623E-05 | global batch size:  1024 | lm loss: 1.833564E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35019/   51900 | consumed samples:     35859456 | elapsed time per iteration (ms): 37658.7 | learning rate: 6.622E-05 | global batch size:  1024 | lm loss: 1.799587E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35020/   51900 | consumed samples:     35860480 | elapsed time per iteration (ms): 37720.4 | learning rate: 6.622E-05 | global batch size:  1024 | lm loss: 1.812068E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35021/   51900 | consumed samples:     35861504 | elapsed time per iteration (ms): 37626.3 | learning rate: 6.621E-05 | global batch size:  1024 | lm loss: 1.811896E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35022/   51900 | consumed samples:     35862528 | elapsed time per iteration (ms): 37629.1 | learning rate: 6.621E-05 | global batch size:  1024 | lm loss: 1.817108E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35023/   51900 | consumed samples:     35863552 | elapsed time per iteration (ms): 37751.6 | learning rate: 6.620E-05 | global batch size:  1024 | lm loss: 1.816989E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35024/   51900 | consumed samples:     35864576 | elapsed time per iteration (ms): 37601.7 | learning rate: 6.620E-05 | global batch size:  1024 | lm loss: 1.807752E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35025/   51900 | consumed samples:     35865600 | elapsed time per iteration (ms): 37740.7 | learning rate: 6.619E-05 | global batch size:  1024 | lm loss: 1.807739E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35026/   51900 | consumed samples:     35866624 | elapsed time per iteration (ms): 37616.9 | learning rate: 6.619E-05 | global batch size:  1024 | lm loss: 1.812618E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35027/   51900 | consumed samples:     35867648 | elapsed time per iteration (ms): 37659.4 | learning rate: 6.618E-05 | global batch size:  1024 | lm loss: 1.826874E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35028/   51900 | consumed samples:     35868672 | elapsed time per iteration (ms): 37639.0 | learning rate: 6.618E-05 | global batch size:  1024 | lm loss: 1.790839E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35029/   51900 | consumed samples:     35869696 | elapsed time per iteration (ms): 37584.3 | learning rate: 6.617E-05 | global batch size:  1024 | lm loss: 1.837211E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35030/   51900 | consumed samples:     35870720 | elapsed time per iteration (ms): 37690.1 | learning rate: 6.617E-05 | global batch size:  1024 | lm loss: 1.814278E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35031/   51900 | consumed samples:     35871744 | elapsed time per iteration (ms): 37706.9 | learning rate: 6.616E-05 | global batch size:  1024 | lm loss: 1.822063E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35032/   51900 | consumed samples:     35872768 | elapsed time per iteration (ms): 37833.5 | learning rate: 6.616E-05 | global batch size:  1024 | lm loss: 1.811630E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35033/   51900 | consumed samples:     35873792 | elapsed time per iteration (ms): 37659.2 | learning rate: 6.615E-05 | global batch size:  1024 | lm loss: 1.809307E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35034/   51900 | consumed samples:     35874816 | elapsed time per iteration (ms): 37614.7 | learning rate: 6.615E-05 | global batch size:  1024 | lm loss: 1.825719E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35035/   51900 | consumed samples:     35875840 | elapsed time per iteration (ms): 37723.0 | learning rate: 6.614E-05 | global batch size:  1024 | lm loss: 1.803795E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35036/   51900 | consumed samples:     35876864 | elapsed time per iteration (ms): 37645.0 | learning rate: 6.614E-05 | global batch size:  1024 | lm loss: 1.814086E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35037/   51900 | consumed samples:     35877888 | elapsed time per iteration (ms): 37655.6 | learning rate: 6.613E-05 | global batch size:  1024 | lm loss: 1.806166E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35038/   51900 | consumed samples:     35878912 | elapsed time per iteration (ms): 37675.3 | learning rate: 6.613E-05 | global batch size:  1024 | lm loss: 1.810896E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35039/   51900 | consumed samples:     35879936 | elapsed time per iteration (ms): 37750.6 | learning rate: 6.612E-05 | global batch size:  1024 | lm loss: 1.837630E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35040/   51900 | consumed samples:     35880960 | elapsed time per iteration (ms): 37786.9 | learning rate: 6.612E-05 | global batch size:  1024 | lm loss: 1.817369E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35041/   51900 | consumed samples:     35881984 | elapsed time per iteration (ms): 37563.1 | learning rate: 6.611E-05 | global batch size:  1024 | lm loss: 1.813359E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35042/   51900 | consumed samples:     35883008 | elapsed time per iteration (ms): 37640.9 | learning rate: 6.611E-05 | global batch size:  1024 | lm loss: 1.820177E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35043/   51900 | consumed samples:     35884032 | elapsed time per iteration (ms): 37654.0 | learning rate: 6.610E-05 | global batch size:  1024 | lm loss: 1.816565E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35044/   51900 | consumed samples:     35885056 | elapsed time per iteration (ms): 37622.0 | learning rate: 6.610E-05 | global batch size:  1024 | lm loss: 1.805757E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35045/   51900 | consumed samples:     35886080 | elapsed time per iteration (ms): 37695.1 | learning rate: 6.609E-05 | global batch size:  1024 | lm loss: 1.812066E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35046/   51900 | consumed samples:     35887104 | elapsed time per iteration (ms): 37623.5 | learning rate: 6.609E-05 | global batch size:  1024 | lm loss: 1.828276E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35047/   51900 | consumed samples:     35888128 | elapsed time per iteration (ms): 37688.0 | learning rate: 6.608E-05 | global batch size:  1024 | lm loss: 1.815816E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35048/   51900 | consumed samples:     35889152 | elapsed time per iteration (ms): 37678.1 | learning rate: 6.608E-05 | global batch size:  1024 | lm loss: 1.815148E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35049/   51900 | consumed samples:     35890176 | elapsed time per iteration (ms): 37674.2 | learning rate: 6.607E-05 | global batch size:  1024 | lm loss: 1.792227E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35050/   51900 | consumed samples:     35891200 | elapsed time per iteration (ms): 37720.8 | learning rate: 6.607E-05 | global batch size:  1024 | lm loss: 1.822389E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35051/   51900 | consumed samples:     35892224 | elapsed time per iteration (ms): 37588.7 | learning rate: 6.606E-05 | global batch size:  1024 | lm loss: 1.790172E+00 | loss scale: 1.0 | grad norm: 0.065 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35052/   51900 | consumed samples:     35893248 | elapsed time per iteration (ms): 37762.4 | learning rate: 6.606E-05 | global batch size:  1024 | lm loss: 1.816161E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35053/   51900 | consumed samples:     35894272 | elapsed time per iteration (ms): 37665.6 | learning rate: 6.605E-05 | global batch size:  1024 | lm loss: 1.827183E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35054/   51900 | consumed samples:     35895296 | elapsed time per iteration (ms): 37687.2 | learning rate: 6.605E-05 | global batch size:  1024 | lm loss: 1.819127E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35055/   51900 | consumed samples:     35896320 | elapsed time per iteration (ms): 37588.4 | learning rate: 6.604E-05 | global batch size:  1024 | lm loss: 1.810492E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35056/   51900 | consumed samples:     35897344 | elapsed time per iteration (ms): 37702.4 | learning rate: 6.604E-05 | global batch size:  1024 | lm loss: 1.818667E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35057/   51900 | consumed samples:     35898368 | elapsed time per iteration (ms): 37623.8 | learning rate: 6.603E-05 | global batch size:  1024 | lm loss: 1.798285E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35058/   51900 | consumed samples:     35899392 | elapsed time per iteration (ms): 37660.5 | learning rate: 6.603E-05 | global batch size:  1024 | lm loss: 1.814144E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35059/   51900 | consumed samples:     35900416 | elapsed time per iteration (ms): 37680.9 | learning rate: 6.602E-05 | global batch size:  1024 | lm loss: 1.818890E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35060/   51900 | consumed samples:     35901440 | elapsed time per iteration (ms): 37684.0 | learning rate: 6.602E-05 | global batch size:  1024 | lm loss: 1.810222E+00 | loss scale: 1.0 | grad norm: 0.209 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35061/   51900 | consumed samples:     35902464 | elapsed time per iteration (ms): 37669.6 | learning rate: 6.601E-05 | global batch size:  1024 | lm loss: 1.825155E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35062/   51900 | consumed samples:     35903488 | elapsed time per iteration (ms): 37644.2 | learning rate: 6.601E-05 | global batch size:  1024 | lm loss: 1.809304E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35063/   51900 | consumed samples:     35904512 | elapsed time per iteration (ms): 37710.2 | learning rate: 6.600E-05 | global batch size:  1024 | lm loss: 1.794594E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35064/   51900 | consumed samples:     35905536 | elapsed time per iteration (ms): 37674.0 | learning rate: 6.600E-05 | global batch size:  1024 | lm loss: 1.798124E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35065/   51900 | consumed samples:     35906560 | elapsed time per iteration (ms): 37722.5 | learning rate: 6.599E-05 | global batch size:  1024 | lm loss: 1.804902E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35066/   51900 | consumed samples:     35907584 | elapsed time per iteration (ms): 37641.1 | learning rate: 6.599E-05 | global batch size:  1024 | lm loss: 1.816097E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35067/   51900 | consumed samples:     35908608 | elapsed time per iteration (ms): 37750.5 | learning rate: 6.598E-05 | global batch size:  1024 | lm loss: 1.805482E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35068/   51900 | consumed samples:     35909632 | elapsed time per iteration (ms): 37800.1 | learning rate: 6.598E-05 | global batch size:  1024 | lm loss: 1.811912E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35069/   51900 | consumed samples:     35910656 | elapsed time per iteration (ms): 37704.3 | learning rate: 6.597E-05 | global batch size:  1024 | lm loss: 1.817832E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35070/   51900 | consumed samples:     35911680 | elapsed time per iteration (ms): 37784.8 | learning rate: 6.597E-05 | global batch size:  1024 | lm loss: 1.812920E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35071/   51900 | consumed samples:     35912704 | elapsed time per iteration (ms): 37635.3 | learning rate: 6.596E-05 | global batch size:  1024 | lm loss: 1.811144E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35072/   51900 | consumed samples:     35913728 | elapsed time per iteration (ms): 37671.0 | learning rate: 6.596E-05 | global batch size:  1024 | lm loss: 1.816814E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35073/   51900 | consumed samples:     35914752 | elapsed time per iteration (ms): 37829.3 | learning rate: 6.595E-05 | global batch size:  1024 | lm loss: 1.801876E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35074/   51900 | consumed samples:     35915776 | elapsed time per iteration (ms): 37617.6 | learning rate: 6.595E-05 | global batch size:  1024 | lm loss: 1.811643E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35075/   51900 | consumed samples:     35916800 | elapsed time per iteration (ms): 37633.0 | learning rate: 6.594E-05 | global batch size:  1024 | lm loss: 1.797859E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35076/   51900 | consumed samples:     35917824 | elapsed time per iteration (ms): 37692.2 | learning rate: 6.594E-05 | global batch size:  1024 | lm loss: 1.816048E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35077/   51900 | consumed samples:     35918848 | elapsed time per iteration (ms): 37671.2 | learning rate: 6.593E-05 | global batch size:  1024 | lm loss: 1.803246E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35078/   51900 | consumed samples:     35919872 | elapsed time per iteration (ms): 37572.1 | learning rate: 6.593E-05 | global batch size:  1024 | lm loss: 1.814739E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35079/   51900 | consumed samples:     35920896 | elapsed time per iteration (ms): 37621.7 | learning rate: 6.592E-05 | global batch size:  1024 | lm loss: 1.823485E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35080/   51900 | consumed samples:     35921920 | elapsed time per iteration (ms): 37663.1 | learning rate: 6.592E-05 | global batch size:  1024 | lm loss: 1.813852E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35081/   51900 | consumed samples:     35922944 | elapsed time per iteration (ms): 37756.8 | learning rate: 6.591E-05 | global batch size:  1024 | lm loss: 1.808952E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35082/   51900 | consumed samples:     35923968 | elapsed time per iteration (ms): 37821.5 | learning rate: 6.591E-05 | global batch size:  1024 | lm loss: 1.819851E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35083/   51900 | consumed samples:     35924992 | elapsed time per iteration (ms): 37623.5 | learning rate: 6.590E-05 | global batch size:  1024 | lm loss: 1.821878E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35084/   51900 | consumed samples:     35926016 | elapsed time per iteration (ms): 37678.0 | learning rate: 6.590E-05 | global batch size:  1024 | lm loss: 1.791382E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35085/   51900 | consumed samples:     35927040 | elapsed time per iteration (ms): 37707.7 | learning rate: 6.589E-05 | global batch size:  1024 | lm loss: 1.818332E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35086/   51900 | consumed samples:     35928064 | elapsed time per iteration (ms): 37646.1 | learning rate: 6.589E-05 | global batch size:  1024 | lm loss: 1.802852E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35087/   51900 | consumed samples:     35929088 | elapsed time per iteration (ms): 37644.9 | learning rate: 6.588E-05 | global batch size:  1024 | lm loss: 1.822415E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35088/   51900 | consumed samples:     35930112 | elapsed time per iteration (ms): 37582.8 | learning rate: 6.588E-05 | global batch size:  1024 | lm loss: 1.817802E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35089/   51900 | consumed samples:     35931136 | elapsed time per iteration (ms): 37640.6 | learning rate: 6.587E-05 | global batch size:  1024 | lm loss: 1.816783E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35090/   51900 | consumed samples:     35932160 | elapsed time per iteration (ms): 37621.3 | learning rate: 6.587E-05 | global batch size:  1024 | lm loss: 1.811176E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35091/   51900 | consumed samples:     35933184 | elapsed time per iteration (ms): 37711.2 | learning rate: 6.586E-05 | global batch size:  1024 | lm loss: 1.819131E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35092/   51900 | consumed samples:     35934208 | elapsed time per iteration (ms): 37644.1 | learning rate: 6.586E-05 | global batch size:  1024 | lm loss: 1.813519E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35093/   51900 | consumed samples:     35935232 | elapsed time per iteration (ms): 37664.3 | learning rate: 6.585E-05 | global batch size:  1024 | lm loss: 1.814739E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35094/   51900 | consumed samples:     35936256 | elapsed time per iteration (ms): 37635.3 | learning rate: 6.585E-05 | global batch size:  1024 | lm loss: 1.815628E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35095/   51900 | consumed samples:     35937280 | elapsed time per iteration (ms): 37689.4 | learning rate: 6.584E-05 | global batch size:  1024 | lm loss: 1.804641E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35096/   51900 | consumed samples:     35938304 | elapsed time per iteration (ms): 37697.9 | learning rate: 6.584E-05 | global batch size:  1024 | lm loss: 1.810076E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35097/   51900 | consumed samples:     35939328 | elapsed time per iteration (ms): 37660.0 | learning rate: 6.584E-05 | global batch size:  1024 | lm loss: 1.811878E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35098/   51900 | consumed samples:     35940352 | elapsed time per iteration (ms): 37683.0 | learning rate: 6.583E-05 | global batch size:  1024 | lm loss: 1.811619E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35099/   51900 | consumed samples:     35941376 | elapsed time per iteration (ms): 37644.7 | learning rate: 6.583E-05 | global batch size:  1024 | lm loss: 1.805976E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35100/   51900 | consumed samples:     35942400 | elapsed time per iteration (ms): 37672.9 | learning rate: 6.582E-05 | global batch size:  1024 | lm loss: 1.817812E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35101/   51900 | consumed samples:     35943424 | elapsed time per iteration (ms): 37566.1 | learning rate: 6.582E-05 | global batch size:  1024 | lm loss: 1.802844E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35102/   51900 | consumed samples:     35944448 | elapsed time per iteration (ms): 37629.6 | learning rate: 6.581E-05 | global batch size:  1024 | lm loss: 1.795779E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35103/   51900 | consumed samples:     35945472 | elapsed time per iteration (ms): 37650.6 | learning rate: 6.581E-05 | global batch size:  1024 | lm loss: 1.803508E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35104/   51900 | consumed samples:     35946496 | elapsed time per iteration (ms): 37780.4 | learning rate: 6.580E-05 | global batch size:  1024 | lm loss: 1.811041E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35105/   51900 | consumed samples:     35947520 | elapsed time per iteration (ms): 37717.1 | learning rate: 6.580E-05 | global batch size:  1024 | lm loss: 1.813131E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35106/   51900 | consumed samples:     35948544 | elapsed time per iteration (ms): 37689.9 | learning rate: 6.579E-05 | global batch size:  1024 | lm loss: 1.827153E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35107/   51900 | consumed samples:     35949568 | elapsed time per iteration (ms): 37663.4 | learning rate: 6.579E-05 | global batch size:  1024 | lm loss: 1.803374E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35108/   51900 | consumed samples:     35950592 | elapsed time per iteration (ms): 37662.0 | learning rate: 6.578E-05 | global batch size:  1024 | lm loss: 1.797400E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35109/   51900 | consumed samples:     35951616 | elapsed time per iteration (ms): 37740.1 | learning rate: 6.578E-05 | global batch size:  1024 | lm loss: 1.804616E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35110/   51900 | consumed samples:     35952640 | elapsed time per iteration (ms): 37691.4 | learning rate: 6.577E-05 | global batch size:  1024 | lm loss: 1.842559E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35111/   51900 | consumed samples:     35953664 | elapsed time per iteration (ms): 37589.8 | learning rate: 6.577E-05 | global batch size:  1024 | lm loss: 1.822984E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35112/   51900 | consumed samples:     35954688 | elapsed time per iteration (ms): 37614.3 | learning rate: 6.576E-05 | global batch size:  1024 | lm loss: 1.820005E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35113/   51900 | consumed samples:     35955712 | elapsed time per iteration (ms): 37688.6 | learning rate: 6.576E-05 | global batch size:  1024 | lm loss: 1.819579E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35114/   51900 | consumed samples:     35956736 | elapsed time per iteration (ms): 37690.1 | learning rate: 6.575E-05 | global batch size:  1024 | lm loss: 1.805336E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35115/   51900 | consumed samples:     35957760 | elapsed time per iteration (ms): 37685.3 | learning rate: 6.575E-05 | global batch size:  1024 | lm loss: 1.805277E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35116/   51900 | consumed samples:     35958784 | elapsed time per iteration (ms): 37673.6 | learning rate: 6.574E-05 | global batch size:  1024 | lm loss: 1.796070E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35117/   51900 | consumed samples:     35959808 | elapsed time per iteration (ms): 37632.0 | learning rate: 6.574E-05 | global batch size:  1024 | lm loss: 1.809744E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35118/   51900 | consumed samples:     35960832 | elapsed time per iteration (ms): 37681.2 | learning rate: 6.573E-05 | global batch size:  1024 | lm loss: 1.817772E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35119/   51900 | consumed samples:     35961856 | elapsed time per iteration (ms): 37575.1 | learning rate: 6.573E-05 | global batch size:  1024 | lm loss: 1.819127E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35120/   51900 | consumed samples:     35962880 | elapsed time per iteration (ms): 37678.0 | learning rate: 6.572E-05 | global batch size:  1024 | lm loss: 1.824187E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35121/   51900 | consumed samples:     35963904 | elapsed time per iteration (ms): 37680.6 | learning rate: 6.572E-05 | global batch size:  1024 | lm loss: 1.811754E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35122/   51900 | consumed samples:     35964928 | elapsed time per iteration (ms): 37552.0 | learning rate: 6.571E-05 | global batch size:  1024 | lm loss: 1.805978E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35123/   51900 | consumed samples:     35965952 | elapsed time per iteration (ms): 37689.0 | learning rate: 6.571E-05 | global batch size:  1024 | lm loss: 1.822624E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35124/   51900 | consumed samples:     35966976 | elapsed time per iteration (ms): 37659.8 | learning rate: 6.570E-05 | global batch size:  1024 | lm loss: 1.811126E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35125/   51900 | consumed samples:     35968000 | elapsed time per iteration (ms): 37576.9 | learning rate: 6.570E-05 | global batch size:  1024 | lm loss: 1.812066E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35126/   51900 | consumed samples:     35969024 | elapsed time per iteration (ms): 37570.2 | learning rate: 6.569E-05 | global batch size:  1024 | lm loss: 1.835867E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35127/   51900 | consumed samples:     35970048 | elapsed time per iteration (ms): 37610.2 | learning rate: 6.569E-05 | global batch size:  1024 | lm loss: 1.799297E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35128/   51900 | consumed samples:     35971072 | elapsed time per iteration (ms): 37678.8 | learning rate: 6.568E-05 | global batch size:  1024 | lm loss: 1.801928E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35129/   51900 | consumed samples:     35972096 | elapsed time per iteration (ms): 37845.8 | learning rate: 6.568E-05 | global batch size:  1024 | lm loss: 1.806234E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35130/   51900 | consumed samples:     35973120 | elapsed time per iteration (ms): 37645.0 | learning rate: 6.567E-05 | global batch size:  1024 | lm loss: 1.806238E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35131/   51900 | consumed samples:     35974144 | elapsed time per iteration (ms): 37688.0 | learning rate: 6.567E-05 | global batch size:  1024 | lm loss: 1.816941E+00 | loss scale: 1.0 | grad norm: 0.112 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35132/   51900 | consumed samples:     35975168 | elapsed time per iteration (ms): 37589.2 | learning rate: 6.566E-05 | global batch size:  1024 | lm loss: 1.800889E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35133/   51900 | consumed samples:     35976192 | elapsed time per iteration (ms): 37657.2 | learning rate: 6.566E-05 | global batch size:  1024 | lm loss: 1.821102E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35134/   51900 | consumed samples:     35977216 | elapsed time per iteration (ms): 37560.6 | learning rate: 6.565E-05 | global batch size:  1024 | lm loss: 1.811127E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35135/   51900 | consumed samples:     35978240 | elapsed time per iteration (ms): 37549.1 | learning rate: 6.565E-05 | global batch size:  1024 | lm loss: 1.815518E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35136/   51900 | consumed samples:     35979264 | elapsed time per iteration (ms): 37733.4 | learning rate: 6.564E-05 | global batch size:  1024 | lm loss: 1.819541E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35137/   51900 | consumed samples:     35980288 | elapsed time per iteration (ms): 37719.9 | learning rate: 6.564E-05 | global batch size:  1024 | lm loss: 1.832652E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35138/   51900 | consumed samples:     35981312 | elapsed time per iteration (ms): 37666.9 | learning rate: 6.563E-05 | global batch size:  1024 | lm loss: 1.810524E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35139/   51900 | consumed samples:     35982336 | elapsed time per iteration (ms): 37609.9 | learning rate: 6.563E-05 | global batch size:  1024 | lm loss: 1.820546E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35140/   51900 | consumed samples:     35983360 | elapsed time per iteration (ms): 37584.8 | learning rate: 6.562E-05 | global batch size:  1024 | lm loss: 1.789422E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35141/   51900 | consumed samples:     35984384 | elapsed time per iteration (ms): 37623.1 | learning rate: 6.562E-05 | global batch size:  1024 | lm loss: 1.816055E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35142/   51900 | consumed samples:     35985408 | elapsed time per iteration (ms): 37679.5 | learning rate: 6.561E-05 | global batch size:  1024 | lm loss: 1.802906E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35143/   51900 | consumed samples:     35986432 | elapsed time per iteration (ms): 37778.1 | learning rate: 6.561E-05 | global batch size:  1024 | lm loss: 1.801621E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35144/   51900 | consumed samples:     35987456 | elapsed time per iteration (ms): 37694.7 | learning rate: 6.560E-05 | global batch size:  1024 | lm loss: 1.806409E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35145/   51900 | consumed samples:     35988480 | elapsed time per iteration (ms): 37717.5 | learning rate: 6.560E-05 | global batch size:  1024 | lm loss: 1.796158E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35146/   51900 | consumed samples:     35989504 | elapsed time per iteration (ms): 37775.4 | learning rate: 6.559E-05 | global batch size:  1024 | lm loss: 1.821687E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35147/   51900 | consumed samples:     35990528 | elapsed time per iteration (ms): 37621.5 | learning rate: 6.559E-05 | global batch size:  1024 | lm loss: 1.807152E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35148/   51900 | consumed samples:     35991552 | elapsed time per iteration (ms): 37691.8 | learning rate: 6.558E-05 | global batch size:  1024 | lm loss: 1.818197E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35149/   51900 | consumed samples:     35992576 | elapsed time per iteration (ms): 37728.1 | learning rate: 6.558E-05 | global batch size:  1024 | lm loss: 1.819310E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35150/   51900 | consumed samples:     35993600 | elapsed time per iteration (ms): 37668.3 | learning rate: 6.557E-05 | global batch size:  1024 | lm loss: 1.826977E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35151/   51900 | consumed samples:     35994624 | elapsed time per iteration (ms): 37588.2 | learning rate: 6.557E-05 | global batch size:  1024 | lm loss: 1.821837E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35152/   51900 | consumed samples:     35995648 | elapsed time per iteration (ms): 37752.2 | learning rate: 6.556E-05 | global batch size:  1024 | lm loss: 1.795732E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35153/   51900 | consumed samples:     35996672 | elapsed time per iteration (ms): 37626.4 | learning rate: 6.556E-05 | global batch size:  1024 | lm loss: 1.821808E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35154/   51900 | consumed samples:     35997696 | elapsed time per iteration (ms): 37630.8 | learning rate: 6.555E-05 | global batch size:  1024 | lm loss: 1.797245E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35155/   51900 | consumed samples:     35998720 | elapsed time per iteration (ms): 37617.7 | learning rate: 6.555E-05 | global batch size:  1024 | lm loss: 1.812632E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35156/   51900 | consumed samples:     35999744 | elapsed time per iteration (ms): 37874.3 | learning rate: 6.554E-05 | global batch size:  1024 | lm loss: 1.838133E+00 | loss scale: 1.0 | grad norm: 0.088 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35157/   51900 | consumed samples:     36000768 | elapsed time per iteration (ms): 37627.6 | learning rate: 6.554E-05 | global batch size:  1024 | lm loss: 1.834571E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35158/   51900 | consumed samples:     36001792 | elapsed time per iteration (ms): 37616.1 | learning rate: 6.553E-05 | global batch size:  1024 | lm loss: 1.810054E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35159/   51900 | consumed samples:     36002816 | elapsed time per iteration (ms): 37607.2 | learning rate: 6.553E-05 | global batch size:  1024 | lm loss: 1.807439E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35160/   51900 | consumed samples:     36003840 | elapsed time per iteration (ms): 37647.9 | learning rate: 6.552E-05 | global batch size:  1024 | lm loss: 1.825425E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35161/   51900 | consumed samples:     36004864 | elapsed time per iteration (ms): 37685.9 | learning rate: 6.552E-05 | global batch size:  1024 | lm loss: 1.806861E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35162/   51900 | consumed samples:     36005888 | elapsed time per iteration (ms): 37692.7 | learning rate: 6.551E-05 | global batch size:  1024 | lm loss: 1.822593E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35163/   51900 | consumed samples:     36006912 | elapsed time per iteration (ms): 37664.4 | learning rate: 6.551E-05 | global batch size:  1024 | lm loss: 1.819360E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35164/   51900 | consumed samples:     36007936 | elapsed time per iteration (ms): 37737.3 | learning rate: 6.550E-05 | global batch size:  1024 | lm loss: 1.802897E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35165/   51900 | consumed samples:     36008960 | elapsed time per iteration (ms): 37641.0 | learning rate: 6.550E-05 | global batch size:  1024 | lm loss: 1.813370E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35166/   51900 | consumed samples:     36009984 | elapsed time per iteration (ms): 37638.2 | learning rate: 6.549E-05 | global batch size:  1024 | lm loss: 1.817672E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35167/   51900 | consumed samples:     36011008 | elapsed time per iteration (ms): 37777.3 | learning rate: 6.549E-05 | global batch size:  1024 | lm loss: 1.813817E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35168/   51900 | consumed samples:     36012032 | elapsed time per iteration (ms): 37751.9 | learning rate: 6.549E-05 | global batch size:  1024 | lm loss: 1.810305E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35169/   51900 | consumed samples:     36013056 | elapsed time per iteration (ms): 37686.0 | learning rate: 6.548E-05 | global batch size:  1024 | lm loss: 1.808061E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35170/   51900 | consumed samples:     36014080 | elapsed time per iteration (ms): 37625.0 | learning rate: 6.548E-05 | global batch size:  1024 | lm loss: 1.813126E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35171/   51900 | consumed samples:     36015104 | elapsed time per iteration (ms): 37799.1 | learning rate: 6.547E-05 | global batch size:  1024 | lm loss: 1.796618E+00 | loss scale: 1.0 | grad norm: 0.090 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35172/   51900 | consumed samples:     36016128 | elapsed time per iteration (ms): 37735.2 | learning rate: 6.547E-05 | global batch size:  1024 | lm loss: 1.839807E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35173/   51900 | consumed samples:     36017152 | elapsed time per iteration (ms): 37721.9 | learning rate: 6.546E-05 | global batch size:  1024 | lm loss: 1.820940E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35174/   51900 | consumed samples:     36018176 | elapsed time per iteration (ms): 37626.5 | learning rate: 6.546E-05 | global batch size:  1024 | lm loss: 1.815020E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35175/   51900 | consumed samples:     36019200 | elapsed time per iteration (ms): 37598.9 | learning rate: 6.545E-05 | global batch size:  1024 | lm loss: 1.818779E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35176/   51900 | consumed samples:     36020224 | elapsed time per iteration (ms): 37617.4 | learning rate: 6.545E-05 | global batch size:  1024 | lm loss: 1.798406E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35177/   51900 | consumed samples:     36021248 | elapsed time per iteration (ms): 37647.1 | learning rate: 6.544E-05 | global batch size:  1024 | lm loss: 1.810532E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35178/   51900 | consumed samples:     36022272 | elapsed time per iteration (ms): 37700.5 | learning rate: 6.544E-05 | global batch size:  1024 | lm loss: 1.822925E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35179/   51900 | consumed samples:     36023296 | elapsed time per iteration (ms): 37732.2 | learning rate: 6.543E-05 | global batch size:  1024 | lm loss: 1.810964E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35180/   51900 | consumed samples:     36024320 | elapsed time per iteration (ms): 37650.4 | learning rate: 6.543E-05 | global batch size:  1024 | lm loss: 1.818023E+00 | loss scale: 1.0 | grad norm: 0.095 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35181/   51900 | consumed samples:     36025344 | elapsed time per iteration (ms): 37710.5 | learning rate: 6.542E-05 | global batch size:  1024 | lm loss: 1.807773E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35182/   51900 | consumed samples:     36026368 | elapsed time per iteration (ms): 37564.2 | learning rate: 6.542E-05 | global batch size:  1024 | lm loss: 1.836438E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35183/   51900 | consumed samples:     36027392 | elapsed time per iteration (ms): 37729.0 | learning rate: 6.541E-05 | global batch size:  1024 | lm loss: 1.808503E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35184/   51900 | consumed samples:     36028416 | elapsed time per iteration (ms): 37685.6 | learning rate: 6.541E-05 | global batch size:  1024 | lm loss: 1.796514E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35185/   51900 | consumed samples:     36029440 | elapsed time per iteration (ms): 37692.1 | learning rate: 6.540E-05 | global batch size:  1024 | lm loss: 1.800646E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35186/   51900 | consumed samples:     36030464 | elapsed time per iteration (ms): 37713.5 | learning rate: 6.540E-05 | global batch size:  1024 | lm loss: 1.829017E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35187/   51900 | consumed samples:     36031488 | elapsed time per iteration (ms): 37678.8 | learning rate: 6.539E-05 | global batch size:  1024 | lm loss: 1.829947E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35188/   51900 | consumed samples:     36032512 | elapsed time per iteration (ms): 37610.2 | learning rate: 6.539E-05 | global batch size:  1024 | lm loss: 1.827597E+00 | loss scale: 1.0 | grad norm: 0.063 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35189/   51900 | consumed samples:     36033536 | elapsed time per iteration (ms): 37687.8 | learning rate: 6.538E-05 | global batch size:  1024 | lm loss: 1.802580E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35190/   51900 | consumed samples:     36034560 | elapsed time per iteration (ms): 37525.7 | learning rate: 6.538E-05 | global batch size:  1024 | lm loss: 1.814067E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35191/   51900 | consumed samples:     36035584 | elapsed time per iteration (ms): 37662.8 | learning rate: 6.537E-05 | global batch size:  1024 | lm loss: 1.805011E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35192/   51900 | consumed samples:     36036608 | elapsed time per iteration (ms): 37661.1 | learning rate: 6.537E-05 | global batch size:  1024 | lm loss: 1.811948E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35193/   51900 | consumed samples:     36037632 | elapsed time per iteration (ms): 37678.6 | learning rate: 6.536E-05 | global batch size:  1024 | lm loss: 1.811866E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35194/   51900 | consumed samples:     36038656 | elapsed time per iteration (ms): 37637.8 | learning rate: 6.536E-05 | global batch size:  1024 | lm loss: 1.805764E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35195/   51900 | consumed samples:     36039680 | elapsed time per iteration (ms): 37636.8 | learning rate: 6.535E-05 | global batch size:  1024 | lm loss: 1.807156E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35196/   51900 | consumed samples:     36040704 | elapsed time per iteration (ms): 37689.2 | learning rate: 6.535E-05 | global batch size:  1024 | lm loss: 1.805175E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35197/   51900 | consumed samples:     36041728 | elapsed time per iteration (ms): 37639.6 | learning rate: 6.534E-05 | global batch size:  1024 | lm loss: 1.821818E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35198/   51900 | consumed samples:     36042752 | elapsed time per iteration (ms): 37683.9 | learning rate: 6.534E-05 | global batch size:  1024 | lm loss: 1.807356E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35199/   51900 | consumed samples:     36043776 | elapsed time per iteration (ms): 37827.6 | learning rate: 6.533E-05 | global batch size:  1024 | lm loss: 1.798476E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35200/   51900 | consumed samples:     36044800 | elapsed time per iteration (ms): 37756.2 | learning rate: 6.533E-05 | global batch size:  1024 | lm loss: 1.811582E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35201/   51900 | consumed samples:     36045824 | elapsed time per iteration (ms): 37787.3 | learning rate: 6.532E-05 | global batch size:  1024 | lm loss: 1.804597E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35202/   51900 | consumed samples:     36046848 | elapsed time per iteration (ms): 37684.7 | learning rate: 6.532E-05 | global batch size:  1024 | lm loss: 1.801554E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35203/   51900 | consumed samples:     36047872 | elapsed time per iteration (ms): 37619.5 | learning rate: 6.531E-05 | global batch size:  1024 | lm loss: 1.820479E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35204/   51900 | consumed samples:     36048896 | elapsed time per iteration (ms): 37648.9 | learning rate: 6.531E-05 | global batch size:  1024 | lm loss: 1.831783E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35205/   51900 | consumed samples:     36049920 | elapsed time per iteration (ms): 37573.5 | learning rate: 6.530E-05 | global batch size:  1024 | lm loss: 1.823605E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35206/   51900 | consumed samples:     36050944 | elapsed time per iteration (ms): 37674.4 | learning rate: 6.530E-05 | global batch size:  1024 | lm loss: 1.802830E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35207/   51900 | consumed samples:     36051968 | elapsed time per iteration (ms): 37716.1 | learning rate: 6.529E-05 | global batch size:  1024 | lm loss: 1.800088E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35208/   51900 | consumed samples:     36052992 | elapsed time per iteration (ms): 37678.4 | learning rate: 6.529E-05 | global batch size:  1024 | lm loss: 1.822723E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35209/   51900 | consumed samples:     36054016 | elapsed time per iteration (ms): 37687.7 | learning rate: 6.528E-05 | global batch size:  1024 | lm loss: 1.826143E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35210/   51900 | consumed samples:     36055040 | elapsed time per iteration (ms): 37788.6 | learning rate: 6.528E-05 | global batch size:  1024 | lm loss: 1.830755E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35211/   51900 | consumed samples:     36056064 | elapsed time per iteration (ms): 37673.1 | learning rate: 6.527E-05 | global batch size:  1024 | lm loss: 1.799792E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35212/   51900 | consumed samples:     36057088 | elapsed time per iteration (ms): 37687.2 | learning rate: 6.527E-05 | global batch size:  1024 | lm loss: 1.804701E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35213/   51900 | consumed samples:     36058112 | elapsed time per iteration (ms): 37695.5 | learning rate: 6.526E-05 | global batch size:  1024 | lm loss: 1.820002E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35214/   51900 | consumed samples:     36059136 | elapsed time per iteration (ms): 37781.1 | learning rate: 6.526E-05 | global batch size:  1024 | lm loss: 1.808172E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35215/   51900 | consumed samples:     36060160 | elapsed time per iteration (ms): 37687.8 | learning rate: 6.525E-05 | global batch size:  1024 | lm loss: 1.828194E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35216/   51900 | consumed samples:     36061184 | elapsed time per iteration (ms): 37656.8 | learning rate: 6.525E-05 | global batch size:  1024 | lm loss: 1.811249E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35217/   51900 | consumed samples:     36062208 | elapsed time per iteration (ms): 37636.5 | learning rate: 6.524E-05 | global batch size:  1024 | lm loss: 1.805941E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35218/   51900 | consumed samples:     36063232 | elapsed time per iteration (ms): 37580.5 | learning rate: 6.524E-05 | global batch size:  1024 | lm loss: 1.798945E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35219/   51900 | consumed samples:     36064256 | elapsed time per iteration (ms): 37603.9 | learning rate: 6.523E-05 | global batch size:  1024 | lm loss: 1.818824E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35220/   51900 | consumed samples:     36065280 | elapsed time per iteration (ms): 37653.5 | learning rate: 6.523E-05 | global batch size:  1024 | lm loss: 1.824875E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35221/   51900 | consumed samples:     36066304 | elapsed time per iteration (ms): 37586.2 | learning rate: 6.522E-05 | global batch size:  1024 | lm loss: 1.813972E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35222/   51900 | consumed samples:     36067328 | elapsed time per iteration (ms): 37674.5 | learning rate: 6.522E-05 | global batch size:  1024 | lm loss: 1.825657E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35223/   51900 | consumed samples:     36068352 | elapsed time per iteration (ms): 37721.1 | learning rate: 6.521E-05 | global batch size:  1024 | lm loss: 1.824510E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35224/   51900 | consumed samples:     36069376 | elapsed time per iteration (ms): 37638.7 | learning rate: 6.521E-05 | global batch size:  1024 | lm loss: 1.804758E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35225/   51900 | consumed samples:     36070400 | elapsed time per iteration (ms): 37582.0 | learning rate: 6.520E-05 | global batch size:  1024 | lm loss: 1.792668E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35226/   51900 | consumed samples:     36071424 | elapsed time per iteration (ms): 37667.2 | learning rate: 6.520E-05 | global batch size:  1024 | lm loss: 1.801791E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35227/   51900 | consumed samples:     36072448 | elapsed time per iteration (ms): 37747.9 | learning rate: 6.519E-05 | global batch size:  1024 | lm loss: 1.817185E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35228/   51900 | consumed samples:     36073472 | elapsed time per iteration (ms): 37660.4 | learning rate: 6.519E-05 | global batch size:  1024 | lm loss: 1.811032E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35229/   51900 | consumed samples:     36074496 | elapsed time per iteration (ms): 37568.6 | learning rate: 6.518E-05 | global batch size:  1024 | lm loss: 1.826412E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35230/   51900 | consumed samples:     36075520 | elapsed time per iteration (ms): 37742.8 | learning rate: 6.518E-05 | global batch size:  1024 | lm loss: 1.821089E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35231/   51900 | consumed samples:     36076544 | elapsed time per iteration (ms): 37529.9 | learning rate: 6.518E-05 | global batch size:  1024 | lm loss: 1.802369E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35232/   51900 | consumed samples:     36077568 | elapsed time per iteration (ms): 37703.8 | learning rate: 6.517E-05 | global batch size:  1024 | lm loss: 1.819160E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35233/   51900 | consumed samples:     36078592 | elapsed time per iteration (ms): 37635.6 | learning rate: 6.517E-05 | global batch size:  1024 | lm loss: 1.815808E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35234/   51900 | consumed samples:     36079616 | elapsed time per iteration (ms): 37607.0 | learning rate: 6.516E-05 | global batch size:  1024 | lm loss: 1.815665E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35235/   51900 | consumed samples:     36080640 | elapsed time per iteration (ms): 37611.8 | learning rate: 6.516E-05 | global batch size:  1024 | lm loss: 1.802863E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35236/   51900 | consumed samples:     36081664 | elapsed time per iteration (ms): 37654.2 | learning rate: 6.515E-05 | global batch size:  1024 | lm loss: 1.814412E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35237/   51900 | consumed samples:     36082688 | elapsed time per iteration (ms): 37854.8 | learning rate: 6.515E-05 | global batch size:  1024 | lm loss: 1.816979E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35238/   51900 | consumed samples:     36083712 | elapsed time per iteration (ms): 37643.3 | learning rate: 6.514E-05 | global batch size:  1024 | lm loss: 1.805756E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35239/   51900 | consumed samples:     36084736 | elapsed time per iteration (ms): 37630.5 | learning rate: 6.514E-05 | global batch size:  1024 | lm loss: 1.820407E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35240/   51900 | consumed samples:     36085760 | elapsed time per iteration (ms): 37635.7 | learning rate: 6.513E-05 | global batch size:  1024 | lm loss: 1.805160E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35241/   51900 | consumed samples:     36086784 | elapsed time per iteration (ms): 37730.8 | learning rate: 6.513E-05 | global batch size:  1024 | lm loss: 1.824663E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35242/   51900 | consumed samples:     36087808 | elapsed time per iteration (ms): 37553.3 | learning rate: 6.512E-05 | global batch size:  1024 | lm loss: 1.817059E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35243/   51900 | consumed samples:     36088832 | elapsed time per iteration (ms): 37544.5 | learning rate: 6.512E-05 | global batch size:  1024 | lm loss: 1.817791E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35244/   51900 | consumed samples:     36089856 | elapsed time per iteration (ms): 37637.0 | learning rate: 6.511E-05 | global batch size:  1024 | lm loss: 1.824143E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35245/   51900 | consumed samples:     36090880 | elapsed time per iteration (ms): 37881.6 | learning rate: 6.511E-05 | global batch size:  1024 | lm loss: 1.814134E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35246/   51900 | consumed samples:     36091904 | elapsed time per iteration (ms): 37773.6 | learning rate: 6.510E-05 | global batch size:  1024 | lm loss: 1.819705E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35247/   51900 | consumed samples:     36092928 | elapsed time per iteration (ms): 37649.7 | learning rate: 6.510E-05 | global batch size:  1024 | lm loss: 1.824099E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35248/   51900 | consumed samples:     36093952 | elapsed time per iteration (ms): 37635.3 | learning rate: 6.509E-05 | global batch size:  1024 | lm loss: 1.814637E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35249/   51900 | consumed samples:     36094976 | elapsed time per iteration (ms): 37748.1 | learning rate: 6.509E-05 | global batch size:  1024 | lm loss: 1.822595E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35250/   51900 | consumed samples:     36096000 | elapsed time per iteration (ms): 37642.7 | learning rate: 6.508E-05 | global batch size:  1024 | lm loss: 1.822629E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35251/   51900 | consumed samples:     36097024 | elapsed time per iteration (ms): 37648.3 | learning rate: 6.508E-05 | global batch size:  1024 | lm loss: 1.807003E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35252/   51900 | consumed samples:     36098048 | elapsed time per iteration (ms): 37707.9 | learning rate: 6.507E-05 | global batch size:  1024 | lm loss: 1.838856E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35253/   51900 | consumed samples:     36099072 | elapsed time per iteration (ms): 37746.9 | learning rate: 6.507E-05 | global batch size:  1024 | lm loss: 1.796425E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35254/   51900 | consumed samples:     36100096 | elapsed time per iteration (ms): 37618.3 | learning rate: 6.506E-05 | global batch size:  1024 | lm loss: 1.818761E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35255/   51900 | consumed samples:     36101120 | elapsed time per iteration (ms): 37675.1 | learning rate: 6.506E-05 | global batch size:  1024 | lm loss: 1.820078E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35256/   51900 | consumed samples:     36102144 | elapsed time per iteration (ms): 37668.4 | learning rate: 6.505E-05 | global batch size:  1024 | lm loss: 1.811872E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35257/   51900 | consumed samples:     36103168 | elapsed time per iteration (ms): 37593.9 | learning rate: 6.505E-05 | global batch size:  1024 | lm loss: 1.833879E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35258/   51900 | consumed samples:     36104192 | elapsed time per iteration (ms): 37683.6 | learning rate: 6.504E-05 | global batch size:  1024 | lm loss: 1.818184E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35259/   51900 | consumed samples:     36105216 | elapsed time per iteration (ms): 37707.5 | learning rate: 6.504E-05 | global batch size:  1024 | lm loss: 1.810592E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35260/   51900 | consumed samples:     36106240 | elapsed time per iteration (ms): 37771.7 | learning rate: 6.503E-05 | global batch size:  1024 | lm loss: 1.827096E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35261/   51900 | consumed samples:     36107264 | elapsed time per iteration (ms): 37653.4 | learning rate: 6.503E-05 | global batch size:  1024 | lm loss: 1.803170E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35262/   51900 | consumed samples:     36108288 | elapsed time per iteration (ms): 37729.5 | learning rate: 6.502E-05 | global batch size:  1024 | lm loss: 1.795098E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35263/   51900 | consumed samples:     36109312 | elapsed time per iteration (ms): 37662.1 | learning rate: 6.502E-05 | global batch size:  1024 | lm loss: 1.804379E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35264/   51900 | consumed samples:     36110336 | elapsed time per iteration (ms): 37711.0 | learning rate: 6.501E-05 | global batch size:  1024 | lm loss: 1.807633E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35265/   51900 | consumed samples:     36111360 | elapsed time per iteration (ms): 37632.2 | learning rate: 6.501E-05 | global batch size:  1024 | lm loss: 1.801713E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35266/   51900 | consumed samples:     36112384 | elapsed time per iteration (ms): 37672.2 | learning rate: 6.500E-05 | global batch size:  1024 | lm loss: 1.817919E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35267/   51900 | consumed samples:     36113408 | elapsed time per iteration (ms): 37680.9 | learning rate: 6.500E-05 | global batch size:  1024 | lm loss: 1.820573E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35268/   51900 | consumed samples:     36114432 | elapsed time per iteration (ms): 37800.4 | learning rate: 6.499E-05 | global batch size:  1024 | lm loss: 1.804251E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35269/   51900 | consumed samples:     36115456 | elapsed time per iteration (ms): 37723.7 | learning rate: 6.499E-05 | global batch size:  1024 | lm loss: 1.801189E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35270/   51900 | consumed samples:     36116480 | elapsed time per iteration (ms): 37666.0 | learning rate: 6.498E-05 | global batch size:  1024 | lm loss: 1.814556E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35271/   51900 | consumed samples:     36117504 | elapsed time per iteration (ms): 37764.4 | learning rate: 6.498E-05 | global batch size:  1024 | lm loss: 1.819627E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35272/   51900 | consumed samples:     36118528 | elapsed time per iteration (ms): 37706.9 | learning rate: 6.497E-05 | global batch size:  1024 | lm loss: 1.821521E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35273/   51900 | consumed samples:     36119552 | elapsed time per iteration (ms): 37662.6 | learning rate: 6.497E-05 | global batch size:  1024 | lm loss: 1.811044E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35274/   51900 | consumed samples:     36120576 | elapsed time per iteration (ms): 37733.2 | learning rate: 6.496E-05 | global batch size:  1024 | lm loss: 1.804701E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35275/   51900 | consumed samples:     36121600 | elapsed time per iteration (ms): 37652.5 | learning rate: 6.496E-05 | global batch size:  1024 | lm loss: 1.813929E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35276/   51900 | consumed samples:     36122624 | elapsed time per iteration (ms): 37644.8 | learning rate: 6.495E-05 | global batch size:  1024 | lm loss: 1.823407E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35277/   51900 | consumed samples:     36123648 | elapsed time per iteration (ms): 37672.8 | learning rate: 6.495E-05 | global batch size:  1024 | lm loss: 1.809346E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35278/   51900 | consumed samples:     36124672 | elapsed time per iteration (ms): 37675.0 | learning rate: 6.494E-05 | global batch size:  1024 | lm loss: 1.804727E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35279/   51900 | consumed samples:     36125696 | elapsed time per iteration (ms): 37744.1 | learning rate: 6.494E-05 | global batch size:  1024 | lm loss: 1.818179E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35280/   51900 | consumed samples:     36126720 | elapsed time per iteration (ms): 37757.2 | learning rate: 6.493E-05 | global batch size:  1024 | lm loss: 1.805941E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35281/   51900 | consumed samples:     36127744 | elapsed time per iteration (ms): 37757.3 | learning rate: 6.493E-05 | global batch size:  1024 | lm loss: 1.830410E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35282/   51900 | consumed samples:     36128768 | elapsed time per iteration (ms): 37646.4 | learning rate: 6.492E-05 | global batch size:  1024 | lm loss: 1.818959E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35283/   51900 | consumed samples:     36129792 | elapsed time per iteration (ms): 37715.8 | learning rate: 6.492E-05 | global batch size:  1024 | lm loss: 1.803620E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35284/   51900 | consumed samples:     36130816 | elapsed time per iteration (ms): 37684.0 | learning rate: 6.491E-05 | global batch size:  1024 | lm loss: 1.807581E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35285/   51900 | consumed samples:     36131840 | elapsed time per iteration (ms): 37670.1 | learning rate: 6.491E-05 | global batch size:  1024 | lm loss: 1.817523E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35286/   51900 | consumed samples:     36132864 | elapsed time per iteration (ms): 37707.2 | learning rate: 6.491E-05 | global batch size:  1024 | lm loss: 1.808395E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35287/   51900 | consumed samples:     36133888 | elapsed time per iteration (ms): 37762.6 | learning rate: 6.490E-05 | global batch size:  1024 | lm loss: 1.822743E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35288/   51900 | consumed samples:     36134912 | elapsed time per iteration (ms): 37699.9 | learning rate: 6.490E-05 | global batch size:  1024 | lm loss: 1.803867E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35289/   51900 | consumed samples:     36135936 | elapsed time per iteration (ms): 37636.3 | learning rate: 6.489E-05 | global batch size:  1024 | lm loss: 1.816344E+00 | loss scale: 1.0 | grad norm: 0.088 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35290/   51900 | consumed samples:     36136960 | elapsed time per iteration (ms): 37622.0 | learning rate: 6.489E-05 | global batch size:  1024 | lm loss: 1.812982E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35291/   51900 | consumed samples:     36137984 | elapsed time per iteration (ms): 37603.5 | learning rate: 6.488E-05 | global batch size:  1024 | lm loss: 1.820312E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35292/   51900 | consumed samples:     36139008 | elapsed time per iteration (ms): 37594.6 | learning rate: 6.488E-05 | global batch size:  1024 | lm loss: 1.802342E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35293/   51900 | consumed samples:     36140032 | elapsed time per iteration (ms): 37797.3 | learning rate: 6.487E-05 | global batch size:  1024 | lm loss: 1.814067E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35294/   51900 | consumed samples:     36141056 | elapsed time per iteration (ms): 37703.8 | learning rate: 6.487E-05 | global batch size:  1024 | lm loss: 1.816890E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35295/   51900 | consumed samples:     36142080 | elapsed time per iteration (ms): 37620.4 | learning rate: 6.486E-05 | global batch size:  1024 | lm loss: 1.808455E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35296/   51900 | consumed samples:     36143104 | elapsed time per iteration (ms): 37654.7 | learning rate: 6.486E-05 | global batch size:  1024 | lm loss: 1.789312E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35297/   51900 | consumed samples:     36144128 | elapsed time per iteration (ms): 37696.2 | learning rate: 6.485E-05 | global batch size:  1024 | lm loss: 1.819493E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35298/   51900 | consumed samples:     36145152 | elapsed time per iteration (ms): 37651.5 | learning rate: 6.485E-05 | global batch size:  1024 | lm loss: 1.821591E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35299/   51900 | consumed samples:     36146176 | elapsed time per iteration (ms): 37708.5 | learning rate: 6.484E-05 | global batch size:  1024 | lm loss: 1.808578E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35300/   51900 | consumed samples:     36147200 | elapsed time per iteration (ms): 37723.4 | learning rate: 6.484E-05 | global batch size:  1024 | lm loss: 1.805160E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35301/   51900 | consumed samples:     36148224 | elapsed time per iteration (ms): 37755.5 | learning rate: 6.483E-05 | global batch size:  1024 | lm loss: 1.833107E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35302/   51900 | consumed samples:     36149248 | elapsed time per iteration (ms): 37759.6 | learning rate: 6.483E-05 | global batch size:  1024 | lm loss: 1.835366E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35303/   51900 | consumed samples:     36150272 | elapsed time per iteration (ms): 37619.2 | learning rate: 6.482E-05 | global batch size:  1024 | lm loss: 1.796737E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35304/   51900 | consumed samples:     36151296 | elapsed time per iteration (ms): 37628.7 | learning rate: 6.482E-05 | global batch size:  1024 | lm loss: 1.823011E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35305/   51900 | consumed samples:     36152320 | elapsed time per iteration (ms): 37597.3 | learning rate: 6.481E-05 | global batch size:  1024 | lm loss: 1.803497E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35306/   51900 | consumed samples:     36153344 | elapsed time per iteration (ms): 37635.2 | learning rate: 6.481E-05 | global batch size:  1024 | lm loss: 1.808686E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35307/   51900 | consumed samples:     36154368 | elapsed time per iteration (ms): 37587.9 | learning rate: 6.480E-05 | global batch size:  1024 | lm loss: 1.827532E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35308/   51900 | consumed samples:     36155392 | elapsed time per iteration (ms): 37656.1 | learning rate: 6.480E-05 | global batch size:  1024 | lm loss: 1.810679E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35309/   51900 | consumed samples:     36156416 | elapsed time per iteration (ms): 37577.2 | learning rate: 6.479E-05 | global batch size:  1024 | lm loss: 1.807849E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35310/   51900 | consumed samples:     36157440 | elapsed time per iteration (ms): 37655.6 | learning rate: 6.479E-05 | global batch size:  1024 | lm loss: 1.812696E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35311/   51900 | consumed samples:     36158464 | elapsed time per iteration (ms): 37631.1 | learning rate: 6.478E-05 | global batch size:  1024 | lm loss: 1.809162E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35312/   51900 | consumed samples:     36159488 | elapsed time per iteration (ms): 37632.9 | learning rate: 6.478E-05 | global batch size:  1024 | lm loss: 1.812371E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35313/   51900 | consumed samples:     36160512 | elapsed time per iteration (ms): 37678.6 | learning rate: 6.477E-05 | global batch size:  1024 | lm loss: 1.812063E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35314/   51900 | consumed samples:     36161536 | elapsed time per iteration (ms): 37727.2 | learning rate: 6.477E-05 | global batch size:  1024 | lm loss: 1.797463E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35315/   51900 | consumed samples:     36162560 | elapsed time per iteration (ms): 37625.1 | learning rate: 6.476E-05 | global batch size:  1024 | lm loss: 1.814559E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35316/   51900 | consumed samples:     36163584 | elapsed time per iteration (ms): 37632.6 | learning rate: 6.476E-05 | global batch size:  1024 | lm loss: 1.819789E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35317/   51900 | consumed samples:     36164608 | elapsed time per iteration (ms): 37625.7 | learning rate: 6.475E-05 | global batch size:  1024 | lm loss: 1.808019E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35318/   51900 | consumed samples:     36165632 | elapsed time per iteration (ms): 37665.4 | learning rate: 6.475E-05 | global batch size:  1024 | lm loss: 1.838228E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35319/   51900 | consumed samples:     36166656 | elapsed time per iteration (ms): 37760.0 | learning rate: 6.474E-05 | global batch size:  1024 | lm loss: 1.806176E+00 | loss scale: 1.0 | grad norm: 0.065 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35320/   51900 | consumed samples:     36167680 | elapsed time per iteration (ms): 37584.3 | learning rate: 6.474E-05 | global batch size:  1024 | lm loss: 1.812072E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35321/   51900 | consumed samples:     36168704 | elapsed time per iteration (ms): 37749.3 | learning rate: 6.473E-05 | global batch size:  1024 | lm loss: 1.813370E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35322/   51900 | consumed samples:     36169728 | elapsed time per iteration (ms): 37557.8 | learning rate: 6.473E-05 | global batch size:  1024 | lm loss: 1.807854E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35323/   51900 | consumed samples:     36170752 | elapsed time per iteration (ms): 37618.1 | learning rate: 6.472E-05 | global batch size:  1024 | lm loss: 1.809092E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35324/   51900 | consumed samples:     36171776 | elapsed time per iteration (ms): 37737.9 | learning rate: 6.472E-05 | global batch size:  1024 | lm loss: 1.824919E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35325/   51900 | consumed samples:     36172800 | elapsed time per iteration (ms): 37698.7 | learning rate: 6.471E-05 | global batch size:  1024 | lm loss: 1.828475E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35326/   51900 | consumed samples:     36173824 | elapsed time per iteration (ms): 37749.3 | learning rate: 6.471E-05 | global batch size:  1024 | lm loss: 1.814999E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35327/   51900 | consumed samples:     36174848 | elapsed time per iteration (ms): 37684.2 | learning rate: 6.470E-05 | global batch size:  1024 | lm loss: 1.815824E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35328/   51900 | consumed samples:     36175872 | elapsed time per iteration (ms): 37679.7 | learning rate: 6.470E-05 | global batch size:  1024 | lm loss: 1.812716E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35329/   51900 | consumed samples:     36176896 | elapsed time per iteration (ms): 37756.0 | learning rate: 6.469E-05 | global batch size:  1024 | lm loss: 1.819347E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35330/   51900 | consumed samples:     36177920 | elapsed time per iteration (ms): 37594.4 | learning rate: 6.469E-05 | global batch size:  1024 | lm loss: 1.823943E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35331/   51900 | consumed samples:     36178944 | elapsed time per iteration (ms): 37608.2 | learning rate: 6.468E-05 | global batch size:  1024 | lm loss: 1.816199E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35332/   51900 | consumed samples:     36179968 | elapsed time per iteration (ms): 37812.3 | learning rate: 6.468E-05 | global batch size:  1024 | lm loss: 1.800978E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35333/   51900 | consumed samples:     36180992 | elapsed time per iteration (ms): 37710.4 | learning rate: 6.467E-05 | global batch size:  1024 | lm loss: 1.820764E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35334/   51900 | consumed samples:     36182016 | elapsed time per iteration (ms): 37630.4 | learning rate: 6.467E-05 | global batch size:  1024 | lm loss: 1.797813E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35335/   51900 | consumed samples:     36183040 | elapsed time per iteration (ms): 37747.5 | learning rate: 6.467E-05 | global batch size:  1024 | lm loss: 1.813385E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35336/   51900 | consumed samples:     36184064 | elapsed time per iteration (ms): 37767.2 | learning rate: 6.466E-05 | global batch size:  1024 | lm loss: 1.805766E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35337/   51900 | consumed samples:     36185088 | elapsed time per iteration (ms): 37652.5 | learning rate: 6.466E-05 | global batch size:  1024 | lm loss: 1.812041E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35338/   51900 | consumed samples:     36186112 | elapsed time per iteration (ms): 37681.8 | learning rate: 6.465E-05 | global batch size:  1024 | lm loss: 1.824669E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35339/   51900 | consumed samples:     36187136 | elapsed time per iteration (ms): 37689.5 | learning rate: 6.465E-05 | global batch size:  1024 | lm loss: 1.806419E+00 | loss scale: 1.0 | grad norm: 0.112 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35340/   51900 | consumed samples:     36188160 | elapsed time per iteration (ms): 37716.6 | learning rate: 6.464E-05 | global batch size:  1024 | lm loss: 1.816905E+00 | loss scale: 1.0 | grad norm: 0.087 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35341/   51900 | consumed samples:     36189184 | elapsed time per iteration (ms): 37580.8 | learning rate: 6.464E-05 | global batch size:  1024 | lm loss: 1.803482E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35342/   51900 | consumed samples:     36190208 | elapsed time per iteration (ms): 37590.5 | learning rate: 6.463E-05 | global batch size:  1024 | lm loss: 1.790448E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35343/   51900 | consumed samples:     36191232 | elapsed time per iteration (ms): 37608.7 | learning rate: 6.463E-05 | global batch size:  1024 | lm loss: 1.821157E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35344/   51900 | consumed samples:     36192256 | elapsed time per iteration (ms): 37731.8 | learning rate: 6.462E-05 | global batch size:  1024 | lm loss: 1.808935E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35345/   51900 | consumed samples:     36193280 | elapsed time per iteration (ms): 37639.5 | learning rate: 6.462E-05 | global batch size:  1024 | lm loss: 1.800588E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35346/   51900 | consumed samples:     36194304 | elapsed time per iteration (ms): 37771.8 | learning rate: 6.461E-05 | global batch size:  1024 | lm loss: 1.815491E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35347/   51900 | consumed samples:     36195328 | elapsed time per iteration (ms): 37717.3 | learning rate: 6.461E-05 | global batch size:  1024 | lm loss: 1.830009E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35348/   51900 | consumed samples:     36196352 | elapsed time per iteration (ms): 37654.1 | learning rate: 6.460E-05 | global batch size:  1024 | lm loss: 1.814242E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35349/   51900 | consumed samples:     36197376 | elapsed time per iteration (ms): 37716.3 | learning rate: 6.460E-05 | global batch size:  1024 | lm loss: 1.814776E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35350/   51900 | consumed samples:     36198400 | elapsed time per iteration (ms): 37800.4 | learning rate: 6.459E-05 | global batch size:  1024 | lm loss: 1.801917E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35351/   51900 | consumed samples:     36199424 | elapsed time per iteration (ms): 37672.1 | learning rate: 6.459E-05 | global batch size:  1024 | lm loss: 1.810866E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35352/   51900 | consumed samples:     36200448 | elapsed time per iteration (ms): 37718.9 | learning rate: 6.458E-05 | global batch size:  1024 | lm loss: 1.813745E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35353/   51900 | consumed samples:     36201472 | elapsed time per iteration (ms): 37699.6 | learning rate: 6.458E-05 | global batch size:  1024 | lm loss: 1.829312E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35354/   51900 | consumed samples:     36202496 | elapsed time per iteration (ms): 37715.9 | learning rate: 6.457E-05 | global batch size:  1024 | lm loss: 1.825175E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35355/   51900 | consumed samples:     36203520 | elapsed time per iteration (ms): 37645.7 | learning rate: 6.457E-05 | global batch size:  1024 | lm loss: 1.816439E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35356/   51900 | consumed samples:     36204544 | elapsed time per iteration (ms): 37788.4 | learning rate: 6.456E-05 | global batch size:  1024 | lm loss: 1.818302E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35357/   51900 | consumed samples:     36205568 | elapsed time per iteration (ms): 37625.9 | learning rate: 6.456E-05 | global batch size:  1024 | lm loss: 1.822352E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35358/   51900 | consumed samples:     36206592 | elapsed time per iteration (ms): 37605.8 | learning rate: 6.455E-05 | global batch size:  1024 | lm loss: 1.816357E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35359/   51900 | consumed samples:     36207616 | elapsed time per iteration (ms): 37684.9 | learning rate: 6.455E-05 | global batch size:  1024 | lm loss: 1.814741E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35360/   51900 | consumed samples:     36208640 | elapsed time per iteration (ms): 37710.5 | learning rate: 6.454E-05 | global batch size:  1024 | lm loss: 1.817034E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35361/   51900 | consumed samples:     36209664 | elapsed time per iteration (ms): 37718.3 | learning rate: 6.454E-05 | global batch size:  1024 | lm loss: 1.799376E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35362/   51900 | consumed samples:     36210688 | elapsed time per iteration (ms): 37748.1 | learning rate: 6.453E-05 | global batch size:  1024 | lm loss: 1.811317E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35363/   51900 | consumed samples:     36211712 | elapsed time per iteration (ms): 37737.9 | learning rate: 6.453E-05 | global batch size:  1024 | lm loss: 1.804305E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35364/   51900 | consumed samples:     36212736 | elapsed time per iteration (ms): 37691.1 | learning rate: 6.452E-05 | global batch size:  1024 | lm loss: 1.802181E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35365/   51900 | consumed samples:     36213760 | elapsed time per iteration (ms): 37595.2 | learning rate: 6.452E-05 | global batch size:  1024 | lm loss: 1.826878E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35366/   51900 | consumed samples:     36214784 | elapsed time per iteration (ms): 37667.6 | learning rate: 6.451E-05 | global batch size:  1024 | lm loss: 1.815938E+00 | loss scale: 1.0 | grad norm: 0.065 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35367/   51900 | consumed samples:     36215808 | elapsed time per iteration (ms): 37711.6 | learning rate: 6.451E-05 | global batch size:  1024 | lm loss: 1.825949E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35368/   51900 | consumed samples:     36216832 | elapsed time per iteration (ms): 37618.0 | learning rate: 6.450E-05 | global batch size:  1024 | lm loss: 1.823159E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35369/   51900 | consumed samples:     36217856 | elapsed time per iteration (ms): 37619.0 | learning rate: 6.450E-05 | global batch size:  1024 | lm loss: 1.817654E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35370/   51900 | consumed samples:     36218880 | elapsed time per iteration (ms): 37576.4 | learning rate: 6.449E-05 | global batch size:  1024 | lm loss: 1.807003E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35371/   51900 | consumed samples:     36219904 | elapsed time per iteration (ms): 37770.3 | learning rate: 6.449E-05 | global batch size:  1024 | lm loss: 1.815005E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35372/   51900 | consumed samples:     36220928 | elapsed time per iteration (ms): 37697.7 | learning rate: 6.448E-05 | global batch size:  1024 | lm loss: 1.810912E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35373/   51900 | consumed samples:     36221952 | elapsed time per iteration (ms): 37742.2 | learning rate: 6.448E-05 | global batch size:  1024 | lm loss: 1.820900E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35374/   51900 | consumed samples:     36222976 | elapsed time per iteration (ms): 37642.1 | learning rate: 6.447E-05 | global batch size:  1024 | lm loss: 1.804849E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35375/   51900 | consumed samples:     36224000 | elapsed time per iteration (ms): 37598.0 | learning rate: 6.447E-05 | global batch size:  1024 | lm loss: 1.815299E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35376/   51900 | consumed samples:     36225024 | elapsed time per iteration (ms): 37734.8 | learning rate: 6.446E-05 | global batch size:  1024 | lm loss: 1.813193E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35377/   51900 | consumed samples:     36226048 | elapsed time per iteration (ms): 37685.9 | learning rate: 6.446E-05 | global batch size:  1024 | lm loss: 1.813985E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35378/   51900 | consumed samples:     36227072 | elapsed time per iteration (ms): 37706.3 | learning rate: 6.445E-05 | global batch size:  1024 | lm loss: 1.823419E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35379/   51900 | consumed samples:     36228096 | elapsed time per iteration (ms): 37665.5 | learning rate: 6.445E-05 | global batch size:  1024 | lm loss: 1.828879E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35380/   51900 | consumed samples:     36229120 | elapsed time per iteration (ms): 37711.7 | learning rate: 6.445E-05 | global batch size:  1024 | lm loss: 1.818752E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35381/   51900 | consumed samples:     36230144 | elapsed time per iteration (ms): 37709.4 | learning rate: 6.444E-05 | global batch size:  1024 | lm loss: 1.801136E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35382/   51900 | consumed samples:     36231168 | elapsed time per iteration (ms): 37727.4 | learning rate: 6.444E-05 | global batch size:  1024 | lm loss: 1.813036E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35383/   51900 | consumed samples:     36232192 | elapsed time per iteration (ms): 37746.4 | learning rate: 6.443E-05 | global batch size:  1024 | lm loss: 1.811929E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35384/   51900 | consumed samples:     36233216 | elapsed time per iteration (ms): 37627.8 | learning rate: 6.443E-05 | global batch size:  1024 | lm loss: 1.821029E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35385/   51900 | consumed samples:     36234240 | elapsed time per iteration (ms): 37888.5 | learning rate: 6.442E-05 | global batch size:  1024 | lm loss: 1.838617E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35386/   51900 | consumed samples:     36235264 | elapsed time per iteration (ms): 37682.0 | learning rate: 6.442E-05 | global batch size:  1024 | lm loss: 1.795208E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35387/   51900 | consumed samples:     36236288 | elapsed time per iteration (ms): 37610.2 | learning rate: 6.441E-05 | global batch size:  1024 | lm loss: 1.833864E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35388/   51900 | consumed samples:     36237312 | elapsed time per iteration (ms): 37724.3 | learning rate: 6.441E-05 | global batch size:  1024 | lm loss: 1.818415E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35389/   51900 | consumed samples:     36238336 | elapsed time per iteration (ms): 37607.5 | learning rate: 6.440E-05 | global batch size:  1024 | lm loss: 1.801775E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35390/   51900 | consumed samples:     36239360 | elapsed time per iteration (ms): 37570.6 | learning rate: 6.440E-05 | global batch size:  1024 | lm loss: 1.831583E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35391/   51900 | consumed samples:     36240384 | elapsed time per iteration (ms): 37582.4 | learning rate: 6.439E-05 | global batch size:  1024 | lm loss: 1.807386E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35392/   51900 | consumed samples:     36241408 | elapsed time per iteration (ms): 37677.4 | learning rate: 6.439E-05 | global batch size:  1024 | lm loss: 1.798098E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35393/   51900 | consumed samples:     36242432 | elapsed time per iteration (ms): 37705.5 | learning rate: 6.438E-05 | global batch size:  1024 | lm loss: 1.801681E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35394/   51900 | consumed samples:     36243456 | elapsed time per iteration (ms): 37705.5 | learning rate: 6.438E-05 | global batch size:  1024 | lm loss: 1.819614E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35395/   51900 | consumed samples:     36244480 | elapsed time per iteration (ms): 37685.5 | learning rate: 6.437E-05 | global batch size:  1024 | lm loss: 1.817250E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35396/   51900 | consumed samples:     36245504 | elapsed time per iteration (ms): 37763.2 | learning rate: 6.437E-05 | global batch size:  1024 | lm loss: 1.829829E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35397/   51900 | consumed samples:     36246528 | elapsed time per iteration (ms): 37756.1 | learning rate: 6.436E-05 | global batch size:  1024 | lm loss: 1.798014E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35398/   51900 | consumed samples:     36247552 | elapsed time per iteration (ms): 37581.2 | learning rate: 6.436E-05 | global batch size:  1024 | lm loss: 1.799281E+00 | loss scale: 1.0 | grad norm: 0.087 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35399/   51900 | consumed samples:     36248576 | elapsed time per iteration (ms): 37636.1 | learning rate: 6.435E-05 | global batch size:  1024 | lm loss: 1.815761E+00 | loss scale: 1.0 | grad norm: 0.090 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35400/   51900 | consumed samples:     36249600 | elapsed time per iteration (ms): 37717.7 | learning rate: 6.435E-05 | global batch size:  1024 | lm loss: 1.798923E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35401/   51900 | consumed samples:     36250624 | elapsed time per iteration (ms): 37754.1 | learning rate: 6.434E-05 | global batch size:  1024 | lm loss: 1.831826E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35402/   51900 | consumed samples:     36251648 | elapsed time per iteration (ms): 37785.1 | learning rate: 6.434E-05 | global batch size:  1024 | lm loss: 1.820057E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35403/   51900 | consumed samples:     36252672 | elapsed time per iteration (ms): 37573.6 | learning rate: 6.433E-05 | global batch size:  1024 | lm loss: 1.809252E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35404/   51900 | consumed samples:     36253696 | elapsed time per iteration (ms): 37636.3 | learning rate: 6.433E-05 | global batch size:  1024 | lm loss: 1.802076E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35405/   51900 | consumed samples:     36254720 | elapsed time per iteration (ms): 37674.7 | learning rate: 6.432E-05 | global batch size:  1024 | lm loss: 1.805433E+00 | loss scale: 1.0 | grad norm: 0.087 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35406/   51900 | consumed samples:     36255744 | elapsed time per iteration (ms): 37808.7 | learning rate: 6.432E-05 | global batch size:  1024 | lm loss: 1.817085E+00 | loss scale: 1.0 | grad norm: 0.090 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35407/   51900 | consumed samples:     36256768 | elapsed time per iteration (ms): 37693.6 | learning rate: 6.431E-05 | global batch size:  1024 | lm loss: 1.802562E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35408/   51900 | consumed samples:     36257792 | elapsed time per iteration (ms): 37710.7 | learning rate: 6.431E-05 | global batch size:  1024 | lm loss: 1.793492E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35409/   51900 | consumed samples:     36258816 | elapsed time per iteration (ms): 37641.9 | learning rate: 6.430E-05 | global batch size:  1024 | lm loss: 1.811981E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35410/   51900 | consumed samples:     36259840 | elapsed time per iteration (ms): 37672.9 | learning rate: 6.430E-05 | global batch size:  1024 | lm loss: 1.795566E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35411/   51900 | consumed samples:     36260864 | elapsed time per iteration (ms): 37577.1 | learning rate: 6.429E-05 | global batch size:  1024 | lm loss: 1.812320E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35412/   51900 | consumed samples:     36261888 | elapsed time per iteration (ms): 37688.3 | learning rate: 6.429E-05 | global batch size:  1024 | lm loss: 1.806048E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35413/   51900 | consumed samples:     36262912 | elapsed time per iteration (ms): 37810.3 | learning rate: 6.428E-05 | global batch size:  1024 | lm loss: 1.801013E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35414/   51900 | consumed samples:     36263936 | elapsed time per iteration (ms): 37689.3 | learning rate: 6.428E-05 | global batch size:  1024 | lm loss: 1.821097E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35415/   51900 | consumed samples:     36264960 | elapsed time per iteration (ms): 37789.0 | learning rate: 6.427E-05 | global batch size:  1024 | lm loss: 1.805070E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35416/   51900 | consumed samples:     36265984 | elapsed time per iteration (ms): 37638.0 | learning rate: 6.427E-05 | global batch size:  1024 | lm loss: 1.810872E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35417/   51900 | consumed samples:     36267008 | elapsed time per iteration (ms): 37609.4 | learning rate: 6.426E-05 | global batch size:  1024 | lm loss: 1.805179E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35418/   51900 | consumed samples:     36268032 | elapsed time per iteration (ms): 37645.5 | learning rate: 6.426E-05 | global batch size:  1024 | lm loss: 1.811935E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35419/   51900 | consumed samples:     36269056 | elapsed time per iteration (ms): 37669.2 | learning rate: 6.425E-05 | global batch size:  1024 | lm loss: 1.829601E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35420/   51900 | consumed samples:     36270080 | elapsed time per iteration (ms): 37730.1 | learning rate: 6.425E-05 | global batch size:  1024 | lm loss: 1.799299E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35421/   51900 | consumed samples:     36271104 | elapsed time per iteration (ms): 37617.7 | learning rate: 6.424E-05 | global batch size:  1024 | lm loss: 1.829535E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35422/   51900 | consumed samples:     36272128 | elapsed time per iteration (ms): 37697.3 | learning rate: 6.424E-05 | global batch size:  1024 | lm loss: 1.804597E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35423/   51900 | consumed samples:     36273152 | elapsed time per iteration (ms): 37560.2 | learning rate: 6.424E-05 | global batch size:  1024 | lm loss: 1.813559E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35424/   51900 | consumed samples:     36274176 | elapsed time per iteration (ms): 37709.8 | learning rate: 6.423E-05 | global batch size:  1024 | lm loss: 1.802163E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35425/   51900 | consumed samples:     36275200 | elapsed time per iteration (ms): 37706.7 | learning rate: 6.423E-05 | global batch size:  1024 | lm loss: 1.811743E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35426/   51900 | consumed samples:     36276224 | elapsed time per iteration (ms): 37758.2 | learning rate: 6.422E-05 | global batch size:  1024 | lm loss: 1.813665E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35427/   51900 | consumed samples:     36277248 | elapsed time per iteration (ms): 37833.5 | learning rate: 6.422E-05 | global batch size:  1024 | lm loss: 1.824466E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35428/   51900 | consumed samples:     36278272 | elapsed time per iteration (ms): 37785.6 | learning rate: 6.421E-05 | global batch size:  1024 | lm loss: 1.808621E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35429/   51900 | consumed samples:     36279296 | elapsed time per iteration (ms): 37729.1 | learning rate: 6.421E-05 | global batch size:  1024 | lm loss: 1.816259E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35430/   51900 | consumed samples:     36280320 | elapsed time per iteration (ms): 37570.0 | learning rate: 6.420E-05 | global batch size:  1024 | lm loss: 1.810786E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35431/   51900 | consumed samples:     36281344 | elapsed time per iteration (ms): 37740.5 | learning rate: 6.420E-05 | global batch size:  1024 | lm loss: 1.807770E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35432/   51900 | consumed samples:     36282368 | elapsed time per iteration (ms): 37674.7 | learning rate: 6.419E-05 | global batch size:  1024 | lm loss: 1.815639E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35433/   51900 | consumed samples:     36283392 | elapsed time per iteration (ms): 37740.7 | learning rate: 6.419E-05 | global batch size:  1024 | lm loss: 1.803391E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35434/   51900 | consumed samples:     36284416 | elapsed time per iteration (ms): 37582.4 | learning rate: 6.418E-05 | global batch size:  1024 | lm loss: 1.801832E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35435/   51900 | consumed samples:     36285440 | elapsed time per iteration (ms): 37676.0 | learning rate: 6.418E-05 | global batch size:  1024 | lm loss: 1.789527E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35436/   51900 | consumed samples:     36286464 | elapsed time per iteration (ms): 37655.3 | learning rate: 6.417E-05 | global batch size:  1024 | lm loss: 1.821535E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35437/   51900 | consumed samples:     36287488 | elapsed time per iteration (ms): 37677.5 | learning rate: 6.417E-05 | global batch size:  1024 | lm loss: 1.799305E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35438/   51900 | consumed samples:     36288512 | elapsed time per iteration (ms): 37597.1 | learning rate: 6.416E-05 | global batch size:  1024 | lm loss: 1.809147E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35439/   51900 | consumed samples:     36289536 | elapsed time per iteration (ms): 37802.9 | learning rate: 6.416E-05 | global batch size:  1024 | lm loss: 1.797473E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35440/   51900 | consumed samples:     36290560 | elapsed time per iteration (ms): 37540.4 | learning rate: 6.415E-05 | global batch size:  1024 | lm loss: 1.809788E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35441/   51900 | consumed samples:     36291584 | elapsed time per iteration (ms): 37740.0 | learning rate: 6.415E-05 | global batch size:  1024 | lm loss: 1.808413E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35442/   51900 | consumed samples:     36292608 | elapsed time per iteration (ms): 37675.5 | learning rate: 6.414E-05 | global batch size:  1024 | lm loss: 1.827523E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35443/   51900 | consumed samples:     36293632 | elapsed time per iteration (ms): 37688.4 | learning rate: 6.414E-05 | global batch size:  1024 | lm loss: 1.798084E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35444/   51900 | consumed samples:     36294656 | elapsed time per iteration (ms): 37881.6 | learning rate: 6.413E-05 | global batch size:  1024 | lm loss: 1.801751E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35445/   51900 | consumed samples:     36295680 | elapsed time per iteration (ms): 37735.2 | learning rate: 6.413E-05 | global batch size:  1024 | lm loss: 1.809975E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35446/   51900 | consumed samples:     36296704 | elapsed time per iteration (ms): 37640.8 | learning rate: 6.412E-05 | global batch size:  1024 | lm loss: 1.808689E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35447/   51900 | consumed samples:     36297728 | elapsed time per iteration (ms): 37675.4 | learning rate: 6.412E-05 | global batch size:  1024 | lm loss: 1.802910E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35448/   51900 | consumed samples:     36298752 | elapsed time per iteration (ms): 37579.6 | learning rate: 6.411E-05 | global batch size:  1024 | lm loss: 1.812193E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35449/   51900 | consumed samples:     36299776 | elapsed time per iteration (ms): 37580.7 | learning rate: 6.411E-05 | global batch size:  1024 | lm loss: 1.788703E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35450/   51900 | consumed samples:     36300800 | elapsed time per iteration (ms): 37756.3 | learning rate: 6.410E-05 | global batch size:  1024 | lm loss: 1.812977E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35451/   51900 | consumed samples:     36301824 | elapsed time per iteration (ms): 37717.3 | learning rate: 6.410E-05 | global batch size:  1024 | lm loss: 1.799978E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35452/   51900 | consumed samples:     36302848 | elapsed time per iteration (ms): 37696.9 | learning rate: 6.409E-05 | global batch size:  1024 | lm loss: 1.807764E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35453/   51900 | consumed samples:     36303872 | elapsed time per iteration (ms): 37629.1 | learning rate: 6.409E-05 | global batch size:  1024 | lm loss: 1.806982E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35454/   51900 | consumed samples:     36304896 | elapsed time per iteration (ms): 37674.3 | learning rate: 6.408E-05 | global batch size:  1024 | lm loss: 1.807542E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35455/   51900 | consumed samples:     36305920 | elapsed time per iteration (ms): 37744.7 | learning rate: 6.408E-05 | global batch size:  1024 | lm loss: 1.835463E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35456/   51900 | consumed samples:     36306944 | elapsed time per iteration (ms): 37623.0 | learning rate: 6.407E-05 | global batch size:  1024 | lm loss: 1.819002E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35457/   51900 | consumed samples:     36307968 | elapsed time per iteration (ms): 37569.2 | learning rate: 6.407E-05 | global batch size:  1024 | lm loss: 1.796923E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35458/   51900 | consumed samples:     36308992 | elapsed time per iteration (ms): 37558.0 | learning rate: 6.406E-05 | global batch size:  1024 | lm loss: 1.809262E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35459/   51900 | consumed samples:     36310016 | elapsed time per iteration (ms): 37640.7 | learning rate: 6.406E-05 | global batch size:  1024 | lm loss: 1.810766E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35460/   51900 | consumed samples:     36311040 | elapsed time per iteration (ms): 37645.0 | learning rate: 6.405E-05 | global batch size:  1024 | lm loss: 1.807133E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35461/   51900 | consumed samples:     36312064 | elapsed time per iteration (ms): 37739.5 | learning rate: 6.405E-05 | global batch size:  1024 | lm loss: 1.812356E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35462/   51900 | consumed samples:     36313088 | elapsed time per iteration (ms): 37589.1 | learning rate: 6.404E-05 | global batch size:  1024 | lm loss: 1.796793E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35463/   51900 | consumed samples:     36314112 | elapsed time per iteration (ms): 37634.6 | learning rate: 6.404E-05 | global batch size:  1024 | lm loss: 1.824618E+00 | loss scale: 1.0 | grad norm: 0.142 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35464/   51900 | consumed samples:     36315136 | elapsed time per iteration (ms): 37624.7 | learning rate: 6.404E-05 | global batch size:  1024 | lm loss: 1.824190E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35465/   51900 | consumed samples:     36316160 | elapsed time per iteration (ms): 37607.2 | learning rate: 6.403E-05 | global batch size:  1024 | lm loss: 1.811794E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35466/   51900 | consumed samples:     36317184 | elapsed time per iteration (ms): 37639.3 | learning rate: 6.403E-05 | global batch size:  1024 | lm loss: 1.812442E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35467/   51900 | consumed samples:     36318208 | elapsed time per iteration (ms): 37626.5 | learning rate: 6.402E-05 | global batch size:  1024 | lm loss: 1.816989E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35468/   51900 | consumed samples:     36319232 | elapsed time per iteration (ms): 37653.3 | learning rate: 6.402E-05 | global batch size:  1024 | lm loss: 1.821893E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35469/   51900 | consumed samples:     36320256 | elapsed time per iteration (ms): 37708.3 | learning rate: 6.401E-05 | global batch size:  1024 | lm loss: 1.833306E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35470/   51900 | consumed samples:     36321280 | elapsed time per iteration (ms): 37666.7 | learning rate: 6.401E-05 | global batch size:  1024 | lm loss: 1.810866E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35471/   51900 | consumed samples:     36322304 | elapsed time per iteration (ms): 37611.4 | learning rate: 6.400E-05 | global batch size:  1024 | lm loss: 1.813162E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35472/   51900 | consumed samples:     36323328 | elapsed time per iteration (ms): 37744.6 | learning rate: 6.400E-05 | global batch size:  1024 | lm loss: 1.814389E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35473/   51900 | consumed samples:     36324352 | elapsed time per iteration (ms): 37700.8 | learning rate: 6.399E-05 | global batch size:  1024 | lm loss: 1.829925E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35474/   51900 | consumed samples:     36325376 | elapsed time per iteration (ms): 37630.9 | learning rate: 6.399E-05 | global batch size:  1024 | lm loss: 1.813716E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35475/   51900 | consumed samples:     36326400 | elapsed time per iteration (ms): 37640.1 | learning rate: 6.398E-05 | global batch size:  1024 | lm loss: 1.813960E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35476/   51900 | consumed samples:     36327424 | elapsed time per iteration (ms): 37680.5 | learning rate: 6.398E-05 | global batch size:  1024 | lm loss: 1.811668E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35477/   51900 | consumed samples:     36328448 | elapsed time per iteration (ms): 37681.4 | learning rate: 6.397E-05 | global batch size:  1024 | lm loss: 1.806877E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35478/   51900 | consumed samples:     36329472 | elapsed time per iteration (ms): 37643.8 | learning rate: 6.397E-05 | global batch size:  1024 | lm loss: 1.815128E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35479/   51900 | consumed samples:     36330496 | elapsed time per iteration (ms): 37661.8 | learning rate: 6.396E-05 | global batch size:  1024 | lm loss: 1.796860E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35480/   51900 | consumed samples:     36331520 | elapsed time per iteration (ms): 37594.1 | learning rate: 6.396E-05 | global batch size:  1024 | lm loss: 1.815254E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35481/   51900 | consumed samples:     36332544 | elapsed time per iteration (ms): 37653.4 | learning rate: 6.395E-05 | global batch size:  1024 | lm loss: 1.810305E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35482/   51900 | consumed samples:     36333568 | elapsed time per iteration (ms): 37598.3 | learning rate: 6.395E-05 | global batch size:  1024 | lm loss: 1.806413E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35483/   51900 | consumed samples:     36334592 | elapsed time per iteration (ms): 37704.3 | learning rate: 6.394E-05 | global batch size:  1024 | lm loss: 1.805455E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35484/   51900 | consumed samples:     36335616 | elapsed time per iteration (ms): 37561.3 | learning rate: 6.394E-05 | global batch size:  1024 | lm loss: 1.812413E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35485/   51900 | consumed samples:     36336640 | elapsed time per iteration (ms): 37722.1 | learning rate: 6.393E-05 | global batch size:  1024 | lm loss: 1.810201E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35486/   51900 | consumed samples:     36337664 | elapsed time per iteration (ms): 37762.9 | learning rate: 6.393E-05 | global batch size:  1024 | lm loss: 1.811375E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35487/   51900 | consumed samples:     36338688 | elapsed time per iteration (ms): 37761.3 | learning rate: 6.392E-05 | global batch size:  1024 | lm loss: 1.803972E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35488/   51900 | consumed samples:     36339712 | elapsed time per iteration (ms): 37605.8 | learning rate: 6.392E-05 | global batch size:  1024 | lm loss: 1.819706E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35489/   51900 | consumed samples:     36340736 | elapsed time per iteration (ms): 37688.4 | learning rate: 6.391E-05 | global batch size:  1024 | lm loss: 1.821510E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35490/   51900 | consumed samples:     36341760 | elapsed time per iteration (ms): 37652.5 | learning rate: 6.391E-05 | global batch size:  1024 | lm loss: 1.807101E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35491/   51900 | consumed samples:     36342784 | elapsed time per iteration (ms): 37717.4 | learning rate: 6.390E-05 | global batch size:  1024 | lm loss: 1.827187E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35492/   51900 | consumed samples:     36343808 | elapsed time per iteration (ms): 37714.3 | learning rate: 6.390E-05 | global batch size:  1024 | lm loss: 1.805918E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35493/   51900 | consumed samples:     36344832 | elapsed time per iteration (ms): 37681.4 | learning rate: 6.389E-05 | global batch size:  1024 | lm loss: 1.836673E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35494/   51900 | consumed samples:     36345856 | elapsed time per iteration (ms): 37759.9 | learning rate: 6.389E-05 | global batch size:  1024 | lm loss: 1.811522E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35495/   51900 | consumed samples:     36346880 | elapsed time per iteration (ms): 37766.4 | learning rate: 6.388E-05 | global batch size:  1024 | lm loss: 1.794588E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35496/   51900 | consumed samples:     36347904 | elapsed time per iteration (ms): 37691.1 | learning rate: 6.388E-05 | global batch size:  1024 | lm loss: 1.814797E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35497/   51900 | consumed samples:     36348928 | elapsed time per iteration (ms): 37738.3 | learning rate: 6.387E-05 | global batch size:  1024 | lm loss: 1.824305E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35498/   51900 | consumed samples:     36349952 | elapsed time per iteration (ms): 37654.3 | learning rate: 6.387E-05 | global batch size:  1024 | lm loss: 1.826714E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35499/   51900 | consumed samples:     36350976 | elapsed time per iteration (ms): 37703.2 | learning rate: 6.386E-05 | global batch size:  1024 | lm loss: 1.803619E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35500/   51900 | consumed samples:     36352000 | elapsed time per iteration (ms): 37648.2 | learning rate: 6.386E-05 | global batch size:  1024 | lm loss: 1.811735E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    save-checkpoint ................................: (133861.92, 133861.98)
 iteration    35501/   51900 | consumed samples:     36353024 | elapsed time per iteration (ms): 37303.6 | learning rate: 6.386E-05 | global batch size:  1024 | lm loss: 1.824862E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35502/   51900 | consumed samples:     36354048 | elapsed time per iteration (ms): 37725.0 | learning rate: 6.385E-05 | global batch size:  1024 | lm loss: 1.808345E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35503/   51900 | consumed samples:     36355072 | elapsed time per iteration (ms): 37724.6 | learning rate: 6.385E-05 | global batch size:  1024 | lm loss: 1.808480E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35504/   51900 | consumed samples:     36356096 | elapsed time per iteration (ms): 37647.7 | learning rate: 6.384E-05 | global batch size:  1024 | lm loss: 1.808344E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35505/   51900 | consumed samples:     36357120 | elapsed time per iteration (ms): 37632.2 | learning rate: 6.384E-05 | global batch size:  1024 | lm loss: 1.811902E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35506/   51900 | consumed samples:     36358144 | elapsed time per iteration (ms): 37681.3 | learning rate: 6.383E-05 | global batch size:  1024 | lm loss: 1.793500E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35507/   51900 | consumed samples:     36359168 | elapsed time per iteration (ms): 37700.6 | learning rate: 6.383E-05 | global batch size:  1024 | lm loss: 1.823796E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35508/   51900 | consumed samples:     36360192 | elapsed time per iteration (ms): 37576.2 | learning rate: 6.382E-05 | global batch size:  1024 | lm loss: 1.811704E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35509/   51900 | consumed samples:     36361216 | elapsed time per iteration (ms): 37717.3 | learning rate: 6.382E-05 | global batch size:  1024 | lm loss: 1.823766E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35510/   51900 | consumed samples:     36362240 | elapsed time per iteration (ms): 37590.6 | learning rate: 6.381E-05 | global batch size:  1024 | lm loss: 1.814532E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35511/   51900 | consumed samples:     36363264 | elapsed time per iteration (ms): 37745.6 | learning rate: 6.381E-05 | global batch size:  1024 | lm loss: 1.816759E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35512/   51900 | consumed samples:     36364288 | elapsed time per iteration (ms): 37658.5 | learning rate: 6.380E-05 | global batch size:  1024 | lm loss: 1.820389E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35513/   51900 | consumed samples:     36365312 | elapsed time per iteration (ms): 37657.5 | learning rate: 6.380E-05 | global batch size:  1024 | lm loss: 1.815105E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35514/   51900 | consumed samples:     36366336 | elapsed time per iteration (ms): 37682.0 | learning rate: 6.379E-05 | global batch size:  1024 | lm loss: 1.813360E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35515/   51900 | consumed samples:     36367360 | elapsed time per iteration (ms): 37672.1 | learning rate: 6.379E-05 | global batch size:  1024 | lm loss: 1.815590E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35516/   51900 | consumed samples:     36368384 | elapsed time per iteration (ms): 37672.4 | learning rate: 6.378E-05 | global batch size:  1024 | lm loss: 1.806499E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35517/   51900 | consumed samples:     36369408 | elapsed time per iteration (ms): 37669.8 | learning rate: 6.378E-05 | global batch size:  1024 | lm loss: 1.803625E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35518/   51900 | consumed samples:     36370432 | elapsed time per iteration (ms): 37629.2 | learning rate: 6.377E-05 | global batch size:  1024 | lm loss: 1.800879E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35519/   51900 | consumed samples:     36371456 | elapsed time per iteration (ms): 37779.5 | learning rate: 6.377E-05 | global batch size:  1024 | lm loss: 1.804232E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35520/   51900 | consumed samples:     36372480 | elapsed time per iteration (ms): 37726.8 | learning rate: 6.376E-05 | global batch size:  1024 | lm loss: 1.787310E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35521/   51900 | consumed samples:     36373504 | elapsed time per iteration (ms): 37694.4 | learning rate: 6.376E-05 | global batch size:  1024 | lm loss: 1.786993E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35522/   51900 | consumed samples:     36374528 | elapsed time per iteration (ms): 37759.5 | learning rate: 6.375E-05 | global batch size:  1024 | lm loss: 1.805872E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35523/   51900 | consumed samples:     36375552 | elapsed time per iteration (ms): 37850.6 | learning rate: 6.375E-05 | global batch size:  1024 | lm loss: 1.815412E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35524/   51900 | consumed samples:     36376576 | elapsed time per iteration (ms): 37675.8 | learning rate: 6.374E-05 | global batch size:  1024 | lm loss: 1.798828E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35525/   51900 | consumed samples:     36377600 | elapsed time per iteration (ms): 37743.0 | learning rate: 6.374E-05 | global batch size:  1024 | lm loss: 1.812703E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35526/   51900 | consumed samples:     36378624 | elapsed time per iteration (ms): 37660.1 | learning rate: 6.373E-05 | global batch size:  1024 | lm loss: 1.812394E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35527/   51900 | consumed samples:     36379648 | elapsed time per iteration (ms): 37698.3 | learning rate: 6.373E-05 | global batch size:  1024 | lm loss: 1.800922E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35528/   51900 | consumed samples:     36380672 | elapsed time per iteration (ms): 37733.6 | learning rate: 6.372E-05 | global batch size:  1024 | lm loss: 1.794465E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35529/   51900 | consumed samples:     36381696 | elapsed time per iteration (ms): 37672.0 | learning rate: 6.372E-05 | global batch size:  1024 | lm loss: 1.819203E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35530/   51900 | consumed samples:     36382720 | elapsed time per iteration (ms): 37678.6 | learning rate: 6.371E-05 | global batch size:  1024 | lm loss: 1.818076E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35531/   51900 | consumed samples:     36383744 | elapsed time per iteration (ms): 37655.5 | learning rate: 6.371E-05 | global batch size:  1024 | lm loss: 1.814215E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35532/   51900 | consumed samples:     36384768 | elapsed time per iteration (ms): 37650.7 | learning rate: 6.370E-05 | global batch size:  1024 | lm loss: 1.817341E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35533/   51900 | consumed samples:     36385792 | elapsed time per iteration (ms): 37684.3 | learning rate: 6.370E-05 | global batch size:  1024 | lm loss: 1.814598E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35534/   51900 | consumed samples:     36386816 | elapsed time per iteration (ms): 37574.3 | learning rate: 6.369E-05 | global batch size:  1024 | lm loss: 1.804853E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35535/   51900 | consumed samples:     36387840 | elapsed time per iteration (ms): 37638.9 | learning rate: 6.369E-05 | global batch size:  1024 | lm loss: 1.805453E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35536/   51900 | consumed samples:     36388864 | elapsed time per iteration (ms): 37538.1 | learning rate: 6.368E-05 | global batch size:  1024 | lm loss: 1.804439E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35537/   51900 | consumed samples:     36389888 | elapsed time per iteration (ms): 37650.2 | learning rate: 6.368E-05 | global batch size:  1024 | lm loss: 1.812172E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35538/   51900 | consumed samples:     36390912 | elapsed time per iteration (ms): 37686.9 | learning rate: 6.368E-05 | global batch size:  1024 | lm loss: 1.799352E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35539/   51900 | consumed samples:     36391936 | elapsed time per iteration (ms): 37767.6 | learning rate: 6.367E-05 | global batch size:  1024 | lm loss: 1.820708E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35540/   51900 | consumed samples:     36392960 | elapsed time per iteration (ms): 37676.8 | learning rate: 6.367E-05 | global batch size:  1024 | lm loss: 1.803783E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35541/   51900 | consumed samples:     36393984 | elapsed time per iteration (ms): 37617.7 | learning rate: 6.366E-05 | global batch size:  1024 | lm loss: 1.810549E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35542/   51900 | consumed samples:     36395008 | elapsed time per iteration (ms): 37576.3 | learning rate: 6.366E-05 | global batch size:  1024 | lm loss: 1.815043E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35543/   51900 | consumed samples:     36396032 | elapsed time per iteration (ms): 37606.0 | learning rate: 6.365E-05 | global batch size:  1024 | lm loss: 1.818990E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35544/   51900 | consumed samples:     36397056 | elapsed time per iteration (ms): 37546.4 | learning rate: 6.365E-05 | global batch size:  1024 | lm loss: 1.813531E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35545/   51900 | consumed samples:     36398080 | elapsed time per iteration (ms): 37640.7 | learning rate: 6.364E-05 | global batch size:  1024 | lm loss: 1.809066E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35546/   51900 | consumed samples:     36399104 | elapsed time per iteration (ms): 37655.2 | learning rate: 6.364E-05 | global batch size:  1024 | lm loss: 1.825647E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35547/   51900 | consumed samples:     36400128 | elapsed time per iteration (ms): 37705.3 | learning rate: 6.363E-05 | global batch size:  1024 | lm loss: 1.813677E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35548/   51900 | consumed samples:     36401152 | elapsed time per iteration (ms): 37647.4 | learning rate: 6.363E-05 | global batch size:  1024 | lm loss: 1.809107E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35549/   51900 | consumed samples:     36402176 | elapsed time per iteration (ms): 37590.9 | learning rate: 6.362E-05 | global batch size:  1024 | lm loss: 1.789246E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35550/   51900 | consumed samples:     36403200 | elapsed time per iteration (ms): 37809.2 | learning rate: 6.362E-05 | global batch size:  1024 | lm loss: 1.818846E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35551/   51900 | consumed samples:     36404224 | elapsed time per iteration (ms): 37582.5 | learning rate: 6.361E-05 | global batch size:  1024 | lm loss: 1.816225E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35552/   51900 | consumed samples:     36405248 | elapsed time per iteration (ms): 37611.0 | learning rate: 6.361E-05 | global batch size:  1024 | lm loss: 1.823751E+00 | loss scale: 1.0 | grad norm: 0.092 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35553/   51900 | consumed samples:     36406272 | elapsed time per iteration (ms): 37677.2 | learning rate: 6.360E-05 | global batch size:  1024 | lm loss: 1.820285E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35554/   51900 | consumed samples:     36407296 | elapsed time per iteration (ms): 37614.0 | learning rate: 6.360E-05 | global batch size:  1024 | lm loss: 1.800429E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35555/   51900 | consumed samples:     36408320 | elapsed time per iteration (ms): 37673.6 | learning rate: 6.359E-05 | global batch size:  1024 | lm loss: 1.808680E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35556/   51900 | consumed samples:     36409344 | elapsed time per iteration (ms): 37639.7 | learning rate: 6.359E-05 | global batch size:  1024 | lm loss: 1.806332E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35557/   51900 | consumed samples:     36410368 | elapsed time per iteration (ms): 37680.9 | learning rate: 6.358E-05 | global batch size:  1024 | lm loss: 1.820134E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35558/   51900 | consumed samples:     36411392 | elapsed time per iteration (ms): 37640.8 | learning rate: 6.358E-05 | global batch size:  1024 | lm loss: 1.830036E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35559/   51900 | consumed samples:     36412416 | elapsed time per iteration (ms): 37613.1 | learning rate: 6.357E-05 | global batch size:  1024 | lm loss: 1.786391E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35560/   51900 | consumed samples:     36413440 | elapsed time per iteration (ms): 37637.5 | learning rate: 6.357E-05 | global batch size:  1024 | lm loss: 1.803156E+00 | loss scale: 1.0 | grad norm: 0.065 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35561/   51900 | consumed samples:     36414464 | elapsed time per iteration (ms): 37644.7 | learning rate: 6.356E-05 | global batch size:  1024 | lm loss: 1.809546E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35562/   51900 | consumed samples:     36415488 | elapsed time per iteration (ms): 37635.5 | learning rate: 6.356E-05 | global batch size:  1024 | lm loss: 1.794884E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35563/   51900 | consumed samples:     36416512 | elapsed time per iteration (ms): 37748.3 | learning rate: 6.355E-05 | global batch size:  1024 | lm loss: 1.816441E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35564/   51900 | consumed samples:     36417536 | elapsed time per iteration (ms): 37674.8 | learning rate: 6.355E-05 | global batch size:  1024 | lm loss: 1.814845E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35565/   51900 | consumed samples:     36418560 | elapsed time per iteration (ms): 37604.5 | learning rate: 6.354E-05 | global batch size:  1024 | lm loss: 1.807350E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35566/   51900 | consumed samples:     36419584 | elapsed time per iteration (ms): 37587.2 | learning rate: 6.354E-05 | global batch size:  1024 | lm loss: 1.832500E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35567/   51900 | consumed samples:     36420608 | elapsed time per iteration (ms): 37622.1 | learning rate: 6.353E-05 | global batch size:  1024 | lm loss: 1.812302E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35568/   51900 | consumed samples:     36421632 | elapsed time per iteration (ms): 37671.7 | learning rate: 6.353E-05 | global batch size:  1024 | lm loss: 1.821419E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35569/   51900 | consumed samples:     36422656 | elapsed time per iteration (ms): 37675.2 | learning rate: 6.352E-05 | global batch size:  1024 | lm loss: 1.801736E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35570/   51900 | consumed samples:     36423680 | elapsed time per iteration (ms): 37626.9 | learning rate: 6.352E-05 | global batch size:  1024 | lm loss: 1.818127E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35571/   51900 | consumed samples:     36424704 | elapsed time per iteration (ms): 37573.0 | learning rate: 6.351E-05 | global batch size:  1024 | lm loss: 1.793558E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35572/   51900 | consumed samples:     36425728 | elapsed time per iteration (ms): 37672.4 | learning rate: 6.351E-05 | global batch size:  1024 | lm loss: 1.810317E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35573/   51900 | consumed samples:     36426752 | elapsed time per iteration (ms): 37740.9 | learning rate: 6.351E-05 | global batch size:  1024 | lm loss: 1.803069E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35574/   51900 | consumed samples:     36427776 | elapsed time per iteration (ms): 37649.8 | learning rate: 6.350E-05 | global batch size:  1024 | lm loss: 1.823274E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35575/   51900 | consumed samples:     36428800 | elapsed time per iteration (ms): 37646.5 | learning rate: 6.350E-05 | global batch size:  1024 | lm loss: 1.819853E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35576/   51900 | consumed samples:     36429824 | elapsed time per iteration (ms): 37660.2 | learning rate: 6.349E-05 | global batch size:  1024 | lm loss: 1.803160E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35577/   51900 | consumed samples:     36430848 | elapsed time per iteration (ms): 37793.3 | learning rate: 6.349E-05 | global batch size:  1024 | lm loss: 1.800284E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35578/   51900 | consumed samples:     36431872 | elapsed time per iteration (ms): 37615.0 | learning rate: 6.348E-05 | global batch size:  1024 | lm loss: 1.816733E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35579/   51900 | consumed samples:     36432896 | elapsed time per iteration (ms): 37804.2 | learning rate: 6.348E-05 | global batch size:  1024 | lm loss: 1.800550E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35580/   51900 | consumed samples:     36433920 | elapsed time per iteration (ms): 37635.2 | learning rate: 6.347E-05 | global batch size:  1024 | lm loss: 1.820357E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35581/   51900 | consumed samples:     36434944 | elapsed time per iteration (ms): 37753.0 | learning rate: 6.347E-05 | global batch size:  1024 | lm loss: 1.816676E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35582/   51900 | consumed samples:     36435968 | elapsed time per iteration (ms): 37651.0 | learning rate: 6.346E-05 | global batch size:  1024 | lm loss: 1.821914E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35583/   51900 | consumed samples:     36436992 | elapsed time per iteration (ms): 37575.3 | learning rate: 6.346E-05 | global batch size:  1024 | lm loss: 1.808475E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35584/   51900 | consumed samples:     36438016 | elapsed time per iteration (ms): 37630.2 | learning rate: 6.345E-05 | global batch size:  1024 | lm loss: 1.812086E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35585/   51900 | consumed samples:     36439040 | elapsed time per iteration (ms): 37671.3 | learning rate: 6.345E-05 | global batch size:  1024 | lm loss: 1.816169E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35586/   51900 | consumed samples:     36440064 | elapsed time per iteration (ms): 37661.3 | learning rate: 6.344E-05 | global batch size:  1024 | lm loss: 1.799240E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35587/   51900 | consumed samples:     36441088 | elapsed time per iteration (ms): 37686.7 | learning rate: 6.344E-05 | global batch size:  1024 | lm loss: 1.809822E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35588/   51900 | consumed samples:     36442112 | elapsed time per iteration (ms): 37707.5 | learning rate: 6.343E-05 | global batch size:  1024 | lm loss: 1.804907E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35589/   51900 | consumed samples:     36443136 | elapsed time per iteration (ms): 37633.1 | learning rate: 6.343E-05 | global batch size:  1024 | lm loss: 1.801686E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35590/   51900 | consumed samples:     36444160 | elapsed time per iteration (ms): 37652.9 | learning rate: 6.342E-05 | global batch size:  1024 | lm loss: 1.812590E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35591/   51900 | consumed samples:     36445184 | elapsed time per iteration (ms): 37620.1 | learning rate: 6.342E-05 | global batch size:  1024 | lm loss: 1.822381E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35592/   51900 | consumed samples:     36446208 | elapsed time per iteration (ms): 37751.7 | learning rate: 6.341E-05 | global batch size:  1024 | lm loss: 1.830934E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35593/   51900 | consumed samples:     36447232 | elapsed time per iteration (ms): 37674.0 | learning rate: 6.341E-05 | global batch size:  1024 | lm loss: 1.803257E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35594/   51900 | consumed samples:     36448256 | elapsed time per iteration (ms): 37656.1 | learning rate: 6.340E-05 | global batch size:  1024 | lm loss: 1.815251E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35595/   51900 | consumed samples:     36449280 | elapsed time per iteration (ms): 37654.0 | learning rate: 6.340E-05 | global batch size:  1024 | lm loss: 1.808546E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35596/   51900 | consumed samples:     36450304 | elapsed time per iteration (ms): 37664.7 | learning rate: 6.339E-05 | global batch size:  1024 | lm loss: 1.816943E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35597/   51900 | consumed samples:     36451328 | elapsed time per iteration (ms): 37592.4 | learning rate: 6.339E-05 | global batch size:  1024 | lm loss: 1.815834E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35598/   51900 | consumed samples:     36452352 | elapsed time per iteration (ms): 37606.1 | learning rate: 6.338E-05 | global batch size:  1024 | lm loss: 1.801986E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35599/   51900 | consumed samples:     36453376 | elapsed time per iteration (ms): 37726.5 | learning rate: 6.338E-05 | global batch size:  1024 | lm loss: 1.801394E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35600/   51900 | consumed samples:     36454400 | elapsed time per iteration (ms): 37723.3 | learning rate: 6.337E-05 | global batch size:  1024 | lm loss: 1.797084E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35601/   51900 | consumed samples:     36455424 | elapsed time per iteration (ms): 37659.9 | learning rate: 6.337E-05 | global batch size:  1024 | lm loss: 1.789760E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35602/   51900 | consumed samples:     36456448 | elapsed time per iteration (ms): 37631.4 | learning rate: 6.336E-05 | global batch size:  1024 | lm loss: 1.807220E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35603/   51900 | consumed samples:     36457472 | elapsed time per iteration (ms): 37612.0 | learning rate: 6.336E-05 | global batch size:  1024 | lm loss: 1.808824E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35604/   51900 | consumed samples:     36458496 | elapsed time per iteration (ms): 37726.8 | learning rate: 6.335E-05 | global batch size:  1024 | lm loss: 1.810398E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35605/   51900 | consumed samples:     36459520 | elapsed time per iteration (ms): 37739.9 | learning rate: 6.335E-05 | global batch size:  1024 | lm loss: 1.795263E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35606/   51900 | consumed samples:     36460544 | elapsed time per iteration (ms): 37606.5 | learning rate: 6.335E-05 | global batch size:  1024 | lm loss: 1.801209E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35607/   51900 | consumed samples:     36461568 | elapsed time per iteration (ms): 37554.1 | learning rate: 6.334E-05 | global batch size:  1024 | lm loss: 1.818982E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35608/   51900 | consumed samples:     36462592 | elapsed time per iteration (ms): 37678.5 | learning rate: 6.334E-05 | global batch size:  1024 | lm loss: 1.811318E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35609/   51900 | consumed samples:     36463616 | elapsed time per iteration (ms): 37586.3 | learning rate: 6.333E-05 | global batch size:  1024 | lm loss: 1.822841E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35610/   51900 | consumed samples:     36464640 | elapsed time per iteration (ms): 37594.5 | learning rate: 6.333E-05 | global batch size:  1024 | lm loss: 1.825293E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35611/   51900 | consumed samples:     36465664 | elapsed time per iteration (ms): 37699.1 | learning rate: 6.332E-05 | global batch size:  1024 | lm loss: 1.821102E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35612/   51900 | consumed samples:     36466688 | elapsed time per iteration (ms): 37650.2 | learning rate: 6.332E-05 | global batch size:  1024 | lm loss: 1.810259E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35613/   51900 | consumed samples:     36467712 | elapsed time per iteration (ms): 37656.3 | learning rate: 6.331E-05 | global batch size:  1024 | lm loss: 1.806365E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35614/   51900 | consumed samples:     36468736 | elapsed time per iteration (ms): 37666.6 | learning rate: 6.331E-05 | global batch size:  1024 | lm loss: 1.817060E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35615/   51900 | consumed samples:     36469760 | elapsed time per iteration (ms): 37564.2 | learning rate: 6.330E-05 | global batch size:  1024 | lm loss: 1.811432E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35616/   51900 | consumed samples:     36470784 | elapsed time per iteration (ms): 37641.8 | learning rate: 6.330E-05 | global batch size:  1024 | lm loss: 1.803921E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35617/   51900 | consumed samples:     36471808 | elapsed time per iteration (ms): 37631.3 | learning rate: 6.329E-05 | global batch size:  1024 | lm loss: 1.810570E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35618/   51900 | consumed samples:     36472832 | elapsed time per iteration (ms): 37713.6 | learning rate: 6.329E-05 | global batch size:  1024 | lm loss: 1.801685E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35619/   51900 | consumed samples:     36473856 | elapsed time per iteration (ms): 37658.1 | learning rate: 6.328E-05 | global batch size:  1024 | lm loss: 1.819785E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35620/   51900 | consumed samples:     36474880 | elapsed time per iteration (ms): 37668.3 | learning rate: 6.328E-05 | global batch size:  1024 | lm loss: 1.824453E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35621/   51900 | consumed samples:     36475904 | elapsed time per iteration (ms): 37797.3 | learning rate: 6.327E-05 | global batch size:  1024 | lm loss: 1.810796E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35622/   51900 | consumed samples:     36476928 | elapsed time per iteration (ms): 37626.0 | learning rate: 6.327E-05 | global batch size:  1024 | lm loss: 1.790398E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35623/   51900 | consumed samples:     36477952 | elapsed time per iteration (ms): 37647.5 | learning rate: 6.326E-05 | global batch size:  1024 | lm loss: 1.821144E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35624/   51900 | consumed samples:     36478976 | elapsed time per iteration (ms): 37593.2 | learning rate: 6.326E-05 | global batch size:  1024 | lm loss: 1.811473E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35625/   51900 | consumed samples:     36480000 | elapsed time per iteration (ms): 37639.2 | learning rate: 6.325E-05 | global batch size:  1024 | lm loss: 1.804371E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35626/   51900 | consumed samples:     36481024 | elapsed time per iteration (ms): 37639.3 | learning rate: 6.325E-05 | global batch size:  1024 | lm loss: 1.809546E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35627/   51900 | consumed samples:     36482048 | elapsed time per iteration (ms): 37597.5 | learning rate: 6.324E-05 | global batch size:  1024 | lm loss: 1.813702E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35628/   51900 | consumed samples:     36483072 | elapsed time per iteration (ms): 37611.9 | learning rate: 6.324E-05 | global batch size:  1024 | lm loss: 1.811323E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35629/   51900 | consumed samples:     36484096 | elapsed time per iteration (ms): 37692.4 | learning rate: 6.323E-05 | global batch size:  1024 | lm loss: 1.808710E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35630/   51900 | consumed samples:     36485120 | elapsed time per iteration (ms): 37676.8 | learning rate: 6.323E-05 | global batch size:  1024 | lm loss: 1.791793E+00 | loss scale: 1.0 | grad norm: 0.064 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35631/   51900 | consumed samples:     36486144 | elapsed time per iteration (ms): 37586.2 | learning rate: 6.322E-05 | global batch size:  1024 | lm loss: 1.816771E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35632/   51900 | consumed samples:     36487168 | elapsed time per iteration (ms): 37684.7 | learning rate: 6.322E-05 | global batch size:  1024 | lm loss: 1.804245E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35633/   51900 | consumed samples:     36488192 | elapsed time per iteration (ms): 37598.7 | learning rate: 6.321E-05 | global batch size:  1024 | lm loss: 1.825563E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35634/   51900 | consumed samples:     36489216 | elapsed time per iteration (ms): 37611.6 | learning rate: 6.321E-05 | global batch size:  1024 | lm loss: 1.822425E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35635/   51900 | consumed samples:     36490240 | elapsed time per iteration (ms): 37562.9 | learning rate: 6.320E-05 | global batch size:  1024 | lm loss: 1.807852E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35636/   51900 | consumed samples:     36491264 | elapsed time per iteration (ms): 37736.1 | learning rate: 6.320E-05 | global batch size:  1024 | lm loss: 1.830142E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35637/   51900 | consumed samples:     36492288 | elapsed time per iteration (ms): 37646.8 | learning rate: 6.320E-05 | global batch size:  1024 | lm loss: 1.821980E+00 | loss scale: 1.0 | grad norm: 0.604 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35638/   51900 | consumed samples:     36493312 | elapsed time per iteration (ms): 37704.5 | learning rate: 6.319E-05 | global batch size:  1024 | lm loss: 1.825399E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35639/   51900 | consumed samples:     36494336 | elapsed time per iteration (ms): 37665.1 | learning rate: 6.319E-05 | global batch size:  1024 | lm loss: 1.815360E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35640/   51900 | consumed samples:     36495360 | elapsed time per iteration (ms): 37680.4 | learning rate: 6.318E-05 | global batch size:  1024 | lm loss: 1.799401E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35641/   51900 | consumed samples:     36496384 | elapsed time per iteration (ms): 37661.2 | learning rate: 6.318E-05 | global batch size:  1024 | lm loss: 1.800448E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35642/   51900 | consumed samples:     36497408 | elapsed time per iteration (ms): 37666.5 | learning rate: 6.317E-05 | global batch size:  1024 | lm loss: 1.839367E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35643/   51900 | consumed samples:     36498432 | elapsed time per iteration (ms): 37768.3 | learning rate: 6.317E-05 | global batch size:  1024 | lm loss: 1.803108E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35644/   51900 | consumed samples:     36499456 | elapsed time per iteration (ms): 37651.2 | learning rate: 6.316E-05 | global batch size:  1024 | lm loss: 1.816304E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35645/   51900 | consumed samples:     36500480 | elapsed time per iteration (ms): 37639.7 | learning rate: 6.316E-05 | global batch size:  1024 | lm loss: 1.814001E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35646/   51900 | consumed samples:     36501504 | elapsed time per iteration (ms): 37731.6 | learning rate: 6.315E-05 | global batch size:  1024 | lm loss: 1.817229E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35647/   51900 | consumed samples:     36502528 | elapsed time per iteration (ms): 37545.9 | learning rate: 6.315E-05 | global batch size:  1024 | lm loss: 1.813106E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35648/   51900 | consumed samples:     36503552 | elapsed time per iteration (ms): 37678.2 | learning rate: 6.314E-05 | global batch size:  1024 | lm loss: 1.820167E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35649/   51900 | consumed samples:     36504576 | elapsed time per iteration (ms): 37636.8 | learning rate: 6.314E-05 | global batch size:  1024 | lm loss: 1.828715E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35650/   51900 | consumed samples:     36505600 | elapsed time per iteration (ms): 37768.8 | learning rate: 6.313E-05 | global batch size:  1024 | lm loss: 1.803339E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35651/   51900 | consumed samples:     36506624 | elapsed time per iteration (ms): 37684.0 | learning rate: 6.313E-05 | global batch size:  1024 | lm loss: 1.829285E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35652/   51900 | consumed samples:     36507648 | elapsed time per iteration (ms): 37590.1 | learning rate: 6.312E-05 | global batch size:  1024 | lm loss: 1.816757E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35653/   51900 | consumed samples:     36508672 | elapsed time per iteration (ms): 37603.5 | learning rate: 6.312E-05 | global batch size:  1024 | lm loss: 1.823114E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35654/   51900 | consumed samples:     36509696 | elapsed time per iteration (ms): 37652.5 | learning rate: 6.311E-05 | global batch size:  1024 | lm loss: 1.806246E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35655/   51900 | consumed samples:     36510720 | elapsed time per iteration (ms): 37690.0 | learning rate: 6.311E-05 | global batch size:  1024 | lm loss: 1.826900E+00 | loss scale: 1.0 | grad norm: 0.113 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35656/   51900 | consumed samples:     36511744 | elapsed time per iteration (ms): 37670.0 | learning rate: 6.310E-05 | global batch size:  1024 | lm loss: 1.812604E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35657/   51900 | consumed samples:     36512768 | elapsed time per iteration (ms): 37805.1 | learning rate: 6.310E-05 | global batch size:  1024 | lm loss: 1.827656E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35658/   51900 | consumed samples:     36513792 | elapsed time per iteration (ms): 37587.0 | learning rate: 6.309E-05 | global batch size:  1024 | lm loss: 1.820588E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35659/   51900 | consumed samples:     36514816 | elapsed time per iteration (ms): 37645.0 | learning rate: 6.309E-05 | global batch size:  1024 | lm loss: 1.807934E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35660/   51900 | consumed samples:     36515840 | elapsed time per iteration (ms): 37638.2 | learning rate: 6.308E-05 | global batch size:  1024 | lm loss: 1.828133E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35661/   51900 | consumed samples:     36516864 | elapsed time per iteration (ms): 37685.8 | learning rate: 6.308E-05 | global batch size:  1024 | lm loss: 1.812109E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35662/   51900 | consumed samples:     36517888 | elapsed time per iteration (ms): 37618.8 | learning rate: 6.307E-05 | global batch size:  1024 | lm loss: 1.826937E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35663/   51900 | consumed samples:     36518912 | elapsed time per iteration (ms): 37667.6 | learning rate: 6.307E-05 | global batch size:  1024 | lm loss: 1.814570E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35664/   51900 | consumed samples:     36519936 | elapsed time per iteration (ms): 37598.6 | learning rate: 6.306E-05 | global batch size:  1024 | lm loss: 1.797499E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35665/   51900 | consumed samples:     36520960 | elapsed time per iteration (ms): 37527.5 | learning rate: 6.306E-05 | global batch size:  1024 | lm loss: 1.811313E+00 | loss scale: 1.0 | grad norm: 0.062 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35666/   51900 | consumed samples:     36521984 | elapsed time per iteration (ms): 37731.4 | learning rate: 6.305E-05 | global batch size:  1024 | lm loss: 1.826433E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35667/   51900 | consumed samples:     36523008 | elapsed time per iteration (ms): 37747.2 | learning rate: 6.305E-05 | global batch size:  1024 | lm loss: 1.815688E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35668/   51900 | consumed samples:     36524032 | elapsed time per iteration (ms): 37708.5 | learning rate: 6.305E-05 | global batch size:  1024 | lm loss: 1.808897E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35669/   51900 | consumed samples:     36525056 | elapsed time per iteration (ms): 37625.8 | learning rate: 6.304E-05 | global batch size:  1024 | lm loss: 1.813579E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35670/   51900 | consumed samples:     36526080 | elapsed time per iteration (ms): 37732.0 | learning rate: 6.304E-05 | global batch size:  1024 | lm loss: 1.811493E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35671/   51900 | consumed samples:     36527104 | elapsed time per iteration (ms): 37814.8 | learning rate: 6.303E-05 | global batch size:  1024 | lm loss: 1.816877E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35672/   51900 | consumed samples:     36528128 | elapsed time per iteration (ms): 37637.7 | learning rate: 6.303E-05 | global batch size:  1024 | lm loss: 1.792354E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35673/   51900 | consumed samples:     36529152 | elapsed time per iteration (ms): 37671.3 | learning rate: 6.302E-05 | global batch size:  1024 | lm loss: 1.821336E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35674/   51900 | consumed samples:     36530176 | elapsed time per iteration (ms): 37587.0 | learning rate: 6.302E-05 | global batch size:  1024 | lm loss: 1.799024E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35675/   51900 | consumed samples:     36531200 | elapsed time per iteration (ms): 37716.4 | learning rate: 6.301E-05 | global batch size:  1024 | lm loss: 1.792812E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35676/   51900 | consumed samples:     36532224 | elapsed time per iteration (ms): 37661.4 | learning rate: 6.301E-05 | global batch size:  1024 | lm loss: 1.810539E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35677/   51900 | consumed samples:     36533248 | elapsed time per iteration (ms): 37795.3 | learning rate: 6.300E-05 | global batch size:  1024 | lm loss: 1.834473E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35678/   51900 | consumed samples:     36534272 | elapsed time per iteration (ms): 37769.4 | learning rate: 6.300E-05 | global batch size:  1024 | lm loss: 1.796842E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35679/   51900 | consumed samples:     36535296 | elapsed time per iteration (ms): 37613.7 | learning rate: 6.299E-05 | global batch size:  1024 | lm loss: 1.802645E+00 | loss scale: 1.0 | grad norm: 0.062 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35680/   51900 | consumed samples:     36536320 | elapsed time per iteration (ms): 37739.1 | learning rate: 6.299E-05 | global batch size:  1024 | lm loss: 1.839247E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35681/   51900 | consumed samples:     36537344 | elapsed time per iteration (ms): 37641.1 | learning rate: 6.298E-05 | global batch size:  1024 | lm loss: 1.788868E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35682/   51900 | consumed samples:     36538368 | elapsed time per iteration (ms): 37686.3 | learning rate: 6.298E-05 | global batch size:  1024 | lm loss: 1.816177E+00 | loss scale: 1.0 | grad norm: 0.064 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35683/   51900 | consumed samples:     36539392 | elapsed time per iteration (ms): 37721.3 | learning rate: 6.297E-05 | global batch size:  1024 | lm loss: 1.824476E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35684/   51900 | consumed samples:     36540416 | elapsed time per iteration (ms): 37779.5 | learning rate: 6.297E-05 | global batch size:  1024 | lm loss: 1.826081E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35685/   51900 | consumed samples:     36541440 | elapsed time per iteration (ms): 37649.4 | learning rate: 6.296E-05 | global batch size:  1024 | lm loss: 1.820908E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35686/   51900 | consumed samples:     36542464 | elapsed time per iteration (ms): 37675.2 | learning rate: 6.296E-05 | global batch size:  1024 | lm loss: 1.819188E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35687/   51900 | consumed samples:     36543488 | elapsed time per iteration (ms): 37703.6 | learning rate: 6.295E-05 | global batch size:  1024 | lm loss: 1.815275E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35688/   51900 | consumed samples:     36544512 | elapsed time per iteration (ms): 37731.8 | learning rate: 6.295E-05 | global batch size:  1024 | lm loss: 1.815125E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35689/   51900 | consumed samples:     36545536 | elapsed time per iteration (ms): 37754.0 | learning rate: 6.294E-05 | global batch size:  1024 | lm loss: 1.810013E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35690/   51900 | consumed samples:     36546560 | elapsed time per iteration (ms): 37723.8 | learning rate: 6.294E-05 | global batch size:  1024 | lm loss: 1.822899E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35691/   51900 | consumed samples:     36547584 | elapsed time per iteration (ms): 37645.2 | learning rate: 6.293E-05 | global batch size:  1024 | lm loss: 1.818193E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35692/   51900 | consumed samples:     36548608 | elapsed time per iteration (ms): 37713.5 | learning rate: 6.293E-05 | global batch size:  1024 | lm loss: 1.816548E+00 | loss scale: 1.0 | grad norm: 0.065 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35693/   51900 | consumed samples:     36549632 | elapsed time per iteration (ms): 37688.1 | learning rate: 6.292E-05 | global batch size:  1024 | lm loss: 1.814078E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35694/   51900 | consumed samples:     36550656 | elapsed time per iteration (ms): 37613.0 | learning rate: 6.292E-05 | global batch size:  1024 | lm loss: 1.803503E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35695/   51900 | consumed samples:     36551680 | elapsed time per iteration (ms): 37794.8 | learning rate: 6.291E-05 | global batch size:  1024 | lm loss: 1.821789E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35696/   51900 | consumed samples:     36552704 | elapsed time per iteration (ms): 37674.9 | learning rate: 6.291E-05 | global batch size:  1024 | lm loss: 1.825210E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35697/   51900 | consumed samples:     36553728 | elapsed time per iteration (ms): 37643.8 | learning rate: 6.291E-05 | global batch size:  1024 | lm loss: 1.816369E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35698/   51900 | consumed samples:     36554752 | elapsed time per iteration (ms): 37693.9 | learning rate: 6.290E-05 | global batch size:  1024 | lm loss: 1.825258E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35699/   51900 | consumed samples:     36555776 | elapsed time per iteration (ms): 37637.7 | learning rate: 6.290E-05 | global batch size:  1024 | lm loss: 1.827014E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35700/   51900 | consumed samples:     36556800 | elapsed time per iteration (ms): 37650.4 | learning rate: 6.289E-05 | global batch size:  1024 | lm loss: 1.817101E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35701/   51900 | consumed samples:     36557824 | elapsed time per iteration (ms): 37709.4 | learning rate: 6.289E-05 | global batch size:  1024 | lm loss: 1.831720E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35702/   51900 | consumed samples:     36558848 | elapsed time per iteration (ms): 37775.3 | learning rate: 6.288E-05 | global batch size:  1024 | lm loss: 1.802485E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35703/   51900 | consumed samples:     36559872 | elapsed time per iteration (ms): 37656.6 | learning rate: 6.288E-05 | global batch size:  1024 | lm loss: 1.805416E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35704/   51900 | consumed samples:     36560896 | elapsed time per iteration (ms): 37627.8 | learning rate: 6.287E-05 | global batch size:  1024 | lm loss: 1.796379E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35705/   51900 | consumed samples:     36561920 | elapsed time per iteration (ms): 37692.9 | learning rate: 6.287E-05 | global batch size:  1024 | lm loss: 1.812564E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35706/   51900 | consumed samples:     36562944 | elapsed time per iteration (ms): 37743.1 | learning rate: 6.286E-05 | global batch size:  1024 | lm loss: 1.831992E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35707/   51900 | consumed samples:     36563968 | elapsed time per iteration (ms): 37627.1 | learning rate: 6.286E-05 | global batch size:  1024 | lm loss: 1.815462E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35708/   51900 | consumed samples:     36564992 | elapsed time per iteration (ms): 37639.4 | learning rate: 6.285E-05 | global batch size:  1024 | lm loss: 1.823525E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35709/   51900 | consumed samples:     36566016 | elapsed time per iteration (ms): 37612.8 | learning rate: 6.285E-05 | global batch size:  1024 | lm loss: 1.801125E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35710/   51900 | consumed samples:     36567040 | elapsed time per iteration (ms): 37706.7 | learning rate: 6.284E-05 | global batch size:  1024 | lm loss: 1.797192E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35711/   51900 | consumed samples:     36568064 | elapsed time per iteration (ms): 37690.0 | learning rate: 6.284E-05 | global batch size:  1024 | lm loss: 1.811471E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35712/   51900 | consumed samples:     36569088 | elapsed time per iteration (ms): 37641.1 | learning rate: 6.283E-05 | global batch size:  1024 | lm loss: 1.819580E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35713/   51900 | consumed samples:     36570112 | elapsed time per iteration (ms): 37671.5 | learning rate: 6.283E-05 | global batch size:  1024 | lm loss: 1.798833E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35714/   51900 | consumed samples:     36571136 | elapsed time per iteration (ms): 37608.3 | learning rate: 6.282E-05 | global batch size:  1024 | lm loss: 1.816996E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35715/   51900 | consumed samples:     36572160 | elapsed time per iteration (ms): 37624.1 | learning rate: 6.282E-05 | global batch size:  1024 | lm loss: 1.797774E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35716/   51900 | consumed samples:     36573184 | elapsed time per iteration (ms): 37624.6 | learning rate: 6.281E-05 | global batch size:  1024 | lm loss: 1.811161E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35717/   51900 | consumed samples:     36574208 | elapsed time per iteration (ms): 37551.5 | learning rate: 6.281E-05 | global batch size:  1024 | lm loss: 1.807782E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35718/   51900 | consumed samples:     36575232 | elapsed time per iteration (ms): 37695.8 | learning rate: 6.280E-05 | global batch size:  1024 | lm loss: 1.810469E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35719/   51900 | consumed samples:     36576256 | elapsed time per iteration (ms): 37692.4 | learning rate: 6.280E-05 | global batch size:  1024 | lm loss: 1.824562E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35720/   51900 | consumed samples:     36577280 | elapsed time per iteration (ms): 37652.3 | learning rate: 6.279E-05 | global batch size:  1024 | lm loss: 1.813626E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35721/   51900 | consumed samples:     36578304 | elapsed time per iteration (ms): 37784.3 | learning rate: 6.279E-05 | global batch size:  1024 | lm loss: 1.801332E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35722/   51900 | consumed samples:     36579328 | elapsed time per iteration (ms): 37701.1 | learning rate: 6.278E-05 | global batch size:  1024 | lm loss: 1.802813E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35723/   51900 | consumed samples:     36580352 | elapsed time per iteration (ms): 37659.3 | learning rate: 6.278E-05 | global batch size:  1024 | lm loss: 1.816401E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35724/   51900 | consumed samples:     36581376 | elapsed time per iteration (ms): 37593.0 | learning rate: 6.277E-05 | global batch size:  1024 | lm loss: 1.799618E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35725/   51900 | consumed samples:     36582400 | elapsed time per iteration (ms): 37769.5 | learning rate: 6.277E-05 | global batch size:  1024 | lm loss: 1.795775E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35726/   51900 | consumed samples:     36583424 | elapsed time per iteration (ms): 37738.8 | learning rate: 6.277E-05 | global batch size:  1024 | lm loss: 1.814611E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35727/   51900 | consumed samples:     36584448 | elapsed time per iteration (ms): 37755.9 | learning rate: 6.276E-05 | global batch size:  1024 | lm loss: 1.792236E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35728/   51900 | consumed samples:     36585472 | elapsed time per iteration (ms): 37740.0 | learning rate: 6.276E-05 | global batch size:  1024 | lm loss: 1.807338E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35729/   51900 | consumed samples:     36586496 | elapsed time per iteration (ms): 37612.8 | learning rate: 6.275E-05 | global batch size:  1024 | lm loss: 1.812061E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35730/   51900 | consumed samples:     36587520 | elapsed time per iteration (ms): 37645.5 | learning rate: 6.275E-05 | global batch size:  1024 | lm loss: 1.820750E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35731/   51900 | consumed samples:     36588544 | elapsed time per iteration (ms): 37653.2 | learning rate: 6.274E-05 | global batch size:  1024 | lm loss: 1.810570E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35732/   51900 | consumed samples:     36589568 | elapsed time per iteration (ms): 37665.6 | learning rate: 6.274E-05 | global batch size:  1024 | lm loss: 1.807378E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35733/   51900 | consumed samples:     36590592 | elapsed time per iteration (ms): 37626.7 | learning rate: 6.273E-05 | global batch size:  1024 | lm loss: 1.797341E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35734/   51900 | consumed samples:     36591616 | elapsed time per iteration (ms): 37684.3 | learning rate: 6.273E-05 | global batch size:  1024 | lm loss: 1.809790E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35735/   51900 | consumed samples:     36592640 | elapsed time per iteration (ms): 37659.0 | learning rate: 6.272E-05 | global batch size:  1024 | lm loss: 1.799565E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35736/   51900 | consumed samples:     36593664 | elapsed time per iteration (ms): 37710.1 | learning rate: 6.272E-05 | global batch size:  1024 | lm loss: 1.797908E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35737/   51900 | consumed samples:     36594688 | elapsed time per iteration (ms): 37645.8 | learning rate: 6.271E-05 | global batch size:  1024 | lm loss: 1.799069E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35738/   51900 | consumed samples:     36595712 | elapsed time per iteration (ms): 37691.0 | learning rate: 6.271E-05 | global batch size:  1024 | lm loss: 1.831346E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35739/   51900 | consumed samples:     36596736 | elapsed time per iteration (ms): 37708.7 | learning rate: 6.270E-05 | global batch size:  1024 | lm loss: 1.824461E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35740/   51900 | consumed samples:     36597760 | elapsed time per iteration (ms): 37627.8 | learning rate: 6.270E-05 | global batch size:  1024 | lm loss: 1.797919E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35741/   51900 | consumed samples:     36598784 | elapsed time per iteration (ms): 37754.0 | learning rate: 6.269E-05 | global batch size:  1024 | lm loss: 1.819677E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35742/   51900 | consumed samples:     36599808 | elapsed time per iteration (ms): 37613.4 | learning rate: 6.269E-05 | global batch size:  1024 | lm loss: 1.827421E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35743/   51900 | consumed samples:     36600832 | elapsed time per iteration (ms): 37664.1 | learning rate: 6.268E-05 | global batch size:  1024 | lm loss: 1.807078E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35744/   51900 | consumed samples:     36601856 | elapsed time per iteration (ms): 37631.2 | learning rate: 6.268E-05 | global batch size:  1024 | lm loss: 1.818730E+00 | loss scale: 1.0 | grad norm: 0.113 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35745/   51900 | consumed samples:     36602880 | elapsed time per iteration (ms): 37596.5 | learning rate: 6.267E-05 | global batch size:  1024 | lm loss: 1.820622E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35746/   51900 | consumed samples:     36603904 | elapsed time per iteration (ms): 37744.4 | learning rate: 6.267E-05 | global batch size:  1024 | lm loss: 1.800467E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35747/   51900 | consumed samples:     36604928 | elapsed time per iteration (ms): 37742.4 | learning rate: 6.266E-05 | global batch size:  1024 | lm loss: 1.815813E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35748/   51900 | consumed samples:     36605952 | elapsed time per iteration (ms): 37652.5 | learning rate: 6.266E-05 | global batch size:  1024 | lm loss: 1.826766E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35749/   51900 | consumed samples:     36606976 | elapsed time per iteration (ms): 37692.8 | learning rate: 6.265E-05 | global batch size:  1024 | lm loss: 1.807673E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35750/   51900 | consumed samples:     36608000 | elapsed time per iteration (ms): 37675.1 | learning rate: 6.265E-05 | global batch size:  1024 | lm loss: 1.813512E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35751/   51900 | consumed samples:     36609024 | elapsed time per iteration (ms): 37756.7 | learning rate: 6.264E-05 | global batch size:  1024 | lm loss: 1.810907E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35752/   51900 | consumed samples:     36610048 | elapsed time per iteration (ms): 37634.3 | learning rate: 6.264E-05 | global batch size:  1024 | lm loss: 1.817232E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35753/   51900 | consumed samples:     36611072 | elapsed time per iteration (ms): 37701.0 | learning rate: 6.263E-05 | global batch size:  1024 | lm loss: 1.800829E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35754/   51900 | consumed samples:     36612096 | elapsed time per iteration (ms): 37746.8 | learning rate: 6.263E-05 | global batch size:  1024 | lm loss: 1.806666E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35755/   51900 | consumed samples:     36613120 | elapsed time per iteration (ms): 37845.4 | learning rate: 6.263E-05 | global batch size:  1024 | lm loss: 1.835161E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35756/   51900 | consumed samples:     36614144 | elapsed time per iteration (ms): 37712.0 | learning rate: 6.262E-05 | global batch size:  1024 | lm loss: 1.813157E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35757/   51900 | consumed samples:     36615168 | elapsed time per iteration (ms): 37745.8 | learning rate: 6.262E-05 | global batch size:  1024 | lm loss: 1.806212E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35758/   51900 | consumed samples:     36616192 | elapsed time per iteration (ms): 37684.2 | learning rate: 6.261E-05 | global batch size:  1024 | lm loss: 1.813976E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35759/   51900 | consumed samples:     36617216 | elapsed time per iteration (ms): 37682.3 | learning rate: 6.261E-05 | global batch size:  1024 | lm loss: 1.816231E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35760/   51900 | consumed samples:     36618240 | elapsed time per iteration (ms): 37709.6 | learning rate: 6.260E-05 | global batch size:  1024 | lm loss: 1.798437E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35761/   51900 | consumed samples:     36619264 | elapsed time per iteration (ms): 37714.2 | learning rate: 6.260E-05 | global batch size:  1024 | lm loss: 1.805375E+00 | loss scale: 1.0 | grad norm: 0.065 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35762/   51900 | consumed samples:     36620288 | elapsed time per iteration (ms): 37629.7 | learning rate: 6.259E-05 | global batch size:  1024 | lm loss: 1.819368E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35763/   51900 | consumed samples:     36621312 | elapsed time per iteration (ms): 37727.5 | learning rate: 6.259E-05 | global batch size:  1024 | lm loss: 1.816487E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35764/   51900 | consumed samples:     36622336 | elapsed time per iteration (ms): 37636.3 | learning rate: 6.258E-05 | global batch size:  1024 | lm loss: 1.819886E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35765/   51900 | consumed samples:     36623360 | elapsed time per iteration (ms): 37551.3 | learning rate: 6.258E-05 | global batch size:  1024 | lm loss: 1.818846E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35766/   51900 | consumed samples:     36624384 | elapsed time per iteration (ms): 37708.5 | learning rate: 6.257E-05 | global batch size:  1024 | lm loss: 1.804110E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35767/   51900 | consumed samples:     36625408 | elapsed time per iteration (ms): 37699.2 | learning rate: 6.257E-05 | global batch size:  1024 | lm loss: 1.806955E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35768/   51900 | consumed samples:     36626432 | elapsed time per iteration (ms): 37661.5 | learning rate: 6.256E-05 | global batch size:  1024 | lm loss: 1.807337E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35769/   51900 | consumed samples:     36627456 | elapsed time per iteration (ms): 37579.1 | learning rate: 6.256E-05 | global batch size:  1024 | lm loss: 1.798894E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35770/   51900 | consumed samples:     36628480 | elapsed time per iteration (ms): 37738.3 | learning rate: 6.255E-05 | global batch size:  1024 | lm loss: 1.820853E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35771/   51900 | consumed samples:     36629504 | elapsed time per iteration (ms): 37689.7 | learning rate: 6.255E-05 | global batch size:  1024 | lm loss: 1.817448E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35772/   51900 | consumed samples:     36630528 | elapsed time per iteration (ms): 37586.0 | learning rate: 6.254E-05 | global batch size:  1024 | lm loss: 1.815090E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35773/   51900 | consumed samples:     36631552 | elapsed time per iteration (ms): 37774.4 | learning rate: 6.254E-05 | global batch size:  1024 | lm loss: 1.815671E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35774/   51900 | consumed samples:     36632576 | elapsed time per iteration (ms): 37655.5 | learning rate: 6.253E-05 | global batch size:  1024 | lm loss: 1.825331E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35775/   51900 | consumed samples:     36633600 | elapsed time per iteration (ms): 37709.4 | learning rate: 6.253E-05 | global batch size:  1024 | lm loss: 1.802999E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35776/   51900 | consumed samples:     36634624 | elapsed time per iteration (ms): 37570.4 | learning rate: 6.252E-05 | global batch size:  1024 | lm loss: 1.818756E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35777/   51900 | consumed samples:     36635648 | elapsed time per iteration (ms): 37668.2 | learning rate: 6.252E-05 | global batch size:  1024 | lm loss: 1.817254E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35778/   51900 | consumed samples:     36636672 | elapsed time per iteration (ms): 37768.8 | learning rate: 6.251E-05 | global batch size:  1024 | lm loss: 1.796605E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35779/   51900 | consumed samples:     36637696 | elapsed time per iteration (ms): 37704.4 | learning rate: 6.251E-05 | global batch size:  1024 | lm loss: 1.801443E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35780/   51900 | consumed samples:     36638720 | elapsed time per iteration (ms): 37659.1 | learning rate: 6.250E-05 | global batch size:  1024 | lm loss: 1.813169E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35781/   51900 | consumed samples:     36639744 | elapsed time per iteration (ms): 37699.8 | learning rate: 6.250E-05 | global batch size:  1024 | lm loss: 1.811275E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35782/   51900 | consumed samples:     36640768 | elapsed time per iteration (ms): 37798.1 | learning rate: 6.250E-05 | global batch size:  1024 | lm loss: 1.814398E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35783/   51900 | consumed samples:     36641792 | elapsed time per iteration (ms): 37747.0 | learning rate: 6.249E-05 | global batch size:  1024 | lm loss: 1.820634E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35784/   51900 | consumed samples:     36642816 | elapsed time per iteration (ms): 37701.6 | learning rate: 6.249E-05 | global batch size:  1024 | lm loss: 1.812891E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35785/   51900 | consumed samples:     36643840 | elapsed time per iteration (ms): 37617.6 | learning rate: 6.248E-05 | global batch size:  1024 | lm loss: 1.813469E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35786/   51900 | consumed samples:     36644864 | elapsed time per iteration (ms): 37756.0 | learning rate: 6.248E-05 | global batch size:  1024 | lm loss: 1.818091E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35787/   51900 | consumed samples:     36645888 | elapsed time per iteration (ms): 37605.2 | learning rate: 6.247E-05 | global batch size:  1024 | lm loss: 1.804526E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35788/   51900 | consumed samples:     36646912 | elapsed time per iteration (ms): 37703.4 | learning rate: 6.247E-05 | global batch size:  1024 | lm loss: 1.821657E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35789/   51900 | consumed samples:     36647936 | elapsed time per iteration (ms): 37691.6 | learning rate: 6.246E-05 | global batch size:  1024 | lm loss: 1.828581E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35790/   51900 | consumed samples:     36648960 | elapsed time per iteration (ms): 37699.9 | learning rate: 6.246E-05 | global batch size:  1024 | lm loss: 1.833923E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35791/   51900 | consumed samples:     36649984 | elapsed time per iteration (ms): 37755.2 | learning rate: 6.245E-05 | global batch size:  1024 | lm loss: 1.801309E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35792/   51900 | consumed samples:     36651008 | elapsed time per iteration (ms): 37782.9 | learning rate: 6.245E-05 | global batch size:  1024 | lm loss: 1.802219E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35793/   51900 | consumed samples:     36652032 | elapsed time per iteration (ms): 37650.0 | learning rate: 6.244E-05 | global batch size:  1024 | lm loss: 1.813832E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35794/   51900 | consumed samples:     36653056 | elapsed time per iteration (ms): 37655.4 | learning rate: 6.244E-05 | global batch size:  1024 | lm loss: 1.791884E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35795/   51900 | consumed samples:     36654080 | elapsed time per iteration (ms): 37749.5 | learning rate: 6.243E-05 | global batch size:  1024 | lm loss: 1.802236E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35796/   51900 | consumed samples:     36655104 | elapsed time per iteration (ms): 37770.3 | learning rate: 6.243E-05 | global batch size:  1024 | lm loss: 1.809793E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35797/   51900 | consumed samples:     36656128 | elapsed time per iteration (ms): 37741.4 | learning rate: 6.242E-05 | global batch size:  1024 | lm loss: 1.813116E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35798/   51900 | consumed samples:     36657152 | elapsed time per iteration (ms): 37711.8 | learning rate: 6.242E-05 | global batch size:  1024 | lm loss: 1.834251E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35799/   51900 | consumed samples:     36658176 | elapsed time per iteration (ms): 37618.2 | learning rate: 6.241E-05 | global batch size:  1024 | lm loss: 1.812343E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35800/   51900 | consumed samples:     36659200 | elapsed time per iteration (ms): 37668.8 | learning rate: 6.241E-05 | global batch size:  1024 | lm loss: 1.821648E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35801/   51900 | consumed samples:     36660224 | elapsed time per iteration (ms): 37716.2 | learning rate: 6.240E-05 | global batch size:  1024 | lm loss: 1.816282E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35802/   51900 | consumed samples:     36661248 | elapsed time per iteration (ms): 37651.8 | learning rate: 6.240E-05 | global batch size:  1024 | lm loss: 1.809979E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35803/   51900 | consumed samples:     36662272 | elapsed time per iteration (ms): 37682.2 | learning rate: 6.239E-05 | global batch size:  1024 | lm loss: 1.832510E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35804/   51900 | consumed samples:     36663296 | elapsed time per iteration (ms): 37688.1 | learning rate: 6.239E-05 | global batch size:  1024 | lm loss: 1.808620E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35805/   51900 | consumed samples:     36664320 | elapsed time per iteration (ms): 37713.8 | learning rate: 6.238E-05 | global batch size:  1024 | lm loss: 1.819331E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35806/   51900 | consumed samples:     36665344 | elapsed time per iteration (ms): 37653.5 | learning rate: 6.238E-05 | global batch size:  1024 | lm loss: 1.822358E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35807/   51900 | consumed samples:     36666368 | elapsed time per iteration (ms): 37667.3 | learning rate: 6.238E-05 | global batch size:  1024 | lm loss: 1.853501E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35808/   51900 | consumed samples:     36667392 | elapsed time per iteration (ms): 37733.0 | learning rate: 6.237E-05 | global batch size:  1024 | lm loss: 1.807087E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35809/   51900 | consumed samples:     36668416 | elapsed time per iteration (ms): 37682.5 | learning rate: 6.237E-05 | global batch size:  1024 | lm loss: 1.806225E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35810/   51900 | consumed samples:     36669440 | elapsed time per iteration (ms): 37685.8 | learning rate: 6.236E-05 | global batch size:  1024 | lm loss: 1.820155E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35811/   51900 | consumed samples:     36670464 | elapsed time per iteration (ms): 37674.0 | learning rate: 6.236E-05 | global batch size:  1024 | lm loss: 1.812248E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35812/   51900 | consumed samples:     36671488 | elapsed time per iteration (ms): 37659.5 | learning rate: 6.235E-05 | global batch size:  1024 | lm loss: 1.810181E+00 | loss scale: 1.0 | grad norm: 0.063 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35813/   51900 | consumed samples:     36672512 | elapsed time per iteration (ms): 37721.5 | learning rate: 6.235E-05 | global batch size:  1024 | lm loss: 1.806190E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35814/   51900 | consumed samples:     36673536 | elapsed time per iteration (ms): 37722.9 | learning rate: 6.234E-05 | global batch size:  1024 | lm loss: 1.808220E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35815/   51900 | consumed samples:     36674560 | elapsed time per iteration (ms): 37709.1 | learning rate: 6.234E-05 | global batch size:  1024 | lm loss: 1.812441E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35816/   51900 | consumed samples:     36675584 | elapsed time per iteration (ms): 37716.9 | learning rate: 6.233E-05 | global batch size:  1024 | lm loss: 1.793539E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35817/   51900 | consumed samples:     36676608 | elapsed time per iteration (ms): 37620.1 | learning rate: 6.233E-05 | global batch size:  1024 | lm loss: 1.815638E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35818/   51900 | consumed samples:     36677632 | elapsed time per iteration (ms): 37621.2 | learning rate: 6.232E-05 | global batch size:  1024 | lm loss: 1.820245E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35819/   51900 | consumed samples:     36678656 | elapsed time per iteration (ms): 37708.9 | learning rate: 6.232E-05 | global batch size:  1024 | lm loss: 1.795537E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35820/   51900 | consumed samples:     36679680 | elapsed time per iteration (ms): 37699.9 | learning rate: 6.231E-05 | global batch size:  1024 | lm loss: 1.802103E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35821/   51900 | consumed samples:     36680704 | elapsed time per iteration (ms): 37736.6 | learning rate: 6.231E-05 | global batch size:  1024 | lm loss: 1.811641E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35822/   51900 | consumed samples:     36681728 | elapsed time per iteration (ms): 37643.8 | learning rate: 6.230E-05 | global batch size:  1024 | lm loss: 1.799690E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35823/   51900 | consumed samples:     36682752 | elapsed time per iteration (ms): 37599.8 | learning rate: 6.230E-05 | global batch size:  1024 | lm loss: 1.797804E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35824/   51900 | consumed samples:     36683776 | elapsed time per iteration (ms): 37801.0 | learning rate: 6.229E-05 | global batch size:  1024 | lm loss: 1.808422E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35825/   51900 | consumed samples:     36684800 | elapsed time per iteration (ms): 37727.6 | learning rate: 6.229E-05 | global batch size:  1024 | lm loss: 1.817616E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35826/   51900 | consumed samples:     36685824 | elapsed time per iteration (ms): 37761.7 | learning rate: 6.228E-05 | global batch size:  1024 | lm loss: 1.816982E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35827/   51900 | consumed samples:     36686848 | elapsed time per iteration (ms): 37688.4 | learning rate: 6.228E-05 | global batch size:  1024 | lm loss: 1.815613E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35828/   51900 | consumed samples:     36687872 | elapsed time per iteration (ms): 37649.4 | learning rate: 6.227E-05 | global batch size:  1024 | lm loss: 1.806969E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35829/   51900 | consumed samples:     36688896 | elapsed time per iteration (ms): 37736.8 | learning rate: 6.227E-05 | global batch size:  1024 | lm loss: 1.808253E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35830/   51900 | consumed samples:     36689920 | elapsed time per iteration (ms): 37618.1 | learning rate: 6.226E-05 | global batch size:  1024 | lm loss: 1.810834E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35831/   51900 | consumed samples:     36690944 | elapsed time per iteration (ms): 37659.9 | learning rate: 6.226E-05 | global batch size:  1024 | lm loss: 1.811030E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35832/   51900 | consumed samples:     36691968 | elapsed time per iteration (ms): 37613.3 | learning rate: 6.225E-05 | global batch size:  1024 | lm loss: 1.803373E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35833/   51900 | consumed samples:     36692992 | elapsed time per iteration (ms): 37640.7 | learning rate: 6.225E-05 | global batch size:  1024 | lm loss: 1.813529E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35834/   51900 | consumed samples:     36694016 | elapsed time per iteration (ms): 37694.6 | learning rate: 6.225E-05 | global batch size:  1024 | lm loss: 1.817790E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35835/   51900 | consumed samples:     36695040 | elapsed time per iteration (ms): 37612.3 | learning rate: 6.224E-05 | global batch size:  1024 | lm loss: 1.816823E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35836/   51900 | consumed samples:     36696064 | elapsed time per iteration (ms): 37636.6 | learning rate: 6.224E-05 | global batch size:  1024 | lm loss: 1.817455E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35837/   51900 | consumed samples:     36697088 | elapsed time per iteration (ms): 37726.6 | learning rate: 6.223E-05 | global batch size:  1024 | lm loss: 1.823012E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35838/   51900 | consumed samples:     36698112 | elapsed time per iteration (ms): 37664.8 | learning rate: 6.223E-05 | global batch size:  1024 | lm loss: 1.819442E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35839/   51900 | consumed samples:     36699136 | elapsed time per iteration (ms): 37694.2 | learning rate: 6.222E-05 | global batch size:  1024 | lm loss: 1.809363E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35840/   51900 | consumed samples:     36700160 | elapsed time per iteration (ms): 37660.5 | learning rate: 6.222E-05 | global batch size:  1024 | lm loss: 1.813056E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35841/   51900 | consumed samples:     36701184 | elapsed time per iteration (ms): 37753.2 | learning rate: 6.221E-05 | global batch size:  1024 | lm loss: 1.825826E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35842/   51900 | consumed samples:     36702208 | elapsed time per iteration (ms): 37638.1 | learning rate: 6.221E-05 | global batch size:  1024 | lm loss: 1.818015E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35843/   51900 | consumed samples:     36703232 | elapsed time per iteration (ms): 37730.3 | learning rate: 6.220E-05 | global batch size:  1024 | lm loss: 1.822652E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35844/   51900 | consumed samples:     36704256 | elapsed time per iteration (ms): 37667.9 | learning rate: 6.220E-05 | global batch size:  1024 | lm loss: 1.813219E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35845/   51900 | consumed samples:     36705280 | elapsed time per iteration (ms): 37651.2 | learning rate: 6.219E-05 | global batch size:  1024 | lm loss: 1.797549E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35846/   51900 | consumed samples:     36706304 | elapsed time per iteration (ms): 37668.8 | learning rate: 6.219E-05 | global batch size:  1024 | lm loss: 1.829390E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35847/   51900 | consumed samples:     36707328 | elapsed time per iteration (ms): 37737.0 | learning rate: 6.218E-05 | global batch size:  1024 | lm loss: 1.803508E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35848/   51900 | consumed samples:     36708352 | elapsed time per iteration (ms): 37677.8 | learning rate: 6.218E-05 | global batch size:  1024 | lm loss: 1.795225E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35849/   51900 | consumed samples:     36709376 | elapsed time per iteration (ms): 37643.3 | learning rate: 6.217E-05 | global batch size:  1024 | lm loss: 1.810477E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35850/   51900 | consumed samples:     36710400 | elapsed time per iteration (ms): 37732.0 | learning rate: 6.217E-05 | global batch size:  1024 | lm loss: 1.804472E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35851/   51900 | consumed samples:     36711424 | elapsed time per iteration (ms): 37762.6 | learning rate: 6.216E-05 | global batch size:  1024 | lm loss: 1.822703E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35852/   51900 | consumed samples:     36712448 | elapsed time per iteration (ms): 37847.8 | learning rate: 6.216E-05 | global batch size:  1024 | lm loss: 1.814358E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35853/   51900 | consumed samples:     36713472 | elapsed time per iteration (ms): 37672.3 | learning rate: 6.215E-05 | global batch size:  1024 | lm loss: 1.816864E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35854/   51900 | consumed samples:     36714496 | elapsed time per iteration (ms): 37745.5 | learning rate: 6.215E-05 | global batch size:  1024 | lm loss: 1.816582E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35855/   51900 | consumed samples:     36715520 | elapsed time per iteration (ms): 37673.1 | learning rate: 6.214E-05 | global batch size:  1024 | lm loss: 1.814090E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35856/   51900 | consumed samples:     36716544 | elapsed time per iteration (ms): 37661.9 | learning rate: 6.214E-05 | global batch size:  1024 | lm loss: 1.811479E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35857/   51900 | consumed samples:     36717568 | elapsed time per iteration (ms): 37686.1 | learning rate: 6.213E-05 | global batch size:  1024 | lm loss: 1.819439E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35858/   51900 | consumed samples:     36718592 | elapsed time per iteration (ms): 37596.0 | learning rate: 6.213E-05 | global batch size:  1024 | lm loss: 1.802799E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35859/   51900 | consumed samples:     36719616 | elapsed time per iteration (ms): 37549.6 | learning rate: 6.213E-05 | global batch size:  1024 | lm loss: 1.807423E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35860/   51900 | consumed samples:     36720640 | elapsed time per iteration (ms): 37630.4 | learning rate: 6.212E-05 | global batch size:  1024 | lm loss: 1.802566E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35861/   51900 | consumed samples:     36721664 | elapsed time per iteration (ms): 37644.5 | learning rate: 6.212E-05 | global batch size:  1024 | lm loss: 1.828720E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35862/   51900 | consumed samples:     36722688 | elapsed time per iteration (ms): 37643.2 | learning rate: 6.211E-05 | global batch size:  1024 | lm loss: 1.835529E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35863/   51900 | consumed samples:     36723712 | elapsed time per iteration (ms): 37603.8 | learning rate: 6.211E-05 | global batch size:  1024 | lm loss: 1.818473E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35864/   51900 | consumed samples:     36724736 | elapsed time per iteration (ms): 37544.2 | learning rate: 6.210E-05 | global batch size:  1024 | lm loss: 1.825802E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35865/   51900 | consumed samples:     36725760 | elapsed time per iteration (ms): 37582.7 | learning rate: 6.210E-05 | global batch size:  1024 | lm loss: 1.797553E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35866/   51900 | consumed samples:     36726784 | elapsed time per iteration (ms): 37569.9 | learning rate: 6.209E-05 | global batch size:  1024 | lm loss: 1.793176E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35867/   51900 | consumed samples:     36727808 | elapsed time per iteration (ms): 37743.1 | learning rate: 6.209E-05 | global batch size:  1024 | lm loss: 1.803521E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35868/   51900 | consumed samples:     36728832 | elapsed time per iteration (ms): 37679.7 | learning rate: 6.208E-05 | global batch size:  1024 | lm loss: 1.821646E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35869/   51900 | consumed samples:     36729856 | elapsed time per iteration (ms): 37712.3 | learning rate: 6.208E-05 | global batch size:  1024 | lm loss: 1.825442E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35870/   51900 | consumed samples:     36730880 | elapsed time per iteration (ms): 37776.0 | learning rate: 6.207E-05 | global batch size:  1024 | lm loss: 1.819276E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35871/   51900 | consumed samples:     36731904 | elapsed time per iteration (ms): 37754.5 | learning rate: 6.207E-05 | global batch size:  1024 | lm loss: 1.820443E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35872/   51900 | consumed samples:     36732928 | elapsed time per iteration (ms): 37693.5 | learning rate: 6.206E-05 | global batch size:  1024 | lm loss: 1.811822E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35873/   51900 | consumed samples:     36733952 | elapsed time per iteration (ms): 37681.7 | learning rate: 6.206E-05 | global batch size:  1024 | lm loss: 1.812863E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35874/   51900 | consumed samples:     36734976 | elapsed time per iteration (ms): 37656.4 | learning rate: 6.205E-05 | global batch size:  1024 | lm loss: 1.808855E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35875/   51900 | consumed samples:     36736000 | elapsed time per iteration (ms): 37739.0 | learning rate: 6.205E-05 | global batch size:  1024 | lm loss: 1.815614E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35876/   51900 | consumed samples:     36737024 | elapsed time per iteration (ms): 37724.3 | learning rate: 6.204E-05 | global batch size:  1024 | lm loss: 1.825275E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35877/   51900 | consumed samples:     36738048 | elapsed time per iteration (ms): 37668.4 | learning rate: 6.204E-05 | global batch size:  1024 | lm loss: 1.799888E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35878/   51900 | consumed samples:     36739072 | elapsed time per iteration (ms): 37691.7 | learning rate: 6.203E-05 | global batch size:  1024 | lm loss: 1.813668E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35879/   51900 | consumed samples:     36740096 | elapsed time per iteration (ms): 37746.3 | learning rate: 6.203E-05 | global batch size:  1024 | lm loss: 1.822809E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35880/   51900 | consumed samples:     36741120 | elapsed time per iteration (ms): 37683.1 | learning rate: 6.202E-05 | global batch size:  1024 | lm loss: 1.829127E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35881/   51900 | consumed samples:     36742144 | elapsed time per iteration (ms): 37717.6 | learning rate: 6.202E-05 | global batch size:  1024 | lm loss: 1.797934E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35882/   51900 | consumed samples:     36743168 | elapsed time per iteration (ms): 37654.5 | learning rate: 6.202E-05 | global batch size:  1024 | lm loss: 1.790793E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35883/   51900 | consumed samples:     36744192 | elapsed time per iteration (ms): 37601.3 | learning rate: 6.201E-05 | global batch size:  1024 | lm loss: 1.804544E+00 | loss scale: 1.0 | grad norm: 0.064 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35884/   51900 | consumed samples:     36745216 | elapsed time per iteration (ms): 37685.1 | learning rate: 6.201E-05 | global batch size:  1024 | lm loss: 1.817548E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35885/   51900 | consumed samples:     36746240 | elapsed time per iteration (ms): 37821.4 | learning rate: 6.200E-05 | global batch size:  1024 | lm loss: 1.815081E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35886/   51900 | consumed samples:     36747264 | elapsed time per iteration (ms): 37792.8 | learning rate: 6.200E-05 | global batch size:  1024 | lm loss: 1.836950E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35887/   51900 | consumed samples:     36748288 | elapsed time per iteration (ms): 37609.1 | learning rate: 6.199E-05 | global batch size:  1024 | lm loss: 1.805392E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35888/   51900 | consumed samples:     36749312 | elapsed time per iteration (ms): 37657.4 | learning rate: 6.199E-05 | global batch size:  1024 | lm loss: 1.825250E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35889/   51900 | consumed samples:     36750336 | elapsed time per iteration (ms): 37746.3 | learning rate: 6.198E-05 | global batch size:  1024 | lm loss: 1.787755E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35890/   51900 | consumed samples:     36751360 | elapsed time per iteration (ms): 37529.4 | learning rate: 6.198E-05 | global batch size:  1024 | lm loss: 1.805478E+00 | loss scale: 1.0 | grad norm: 0.095 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35891/   51900 | consumed samples:     36752384 | elapsed time per iteration (ms): 37691.8 | learning rate: 6.197E-05 | global batch size:  1024 | lm loss: 1.789973E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35892/   51900 | consumed samples:     36753408 | elapsed time per iteration (ms): 37645.2 | learning rate: 6.197E-05 | global batch size:  1024 | lm loss: 1.822273E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35893/   51900 | consumed samples:     36754432 | elapsed time per iteration (ms): 37714.6 | learning rate: 6.196E-05 | global batch size:  1024 | lm loss: 1.808746E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35894/   51900 | consumed samples:     36755456 | elapsed time per iteration (ms): 37591.6 | learning rate: 6.196E-05 | global batch size:  1024 | lm loss: 1.794623E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35895/   51900 | consumed samples:     36756480 | elapsed time per iteration (ms): 37656.9 | learning rate: 6.195E-05 | global batch size:  1024 | lm loss: 1.831889E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35896/   51900 | consumed samples:     36757504 | elapsed time per iteration (ms): 37621.5 | learning rate: 6.195E-05 | global batch size:  1024 | lm loss: 1.790054E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35897/   51900 | consumed samples:     36758528 | elapsed time per iteration (ms): 37678.7 | learning rate: 6.194E-05 | global batch size:  1024 | lm loss: 1.816089E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35898/   51900 | consumed samples:     36759552 | elapsed time per iteration (ms): 37674.8 | learning rate: 6.194E-05 | global batch size:  1024 | lm loss: 1.814504E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35899/   51900 | consumed samples:     36760576 | elapsed time per iteration (ms): 37659.1 | learning rate: 6.193E-05 | global batch size:  1024 | lm loss: 1.815409E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35900/   51900 | consumed samples:     36761600 | elapsed time per iteration (ms): 37672.9 | learning rate: 6.193E-05 | global batch size:  1024 | lm loss: 1.817234E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35901/   51900 | consumed samples:     36762624 | elapsed time per iteration (ms): 37573.7 | learning rate: 6.192E-05 | global batch size:  1024 | lm loss: 1.828292E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35902/   51900 | consumed samples:     36763648 | elapsed time per iteration (ms): 37640.6 | learning rate: 6.192E-05 | global batch size:  1024 | lm loss: 1.832245E+00 | loss scale: 1.0 | grad norm: 0.131 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35903/   51900 | consumed samples:     36764672 | elapsed time per iteration (ms): 37759.7 | learning rate: 6.191E-05 | global batch size:  1024 | lm loss: 1.791233E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35904/   51900 | consumed samples:     36765696 | elapsed time per iteration (ms): 37666.0 | learning rate: 6.191E-05 | global batch size:  1024 | lm loss: 1.802674E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35905/   51900 | consumed samples:     36766720 | elapsed time per iteration (ms): 37724.2 | learning rate: 6.190E-05 | global batch size:  1024 | lm loss: 1.813437E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35906/   51900 | consumed samples:     36767744 | elapsed time per iteration (ms): 37766.6 | learning rate: 6.190E-05 | global batch size:  1024 | lm loss: 1.816231E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35907/   51900 | consumed samples:     36768768 | elapsed time per iteration (ms): 37788.3 | learning rate: 6.190E-05 | global batch size:  1024 | lm loss: 1.807917E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35908/   51900 | consumed samples:     36769792 | elapsed time per iteration (ms): 37654.1 | learning rate: 6.189E-05 | global batch size:  1024 | lm loss: 1.824411E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35909/   51900 | consumed samples:     36770816 | elapsed time per iteration (ms): 37861.2 | learning rate: 6.189E-05 | global batch size:  1024 | lm loss: 1.810278E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35910/   51900 | consumed samples:     36771840 | elapsed time per iteration (ms): 37717.6 | learning rate: 6.188E-05 | global batch size:  1024 | lm loss: 1.812196E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35911/   51900 | consumed samples:     36772864 | elapsed time per iteration (ms): 37625.5 | learning rate: 6.188E-05 | global batch size:  1024 | lm loss: 1.804845E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35912/   51900 | consumed samples:     36773888 | elapsed time per iteration (ms): 37635.3 | learning rate: 6.187E-05 | global batch size:  1024 | lm loss: 1.801483E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35913/   51900 | consumed samples:     36774912 | elapsed time per iteration (ms): 37729.3 | learning rate: 6.187E-05 | global batch size:  1024 | lm loss: 1.796108E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35914/   51900 | consumed samples:     36775936 | elapsed time per iteration (ms): 37653.3 | learning rate: 6.186E-05 | global batch size:  1024 | lm loss: 1.809420E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35915/   51900 | consumed samples:     36776960 | elapsed time per iteration (ms): 37679.6 | learning rate: 6.186E-05 | global batch size:  1024 | lm loss: 1.826494E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35916/   51900 | consumed samples:     36777984 | elapsed time per iteration (ms): 37711.0 | learning rate: 6.185E-05 | global batch size:  1024 | lm loss: 1.806592E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35917/   51900 | consumed samples:     36779008 | elapsed time per iteration (ms): 37662.7 | learning rate: 6.185E-05 | global batch size:  1024 | lm loss: 1.828874E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35918/   51900 | consumed samples:     36780032 | elapsed time per iteration (ms): 37703.1 | learning rate: 6.184E-05 | global batch size:  1024 | lm loss: 1.812047E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35919/   51900 | consumed samples:     36781056 | elapsed time per iteration (ms): 37622.2 | learning rate: 6.184E-05 | global batch size:  1024 | lm loss: 1.807589E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35920/   51900 | consumed samples:     36782080 | elapsed time per iteration (ms): 37744.3 | learning rate: 6.183E-05 | global batch size:  1024 | lm loss: 1.810701E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35921/   51900 | consumed samples:     36783104 | elapsed time per iteration (ms): 37742.4 | learning rate: 6.183E-05 | global batch size:  1024 | lm loss: 1.825789E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35922/   51900 | consumed samples:     36784128 | elapsed time per iteration (ms): 37817.7 | learning rate: 6.182E-05 | global batch size:  1024 | lm loss: 1.800854E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35923/   51900 | consumed samples:     36785152 | elapsed time per iteration (ms): 37628.7 | learning rate: 6.182E-05 | global batch size:  1024 | lm loss: 1.818903E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35924/   51900 | consumed samples:     36786176 | elapsed time per iteration (ms): 37750.7 | learning rate: 6.181E-05 | global batch size:  1024 | lm loss: 1.809434E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35925/   51900 | consumed samples:     36787200 | elapsed time per iteration (ms): 37696.4 | learning rate: 6.181E-05 | global batch size:  1024 | lm loss: 1.806169E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35926/   51900 | consumed samples:     36788224 | elapsed time per iteration (ms): 37698.9 | learning rate: 6.180E-05 | global batch size:  1024 | lm loss: 1.811861E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35927/   51900 | consumed samples:     36789248 | elapsed time per iteration (ms): 37731.0 | learning rate: 6.180E-05 | global batch size:  1024 | lm loss: 1.812100E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35928/   51900 | consumed samples:     36790272 | elapsed time per iteration (ms): 37593.8 | learning rate: 6.179E-05 | global batch size:  1024 | lm loss: 1.801790E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35929/   51900 | consumed samples:     36791296 | elapsed time per iteration (ms): 37704.9 | learning rate: 6.179E-05 | global batch size:  1024 | lm loss: 1.820733E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35930/   51900 | consumed samples:     36792320 | elapsed time per iteration (ms): 37774.4 | learning rate: 6.179E-05 | global batch size:  1024 | lm loss: 1.797130E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35931/   51900 | consumed samples:     36793344 | elapsed time per iteration (ms): 37602.9 | learning rate: 6.178E-05 | global batch size:  1024 | lm loss: 1.804360E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35932/   51900 | consumed samples:     36794368 | elapsed time per iteration (ms): 37593.4 | learning rate: 6.178E-05 | global batch size:  1024 | lm loss: 1.820871E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35933/   51900 | consumed samples:     36795392 | elapsed time per iteration (ms): 37614.8 | learning rate: 6.177E-05 | global batch size:  1024 | lm loss: 1.794659E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35934/   51900 | consumed samples:     36796416 | elapsed time per iteration (ms): 37718.0 | learning rate: 6.177E-05 | global batch size:  1024 | lm loss: 1.820328E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35935/   51900 | consumed samples:     36797440 | elapsed time per iteration (ms): 37674.0 | learning rate: 6.176E-05 | global batch size:  1024 | lm loss: 1.801901E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35936/   51900 | consumed samples:     36798464 | elapsed time per iteration (ms): 37709.0 | learning rate: 6.176E-05 | global batch size:  1024 | lm loss: 1.784908E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35937/   51900 | consumed samples:     36799488 | elapsed time per iteration (ms): 37624.7 | learning rate: 6.175E-05 | global batch size:  1024 | lm loss: 1.811275E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35938/   51900 | consumed samples:     36800512 | elapsed time per iteration (ms): 37725.8 | learning rate: 6.175E-05 | global batch size:  1024 | lm loss: 1.822511E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35939/   51900 | consumed samples:     36801536 | elapsed time per iteration (ms): 37579.7 | learning rate: 6.174E-05 | global batch size:  1024 | lm loss: 1.818517E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35940/   51900 | consumed samples:     36802560 | elapsed time per iteration (ms): 37852.0 | learning rate: 6.174E-05 | global batch size:  1024 | lm loss: 1.821846E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35941/   51900 | consumed samples:     36803584 | elapsed time per iteration (ms): 37626.8 | learning rate: 6.173E-05 | global batch size:  1024 | lm loss: 1.807343E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35942/   51900 | consumed samples:     36804608 | elapsed time per iteration (ms): 37644.3 | learning rate: 6.173E-05 | global batch size:  1024 | lm loss: 1.815483E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35943/   51900 | consumed samples:     36805632 | elapsed time per iteration (ms): 37656.5 | learning rate: 6.172E-05 | global batch size:  1024 | lm loss: 1.790439E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35944/   51900 | consumed samples:     36806656 | elapsed time per iteration (ms): 37595.7 | learning rate: 6.172E-05 | global batch size:  1024 | lm loss: 1.815324E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35945/   51900 | consumed samples:     36807680 | elapsed time per iteration (ms): 37770.4 | learning rate: 6.171E-05 | global batch size:  1024 | lm loss: 1.823160E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35946/   51900 | consumed samples:     36808704 | elapsed time per iteration (ms): 37639.1 | learning rate: 6.171E-05 | global batch size:  1024 | lm loss: 1.813442E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35947/   51900 | consumed samples:     36809728 | elapsed time per iteration (ms): 37713.9 | learning rate: 6.170E-05 | global batch size:  1024 | lm loss: 1.811461E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35948/   51900 | consumed samples:     36810752 | elapsed time per iteration (ms): 37667.5 | learning rate: 6.170E-05 | global batch size:  1024 | lm loss: 1.805909E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35949/   51900 | consumed samples:     36811776 | elapsed time per iteration (ms): 37666.1 | learning rate: 6.169E-05 | global batch size:  1024 | lm loss: 1.805957E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35950/   51900 | consumed samples:     36812800 | elapsed time per iteration (ms): 37686.7 | learning rate: 6.169E-05 | global batch size:  1024 | lm loss: 1.810485E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35951/   51900 | consumed samples:     36813824 | elapsed time per iteration (ms): 37728.6 | learning rate: 6.168E-05 | global batch size:  1024 | lm loss: 1.801720E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35952/   51900 | consumed samples:     36814848 | elapsed time per iteration (ms): 37598.5 | learning rate: 6.168E-05 | global batch size:  1024 | lm loss: 1.779462E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35953/   51900 | consumed samples:     36815872 | elapsed time per iteration (ms): 37703.8 | learning rate: 6.168E-05 | global batch size:  1024 | lm loss: 1.801374E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35954/   51900 | consumed samples:     36816896 | elapsed time per iteration (ms): 37729.7 | learning rate: 6.167E-05 | global batch size:  1024 | lm loss: 1.827280E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35955/   51900 | consumed samples:     36817920 | elapsed time per iteration (ms): 37656.6 | learning rate: 6.167E-05 | global batch size:  1024 | lm loss: 1.799578E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35956/   51900 | consumed samples:     36818944 | elapsed time per iteration (ms): 37714.1 | learning rate: 6.166E-05 | global batch size:  1024 | lm loss: 1.826404E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35957/   51900 | consumed samples:     36819968 | elapsed time per iteration (ms): 37605.7 | learning rate: 6.166E-05 | global batch size:  1024 | lm loss: 1.810749E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35958/   51900 | consumed samples:     36820992 | elapsed time per iteration (ms): 37606.7 | learning rate: 6.165E-05 | global batch size:  1024 | lm loss: 1.812784E+00 | loss scale: 1.0 | grad norm: 0.087 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35959/   51900 | consumed samples:     36822016 | elapsed time per iteration (ms): 37570.5 | learning rate: 6.165E-05 | global batch size:  1024 | lm loss: 1.804643E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35960/   51900 | consumed samples:     36823040 | elapsed time per iteration (ms): 37629.2 | learning rate: 6.164E-05 | global batch size:  1024 | lm loss: 1.807982E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35961/   51900 | consumed samples:     36824064 | elapsed time per iteration (ms): 37655.2 | learning rate: 6.164E-05 | global batch size:  1024 | lm loss: 1.820863E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35962/   51900 | consumed samples:     36825088 | elapsed time per iteration (ms): 37691.2 | learning rate: 6.163E-05 | global batch size:  1024 | lm loss: 1.811767E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35963/   51900 | consumed samples:     36826112 | elapsed time per iteration (ms): 37705.7 | learning rate: 6.163E-05 | global batch size:  1024 | lm loss: 1.817981E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35964/   51900 | consumed samples:     36827136 | elapsed time per iteration (ms): 37626.6 | learning rate: 6.162E-05 | global batch size:  1024 | lm loss: 1.801736E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35965/   51900 | consumed samples:     36828160 | elapsed time per iteration (ms): 37710.1 | learning rate: 6.162E-05 | global batch size:  1024 | lm loss: 1.810422E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35966/   51900 | consumed samples:     36829184 | elapsed time per iteration (ms): 37647.0 | learning rate: 6.161E-05 | global batch size:  1024 | lm loss: 1.818021E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35967/   51900 | consumed samples:     36830208 | elapsed time per iteration (ms): 37634.1 | learning rate: 6.161E-05 | global batch size:  1024 | lm loss: 1.814749E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35968/   51900 | consumed samples:     36831232 | elapsed time per iteration (ms): 37712.8 | learning rate: 6.160E-05 | global batch size:  1024 | lm loss: 1.821504E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35969/   51900 | consumed samples:     36832256 | elapsed time per iteration (ms): 37666.2 | learning rate: 6.160E-05 | global batch size:  1024 | lm loss: 1.813096E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35970/   51900 | consumed samples:     36833280 | elapsed time per iteration (ms): 37606.9 | learning rate: 6.159E-05 | global batch size:  1024 | lm loss: 1.829233E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35971/   51900 | consumed samples:     36834304 | elapsed time per iteration (ms): 37697.8 | learning rate: 6.159E-05 | global batch size:  1024 | lm loss: 1.827851E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35972/   51900 | consumed samples:     36835328 | elapsed time per iteration (ms): 37564.0 | learning rate: 6.158E-05 | global batch size:  1024 | lm loss: 1.830692E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35973/   51900 | consumed samples:     36836352 | elapsed time per iteration (ms): 37671.1 | learning rate: 6.158E-05 | global batch size:  1024 | lm loss: 1.807332E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35974/   51900 | consumed samples:     36837376 | elapsed time per iteration (ms): 37660.4 | learning rate: 6.157E-05 | global batch size:  1024 | lm loss: 1.802794E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35975/   51900 | consumed samples:     36838400 | elapsed time per iteration (ms): 37764.9 | learning rate: 6.157E-05 | global batch size:  1024 | lm loss: 1.819595E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35976/   51900 | consumed samples:     36839424 | elapsed time per iteration (ms): 37703.9 | learning rate: 6.157E-05 | global batch size:  1024 | lm loss: 1.809712E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35977/   51900 | consumed samples:     36840448 | elapsed time per iteration (ms): 37762.5 | learning rate: 6.156E-05 | global batch size:  1024 | lm loss: 1.788633E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35978/   51900 | consumed samples:     36841472 | elapsed time per iteration (ms): 37701.3 | learning rate: 6.156E-05 | global batch size:  1024 | lm loss: 1.815373E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35979/   51900 | consumed samples:     36842496 | elapsed time per iteration (ms): 37620.6 | learning rate: 6.155E-05 | global batch size:  1024 | lm loss: 1.806330E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35980/   51900 | consumed samples:     36843520 | elapsed time per iteration (ms): 37669.9 | learning rate: 6.155E-05 | global batch size:  1024 | lm loss: 1.815023E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35981/   51900 | consumed samples:     36844544 | elapsed time per iteration (ms): 37791.6 | learning rate: 6.154E-05 | global batch size:  1024 | lm loss: 1.808775E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35982/   51900 | consumed samples:     36845568 | elapsed time per iteration (ms): 37721.0 | learning rate: 6.154E-05 | global batch size:  1024 | lm loss: 1.818490E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35983/   51900 | consumed samples:     36846592 | elapsed time per iteration (ms): 37691.0 | learning rate: 6.153E-05 | global batch size:  1024 | lm loss: 1.793896E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35984/   51900 | consumed samples:     36847616 | elapsed time per iteration (ms): 37659.1 | learning rate: 6.153E-05 | global batch size:  1024 | lm loss: 1.801448E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35985/   51900 | consumed samples:     36848640 | elapsed time per iteration (ms): 37674.6 | learning rate: 6.152E-05 | global batch size:  1024 | lm loss: 1.807390E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35986/   51900 | consumed samples:     36849664 | elapsed time per iteration (ms): 37619.2 | learning rate: 6.152E-05 | global batch size:  1024 | lm loss: 1.804329E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35987/   51900 | consumed samples:     36850688 | elapsed time per iteration (ms): 37662.3 | learning rate: 6.151E-05 | global batch size:  1024 | lm loss: 1.815496E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35988/   51900 | consumed samples:     36851712 | elapsed time per iteration (ms): 37649.4 | learning rate: 6.151E-05 | global batch size:  1024 | lm loss: 1.792556E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35989/   51900 | consumed samples:     36852736 | elapsed time per iteration (ms): 37646.5 | learning rate: 6.150E-05 | global batch size:  1024 | lm loss: 1.813217E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35990/   51900 | consumed samples:     36853760 | elapsed time per iteration (ms): 37710.6 | learning rate: 6.150E-05 | global batch size:  1024 | lm loss: 1.809700E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35991/   51900 | consumed samples:     36854784 | elapsed time per iteration (ms): 37770.3 | learning rate: 6.149E-05 | global batch size:  1024 | lm loss: 1.804650E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35992/   51900 | consumed samples:     36855808 | elapsed time per iteration (ms): 37732.7 | learning rate: 6.149E-05 | global batch size:  1024 | lm loss: 1.817592E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35993/   51900 | consumed samples:     36856832 | elapsed time per iteration (ms): 37683.2 | learning rate: 6.148E-05 | global batch size:  1024 | lm loss: 1.814867E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35994/   51900 | consumed samples:     36857856 | elapsed time per iteration (ms): 37775.1 | learning rate: 6.148E-05 | global batch size:  1024 | lm loss: 1.818009E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35995/   51900 | consumed samples:     36858880 | elapsed time per iteration (ms): 37573.1 | learning rate: 6.147E-05 | global batch size:  1024 | lm loss: 1.821641E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35996/   51900 | consumed samples:     36859904 | elapsed time per iteration (ms): 37666.1 | learning rate: 6.147E-05 | global batch size:  1024 | lm loss: 1.812453E+00 | loss scale: 1.0 | grad norm: 0.065 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35997/   51900 | consumed samples:     36860928 | elapsed time per iteration (ms): 37679.2 | learning rate: 6.147E-05 | global batch size:  1024 | lm loss: 1.804231E+00 | loss scale: 1.0 | grad norm: 0.065 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35998/   51900 | consumed samples:     36861952 | elapsed time per iteration (ms): 37726.8 | learning rate: 6.146E-05 | global batch size:  1024 | lm loss: 1.798104E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    35999/   51900 | consumed samples:     36862976 | elapsed time per iteration (ms): 37691.8 | learning rate: 6.146E-05 | global batch size:  1024 | lm loss: 1.800104E+00 | loss scale: 1.0 | grad norm: 0.062 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36000/   51900 | consumed samples:     36864000 | elapsed time per iteration (ms): 37589.2 | learning rate: 6.145E-05 | global batch size:  1024 | lm loss: 1.798802E+00 | loss scale: 1.0 | grad norm: 0.065 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    save-checkpoint ................................: (146228.55, 146228.62)
 iteration    36001/   51900 | consumed samples:     36865024 | elapsed time per iteration (ms): 37697.7 | learning rate: 6.145E-05 | global batch size:  1024 | lm loss: 1.818914E+00 | loss scale: 1.0 | grad norm: 0.065 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36002/   51900 | consumed samples:     36866048 | elapsed time per iteration (ms): 37542.6 | learning rate: 6.144E-05 | global batch size:  1024 | lm loss: 1.812864E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36003/   51900 | consumed samples:     36867072 | elapsed time per iteration (ms): 37677.9 | learning rate: 6.144E-05 | global batch size:  1024 | lm loss: 1.821917E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36004/   51900 | consumed samples:     36868096 | elapsed time per iteration (ms): 37778.7 | learning rate: 6.143E-05 | global batch size:  1024 | lm loss: 1.803186E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36005/   51900 | consumed samples:     36869120 | elapsed time per iteration (ms): 37591.8 | learning rate: 6.143E-05 | global batch size:  1024 | lm loss: 1.809722E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36006/   51900 | consumed samples:     36870144 | elapsed time per iteration (ms): 37669.0 | learning rate: 6.142E-05 | global batch size:  1024 | lm loss: 1.818895E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36007/   51900 | consumed samples:     36871168 | elapsed time per iteration (ms): 37658.5 | learning rate: 6.142E-05 | global batch size:  1024 | lm loss: 1.821504E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36008/   51900 | consumed samples:     36872192 | elapsed time per iteration (ms): 37721.2 | learning rate: 6.141E-05 | global batch size:  1024 | lm loss: 1.795487E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36009/   51900 | consumed samples:     36873216 | elapsed time per iteration (ms): 37930.9 | learning rate: 6.141E-05 | global batch size:  1024 | lm loss: 1.793011E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36010/   51900 | consumed samples:     36874240 | elapsed time per iteration (ms): 37763.5 | learning rate: 6.140E-05 | global batch size:  1024 | lm loss: 1.829248E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36011/   51900 | consumed samples:     36875264 | elapsed time per iteration (ms): 37692.0 | learning rate: 6.140E-05 | global batch size:  1024 | lm loss: 1.824334E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36012/   51900 | consumed samples:     36876288 | elapsed time per iteration (ms): 37708.8 | learning rate: 6.139E-05 | global batch size:  1024 | lm loss: 1.796574E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36013/   51900 | consumed samples:     36877312 | elapsed time per iteration (ms): 37763.3 | learning rate: 6.139E-05 | global batch size:  1024 | lm loss: 1.808171E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36014/   51900 | consumed samples:     36878336 | elapsed time per iteration (ms): 37551.8 | learning rate: 6.138E-05 | global batch size:  1024 | lm loss: 1.814832E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36015/   51900 | consumed samples:     36879360 | elapsed time per iteration (ms): 37628.3 | learning rate: 6.138E-05 | global batch size:  1024 | lm loss: 1.801301E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36016/   51900 | consumed samples:     36880384 | elapsed time per iteration (ms): 37670.1 | learning rate: 6.137E-05 | global batch size:  1024 | lm loss: 1.805508E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36017/   51900 | consumed samples:     36881408 | elapsed time per iteration (ms): 37732.4 | learning rate: 6.137E-05 | global batch size:  1024 | lm loss: 1.812615E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36018/   51900 | consumed samples:     36882432 | elapsed time per iteration (ms): 37620.3 | learning rate: 6.136E-05 | global batch size:  1024 | lm loss: 1.803775E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36019/   51900 | consumed samples:     36883456 | elapsed time per iteration (ms): 37774.6 | learning rate: 6.136E-05 | global batch size:  1024 | lm loss: 1.807066E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36020/   51900 | consumed samples:     36884480 | elapsed time per iteration (ms): 37735.4 | learning rate: 6.136E-05 | global batch size:  1024 | lm loss: 1.810144E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36021/   51900 | consumed samples:     36885504 | elapsed time per iteration (ms): 37588.2 | learning rate: 6.135E-05 | global batch size:  1024 | lm loss: 1.817794E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36022/   51900 | consumed samples:     36886528 | elapsed time per iteration (ms): 37713.0 | learning rate: 6.135E-05 | global batch size:  1024 | lm loss: 1.805763E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36023/   51900 | consumed samples:     36887552 | elapsed time per iteration (ms): 37689.6 | learning rate: 6.134E-05 | global batch size:  1024 | lm loss: 1.800971E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36024/   51900 | consumed samples:     36888576 | elapsed time per iteration (ms): 37770.5 | learning rate: 6.134E-05 | global batch size:  1024 | lm loss: 1.808893E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36025/   51900 | consumed samples:     36889600 | elapsed time per iteration (ms): 37562.1 | learning rate: 6.133E-05 | global batch size:  1024 | lm loss: 1.810963E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36026/   51900 | consumed samples:     36890624 | elapsed time per iteration (ms): 37595.3 | learning rate: 6.133E-05 | global batch size:  1024 | lm loss: 1.803949E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36027/   51900 | consumed samples:     36891648 | elapsed time per iteration (ms): 37609.0 | learning rate: 6.132E-05 | global batch size:  1024 | lm loss: 1.816701E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36028/   51900 | consumed samples:     36892672 | elapsed time per iteration (ms): 37690.8 | learning rate: 6.132E-05 | global batch size:  1024 | lm loss: 1.807658E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36029/   51900 | consumed samples:     36893696 | elapsed time per iteration (ms): 37635.9 | learning rate: 6.131E-05 | global batch size:  1024 | lm loss: 1.829313E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36030/   51900 | consumed samples:     36894720 | elapsed time per iteration (ms): 37703.4 | learning rate: 6.131E-05 | global batch size:  1024 | lm loss: 1.798672E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36031/   51900 | consumed samples:     36895744 | elapsed time per iteration (ms): 37693.3 | learning rate: 6.130E-05 | global batch size:  1024 | lm loss: 1.804011E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36032/   51900 | consumed samples:     36896768 | elapsed time per iteration (ms): 37708.4 | learning rate: 6.130E-05 | global batch size:  1024 | lm loss: 1.806780E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36033/   51900 | consumed samples:     36897792 | elapsed time per iteration (ms): 37777.5 | learning rate: 6.129E-05 | global batch size:  1024 | lm loss: 1.819152E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36034/   51900 | consumed samples:     36898816 | elapsed time per iteration (ms): 37747.3 | learning rate: 6.129E-05 | global batch size:  1024 | lm loss: 1.823399E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36035/   51900 | consumed samples:     36899840 | elapsed time per iteration (ms): 37741.1 | learning rate: 6.128E-05 | global batch size:  1024 | lm loss: 1.809033E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36036/   51900 | consumed samples:     36900864 | elapsed time per iteration (ms): 37566.0 | learning rate: 6.128E-05 | global batch size:  1024 | lm loss: 1.798423E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36037/   51900 | consumed samples:     36901888 | elapsed time per iteration (ms): 37577.2 | learning rate: 6.127E-05 | global batch size:  1024 | lm loss: 1.808985E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36038/   51900 | consumed samples:     36902912 | elapsed time per iteration (ms): 37631.5 | learning rate: 6.127E-05 | global batch size:  1024 | lm loss: 1.810056E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36039/   51900 | consumed samples:     36903936 | elapsed time per iteration (ms): 37682.8 | learning rate: 6.126E-05 | global batch size:  1024 | lm loss: 1.781688E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36040/   51900 | consumed samples:     36904960 | elapsed time per iteration (ms): 37682.8 | learning rate: 6.126E-05 | global batch size:  1024 | lm loss: 1.816037E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36041/   51900 | consumed samples:     36905984 | elapsed time per iteration (ms): 37687.8 | learning rate: 6.126E-05 | global batch size:  1024 | lm loss: 1.808720E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36042/   51900 | consumed samples:     36907008 | elapsed time per iteration (ms): 37687.7 | learning rate: 6.125E-05 | global batch size:  1024 | lm loss: 1.808382E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36043/   51900 | consumed samples:     36908032 | elapsed time per iteration (ms): 37630.7 | learning rate: 6.125E-05 | global batch size:  1024 | lm loss: 1.795242E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36044/   51900 | consumed samples:     36909056 | elapsed time per iteration (ms): 37658.0 | learning rate: 6.124E-05 | global batch size:  1024 | lm loss: 1.815421E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36045/   51900 | consumed samples:     36910080 | elapsed time per iteration (ms): 37766.4 | learning rate: 6.124E-05 | global batch size:  1024 | lm loss: 1.811638E+00 | loss scale: 1.0 | grad norm: 0.131 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36046/   51900 | consumed samples:     36911104 | elapsed time per iteration (ms): 37785.4 | learning rate: 6.123E-05 | global batch size:  1024 | lm loss: 1.801841E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36047/   51900 | consumed samples:     36912128 | elapsed time per iteration (ms): 37756.4 | learning rate: 6.123E-05 | global batch size:  1024 | lm loss: 1.800199E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36048/   51900 | consumed samples:     36913152 | elapsed time per iteration (ms): 37676.7 | learning rate: 6.122E-05 | global batch size:  1024 | lm loss: 1.818468E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36049/   51900 | consumed samples:     36914176 | elapsed time per iteration (ms): 37645.0 | learning rate: 6.122E-05 | global batch size:  1024 | lm loss: 1.806288E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36050/   51900 | consumed samples:     36915200 | elapsed time per iteration (ms): 37871.5 | learning rate: 6.121E-05 | global batch size:  1024 | lm loss: 1.817216E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36051/   51900 | consumed samples:     36916224 | elapsed time per iteration (ms): 37683.4 | learning rate: 6.121E-05 | global batch size:  1024 | lm loss: 1.808391E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36052/   51900 | consumed samples:     36917248 | elapsed time per iteration (ms): 37801.6 | learning rate: 6.120E-05 | global batch size:  1024 | lm loss: 1.805956E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36053/   51900 | consumed samples:     36918272 | elapsed time per iteration (ms): 37678.9 | learning rate: 6.120E-05 | global batch size:  1024 | lm loss: 1.798725E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36054/   51900 | consumed samples:     36919296 | elapsed time per iteration (ms): 37797.7 | learning rate: 6.119E-05 | global batch size:  1024 | lm loss: 1.825126E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36055/   51900 | consumed samples:     36920320 | elapsed time per iteration (ms): 37735.4 | learning rate: 6.119E-05 | global batch size:  1024 | lm loss: 1.799580E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36056/   51900 | consumed samples:     36921344 | elapsed time per iteration (ms): 37643.2 | learning rate: 6.118E-05 | global batch size:  1024 | lm loss: 1.794294E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36057/   51900 | consumed samples:     36922368 | elapsed time per iteration (ms): 37755.0 | learning rate: 6.118E-05 | global batch size:  1024 | lm loss: 1.818709E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36058/   51900 | consumed samples:     36923392 | elapsed time per iteration (ms): 37807.9 | learning rate: 6.117E-05 | global batch size:  1024 | lm loss: 1.816444E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36059/   51900 | consumed samples:     36924416 | elapsed time per iteration (ms): 37689.7 | learning rate: 6.117E-05 | global batch size:  1024 | lm loss: 1.808077E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36060/   51900 | consumed samples:     36925440 | elapsed time per iteration (ms): 37693.3 | learning rate: 6.116E-05 | global batch size:  1024 | lm loss: 1.825952E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36061/   51900 | consumed samples:     36926464 | elapsed time per iteration (ms): 37582.7 | learning rate: 6.116E-05 | global batch size:  1024 | lm loss: 1.815155E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36062/   51900 | consumed samples:     36927488 | elapsed time per iteration (ms): 37664.3 | learning rate: 6.116E-05 | global batch size:  1024 | lm loss: 1.804071E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36063/   51900 | consumed samples:     36928512 | elapsed time per iteration (ms): 37745.2 | learning rate: 6.115E-05 | global batch size:  1024 | lm loss: 1.803005E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36064/   51900 | consumed samples:     36929536 | elapsed time per iteration (ms): 37624.5 | learning rate: 6.115E-05 | global batch size:  1024 | lm loss: 1.805839E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36065/   51900 | consumed samples:     36930560 | elapsed time per iteration (ms): 37566.5 | learning rate: 6.114E-05 | global batch size:  1024 | lm loss: 1.822642E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36066/   51900 | consumed samples:     36931584 | elapsed time per iteration (ms): 37742.7 | learning rate: 6.114E-05 | global batch size:  1024 | lm loss: 1.812845E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36067/   51900 | consumed samples:     36932608 | elapsed time per iteration (ms): 37575.6 | learning rate: 6.113E-05 | global batch size:  1024 | lm loss: 1.789702E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36068/   51900 | consumed samples:     36933632 | elapsed time per iteration (ms): 37682.2 | learning rate: 6.113E-05 | global batch size:  1024 | lm loss: 1.798368E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36069/   51900 | consumed samples:     36934656 | elapsed time per iteration (ms): 37601.1 | learning rate: 6.112E-05 | global batch size:  1024 | lm loss: 1.817469E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36070/   51900 | consumed samples:     36935680 | elapsed time per iteration (ms): 37697.1 | learning rate: 6.112E-05 | global batch size:  1024 | lm loss: 1.810436E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36071/   51900 | consumed samples:     36936704 | elapsed time per iteration (ms): 37674.4 | learning rate: 6.111E-05 | global batch size:  1024 | lm loss: 1.814302E+00 | loss scale: 1.0 | grad norm: 0.065 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36072/   51900 | consumed samples:     36937728 | elapsed time per iteration (ms): 37633.6 | learning rate: 6.111E-05 | global batch size:  1024 | lm loss: 1.826685E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36073/   51900 | consumed samples:     36938752 | elapsed time per iteration (ms): 37634.5 | learning rate: 6.110E-05 | global batch size:  1024 | lm loss: 1.792573E+00 | loss scale: 1.0 | grad norm: 0.065 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36074/   51900 | consumed samples:     36939776 | elapsed time per iteration (ms): 37625.5 | learning rate: 6.110E-05 | global batch size:  1024 | lm loss: 1.811709E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36075/   51900 | consumed samples:     36940800 | elapsed time per iteration (ms): 37592.7 | learning rate: 6.109E-05 | global batch size:  1024 | lm loss: 1.800851E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36076/   51900 | consumed samples:     36941824 | elapsed time per iteration (ms): 37751.5 | learning rate: 6.109E-05 | global batch size:  1024 | lm loss: 1.829855E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36077/   51900 | consumed samples:     36942848 | elapsed time per iteration (ms): 37704.1 | learning rate: 6.108E-05 | global batch size:  1024 | lm loss: 1.818327E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36078/   51900 | consumed samples:     36943872 | elapsed time per iteration (ms): 37667.1 | learning rate: 6.108E-05 | global batch size:  1024 | lm loss: 1.812101E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36079/   51900 | consumed samples:     36944896 | elapsed time per iteration (ms): 37712.7 | learning rate: 6.107E-05 | global batch size:  1024 | lm loss: 1.804941E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36080/   51900 | consumed samples:     36945920 | elapsed time per iteration (ms): 37701.6 | learning rate: 6.107E-05 | global batch size:  1024 | lm loss: 1.806362E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36081/   51900 | consumed samples:     36946944 | elapsed time per iteration (ms): 37673.7 | learning rate: 6.106E-05 | global batch size:  1024 | lm loss: 1.834381E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36082/   51900 | consumed samples:     36947968 | elapsed time per iteration (ms): 37698.2 | learning rate: 6.106E-05 | global batch size:  1024 | lm loss: 1.806002E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36083/   51900 | consumed samples:     36948992 | elapsed time per iteration (ms): 37669.1 | learning rate: 6.106E-05 | global batch size:  1024 | lm loss: 1.825195E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36084/   51900 | consumed samples:     36950016 | elapsed time per iteration (ms): 37614.1 | learning rate: 6.105E-05 | global batch size:  1024 | lm loss: 1.838743E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36085/   51900 | consumed samples:     36951040 | elapsed time per iteration (ms): 37646.2 | learning rate: 6.105E-05 | global batch size:  1024 | lm loss: 1.828602E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36086/   51900 | consumed samples:     36952064 | elapsed time per iteration (ms): 37684.9 | learning rate: 6.104E-05 | global batch size:  1024 | lm loss: 1.802465E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36087/   51900 | consumed samples:     36953088 | elapsed time per iteration (ms): 37647.7 | learning rate: 6.104E-05 | global batch size:  1024 | lm loss: 1.791338E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36088/   51900 | consumed samples:     36954112 | elapsed time per iteration (ms): 37615.4 | learning rate: 6.103E-05 | global batch size:  1024 | lm loss: 1.814985E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36089/   51900 | consumed samples:     36955136 | elapsed time per iteration (ms): 37599.5 | learning rate: 6.103E-05 | global batch size:  1024 | lm loss: 1.811432E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36090/   51900 | consumed samples:     36956160 | elapsed time per iteration (ms): 37563.9 | learning rate: 6.102E-05 | global batch size:  1024 | lm loss: 1.828206E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36091/   51900 | consumed samples:     36957184 | elapsed time per iteration (ms): 37625.4 | learning rate: 6.102E-05 | global batch size:  1024 | lm loss: 1.812986E+00 | loss scale: 1.0 | grad norm: 0.065 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36092/   51900 | consumed samples:     36958208 | elapsed time per iteration (ms): 37681.9 | learning rate: 6.101E-05 | global batch size:  1024 | lm loss: 1.804798E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36093/   51900 | consumed samples:     36959232 | elapsed time per iteration (ms): 37628.9 | learning rate: 6.101E-05 | global batch size:  1024 | lm loss: 1.816504E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36094/   51900 | consumed samples:     36960256 | elapsed time per iteration (ms): 37584.8 | learning rate: 6.100E-05 | global batch size:  1024 | lm loss: 1.792290E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36095/   51900 | consumed samples:     36961280 | elapsed time per iteration (ms): 37702.6 | learning rate: 6.100E-05 | global batch size:  1024 | lm loss: 1.804601E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36096/   51900 | consumed samples:     36962304 | elapsed time per iteration (ms): 37612.3 | learning rate: 6.099E-05 | global batch size:  1024 | lm loss: 1.802027E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36097/   51900 | consumed samples:     36963328 | elapsed time per iteration (ms): 37627.2 | learning rate: 6.099E-05 | global batch size:  1024 | lm loss: 1.828399E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36098/   51900 | consumed samples:     36964352 | elapsed time per iteration (ms): 37697.7 | learning rate: 6.098E-05 | global batch size:  1024 | lm loss: 1.826632E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36099/   51900 | consumed samples:     36965376 | elapsed time per iteration (ms): 37698.5 | learning rate: 6.098E-05 | global batch size:  1024 | lm loss: 1.811344E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36100/   51900 | consumed samples:     36966400 | elapsed time per iteration (ms): 37642.9 | learning rate: 6.097E-05 | global batch size:  1024 | lm loss: 1.832140E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36101/   51900 | consumed samples:     36967424 | elapsed time per iteration (ms): 37712.8 | learning rate: 6.097E-05 | global batch size:  1024 | lm loss: 1.792133E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36102/   51900 | consumed samples:     36968448 | elapsed time per iteration (ms): 37683.0 | learning rate: 6.097E-05 | global batch size:  1024 | lm loss: 1.814490E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36103/   51900 | consumed samples:     36969472 | elapsed time per iteration (ms): 37599.3 | learning rate: 6.096E-05 | global batch size:  1024 | lm loss: 1.798811E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36104/   51900 | consumed samples:     36970496 | elapsed time per iteration (ms): 37692.1 | learning rate: 6.096E-05 | global batch size:  1024 | lm loss: 1.816984E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36105/   51900 | consumed samples:     36971520 | elapsed time per iteration (ms): 37693.9 | learning rate: 6.095E-05 | global batch size:  1024 | lm loss: 1.810655E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36106/   51900 | consumed samples:     36972544 | elapsed time per iteration (ms): 37610.5 | learning rate: 6.095E-05 | global batch size:  1024 | lm loss: 1.807034E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36107/   51900 | consumed samples:     36973568 | elapsed time per iteration (ms): 37647.9 | learning rate: 6.094E-05 | global batch size:  1024 | lm loss: 1.812837E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36108/   51900 | consumed samples:     36974592 | elapsed time per iteration (ms): 37592.3 | learning rate: 6.094E-05 | global batch size:  1024 | lm loss: 1.805406E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36109/   51900 | consumed samples:     36975616 | elapsed time per iteration (ms): 37638.1 | learning rate: 6.093E-05 | global batch size:  1024 | lm loss: 1.804972E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36110/   51900 | consumed samples:     36976640 | elapsed time per iteration (ms): 37583.1 | learning rate: 6.093E-05 | global batch size:  1024 | lm loss: 1.807562E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36111/   51900 | consumed samples:     36977664 | elapsed time per iteration (ms): 37622.7 | learning rate: 6.092E-05 | global batch size:  1024 | lm loss: 1.813863E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36112/   51900 | consumed samples:     36978688 | elapsed time per iteration (ms): 37599.0 | learning rate: 6.092E-05 | global batch size:  1024 | lm loss: 1.802613E+00 | loss scale: 1.0 | grad norm: 0.092 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36113/   51900 | consumed samples:     36979712 | elapsed time per iteration (ms): 37749.8 | learning rate: 6.091E-05 | global batch size:  1024 | lm loss: 1.807222E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36114/   51900 | consumed samples:     36980736 | elapsed time per iteration (ms): 37542.9 | learning rate: 6.091E-05 | global batch size:  1024 | lm loss: 1.825304E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36115/   51900 | consumed samples:     36981760 | elapsed time per iteration (ms): 37763.6 | learning rate: 6.090E-05 | global batch size:  1024 | lm loss: 1.815508E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36116/   51900 | consumed samples:     36982784 | elapsed time per iteration (ms): 37667.5 | learning rate: 6.090E-05 | global batch size:  1024 | lm loss: 1.809742E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36117/   51900 | consumed samples:     36983808 | elapsed time per iteration (ms): 37638.3 | learning rate: 6.089E-05 | global batch size:  1024 | lm loss: 1.805937E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36118/   51900 | consumed samples:     36984832 | elapsed time per iteration (ms): 37555.9 | learning rate: 6.089E-05 | global batch size:  1024 | lm loss: 1.807921E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36119/   51900 | consumed samples:     36985856 | elapsed time per iteration (ms): 37685.1 | learning rate: 6.088E-05 | global batch size:  1024 | lm loss: 1.810749E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36120/   51900 | consumed samples:     36986880 | elapsed time per iteration (ms): 37680.5 | learning rate: 6.088E-05 | global batch size:  1024 | lm loss: 1.809356E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36121/   51900 | consumed samples:     36987904 | elapsed time per iteration (ms): 37652.8 | learning rate: 6.087E-05 | global batch size:  1024 | lm loss: 1.794242E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36122/   51900 | consumed samples:     36988928 | elapsed time per iteration (ms): 37816.7 | learning rate: 6.087E-05 | global batch size:  1024 | lm loss: 1.814373E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36123/   51900 | consumed samples:     36989952 | elapsed time per iteration (ms): 37728.6 | learning rate: 6.087E-05 | global batch size:  1024 | lm loss: 1.798504E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36124/   51900 | consumed samples:     36990976 | elapsed time per iteration (ms): 37731.7 | learning rate: 6.086E-05 | global batch size:  1024 | lm loss: 1.803710E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36125/   51900 | consumed samples:     36992000 | elapsed time per iteration (ms): 37606.6 | learning rate: 6.086E-05 | global batch size:  1024 | lm loss: 1.809109E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36126/   51900 | consumed samples:     36993024 | elapsed time per iteration (ms): 37627.9 | learning rate: 6.085E-05 | global batch size:  1024 | lm loss: 1.821481E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36127/   51900 | consumed samples:     36994048 | elapsed time per iteration (ms): 37548.3 | learning rate: 6.085E-05 | global batch size:  1024 | lm loss: 1.824638E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36128/   51900 | consumed samples:     36995072 | elapsed time per iteration (ms): 37692.3 | learning rate: 6.084E-05 | global batch size:  1024 | lm loss: 1.807083E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36129/   51900 | consumed samples:     36996096 | elapsed time per iteration (ms): 37613.8 | learning rate: 6.084E-05 | global batch size:  1024 | lm loss: 1.814574E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36130/   51900 | consumed samples:     36997120 | elapsed time per iteration (ms): 37592.9 | learning rate: 6.083E-05 | global batch size:  1024 | lm loss: 1.809515E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36131/   51900 | consumed samples:     36998144 | elapsed time per iteration (ms): 37673.5 | learning rate: 6.083E-05 | global batch size:  1024 | lm loss: 1.817017E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36132/   51900 | consumed samples:     36999168 | elapsed time per iteration (ms): 37695.3 | learning rate: 6.082E-05 | global batch size:  1024 | lm loss: 1.824122E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36133/   51900 | consumed samples:     37000192 | elapsed time per iteration (ms): 37673.2 | learning rate: 6.082E-05 | global batch size:  1024 | lm loss: 1.827109E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36134/   51900 | consumed samples:     37001216 | elapsed time per iteration (ms): 37654.8 | learning rate: 6.081E-05 | global batch size:  1024 | lm loss: 1.824802E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36135/   51900 | consumed samples:     37002240 | elapsed time per iteration (ms): 37783.0 | learning rate: 6.081E-05 | global batch size:  1024 | lm loss: 1.828707E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36136/   51900 | consumed samples:     37003264 | elapsed time per iteration (ms): 37666.2 | learning rate: 6.080E-05 | global batch size:  1024 | lm loss: 1.819638E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36137/   51900 | consumed samples:     37004288 | elapsed time per iteration (ms): 37689.4 | learning rate: 6.080E-05 | global batch size:  1024 | lm loss: 1.813248E+00 | loss scale: 1.0 | grad norm: 0.063 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36138/   51900 | consumed samples:     37005312 | elapsed time per iteration (ms): 37705.6 | learning rate: 6.079E-05 | global batch size:  1024 | lm loss: 1.796361E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36139/   51900 | consumed samples:     37006336 | elapsed time per iteration (ms): 37682.9 | learning rate: 6.079E-05 | global batch size:  1024 | lm loss: 1.806350E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36140/   51900 | consumed samples:     37007360 | elapsed time per iteration (ms): 37709.6 | learning rate: 6.078E-05 | global batch size:  1024 | lm loss: 1.813252E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36141/   51900 | consumed samples:     37008384 | elapsed time per iteration (ms): 37708.1 | learning rate: 6.078E-05 | global batch size:  1024 | lm loss: 1.799063E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36142/   51900 | consumed samples:     37009408 | elapsed time per iteration (ms): 37664.7 | learning rate: 6.078E-05 | global batch size:  1024 | lm loss: 1.807965E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36143/   51900 | consumed samples:     37010432 | elapsed time per iteration (ms): 37664.1 | learning rate: 6.077E-05 | global batch size:  1024 | lm loss: 1.800773E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36144/   51900 | consumed samples:     37011456 | elapsed time per iteration (ms): 37680.9 | learning rate: 6.077E-05 | global batch size:  1024 | lm loss: 1.807045E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36145/   51900 | consumed samples:     37012480 | elapsed time per iteration (ms): 37740.2 | learning rate: 6.076E-05 | global batch size:  1024 | lm loss: 1.794229E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36146/   51900 | consumed samples:     37013504 | elapsed time per iteration (ms): 37658.0 | learning rate: 6.076E-05 | global batch size:  1024 | lm loss: 1.817265E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36147/   51900 | consumed samples:     37014528 | elapsed time per iteration (ms): 37707.4 | learning rate: 6.075E-05 | global batch size:  1024 | lm loss: 1.808763E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36148/   51900 | consumed samples:     37015552 | elapsed time per iteration (ms): 37652.7 | learning rate: 6.075E-05 | global batch size:  1024 | lm loss: 1.804450E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36149/   51900 | consumed samples:     37016576 | elapsed time per iteration (ms): 37579.1 | learning rate: 6.074E-05 | global batch size:  1024 | lm loss: 1.817382E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36150/   51900 | consumed samples:     37017600 | elapsed time per iteration (ms): 37629.8 | learning rate: 6.074E-05 | global batch size:  1024 | lm loss: 1.825174E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36151/   51900 | consumed samples:     37018624 | elapsed time per iteration (ms): 37682.9 | learning rate: 6.073E-05 | global batch size:  1024 | lm loss: 1.832253E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36152/   51900 | consumed samples:     37019648 | elapsed time per iteration (ms): 37533.5 | learning rate: 6.073E-05 | global batch size:  1024 | lm loss: 1.819778E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36153/   51900 | consumed samples:     37020672 | elapsed time per iteration (ms): 37742.0 | learning rate: 6.072E-05 | global batch size:  1024 | lm loss: 1.791129E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36154/   51900 | consumed samples:     37021696 | elapsed time per iteration (ms): 37626.8 | learning rate: 6.072E-05 | global batch size:  1024 | lm loss: 1.805116E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36155/   51900 | consumed samples:     37022720 | elapsed time per iteration (ms): 37585.7 | learning rate: 6.071E-05 | global batch size:  1024 | lm loss: 1.793921E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36156/   51900 | consumed samples:     37023744 | elapsed time per iteration (ms): 37788.8 | learning rate: 6.071E-05 | global batch size:  1024 | lm loss: 1.810296E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36157/   51900 | consumed samples:     37024768 | elapsed time per iteration (ms): 37703.6 | learning rate: 6.070E-05 | global batch size:  1024 | lm loss: 1.818758E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36158/   51900 | consumed samples:     37025792 | elapsed time per iteration (ms): 37636.4 | learning rate: 6.070E-05 | global batch size:  1024 | lm loss: 1.809149E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36159/   51900 | consumed samples:     37026816 | elapsed time per iteration (ms): 37756.1 | learning rate: 6.069E-05 | global batch size:  1024 | lm loss: 1.820684E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36160/   51900 | consumed samples:     37027840 | elapsed time per iteration (ms): 37716.4 | learning rate: 6.069E-05 | global batch size:  1024 | lm loss: 1.806779E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36161/   51900 | consumed samples:     37028864 | elapsed time per iteration (ms): 37589.1 | learning rate: 6.069E-05 | global batch size:  1024 | lm loss: 1.797556E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36162/   51900 | consumed samples:     37029888 | elapsed time per iteration (ms): 37676.9 | learning rate: 6.068E-05 | global batch size:  1024 | lm loss: 1.825958E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36163/   51900 | consumed samples:     37030912 | elapsed time per iteration (ms): 37802.2 | learning rate: 6.068E-05 | global batch size:  1024 | lm loss: 1.804792E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36164/   51900 | consumed samples:     37031936 | elapsed time per iteration (ms): 37632.7 | learning rate: 6.067E-05 | global batch size:  1024 | lm loss: 1.803548E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36165/   51900 | consumed samples:     37032960 | elapsed time per iteration (ms): 37690.8 | learning rate: 6.067E-05 | global batch size:  1024 | lm loss: 1.820244E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36166/   51900 | consumed samples:     37033984 | elapsed time per iteration (ms): 37657.9 | learning rate: 6.066E-05 | global batch size:  1024 | lm loss: 1.787311E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36167/   51900 | consumed samples:     37035008 | elapsed time per iteration (ms): 37704.7 | learning rate: 6.066E-05 | global batch size:  1024 | lm loss: 1.805620E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36168/   51900 | consumed samples:     37036032 | elapsed time per iteration (ms): 37565.8 | learning rate: 6.065E-05 | global batch size:  1024 | lm loss: 1.807334E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36169/   51900 | consumed samples:     37037056 | elapsed time per iteration (ms): 37698.9 | learning rate: 6.065E-05 | global batch size:  1024 | lm loss: 1.806692E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36170/   51900 | consumed samples:     37038080 | elapsed time per iteration (ms): 37764.2 | learning rate: 6.064E-05 | global batch size:  1024 | lm loss: 1.811575E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36171/   51900 | consumed samples:     37039104 | elapsed time per iteration (ms): 37678.2 | learning rate: 6.064E-05 | global batch size:  1024 | lm loss: 1.811036E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36172/   51900 | consumed samples:     37040128 | elapsed time per iteration (ms): 37736.3 | learning rate: 6.063E-05 | global batch size:  1024 | lm loss: 1.795727E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36173/   51900 | consumed samples:     37041152 | elapsed time per iteration (ms): 37733.1 | learning rate: 6.063E-05 | global batch size:  1024 | lm loss: 1.820635E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36174/   51900 | consumed samples:     37042176 | elapsed time per iteration (ms): 37720.5 | learning rate: 6.062E-05 | global batch size:  1024 | lm loss: 1.819682E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36175/   51900 | consumed samples:     37043200 | elapsed time per iteration (ms): 37567.4 | learning rate: 6.062E-05 | global batch size:  1024 | lm loss: 1.813292E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36176/   51900 | consumed samples:     37044224 | elapsed time per iteration (ms): 37669.3 | learning rate: 6.061E-05 | global batch size:  1024 | lm loss: 1.807559E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36177/   51900 | consumed samples:     37045248 | elapsed time per iteration (ms): 37646.7 | learning rate: 6.061E-05 | global batch size:  1024 | lm loss: 1.814013E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36178/   51900 | consumed samples:     37046272 | elapsed time per iteration (ms): 37644.2 | learning rate: 6.060E-05 | global batch size:  1024 | lm loss: 1.808013E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36179/   51900 | consumed samples:     37047296 | elapsed time per iteration (ms): 37756.1 | learning rate: 6.060E-05 | global batch size:  1024 | lm loss: 1.818964E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36180/   51900 | consumed samples:     37048320 | elapsed time per iteration (ms): 37662.9 | learning rate: 6.060E-05 | global batch size:  1024 | lm loss: 1.813936E+00 | loss scale: 1.0 | grad norm: 0.063 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36181/   51900 | consumed samples:     37049344 | elapsed time per iteration (ms): 37657.6 | learning rate: 6.059E-05 | global batch size:  1024 | lm loss: 1.804852E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36182/   51900 | consumed samples:     37050368 | elapsed time per iteration (ms): 37717.7 | learning rate: 6.059E-05 | global batch size:  1024 | lm loss: 1.799331E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36183/   51900 | consumed samples:     37051392 | elapsed time per iteration (ms): 37666.2 | learning rate: 6.058E-05 | global batch size:  1024 | lm loss: 1.808530E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36184/   51900 | consumed samples:     37052416 | elapsed time per iteration (ms): 37608.1 | learning rate: 6.058E-05 | global batch size:  1024 | lm loss: 1.813416E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36185/   51900 | consumed samples:     37053440 | elapsed time per iteration (ms): 37640.2 | learning rate: 6.057E-05 | global batch size:  1024 | lm loss: 1.806362E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36186/   51900 | consumed samples:     37054464 | elapsed time per iteration (ms): 37628.6 | learning rate: 6.057E-05 | global batch size:  1024 | lm loss: 1.823846E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36187/   51900 | consumed samples:     37055488 | elapsed time per iteration (ms): 37739.0 | learning rate: 6.056E-05 | global batch size:  1024 | lm loss: 1.825831E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36188/   51900 | consumed samples:     37056512 | elapsed time per iteration (ms): 37710.6 | learning rate: 6.056E-05 | global batch size:  1024 | lm loss: 1.814354E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36189/   51900 | consumed samples:     37057536 | elapsed time per iteration (ms): 37717.6 | learning rate: 6.055E-05 | global batch size:  1024 | lm loss: 1.804421E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36190/   51900 | consumed samples:     37058560 | elapsed time per iteration (ms): 37681.3 | learning rate: 6.055E-05 | global batch size:  1024 | lm loss: 1.804741E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36191/   51900 | consumed samples:     37059584 | elapsed time per iteration (ms): 37718.7 | learning rate: 6.054E-05 | global batch size:  1024 | lm loss: 1.815856E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36192/   51900 | consumed samples:     37060608 | elapsed time per iteration (ms): 37603.3 | learning rate: 6.054E-05 | global batch size:  1024 | lm loss: 1.812056E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36193/   51900 | consumed samples:     37061632 | elapsed time per iteration (ms): 37665.9 | learning rate: 6.053E-05 | global batch size:  1024 | lm loss: 1.817841E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36194/   51900 | consumed samples:     37062656 | elapsed time per iteration (ms): 37713.8 | learning rate: 6.053E-05 | global batch size:  1024 | lm loss: 1.805644E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36195/   51900 | consumed samples:     37063680 | elapsed time per iteration (ms): 37645.5 | learning rate: 6.052E-05 | global batch size:  1024 | lm loss: 1.797690E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36196/   51900 | consumed samples:     37064704 | elapsed time per iteration (ms): 37631.0 | learning rate: 6.052E-05 | global batch size:  1024 | lm loss: 1.795848E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36197/   51900 | consumed samples:     37065728 | elapsed time per iteration (ms): 37713.5 | learning rate: 6.051E-05 | global batch size:  1024 | lm loss: 1.794142E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36198/   51900 | consumed samples:     37066752 | elapsed time per iteration (ms): 37659.8 | learning rate: 6.051E-05 | global batch size:  1024 | lm loss: 1.817972E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36199/   51900 | consumed samples:     37067776 | elapsed time per iteration (ms): 37689.9 | learning rate: 6.051E-05 | global batch size:  1024 | lm loss: 1.814084E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36200/   51900 | consumed samples:     37068800 | elapsed time per iteration (ms): 37642.4 | learning rate: 6.050E-05 | global batch size:  1024 | lm loss: 1.797545E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36201/   51900 | consumed samples:     37069824 | elapsed time per iteration (ms): 37621.7 | learning rate: 6.050E-05 | global batch size:  1024 | lm loss: 1.805802E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36202/   51900 | consumed samples:     37070848 | elapsed time per iteration (ms): 37659.0 | learning rate: 6.049E-05 | global batch size:  1024 | lm loss: 1.791277E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36203/   51900 | consumed samples:     37071872 | elapsed time per iteration (ms): 37685.7 | learning rate: 6.049E-05 | global batch size:  1024 | lm loss: 1.807406E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36204/   51900 | consumed samples:     37072896 | elapsed time per iteration (ms): 37678.7 | learning rate: 6.048E-05 | global batch size:  1024 | lm loss: 1.812555E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36205/   51900 | consumed samples:     37073920 | elapsed time per iteration (ms): 37646.5 | learning rate: 6.048E-05 | global batch size:  1024 | lm loss: 1.812300E+00 | loss scale: 1.0 | grad norm: 0.065 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36206/   51900 | consumed samples:     37074944 | elapsed time per iteration (ms): 37703.4 | learning rate: 6.047E-05 | global batch size:  1024 | lm loss: 1.806549E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36207/   51900 | consumed samples:     37075968 | elapsed time per iteration (ms): 37705.8 | learning rate: 6.047E-05 | global batch size:  1024 | lm loss: 1.800393E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36208/   51900 | consumed samples:     37076992 | elapsed time per iteration (ms): 37667.0 | learning rate: 6.046E-05 | global batch size:  1024 | lm loss: 1.801990E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36209/   51900 | consumed samples:     37078016 | elapsed time per iteration (ms): 37712.6 | learning rate: 6.046E-05 | global batch size:  1024 | lm loss: 1.813306E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36210/   51900 | consumed samples:     37079040 | elapsed time per iteration (ms): 37618.5 | learning rate: 6.045E-05 | global batch size:  1024 | lm loss: 1.805260E+00 | loss scale: 1.0 | grad norm: 0.064 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36211/   51900 | consumed samples:     37080064 | elapsed time per iteration (ms): 37731.5 | learning rate: 6.045E-05 | global batch size:  1024 | lm loss: 1.802285E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36212/   51900 | consumed samples:     37081088 | elapsed time per iteration (ms): 37728.8 | learning rate: 6.044E-05 | global batch size:  1024 | lm loss: 1.814704E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36213/   51900 | consumed samples:     37082112 | elapsed time per iteration (ms): 37666.6 | learning rate: 6.044E-05 | global batch size:  1024 | lm loss: 1.784955E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36214/   51900 | consumed samples:     37083136 | elapsed time per iteration (ms): 37679.8 | learning rate: 6.043E-05 | global batch size:  1024 | lm loss: 1.808661E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36215/   51900 | consumed samples:     37084160 | elapsed time per iteration (ms): 37731.3 | learning rate: 6.043E-05 | global batch size:  1024 | lm loss: 1.827277E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36216/   51900 | consumed samples:     37085184 | elapsed time per iteration (ms): 37640.2 | learning rate: 6.042E-05 | global batch size:  1024 | lm loss: 1.808920E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36217/   51900 | consumed samples:     37086208 | elapsed time per iteration (ms): 37618.4 | learning rate: 6.042E-05 | global batch size:  1024 | lm loss: 1.804392E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36218/   51900 | consumed samples:     37087232 | elapsed time per iteration (ms): 37530.0 | learning rate: 6.042E-05 | global batch size:  1024 | lm loss: 1.822949E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36219/   51900 | consumed samples:     37088256 | elapsed time per iteration (ms): 37701.1 | learning rate: 6.041E-05 | global batch size:  1024 | lm loss: 1.813689E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36220/   51900 | consumed samples:     37089280 | elapsed time per iteration (ms): 37782.3 | learning rate: 6.041E-05 | global batch size:  1024 | lm loss: 1.810416E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36221/   51900 | consumed samples:     37090304 | elapsed time per iteration (ms): 37644.2 | learning rate: 6.040E-05 | global batch size:  1024 | lm loss: 1.803631E+00 | loss scale: 1.0 | grad norm: 0.208 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36222/   51900 | consumed samples:     37091328 | elapsed time per iteration (ms): 37662.0 | learning rate: 6.040E-05 | global batch size:  1024 | lm loss: 1.826646E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36223/   51900 | consumed samples:     37092352 | elapsed time per iteration (ms): 37603.2 | learning rate: 6.039E-05 | global batch size:  1024 | lm loss: 1.815594E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36224/   51900 | consumed samples:     37093376 | elapsed time per iteration (ms): 37767.7 | learning rate: 6.039E-05 | global batch size:  1024 | lm loss: 1.809651E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36225/   51900 | consumed samples:     37094400 | elapsed time per iteration (ms): 37681.5 | learning rate: 6.038E-05 | global batch size:  1024 | lm loss: 1.813667E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36226/   51900 | consumed samples:     37095424 | elapsed time per iteration (ms): 37683.7 | learning rate: 6.038E-05 | global batch size:  1024 | lm loss: 1.791403E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36227/   51900 | consumed samples:     37096448 | elapsed time per iteration (ms): 37663.1 | learning rate: 6.037E-05 | global batch size:  1024 | lm loss: 1.816452E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36228/   51900 | consumed samples:     37097472 | elapsed time per iteration (ms): 37636.1 | learning rate: 6.037E-05 | global batch size:  1024 | lm loss: 1.815647E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36229/   51900 | consumed samples:     37098496 | elapsed time per iteration (ms): 37674.1 | learning rate: 6.036E-05 | global batch size:  1024 | lm loss: 1.805147E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36230/   51900 | consumed samples:     37099520 | elapsed time per iteration (ms): 37741.6 | learning rate: 6.036E-05 | global batch size:  1024 | lm loss: 1.825850E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36231/   51900 | consumed samples:     37100544 | elapsed time per iteration (ms): 37681.1 | learning rate: 6.035E-05 | global batch size:  1024 | lm loss: 1.806323E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36232/   51900 | consumed samples:     37101568 | elapsed time per iteration (ms): 37665.4 | learning rate: 6.035E-05 | global batch size:  1024 | lm loss: 1.797680E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36233/   51900 | consumed samples:     37102592 | elapsed time per iteration (ms): 37627.8 | learning rate: 6.034E-05 | global batch size:  1024 | lm loss: 1.800244E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36234/   51900 | consumed samples:     37103616 | elapsed time per iteration (ms): 37551.5 | learning rate: 6.034E-05 | global batch size:  1024 | lm loss: 1.816447E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36235/   51900 | consumed samples:     37104640 | elapsed time per iteration (ms): 37634.0 | learning rate: 6.033E-05 | global batch size:  1024 | lm loss: 1.806666E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36236/   51900 | consumed samples:     37105664 | elapsed time per iteration (ms): 37638.7 | learning rate: 6.033E-05 | global batch size:  1024 | lm loss: 1.811101E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36237/   51900 | consumed samples:     37106688 | elapsed time per iteration (ms): 37656.9 | learning rate: 6.033E-05 | global batch size:  1024 | lm loss: 1.817109E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36238/   51900 | consumed samples:     37107712 | elapsed time per iteration (ms): 37804.0 | learning rate: 6.032E-05 | global batch size:  1024 | lm loss: 1.811754E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36239/   51900 | consumed samples:     37108736 | elapsed time per iteration (ms): 37642.9 | learning rate: 6.032E-05 | global batch size:  1024 | lm loss: 1.822732E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36240/   51900 | consumed samples:     37109760 | elapsed time per iteration (ms): 37713.1 | learning rate: 6.031E-05 | global batch size:  1024 | lm loss: 1.795409E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36241/   51900 | consumed samples:     37110784 | elapsed time per iteration (ms): 37665.8 | learning rate: 6.031E-05 | global batch size:  1024 | lm loss: 1.797451E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36242/   51900 | consumed samples:     37111808 | elapsed time per iteration (ms): 37670.3 | learning rate: 6.030E-05 | global batch size:  1024 | lm loss: 1.813859E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36243/   51900 | consumed samples:     37112832 | elapsed time per iteration (ms): 37538.3 | learning rate: 6.030E-05 | global batch size:  1024 | lm loss: 1.810714E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36244/   51900 | consumed samples:     37113856 | elapsed time per iteration (ms): 37616.6 | learning rate: 6.029E-05 | global batch size:  1024 | lm loss: 1.821353E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36245/   51900 | consumed samples:     37114880 | elapsed time per iteration (ms): 37768.0 | learning rate: 6.029E-05 | global batch size:  1024 | lm loss: 1.792472E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36246/   51900 | consumed samples:     37115904 | elapsed time per iteration (ms): 37695.4 | learning rate: 6.028E-05 | global batch size:  1024 | lm loss: 1.817690E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36247/   51900 | consumed samples:     37116928 | elapsed time per iteration (ms): 37713.4 | learning rate: 6.028E-05 | global batch size:  1024 | lm loss: 1.809242E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36248/   51900 | consumed samples:     37117952 | elapsed time per iteration (ms): 37710.2 | learning rate: 6.027E-05 | global batch size:  1024 | lm loss: 1.824088E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36249/   51900 | consumed samples:     37118976 | elapsed time per iteration (ms): 37718.8 | learning rate: 6.027E-05 | global batch size:  1024 | lm loss: 1.816834E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36250/   51900 | consumed samples:     37120000 | elapsed time per iteration (ms): 37574.5 | learning rate: 6.026E-05 | global batch size:  1024 | lm loss: 1.820380E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36251/   51900 | consumed samples:     37121024 | elapsed time per iteration (ms): 37591.8 | learning rate: 6.026E-05 | global batch size:  1024 | lm loss: 1.797860E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36252/   51900 | consumed samples:     37122048 | elapsed time per iteration (ms): 37624.3 | learning rate: 6.025E-05 | global batch size:  1024 | lm loss: 1.804157E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36253/   51900 | consumed samples:     37123072 | elapsed time per iteration (ms): 37706.1 | learning rate: 6.025E-05 | global batch size:  1024 | lm loss: 1.811476E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36254/   51900 | consumed samples:     37124096 | elapsed time per iteration (ms): 37663.0 | learning rate: 6.025E-05 | global batch size:  1024 | lm loss: 1.812753E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36255/   51900 | consumed samples:     37125120 | elapsed time per iteration (ms): 37654.7 | learning rate: 6.024E-05 | global batch size:  1024 | lm loss: 1.808772E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36256/   51900 | consumed samples:     37126144 | elapsed time per iteration (ms): 37681.1 | learning rate: 6.024E-05 | global batch size:  1024 | lm loss: 1.800097E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36257/   51900 | consumed samples:     37127168 | elapsed time per iteration (ms): 37865.9 | learning rate: 6.023E-05 | global batch size:  1024 | lm loss: 1.813294E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36258/   51900 | consumed samples:     37128192 | elapsed time per iteration (ms): 37696.8 | learning rate: 6.023E-05 | global batch size:  1024 | lm loss: 1.808038E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36259/   51900 | consumed samples:     37129216 | elapsed time per iteration (ms): 37655.1 | learning rate: 6.022E-05 | global batch size:  1024 | lm loss: 1.816599E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36260/   51900 | consumed samples:     37130240 | elapsed time per iteration (ms): 37650.8 | learning rate: 6.022E-05 | global batch size:  1024 | lm loss: 1.804024E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36261/   51900 | consumed samples:     37131264 | elapsed time per iteration (ms): 37703.6 | learning rate: 6.021E-05 | global batch size:  1024 | lm loss: 1.814217E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36262/   51900 | consumed samples:     37132288 | elapsed time per iteration (ms): 37623.1 | learning rate: 6.021E-05 | global batch size:  1024 | lm loss: 1.810825E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36263/   51900 | consumed samples:     37133312 | elapsed time per iteration (ms): 37655.1 | learning rate: 6.020E-05 | global batch size:  1024 | lm loss: 1.803248E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36264/   51900 | consumed samples:     37134336 | elapsed time per iteration (ms): 37687.9 | learning rate: 6.020E-05 | global batch size:  1024 | lm loss: 1.818460E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36265/   51900 | consumed samples:     37135360 | elapsed time per iteration (ms): 37756.8 | learning rate: 6.019E-05 | global batch size:  1024 | lm loss: 1.811440E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36266/   51900 | consumed samples:     37136384 | elapsed time per iteration (ms): 37654.8 | learning rate: 6.019E-05 | global batch size:  1024 | lm loss: 1.804166E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36267/   51900 | consumed samples:     37137408 | elapsed time per iteration (ms): 37760.6 | learning rate: 6.018E-05 | global batch size:  1024 | lm loss: 1.823624E+00 | loss scale: 1.0 | grad norm: 0.089 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36268/   51900 | consumed samples:     37138432 | elapsed time per iteration (ms): 37667.5 | learning rate: 6.018E-05 | global batch size:  1024 | lm loss: 1.812935E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36269/   51900 | consumed samples:     37139456 | elapsed time per iteration (ms): 37815.1 | learning rate: 6.017E-05 | global batch size:  1024 | lm loss: 1.812309E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36270/   51900 | consumed samples:     37140480 | elapsed time per iteration (ms): 37606.8 | learning rate: 6.017E-05 | global batch size:  1024 | lm loss: 1.806015E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36271/   51900 | consumed samples:     37141504 | elapsed time per iteration (ms): 37690.0 | learning rate: 6.016E-05 | global batch size:  1024 | lm loss: 1.810783E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36272/   51900 | consumed samples:     37142528 | elapsed time per iteration (ms): 37636.4 | learning rate: 6.016E-05 | global batch size:  1024 | lm loss: 1.808109E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36273/   51900 | consumed samples:     37143552 | elapsed time per iteration (ms): 37675.8 | learning rate: 6.016E-05 | global batch size:  1024 | lm loss: 1.812624E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36274/   51900 | consumed samples:     37144576 | elapsed time per iteration (ms): 37642.5 | learning rate: 6.015E-05 | global batch size:  1024 | lm loss: 1.820256E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36275/   51900 | consumed samples:     37145600 | elapsed time per iteration (ms): 37688.2 | learning rate: 6.015E-05 | global batch size:  1024 | lm loss: 1.817664E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36276/   51900 | consumed samples:     37146624 | elapsed time per iteration (ms): 37689.3 | learning rate: 6.014E-05 | global batch size:  1024 | lm loss: 1.816058E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36277/   51900 | consumed samples:     37147648 | elapsed time per iteration (ms): 37689.2 | learning rate: 6.014E-05 | global batch size:  1024 | lm loss: 1.814164E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36278/   51900 | consumed samples:     37148672 | elapsed time per iteration (ms): 37565.9 | learning rate: 6.013E-05 | global batch size:  1024 | lm loss: 1.810818E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36279/   51900 | consumed samples:     37149696 | elapsed time per iteration (ms): 37675.9 | learning rate: 6.013E-05 | global batch size:  1024 | lm loss: 1.805436E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36280/   51900 | consumed samples:     37150720 | elapsed time per iteration (ms): 37596.7 | learning rate: 6.012E-05 | global batch size:  1024 | lm loss: 1.801178E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36281/   51900 | consumed samples:     37151744 | elapsed time per iteration (ms): 37649.1 | learning rate: 6.012E-05 | global batch size:  1024 | lm loss: 1.818754E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36282/   51900 | consumed samples:     37152768 | elapsed time per iteration (ms): 37736.3 | learning rate: 6.011E-05 | global batch size:  1024 | lm loss: 1.823978E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36283/   51900 | consumed samples:     37153792 | elapsed time per iteration (ms): 37653.3 | learning rate: 6.011E-05 | global batch size:  1024 | lm loss: 1.810694E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36284/   51900 | consumed samples:     37154816 | elapsed time per iteration (ms): 37754.0 | learning rate: 6.010E-05 | global batch size:  1024 | lm loss: 1.791941E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36285/   51900 | consumed samples:     37155840 | elapsed time per iteration (ms): 37582.6 | learning rate: 6.010E-05 | global batch size:  1024 | lm loss: 1.820201E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36286/   51900 | consumed samples:     37156864 | elapsed time per iteration (ms): 37746.0 | learning rate: 6.009E-05 | global batch size:  1024 | lm loss: 1.797428E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36287/   51900 | consumed samples:     37157888 | elapsed time per iteration (ms): 37728.6 | learning rate: 6.009E-05 | global batch size:  1024 | lm loss: 1.802056E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36288/   51900 | consumed samples:     37158912 | elapsed time per iteration (ms): 37790.4 | learning rate: 6.008E-05 | global batch size:  1024 | lm loss: 1.811318E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36289/   51900 | consumed samples:     37159936 | elapsed time per iteration (ms): 37704.7 | learning rate: 6.008E-05 | global batch size:  1024 | lm loss: 1.818536E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36290/   51900 | consumed samples:     37160960 | elapsed time per iteration (ms): 37650.8 | learning rate: 6.008E-05 | global batch size:  1024 | lm loss: 1.806536E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36291/   51900 | consumed samples:     37161984 | elapsed time per iteration (ms): 37614.7 | learning rate: 6.007E-05 | global batch size:  1024 | lm loss: 1.814192E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36292/   51900 | consumed samples:     37163008 | elapsed time per iteration (ms): 37548.0 | learning rate: 6.007E-05 | global batch size:  1024 | lm loss: 1.828814E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36293/   51900 | consumed samples:     37164032 | elapsed time per iteration (ms): 37784.3 | learning rate: 6.006E-05 | global batch size:  1024 | lm loss: 1.819573E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36294/   51900 | consumed samples:     37165056 | elapsed time per iteration (ms): 37614.5 | learning rate: 6.006E-05 | global batch size:  1024 | lm loss: 1.814814E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36295/   51900 | consumed samples:     37166080 | elapsed time per iteration (ms): 37691.6 | learning rate: 6.005E-05 | global batch size:  1024 | lm loss: 1.816508E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36296/   51900 | consumed samples:     37167104 | elapsed time per iteration (ms): 37787.5 | learning rate: 6.005E-05 | global batch size:  1024 | lm loss: 1.827357E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36297/   51900 | consumed samples:     37168128 | elapsed time per iteration (ms): 37753.6 | learning rate: 6.004E-05 | global batch size:  1024 | lm loss: 1.819057E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36298/   51900 | consumed samples:     37169152 | elapsed time per iteration (ms): 37589.2 | learning rate: 6.004E-05 | global batch size:  1024 | lm loss: 1.800134E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36299/   51900 | consumed samples:     37170176 | elapsed time per iteration (ms): 37740.8 | learning rate: 6.003E-05 | global batch size:  1024 | lm loss: 1.806271E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36300/   51900 | consumed samples:     37171200 | elapsed time per iteration (ms): 37658.6 | learning rate: 6.003E-05 | global batch size:  1024 | lm loss: 1.814949E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36301/   51900 | consumed samples:     37172224 | elapsed time per iteration (ms): 37790.0 | learning rate: 6.002E-05 | global batch size:  1024 | lm loss: 1.803189E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36302/   51900 | consumed samples:     37173248 | elapsed time per iteration (ms): 37582.3 | learning rate: 6.002E-05 | global batch size:  1024 | lm loss: 1.812747E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36303/   51900 | consumed samples:     37174272 | elapsed time per iteration (ms): 37673.1 | learning rate: 6.001E-05 | global batch size:  1024 | lm loss: 1.806824E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36304/   51900 | consumed samples:     37175296 | elapsed time per iteration (ms): 37719.9 | learning rate: 6.001E-05 | global batch size:  1024 | lm loss: 1.821987E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36305/   51900 | consumed samples:     37176320 | elapsed time per iteration (ms): 37693.7 | learning rate: 6.000E-05 | global batch size:  1024 | lm loss: 1.800796E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36306/   51900 | consumed samples:     37177344 | elapsed time per iteration (ms): 37601.2 | learning rate: 6.000E-05 | global batch size:  1024 | lm loss: 1.813725E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36307/   51900 | consumed samples:     37178368 | elapsed time per iteration (ms): 37645.4 | learning rate: 6.000E-05 | global batch size:  1024 | lm loss: 1.811650E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36308/   51900 | consumed samples:     37179392 | elapsed time per iteration (ms): 37767.4 | learning rate: 5.999E-05 | global batch size:  1024 | lm loss: 1.821063E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36309/   51900 | consumed samples:     37180416 | elapsed time per iteration (ms): 37677.5 | learning rate: 5.999E-05 | global batch size:  1024 | lm loss: 1.822408E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36310/   51900 | consumed samples:     37181440 | elapsed time per iteration (ms): 37673.5 | learning rate: 5.998E-05 | global batch size:  1024 | lm loss: 1.809798E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36311/   51900 | consumed samples:     37182464 | elapsed time per iteration (ms): 37692.7 | learning rate: 5.998E-05 | global batch size:  1024 | lm loss: 1.809464E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36312/   51900 | consumed samples:     37183488 | elapsed time per iteration (ms): 37636.3 | learning rate: 5.997E-05 | global batch size:  1024 | lm loss: 1.802761E+00 | loss scale: 1.0 | grad norm: 0.158 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36313/   51900 | consumed samples:     37184512 | elapsed time per iteration (ms): 37761.9 | learning rate: 5.997E-05 | global batch size:  1024 | lm loss: 1.802946E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36314/   51900 | consumed samples:     37185536 | elapsed time per iteration (ms): 37623.4 | learning rate: 5.996E-05 | global batch size:  1024 | lm loss: 1.819476E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36315/   51900 | consumed samples:     37186560 | elapsed time per iteration (ms): 37803.6 | learning rate: 5.996E-05 | global batch size:  1024 | lm loss: 1.810840E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36316/   51900 | consumed samples:     37187584 | elapsed time per iteration (ms): 37667.1 | learning rate: 5.995E-05 | global batch size:  1024 | lm loss: 1.802450E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36317/   51900 | consumed samples:     37188608 | elapsed time per iteration (ms): 37645.0 | learning rate: 5.995E-05 | global batch size:  1024 | lm loss: 1.812894E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36318/   51900 | consumed samples:     37189632 | elapsed time per iteration (ms): 37772.9 | learning rate: 5.994E-05 | global batch size:  1024 | lm loss: 1.814184E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36319/   51900 | consumed samples:     37190656 | elapsed time per iteration (ms): 37592.3 | learning rate: 5.994E-05 | global batch size:  1024 | lm loss: 1.815734E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36320/   51900 | consumed samples:     37191680 | elapsed time per iteration (ms): 37685.3 | learning rate: 5.993E-05 | global batch size:  1024 | lm loss: 1.812934E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36321/   51900 | consumed samples:     37192704 | elapsed time per iteration (ms): 37650.5 | learning rate: 5.993E-05 | global batch size:  1024 | lm loss: 1.806546E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36322/   51900 | consumed samples:     37193728 | elapsed time per iteration (ms): 37632.8 | learning rate: 5.992E-05 | global batch size:  1024 | lm loss: 1.807720E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36323/   51900 | consumed samples:     37194752 | elapsed time per iteration (ms): 37637.9 | learning rate: 5.992E-05 | global batch size:  1024 | lm loss: 1.819345E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36324/   51900 | consumed samples:     37195776 | elapsed time per iteration (ms): 37676.4 | learning rate: 5.992E-05 | global batch size:  1024 | lm loss: 1.802214E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36325/   51900 | consumed samples:     37196800 | elapsed time per iteration (ms): 37603.7 | learning rate: 5.991E-05 | global batch size:  1024 | lm loss: 1.825457E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36326/   51900 | consumed samples:     37197824 | elapsed time per iteration (ms): 37635.1 | learning rate: 5.991E-05 | global batch size:  1024 | lm loss: 1.809308E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36327/   51900 | consumed samples:     37198848 | elapsed time per iteration (ms): 37665.3 | learning rate: 5.990E-05 | global batch size:  1024 | lm loss: 1.804196E+00 | loss scale: 1.0 | grad norm: 0.087 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36328/   51900 | consumed samples:     37199872 | elapsed time per iteration (ms): 37662.4 | learning rate: 5.990E-05 | global batch size:  1024 | lm loss: 1.807230E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36329/   51900 | consumed samples:     37200896 | elapsed time per iteration (ms): 37687.2 | learning rate: 5.989E-05 | global batch size:  1024 | lm loss: 1.836922E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36330/   51900 | consumed samples:     37201920 | elapsed time per iteration (ms): 37624.5 | learning rate: 5.989E-05 | global batch size:  1024 | lm loss: 1.807081E+00 | loss scale: 1.0 | grad norm: 0.087 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36331/   51900 | consumed samples:     37202944 | elapsed time per iteration (ms): 37585.1 | learning rate: 5.988E-05 | global batch size:  1024 | lm loss: 1.809476E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36332/   51900 | consumed samples:     37203968 | elapsed time per iteration (ms): 37634.9 | learning rate: 5.988E-05 | global batch size:  1024 | lm loss: 1.813284E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36333/   51900 | consumed samples:     37204992 | elapsed time per iteration (ms): 37729.7 | learning rate: 5.987E-05 | global batch size:  1024 | lm loss: 1.798265E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36334/   51900 | consumed samples:     37206016 | elapsed time per iteration (ms): 37639.9 | learning rate: 5.987E-05 | global batch size:  1024 | lm loss: 1.787308E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36335/   51900 | consumed samples:     37207040 | elapsed time per iteration (ms): 37591.0 | learning rate: 5.986E-05 | global batch size:  1024 | lm loss: 1.826193E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36336/   51900 | consumed samples:     37208064 | elapsed time per iteration (ms): 37602.9 | learning rate: 5.986E-05 | global batch size:  1024 | lm loss: 1.815213E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36337/   51900 | consumed samples:     37209088 | elapsed time per iteration (ms): 37747.5 | learning rate: 5.985E-05 | global batch size:  1024 | lm loss: 1.795067E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36338/   51900 | consumed samples:     37210112 | elapsed time per iteration (ms): 37699.8 | learning rate: 5.985E-05 | global batch size:  1024 | lm loss: 1.830728E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36339/   51900 | consumed samples:     37211136 | elapsed time per iteration (ms): 37638.1 | learning rate: 5.984E-05 | global batch size:  1024 | lm loss: 1.817768E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36340/   51900 | consumed samples:     37212160 | elapsed time per iteration (ms): 37697.3 | learning rate: 5.984E-05 | global batch size:  1024 | lm loss: 1.816198E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36341/   51900 | consumed samples:     37213184 | elapsed time per iteration (ms): 37703.0 | learning rate: 5.984E-05 | global batch size:  1024 | lm loss: 1.825881E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36342/   51900 | consumed samples:     37214208 | elapsed time per iteration (ms): 37646.0 | learning rate: 5.983E-05 | global batch size:  1024 | lm loss: 1.796481E+00 | loss scale: 1.0 | grad norm: 0.089 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36343/   51900 | consumed samples:     37215232 | elapsed time per iteration (ms): 37703.8 | learning rate: 5.983E-05 | global batch size:  1024 | lm loss: 1.819036E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36344/   51900 | consumed samples:     37216256 | elapsed time per iteration (ms): 37726.1 | learning rate: 5.982E-05 | global batch size:  1024 | lm loss: 1.807204E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36345/   51900 | consumed samples:     37217280 | elapsed time per iteration (ms): 37736.0 | learning rate: 5.982E-05 | global batch size:  1024 | lm loss: 1.816528E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36346/   51900 | consumed samples:     37218304 | elapsed time per iteration (ms): 37654.9 | learning rate: 5.981E-05 | global batch size:  1024 | lm loss: 1.820751E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36347/   51900 | consumed samples:     37219328 | elapsed time per iteration (ms): 37659.9 | learning rate: 5.981E-05 | global batch size:  1024 | lm loss: 1.821362E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36348/   51900 | consumed samples:     37220352 | elapsed time per iteration (ms): 37613.2 | learning rate: 5.980E-05 | global batch size:  1024 | lm loss: 1.793456E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36349/   51900 | consumed samples:     37221376 | elapsed time per iteration (ms): 37662.9 | learning rate: 5.980E-05 | global batch size:  1024 | lm loss: 1.806391E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36350/   51900 | consumed samples:     37222400 | elapsed time per iteration (ms): 37713.0 | learning rate: 5.979E-05 | global batch size:  1024 | lm loss: 1.814292E+00 | loss scale: 1.0 | grad norm: 0.063 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36351/   51900 | consumed samples:     37223424 | elapsed time per iteration (ms): 37670.2 | learning rate: 5.979E-05 | global batch size:  1024 | lm loss: 1.812513E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36352/   51900 | consumed samples:     37224448 | elapsed time per iteration (ms): 37745.5 | learning rate: 5.978E-05 | global batch size:  1024 | lm loss: 1.811657E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36353/   51900 | consumed samples:     37225472 | elapsed time per iteration (ms): 37719.8 | learning rate: 5.978E-05 | global batch size:  1024 | lm loss: 1.800637E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36354/   51900 | consumed samples:     37226496 | elapsed time per iteration (ms): 37714.1 | learning rate: 5.977E-05 | global batch size:  1024 | lm loss: 1.817469E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36355/   51900 | consumed samples:     37227520 | elapsed time per iteration (ms): 37689.7 | learning rate: 5.977E-05 | global batch size:  1024 | lm loss: 1.807687E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36356/   51900 | consumed samples:     37228544 | elapsed time per iteration (ms): 37662.8 | learning rate: 5.976E-05 | global batch size:  1024 | lm loss: 1.824762E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36357/   51900 | consumed samples:     37229568 | elapsed time per iteration (ms): 37650.7 | learning rate: 5.976E-05 | global batch size:  1024 | lm loss: 1.810381E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36358/   51900 | consumed samples:     37230592 | elapsed time per iteration (ms): 37819.1 | learning rate: 5.976E-05 | global batch size:  1024 | lm loss: 1.821733E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36359/   51900 | consumed samples:     37231616 | elapsed time per iteration (ms): 37558.3 | learning rate: 5.975E-05 | global batch size:  1024 | lm loss: 1.819106E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36360/   51900 | consumed samples:     37232640 | elapsed time per iteration (ms): 37568.5 | learning rate: 5.975E-05 | global batch size:  1024 | lm loss: 1.814381E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36361/   51900 | consumed samples:     37233664 | elapsed time per iteration (ms): 37608.2 | learning rate: 5.974E-05 | global batch size:  1024 | lm loss: 1.803655E+00 | loss scale: 1.0 | grad norm: 0.064 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36362/   51900 | consumed samples:     37234688 | elapsed time per iteration (ms): 37687.2 | learning rate: 5.974E-05 | global batch size:  1024 | lm loss: 1.820216E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36363/   51900 | consumed samples:     37235712 | elapsed time per iteration (ms): 37697.5 | learning rate: 5.973E-05 | global batch size:  1024 | lm loss: 1.810942E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36364/   51900 | consumed samples:     37236736 | elapsed time per iteration (ms): 37666.8 | learning rate: 5.973E-05 | global batch size:  1024 | lm loss: 1.806480E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36365/   51900 | consumed samples:     37237760 | elapsed time per iteration (ms): 37571.0 | learning rate: 5.972E-05 | global batch size:  1024 | lm loss: 1.815247E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36366/   51900 | consumed samples:     37238784 | elapsed time per iteration (ms): 37751.1 | learning rate: 5.972E-05 | global batch size:  1024 | lm loss: 1.820135E+00 | loss scale: 1.0 | grad norm: 0.093 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36367/   51900 | consumed samples:     37239808 | elapsed time per iteration (ms): 37708.4 | learning rate: 5.971E-05 | global batch size:  1024 | lm loss: 1.795082E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36368/   51900 | consumed samples:     37240832 | elapsed time per iteration (ms): 37730.9 | learning rate: 5.971E-05 | global batch size:  1024 | lm loss: 1.805110E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36369/   51900 | consumed samples:     37241856 | elapsed time per iteration (ms): 37650.4 | learning rate: 5.970E-05 | global batch size:  1024 | lm loss: 1.804617E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36370/   51900 | consumed samples:     37242880 | elapsed time per iteration (ms): 37687.0 | learning rate: 5.970E-05 | global batch size:  1024 | lm loss: 1.801527E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36371/   51900 | consumed samples:     37243904 | elapsed time per iteration (ms): 37767.4 | learning rate: 5.969E-05 | global batch size:  1024 | lm loss: 1.800275E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36372/   51900 | consumed samples:     37244928 | elapsed time per iteration (ms): 37734.2 | learning rate: 5.969E-05 | global batch size:  1024 | lm loss: 1.798564E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36373/   51900 | consumed samples:     37245952 | elapsed time per iteration (ms): 37690.0 | learning rate: 5.968E-05 | global batch size:  1024 | lm loss: 1.818482E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36374/   51900 | consumed samples:     37246976 | elapsed time per iteration (ms): 37691.5 | learning rate: 5.968E-05 | global batch size:  1024 | lm loss: 1.800963E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36375/   51900 | consumed samples:     37248000 | elapsed time per iteration (ms): 37796.2 | learning rate: 5.968E-05 | global batch size:  1024 | lm loss: 1.810277E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36376/   51900 | consumed samples:     37249024 | elapsed time per iteration (ms): 37632.3 | learning rate: 5.967E-05 | global batch size:  1024 | lm loss: 1.799460E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36377/   51900 | consumed samples:     37250048 | elapsed time per iteration (ms): 37689.1 | learning rate: 5.967E-05 | global batch size:  1024 | lm loss: 1.810663E+00 | loss scale: 1.0 | grad norm: 0.064 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36378/   51900 | consumed samples:     37251072 | elapsed time per iteration (ms): 37749.5 | learning rate: 5.966E-05 | global batch size:  1024 | lm loss: 1.825434E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36379/   51900 | consumed samples:     37252096 | elapsed time per iteration (ms): 37710.9 | learning rate: 5.966E-05 | global batch size:  1024 | lm loss: 1.787194E+00 | loss scale: 1.0 | grad norm: 0.095 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36380/   51900 | consumed samples:     37253120 | elapsed time per iteration (ms): 37652.7 | learning rate: 5.965E-05 | global batch size:  1024 | lm loss: 1.810877E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36381/   51900 | consumed samples:     37254144 | elapsed time per iteration (ms): 37615.3 | learning rate: 5.965E-05 | global batch size:  1024 | lm loss: 1.816764E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36382/   51900 | consumed samples:     37255168 | elapsed time per iteration (ms): 37645.5 | learning rate: 5.964E-05 | global batch size:  1024 | lm loss: 1.789103E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36383/   51900 | consumed samples:     37256192 | elapsed time per iteration (ms): 37716.5 | learning rate: 5.964E-05 | global batch size:  1024 | lm loss: 1.811692E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36384/   51900 | consumed samples:     37257216 | elapsed time per iteration (ms): 37631.7 | learning rate: 5.963E-05 | global batch size:  1024 | lm loss: 1.813107E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36385/   51900 | consumed samples:     37258240 | elapsed time per iteration (ms): 37775.6 | learning rate: 5.963E-05 | global batch size:  1024 | lm loss: 1.814209E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36386/   51900 | consumed samples:     37259264 | elapsed time per iteration (ms): 37617.9 | learning rate: 5.962E-05 | global batch size:  1024 | lm loss: 1.818515E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36387/   51900 | consumed samples:     37260288 | elapsed time per iteration (ms): 37713.6 | learning rate: 5.962E-05 | global batch size:  1024 | lm loss: 1.792475E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36388/   51900 | consumed samples:     37261312 | elapsed time per iteration (ms): 37653.7 | learning rate: 5.961E-05 | global batch size:  1024 | lm loss: 1.807015E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36389/   51900 | consumed samples:     37262336 | elapsed time per iteration (ms): 37639.1 | learning rate: 5.961E-05 | global batch size:  1024 | lm loss: 1.813565E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36390/   51900 | consumed samples:     37263360 | elapsed time per iteration (ms): 37687.8 | learning rate: 5.960E-05 | global batch size:  1024 | lm loss: 1.826717E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36391/   51900 | consumed samples:     37264384 | elapsed time per iteration (ms): 37711.3 | learning rate: 5.960E-05 | global batch size:  1024 | lm loss: 1.792792E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36392/   51900 | consumed samples:     37265408 | elapsed time per iteration (ms): 37516.4 | learning rate: 5.960E-05 | global batch size:  1024 | lm loss: 1.808064E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36393/   51900 | consumed samples:     37266432 | elapsed time per iteration (ms): 37692.8 | learning rate: 5.959E-05 | global batch size:  1024 | lm loss: 1.809916E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36394/   51900 | consumed samples:     37267456 | elapsed time per iteration (ms): 37659.1 | learning rate: 5.959E-05 | global batch size:  1024 | lm loss: 1.796818E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36395/   51900 | consumed samples:     37268480 | elapsed time per iteration (ms): 37737.8 | learning rate: 5.958E-05 | global batch size:  1024 | lm loss: 1.815756E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36396/   51900 | consumed samples:     37269504 | elapsed time per iteration (ms): 37663.6 | learning rate: 5.958E-05 | global batch size:  1024 | lm loss: 1.818255E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36397/   51900 | consumed samples:     37270528 | elapsed time per iteration (ms): 37667.3 | learning rate: 5.957E-05 | global batch size:  1024 | lm loss: 1.816390E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36398/   51900 | consumed samples:     37271552 | elapsed time per iteration (ms): 37745.4 | learning rate: 5.957E-05 | global batch size:  1024 | lm loss: 1.811236E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36399/   51900 | consumed samples:     37272576 | elapsed time per iteration (ms): 37688.7 | learning rate: 5.956E-05 | global batch size:  1024 | lm loss: 1.811136E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36400/   51900 | consumed samples:     37273600 | elapsed time per iteration (ms): 37702.5 | learning rate: 5.956E-05 | global batch size:  1024 | lm loss: 1.811092E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36401/   51900 | consumed samples:     37274624 | elapsed time per iteration (ms): 37873.9 | learning rate: 5.955E-05 | global batch size:  1024 | lm loss: 1.813253E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36402/   51900 | consumed samples:     37275648 | elapsed time per iteration (ms): 37805.7 | learning rate: 5.955E-05 | global batch size:  1024 | lm loss: 1.818569E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36403/   51900 | consumed samples:     37276672 | elapsed time per iteration (ms): 37695.0 | learning rate: 5.954E-05 | global batch size:  1024 | lm loss: 1.809395E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36404/   51900 | consumed samples:     37277696 | elapsed time per iteration (ms): 37566.4 | learning rate: 5.954E-05 | global batch size:  1024 | lm loss: 1.812412E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36405/   51900 | consumed samples:     37278720 | elapsed time per iteration (ms): 37600.1 | learning rate: 5.953E-05 | global batch size:  1024 | lm loss: 1.805796E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36406/   51900 | consumed samples:     37279744 | elapsed time per iteration (ms): 37781.4 | learning rate: 5.953E-05 | global batch size:  1024 | lm loss: 1.803584E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36407/   51900 | consumed samples:     37280768 | elapsed time per iteration (ms): 37624.4 | learning rate: 5.953E-05 | global batch size:  1024 | lm loss: 1.805673E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36408/   51900 | consumed samples:     37281792 | elapsed time per iteration (ms): 37695.9 | learning rate: 5.952E-05 | global batch size:  1024 | lm loss: 1.829299E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36409/   51900 | consumed samples:     37282816 | elapsed time per iteration (ms): 37661.3 | learning rate: 5.952E-05 | global batch size:  1024 | lm loss: 1.801217E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36410/   51900 | consumed samples:     37283840 | elapsed time per iteration (ms): 37671.0 | learning rate: 5.951E-05 | global batch size:  1024 | lm loss: 1.841042E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36411/   51900 | consumed samples:     37284864 | elapsed time per iteration (ms): 37702.7 | learning rate: 5.951E-05 | global batch size:  1024 | lm loss: 1.795868E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36412/   51900 | consumed samples:     37285888 | elapsed time per iteration (ms): 37657.7 | learning rate: 5.950E-05 | global batch size:  1024 | lm loss: 1.799985E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36413/   51900 | consumed samples:     37286912 | elapsed time per iteration (ms): 37687.4 | learning rate: 5.950E-05 | global batch size:  1024 | lm loss: 1.812961E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36414/   51900 | consumed samples:     37287936 | elapsed time per iteration (ms): 37758.6 | learning rate: 5.949E-05 | global batch size:  1024 | lm loss: 1.822116E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36415/   51900 | consumed samples:     37288960 | elapsed time per iteration (ms): 37648.1 | learning rate: 5.949E-05 | global batch size:  1024 | lm loss: 1.793541E+00 | loss scale: 1.0 | grad norm: 0.065 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36416/   51900 | consumed samples:     37289984 | elapsed time per iteration (ms): 37747.9 | learning rate: 5.948E-05 | global batch size:  1024 | lm loss: 1.826956E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36417/   51900 | consumed samples:     37291008 | elapsed time per iteration (ms): 37765.3 | learning rate: 5.948E-05 | global batch size:  1024 | lm loss: 1.823035E+00 | loss scale: 1.0 | grad norm: 0.091 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36418/   51900 | consumed samples:     37292032 | elapsed time per iteration (ms): 37693.4 | learning rate: 5.947E-05 | global batch size:  1024 | lm loss: 1.793142E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36419/   51900 | consumed samples:     37293056 | elapsed time per iteration (ms): 37720.5 | learning rate: 5.947E-05 | global batch size:  1024 | lm loss: 1.808512E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36420/   51900 | consumed samples:     37294080 | elapsed time per iteration (ms): 37614.4 | learning rate: 5.946E-05 | global batch size:  1024 | lm loss: 1.800493E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36421/   51900 | consumed samples:     37295104 | elapsed time per iteration (ms): 37757.2 | learning rate: 5.946E-05 | global batch size:  1024 | lm loss: 1.814251E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36422/   51900 | consumed samples:     37296128 | elapsed time per iteration (ms): 37645.6 | learning rate: 5.945E-05 | global batch size:  1024 | lm loss: 1.803261E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36423/   51900 | consumed samples:     37297152 | elapsed time per iteration (ms): 37566.9 | learning rate: 5.945E-05 | global batch size:  1024 | lm loss: 1.807915E+00 | loss scale: 1.0 | grad norm: 0.065 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36424/   51900 | consumed samples:     37298176 | elapsed time per iteration (ms): 37685.5 | learning rate: 5.945E-05 | global batch size:  1024 | lm loss: 1.823008E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36425/   51900 | consumed samples:     37299200 | elapsed time per iteration (ms): 37690.0 | learning rate: 5.944E-05 | global batch size:  1024 | lm loss: 1.811935E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36426/   51900 | consumed samples:     37300224 | elapsed time per iteration (ms): 37568.3 | learning rate: 5.944E-05 | global batch size:  1024 | lm loss: 1.812080E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36427/   51900 | consumed samples:     37301248 | elapsed time per iteration (ms): 37603.1 | learning rate: 5.943E-05 | global batch size:  1024 | lm loss: 1.802886E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36428/   51900 | consumed samples:     37302272 | elapsed time per iteration (ms): 37703.5 | learning rate: 5.943E-05 | global batch size:  1024 | lm loss: 1.806276E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36429/   51900 | consumed samples:     37303296 | elapsed time per iteration (ms): 37626.0 | learning rate: 5.942E-05 | global batch size:  1024 | lm loss: 1.813884E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36430/   51900 | consumed samples:     37304320 | elapsed time per iteration (ms): 37755.6 | learning rate: 5.942E-05 | global batch size:  1024 | lm loss: 1.817308E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36431/   51900 | consumed samples:     37305344 | elapsed time per iteration (ms): 37674.6 | learning rate: 5.941E-05 | global batch size:  1024 | lm loss: 1.798296E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36432/   51900 | consumed samples:     37306368 | elapsed time per iteration (ms): 37783.1 | learning rate: 5.941E-05 | global batch size:  1024 | lm loss: 1.801303E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36433/   51900 | consumed samples:     37307392 | elapsed time per iteration (ms): 37681.9 | learning rate: 5.940E-05 | global batch size:  1024 | lm loss: 1.800159E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36434/   51900 | consumed samples:     37308416 | elapsed time per iteration (ms): 37665.3 | learning rate: 5.940E-05 | global batch size:  1024 | lm loss: 1.800869E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36435/   51900 | consumed samples:     37309440 | elapsed time per iteration (ms): 37673.9 | learning rate: 5.939E-05 | global batch size:  1024 | lm loss: 1.832600E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36436/   51900 | consumed samples:     37310464 | elapsed time per iteration (ms): 37715.1 | learning rate: 5.939E-05 | global batch size:  1024 | lm loss: 1.813048E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36437/   51900 | consumed samples:     37311488 | elapsed time per iteration (ms): 37702.0 | learning rate: 5.938E-05 | global batch size:  1024 | lm loss: 1.803429E+00 | loss scale: 1.0 | grad norm: 0.089 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36438/   51900 | consumed samples:     37312512 | elapsed time per iteration (ms): 37655.4 | learning rate: 5.938E-05 | global batch size:  1024 | lm loss: 1.795966E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36439/   51900 | consumed samples:     37313536 | elapsed time per iteration (ms): 37715.2 | learning rate: 5.938E-05 | global batch size:  1024 | lm loss: 1.817519E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36440/   51900 | consumed samples:     37314560 | elapsed time per iteration (ms): 37704.5 | learning rate: 5.937E-05 | global batch size:  1024 | lm loss: 1.801910E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36441/   51900 | consumed samples:     37315584 | elapsed time per iteration (ms): 37702.7 | learning rate: 5.937E-05 | global batch size:  1024 | lm loss: 1.805012E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36442/   51900 | consumed samples:     37316608 | elapsed time per iteration (ms): 37651.8 | learning rate: 5.936E-05 | global batch size:  1024 | lm loss: 1.788877E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36443/   51900 | consumed samples:     37317632 | elapsed time per iteration (ms): 37639.1 | learning rate: 5.936E-05 | global batch size:  1024 | lm loss: 1.811353E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36444/   51900 | consumed samples:     37318656 | elapsed time per iteration (ms): 37640.8 | learning rate: 5.935E-05 | global batch size:  1024 | lm loss: 1.816350E+00 | loss scale: 1.0 | grad norm: 0.065 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36445/   51900 | consumed samples:     37319680 | elapsed time per iteration (ms): 37608.5 | learning rate: 5.935E-05 | global batch size:  1024 | lm loss: 1.802015E+00 | loss scale: 1.0 | grad norm: 0.064 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36446/   51900 | consumed samples:     37320704 | elapsed time per iteration (ms): 37731.4 | learning rate: 5.934E-05 | global batch size:  1024 | lm loss: 1.800956E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36447/   51900 | consumed samples:     37321728 | elapsed time per iteration (ms): 37642.6 | learning rate: 5.934E-05 | global batch size:  1024 | lm loss: 1.815208E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36448/   51900 | consumed samples:     37322752 | elapsed time per iteration (ms): 37635.3 | learning rate: 5.933E-05 | global batch size:  1024 | lm loss: 1.794327E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36449/   51900 | consumed samples:     37323776 | elapsed time per iteration (ms): 37698.2 | learning rate: 5.933E-05 | global batch size:  1024 | lm loss: 1.794973E+00 | loss scale: 1.0 | grad norm: 0.092 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36450/   51900 | consumed samples:     37324800 | elapsed time per iteration (ms): 37593.1 | learning rate: 5.932E-05 | global batch size:  1024 | lm loss: 1.786513E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36451/   51900 | consumed samples:     37325824 | elapsed time per iteration (ms): 37603.2 | learning rate: 5.932E-05 | global batch size:  1024 | lm loss: 1.816807E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36452/   51900 | consumed samples:     37326848 | elapsed time per iteration (ms): 37730.6 | learning rate: 5.931E-05 | global batch size:  1024 | lm loss: 1.800531E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36453/   51900 | consumed samples:     37327872 | elapsed time per iteration (ms): 37640.0 | learning rate: 5.931E-05 | global batch size:  1024 | lm loss: 1.800856E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36454/   51900 | consumed samples:     37328896 | elapsed time per iteration (ms): 37605.5 | learning rate: 5.930E-05 | global batch size:  1024 | lm loss: 1.810663E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36455/   51900 | consumed samples:     37329920 | elapsed time per iteration (ms): 37744.2 | learning rate: 5.930E-05 | global batch size:  1024 | lm loss: 1.808897E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36456/   51900 | consumed samples:     37330944 | elapsed time per iteration (ms): 37660.3 | learning rate: 5.930E-05 | global batch size:  1024 | lm loss: 1.797006E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36457/   51900 | consumed samples:     37331968 | elapsed time per iteration (ms): 37742.1 | learning rate: 5.929E-05 | global batch size:  1024 | lm loss: 1.819647E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36458/   51900 | consumed samples:     37332992 | elapsed time per iteration (ms): 37632.2 | learning rate: 5.929E-05 | global batch size:  1024 | lm loss: 1.811007E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36459/   51900 | consumed samples:     37334016 | elapsed time per iteration (ms): 37716.1 | learning rate: 5.928E-05 | global batch size:  1024 | lm loss: 1.827691E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36460/   51900 | consumed samples:     37335040 | elapsed time per iteration (ms): 37655.3 | learning rate: 5.928E-05 | global batch size:  1024 | lm loss: 1.808142E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36461/   51900 | consumed samples:     37336064 | elapsed time per iteration (ms): 37633.7 | learning rate: 5.927E-05 | global batch size:  1024 | lm loss: 1.814269E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36462/   51900 | consumed samples:     37337088 | elapsed time per iteration (ms): 37683.9 | learning rate: 5.927E-05 | global batch size:  1024 | lm loss: 1.829042E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36463/   51900 | consumed samples:     37338112 | elapsed time per iteration (ms): 37575.9 | learning rate: 5.926E-05 | global batch size:  1024 | lm loss: 1.806612E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36464/   51900 | consumed samples:     37339136 | elapsed time per iteration (ms): 37795.5 | learning rate: 5.926E-05 | global batch size:  1024 | lm loss: 1.811624E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36465/   51900 | consumed samples:     37340160 | elapsed time per iteration (ms): 37672.0 | learning rate: 5.925E-05 | global batch size:  1024 | lm loss: 1.818042E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36466/   51900 | consumed samples:     37341184 | elapsed time per iteration (ms): 37665.6 | learning rate: 5.925E-05 | global batch size:  1024 | lm loss: 1.817552E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36467/   51900 | consumed samples:     37342208 | elapsed time per iteration (ms): 37657.7 | learning rate: 5.924E-05 | global batch size:  1024 | lm loss: 1.820809E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36468/   51900 | consumed samples:     37343232 | elapsed time per iteration (ms): 37739.3 | learning rate: 5.924E-05 | global batch size:  1024 | lm loss: 1.814754E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36469/   51900 | consumed samples:     37344256 | elapsed time per iteration (ms): 37605.4 | learning rate: 5.923E-05 | global batch size:  1024 | lm loss: 1.814560E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36470/   51900 | consumed samples:     37345280 | elapsed time per iteration (ms): 37648.1 | learning rate: 5.923E-05 | global batch size:  1024 | lm loss: 1.810141E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36471/   51900 | consumed samples:     37346304 | elapsed time per iteration (ms): 37726.8 | learning rate: 5.923E-05 | global batch size:  1024 | lm loss: 1.818421E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36472/   51900 | consumed samples:     37347328 | elapsed time per iteration (ms): 37634.6 | learning rate: 5.922E-05 | global batch size:  1024 | lm loss: 1.791305E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36473/   51900 | consumed samples:     37348352 | elapsed time per iteration (ms): 37723.3 | learning rate: 5.922E-05 | global batch size:  1024 | lm loss: 1.813324E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36474/   51900 | consumed samples:     37349376 | elapsed time per iteration (ms): 37651.1 | learning rate: 5.921E-05 | global batch size:  1024 | lm loss: 1.804071E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36475/   51900 | consumed samples:     37350400 | elapsed time per iteration (ms): 37648.0 | learning rate: 5.921E-05 | global batch size:  1024 | lm loss: 1.817461E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36476/   51900 | consumed samples:     37351424 | elapsed time per iteration (ms): 37714.4 | learning rate: 5.920E-05 | global batch size:  1024 | lm loss: 1.828944E+00 | loss scale: 1.0 | grad norm: 0.091 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36477/   51900 | consumed samples:     37352448 | elapsed time per iteration (ms): 37724.1 | learning rate: 5.920E-05 | global batch size:  1024 | lm loss: 1.807405E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36478/   51900 | consumed samples:     37353472 | elapsed time per iteration (ms): 37672.1 | learning rate: 5.919E-05 | global batch size:  1024 | lm loss: 1.808898E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36479/   51900 | consumed samples:     37354496 | elapsed time per iteration (ms): 37726.5 | learning rate: 5.919E-05 | global batch size:  1024 | lm loss: 1.793329E+00 | loss scale: 1.0 | grad norm: 0.144 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36480/   51900 | consumed samples:     37355520 | elapsed time per iteration (ms): 37674.6 | learning rate: 5.918E-05 | global batch size:  1024 | lm loss: 1.829685E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36481/   51900 | consumed samples:     37356544 | elapsed time per iteration (ms): 37666.7 | learning rate: 5.918E-05 | global batch size:  1024 | lm loss: 1.807367E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36482/   51900 | consumed samples:     37357568 | elapsed time per iteration (ms): 37702.7 | learning rate: 5.917E-05 | global batch size:  1024 | lm loss: 1.803171E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36483/   51900 | consumed samples:     37358592 | elapsed time per iteration (ms): 37619.5 | learning rate: 5.917E-05 | global batch size:  1024 | lm loss: 1.811142E+00 | loss scale: 1.0 | grad norm: 0.304 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36484/   51900 | consumed samples:     37359616 | elapsed time per iteration (ms): 37707.5 | learning rate: 5.916E-05 | global batch size:  1024 | lm loss: 1.801676E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36485/   51900 | consumed samples:     37360640 | elapsed time per iteration (ms): 37527.1 | learning rate: 5.916E-05 | global batch size:  1024 | lm loss: 1.837739E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36486/   51900 | consumed samples:     37361664 | elapsed time per iteration (ms): 37701.1 | learning rate: 5.916E-05 | global batch size:  1024 | lm loss: 1.816337E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36487/   51900 | consumed samples:     37362688 | elapsed time per iteration (ms): 37603.3 | learning rate: 5.915E-05 | global batch size:  1024 | lm loss: 1.804857E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36488/   51900 | consumed samples:     37363712 | elapsed time per iteration (ms): 37627.9 | learning rate: 5.915E-05 | global batch size:  1024 | lm loss: 1.814151E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36489/   51900 | consumed samples:     37364736 | elapsed time per iteration (ms): 37592.1 | learning rate: 5.914E-05 | global batch size:  1024 | lm loss: 1.813752E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36490/   51900 | consumed samples:     37365760 | elapsed time per iteration (ms): 37673.1 | learning rate: 5.914E-05 | global batch size:  1024 | lm loss: 1.802914E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36491/   51900 | consumed samples:     37366784 | elapsed time per iteration (ms): 37658.5 | learning rate: 5.913E-05 | global batch size:  1024 | lm loss: 1.818220E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36492/   51900 | consumed samples:     37367808 | elapsed time per iteration (ms): 37579.4 | learning rate: 5.913E-05 | global batch size:  1024 | lm loss: 1.821387E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36493/   51900 | consumed samples:     37368832 | elapsed time per iteration (ms): 37696.0 | learning rate: 5.912E-05 | global batch size:  1024 | lm loss: 1.804307E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36494/   51900 | consumed samples:     37369856 | elapsed time per iteration (ms): 37646.8 | learning rate: 5.912E-05 | global batch size:  1024 | lm loss: 1.811592E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36495/   51900 | consumed samples:     37370880 | elapsed time per iteration (ms): 37663.6 | learning rate: 5.911E-05 | global batch size:  1024 | lm loss: 1.809321E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36496/   51900 | consumed samples:     37371904 | elapsed time per iteration (ms): 37599.3 | learning rate: 5.911E-05 | global batch size:  1024 | lm loss: 1.810958E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36497/   51900 | consumed samples:     37372928 | elapsed time per iteration (ms): 37694.9 | learning rate: 5.910E-05 | global batch size:  1024 | lm loss: 1.834106E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36498/   51900 | consumed samples:     37373952 | elapsed time per iteration (ms): 37675.5 | learning rate: 5.910E-05 | global batch size:  1024 | lm loss: 1.809325E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36499/   51900 | consumed samples:     37374976 | elapsed time per iteration (ms): 37714.0 | learning rate: 5.909E-05 | global batch size:  1024 | lm loss: 1.822039E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36500/   51900 | consumed samples:     37376000 | elapsed time per iteration (ms): 37662.4 | learning rate: 5.909E-05 | global batch size:  1024 | lm loss: 1.794710E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    save-checkpoint ................................: (137594.65, 137594.73)
 iteration    36501/   51900 | consumed samples:     37377024 | elapsed time per iteration (ms): 37253.4 | learning rate: 5.908E-05 | global batch size:  1024 | lm loss: 1.815367E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36502/   51900 | consumed samples:     37378048 | elapsed time per iteration (ms): 37746.3 | learning rate: 5.908E-05 | global batch size:  1024 | lm loss: 1.817336E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36503/   51900 | consumed samples:     37379072 | elapsed time per iteration (ms): 37611.9 | learning rate: 5.908E-05 | global batch size:  1024 | lm loss: 1.813649E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36504/   51900 | consumed samples:     37380096 | elapsed time per iteration (ms): 37569.5 | learning rate: 5.907E-05 | global batch size:  1024 | lm loss: 1.815471E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36505/   51900 | consumed samples:     37381120 | elapsed time per iteration (ms): 37734.7 | learning rate: 5.907E-05 | global batch size:  1024 | lm loss: 1.803761E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36506/   51900 | consumed samples:     37382144 | elapsed time per iteration (ms): 37540.3 | learning rate: 5.906E-05 | global batch size:  1024 | lm loss: 1.813805E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36507/   51900 | consumed samples:     37383168 | elapsed time per iteration (ms): 37666.4 | learning rate: 5.906E-05 | global batch size:  1024 | lm loss: 1.793330E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36508/   51900 | consumed samples:     37384192 | elapsed time per iteration (ms): 37690.8 | learning rate: 5.905E-05 | global batch size:  1024 | lm loss: 1.788773E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36509/   51900 | consumed samples:     37385216 | elapsed time per iteration (ms): 37767.8 | learning rate: 5.905E-05 | global batch size:  1024 | lm loss: 1.807536E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36510/   51900 | consumed samples:     37386240 | elapsed time per iteration (ms): 37742.5 | learning rate: 5.904E-05 | global batch size:  1024 | lm loss: 1.807610E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36511/   51900 | consumed samples:     37387264 | elapsed time per iteration (ms): 37677.1 | learning rate: 5.904E-05 | global batch size:  1024 | lm loss: 1.798562E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36512/   51900 | consumed samples:     37388288 | elapsed time per iteration (ms): 37595.8 | learning rate: 5.903E-05 | global batch size:  1024 | lm loss: 1.826435E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36513/   51900 | consumed samples:     37389312 | elapsed time per iteration (ms): 37575.2 | learning rate: 5.903E-05 | global batch size:  1024 | lm loss: 1.812104E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36514/   51900 | consumed samples:     37390336 | elapsed time per iteration (ms): 37697.9 | learning rate: 5.902E-05 | global batch size:  1024 | lm loss: 1.829612E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36515/   51900 | consumed samples:     37391360 | elapsed time per iteration (ms): 37638.1 | learning rate: 5.902E-05 | global batch size:  1024 | lm loss: 1.801192E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36516/   51900 | consumed samples:     37392384 | elapsed time per iteration (ms): 37693.3 | learning rate: 5.901E-05 | global batch size:  1024 | lm loss: 1.800367E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36517/   51900 | consumed samples:     37393408 | elapsed time per iteration (ms): 37662.5 | learning rate: 5.901E-05 | global batch size:  1024 | lm loss: 1.820594E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36518/   51900 | consumed samples:     37394432 | elapsed time per iteration (ms): 37645.4 | learning rate: 5.901E-05 | global batch size:  1024 | lm loss: 1.805950E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36519/   51900 | consumed samples:     37395456 | elapsed time per iteration (ms): 37649.0 | learning rate: 5.900E-05 | global batch size:  1024 | lm loss: 1.821394E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36520/   51900 | consumed samples:     37396480 | elapsed time per iteration (ms): 37698.7 | learning rate: 5.900E-05 | global batch size:  1024 | lm loss: 1.805381E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36521/   51900 | consumed samples:     37397504 | elapsed time per iteration (ms): 37595.4 | learning rate: 5.899E-05 | global batch size:  1024 | lm loss: 1.803593E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36522/   51900 | consumed samples:     37398528 | elapsed time per iteration (ms): 37596.5 | learning rate: 5.899E-05 | global batch size:  1024 | lm loss: 1.818312E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36523/   51900 | consumed samples:     37399552 | elapsed time per iteration (ms): 37714.0 | learning rate: 5.898E-05 | global batch size:  1024 | lm loss: 1.809390E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36524/   51900 | consumed samples:     37400576 | elapsed time per iteration (ms): 37665.7 | learning rate: 5.898E-05 | global batch size:  1024 | lm loss: 1.801191E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36525/   51900 | consumed samples:     37401600 | elapsed time per iteration (ms): 37720.7 | learning rate: 5.897E-05 | global batch size:  1024 | lm loss: 1.801137E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36526/   51900 | consumed samples:     37402624 | elapsed time per iteration (ms): 37671.7 | learning rate: 5.897E-05 | global batch size:  1024 | lm loss: 1.811351E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36527/   51900 | consumed samples:     37403648 | elapsed time per iteration (ms): 37648.5 | learning rate: 5.896E-05 | global batch size:  1024 | lm loss: 1.817211E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36528/   51900 | consumed samples:     37404672 | elapsed time per iteration (ms): 37663.8 | learning rate: 5.896E-05 | global batch size:  1024 | lm loss: 1.794895E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36529/   51900 | consumed samples:     37405696 | elapsed time per iteration (ms): 37614.0 | learning rate: 5.895E-05 | global batch size:  1024 | lm loss: 1.798557E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36530/   51900 | consumed samples:     37406720 | elapsed time per iteration (ms): 37631.9 | learning rate: 5.895E-05 | global batch size:  1024 | lm loss: 1.810040E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36531/   51900 | consumed samples:     37407744 | elapsed time per iteration (ms): 37751.3 | learning rate: 5.894E-05 | global batch size:  1024 | lm loss: 1.789323E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36532/   51900 | consumed samples:     37408768 | elapsed time per iteration (ms): 37790.5 | learning rate: 5.894E-05 | global batch size:  1024 | lm loss: 1.820200E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36533/   51900 | consumed samples:     37409792 | elapsed time per iteration (ms): 37601.0 | learning rate: 5.894E-05 | global batch size:  1024 | lm loss: 1.818253E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36534/   51900 | consumed samples:     37410816 | elapsed time per iteration (ms): 37709.4 | learning rate: 5.893E-05 | global batch size:  1024 | lm loss: 1.807764E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36535/   51900 | consumed samples:     37411840 | elapsed time per iteration (ms): 37703.1 | learning rate: 5.893E-05 | global batch size:  1024 | lm loss: 1.818078E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36536/   51900 | consumed samples:     37412864 | elapsed time per iteration (ms): 37638.9 | learning rate: 5.892E-05 | global batch size:  1024 | lm loss: 1.816065E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36537/   51900 | consumed samples:     37413888 | elapsed time per iteration (ms): 37560.3 | learning rate: 5.892E-05 | global batch size:  1024 | lm loss: 1.813841E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36538/   51900 | consumed samples:     37414912 | elapsed time per iteration (ms): 37684.3 | learning rate: 5.891E-05 | global batch size:  1024 | lm loss: 1.811928E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36539/   51900 | consumed samples:     37415936 | elapsed time per iteration (ms): 37647.1 | learning rate: 5.891E-05 | global batch size:  1024 | lm loss: 1.814893E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36540/   51900 | consumed samples:     37416960 | elapsed time per iteration (ms): 37630.7 | learning rate: 5.890E-05 | global batch size:  1024 | lm loss: 1.794448E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36541/   51900 | consumed samples:     37417984 | elapsed time per iteration (ms): 37734.6 | learning rate: 5.890E-05 | global batch size:  1024 | lm loss: 1.813749E+00 | loss scale: 1.0 | grad norm: 0.065 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36542/   51900 | consumed samples:     37419008 | elapsed time per iteration (ms): 37675.4 | learning rate: 5.889E-05 | global batch size:  1024 | lm loss: 1.805698E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36543/   51900 | consumed samples:     37420032 | elapsed time per iteration (ms): 37623.7 | learning rate: 5.889E-05 | global batch size:  1024 | lm loss: 1.818891E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36544/   51900 | consumed samples:     37421056 | elapsed time per iteration (ms): 37682.4 | learning rate: 5.888E-05 | global batch size:  1024 | lm loss: 1.808909E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36545/   51900 | consumed samples:     37422080 | elapsed time per iteration (ms): 37641.4 | learning rate: 5.888E-05 | global batch size:  1024 | lm loss: 1.790434E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36546/   51900 | consumed samples:     37423104 | elapsed time per iteration (ms): 37669.8 | learning rate: 5.887E-05 | global batch size:  1024 | lm loss: 1.797716E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36547/   51900 | consumed samples:     37424128 | elapsed time per iteration (ms): 37551.3 | learning rate: 5.887E-05 | global batch size:  1024 | lm loss: 1.793690E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36548/   51900 | consumed samples:     37425152 | elapsed time per iteration (ms): 37609.0 | learning rate: 5.887E-05 | global batch size:  1024 | lm loss: 1.820739E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36549/   51900 | consumed samples:     37426176 | elapsed time per iteration (ms): 37696.5 | learning rate: 5.886E-05 | global batch size:  1024 | lm loss: 1.826801E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36550/   51900 | consumed samples:     37427200 | elapsed time per iteration (ms): 37768.5 | learning rate: 5.886E-05 | global batch size:  1024 | lm loss: 1.807098E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36551/   51900 | consumed samples:     37428224 | elapsed time per iteration (ms): 37661.6 | learning rate: 5.885E-05 | global batch size:  1024 | lm loss: 1.808578E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36552/   51900 | consumed samples:     37429248 | elapsed time per iteration (ms): 37687.2 | learning rate: 5.885E-05 | global batch size:  1024 | lm loss: 1.823334E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36553/   51900 | consumed samples:     37430272 | elapsed time per iteration (ms): 37755.6 | learning rate: 5.884E-05 | global batch size:  1024 | lm loss: 1.804647E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36554/   51900 | consumed samples:     37431296 | elapsed time per iteration (ms): 37574.7 | learning rate: 5.884E-05 | global batch size:  1024 | lm loss: 1.790082E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36555/   51900 | consumed samples:     37432320 | elapsed time per iteration (ms): 37626.4 | learning rate: 5.883E-05 | global batch size:  1024 | lm loss: 1.814906E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36556/   51900 | consumed samples:     37433344 | elapsed time per iteration (ms): 37617.6 | learning rate: 5.883E-05 | global batch size:  1024 | lm loss: 1.811883E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36557/   51900 | consumed samples:     37434368 | elapsed time per iteration (ms): 37629.5 | learning rate: 5.882E-05 | global batch size:  1024 | lm loss: 1.799178E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36558/   51900 | consumed samples:     37435392 | elapsed time per iteration (ms): 37663.3 | learning rate: 5.882E-05 | global batch size:  1024 | lm loss: 1.778427E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36559/   51900 | consumed samples:     37436416 | elapsed time per iteration (ms): 37722.5 | learning rate: 5.881E-05 | global batch size:  1024 | lm loss: 1.798733E+00 | loss scale: 1.0 | grad norm: 0.106 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36560/   51900 | consumed samples:     37437440 | elapsed time per iteration (ms): 37651.7 | learning rate: 5.881E-05 | global batch size:  1024 | lm loss: 1.810473E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36561/   51900 | consumed samples:     37438464 | elapsed time per iteration (ms): 37766.4 | learning rate: 5.880E-05 | global batch size:  1024 | lm loss: 1.819304E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36562/   51900 | consumed samples:     37439488 | elapsed time per iteration (ms): 37698.9 | learning rate: 5.880E-05 | global batch size:  1024 | lm loss: 1.802585E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36563/   51900 | consumed samples:     37440512 | elapsed time per iteration (ms): 37596.3 | learning rate: 5.880E-05 | global batch size:  1024 | lm loss: 1.817782E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36564/   51900 | consumed samples:     37441536 | elapsed time per iteration (ms): 37567.6 | learning rate: 5.879E-05 | global batch size:  1024 | lm loss: 1.820795E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36565/   51900 | consumed samples:     37442560 | elapsed time per iteration (ms): 37617.3 | learning rate: 5.879E-05 | global batch size:  1024 | lm loss: 1.811953E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36566/   51900 | consumed samples:     37443584 | elapsed time per iteration (ms): 37713.7 | learning rate: 5.878E-05 | global batch size:  1024 | lm loss: 1.810632E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36567/   51900 | consumed samples:     37444608 | elapsed time per iteration (ms): 37656.2 | learning rate: 5.878E-05 | global batch size:  1024 | lm loss: 1.805570E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36568/   51900 | consumed samples:     37445632 | elapsed time per iteration (ms): 37723.4 | learning rate: 5.877E-05 | global batch size:  1024 | lm loss: 1.808850E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36569/   51900 | consumed samples:     37446656 | elapsed time per iteration (ms): 37705.9 | learning rate: 5.877E-05 | global batch size:  1024 | lm loss: 1.821412E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36570/   51900 | consumed samples:     37447680 | elapsed time per iteration (ms): 37661.2 | learning rate: 5.876E-05 | global batch size:  1024 | lm loss: 1.808701E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36571/   51900 | consumed samples:     37448704 | elapsed time per iteration (ms): 37587.4 | learning rate: 5.876E-05 | global batch size:  1024 | lm loss: 1.802759E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36572/   51900 | consumed samples:     37449728 | elapsed time per iteration (ms): 37641.5 | learning rate: 5.875E-05 | global batch size:  1024 | lm loss: 1.806275E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36573/   51900 | consumed samples:     37450752 | elapsed time per iteration (ms): 37653.9 | learning rate: 5.875E-05 | global batch size:  1024 | lm loss: 1.811072E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36574/   51900 | consumed samples:     37451776 | elapsed time per iteration (ms): 37756.2 | learning rate: 5.874E-05 | global batch size:  1024 | lm loss: 1.802546E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36575/   51900 | consumed samples:     37452800 | elapsed time per iteration (ms): 37551.9 | learning rate: 5.874E-05 | global batch size:  1024 | lm loss: 1.819416E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36576/   51900 | consumed samples:     37453824 | elapsed time per iteration (ms): 37642.7 | learning rate: 5.874E-05 | global batch size:  1024 | lm loss: 1.805341E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36577/   51900 | consumed samples:     37454848 | elapsed time per iteration (ms): 37653.7 | learning rate: 5.873E-05 | global batch size:  1024 | lm loss: 1.814634E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
wandb: Network error resolved after 0:03:28.530346, resuming normal operation.
 iteration    36578/   51900 | consumed samples:     37455872 | elapsed time per iteration (ms): 37702.1 | learning rate: 5.873E-05 | global batch size:  1024 | lm loss: 1.806293E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36579/   51900 | consumed samples:     37456896 | elapsed time per iteration (ms): 37748.9 | learning rate: 5.872E-05 | global batch size:  1024 | lm loss: 1.808600E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36580/   51900 | consumed samples:     37457920 | elapsed time per iteration (ms): 37655.0 | learning rate: 5.872E-05 | global batch size:  1024 | lm loss: 1.809583E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36581/   51900 | consumed samples:     37458944 | elapsed time per iteration (ms): 37698.3 | learning rate: 5.871E-05 | global batch size:  1024 | lm loss: 1.807647E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36582/   51900 | consumed samples:     37459968 | elapsed time per iteration (ms): 37837.6 | learning rate: 5.871E-05 | global batch size:  1024 | lm loss: 1.802181E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36583/   51900 | consumed samples:     37460992 | elapsed time per iteration (ms): 37631.4 | learning rate: 5.870E-05 | global batch size:  1024 | lm loss: 1.810969E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36584/   51900 | consumed samples:     37462016 | elapsed time per iteration (ms): 37640.1 | learning rate: 5.870E-05 | global batch size:  1024 | lm loss: 1.815127E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36585/   51900 | consumed samples:     37463040 | elapsed time per iteration (ms): 37635.0 | learning rate: 5.869E-05 | global batch size:  1024 | lm loss: 1.816923E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36586/   51900 | consumed samples:     37464064 | elapsed time per iteration (ms): 37683.7 | learning rate: 5.869E-05 | global batch size:  1024 | lm loss: 1.797888E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36587/   51900 | consumed samples:     37465088 | elapsed time per iteration (ms): 37819.5 | learning rate: 5.868E-05 | global batch size:  1024 | lm loss: 1.797774E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36588/   51900 | consumed samples:     37466112 | elapsed time per iteration (ms): 37745.6 | learning rate: 5.868E-05 | global batch size:  1024 | lm loss: 1.793093E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36589/   51900 | consumed samples:     37467136 | elapsed time per iteration (ms): 37687.1 | learning rate: 5.867E-05 | global batch size:  1024 | lm loss: 1.805249E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36590/   51900 | consumed samples:     37468160 | elapsed time per iteration (ms): 37698.0 | learning rate: 5.867E-05 | global batch size:  1024 | lm loss: 1.808229E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36591/   51900 | consumed samples:     37469184 | elapsed time per iteration (ms): 37574.6 | learning rate: 5.867E-05 | global batch size:  1024 | lm loss: 1.780518E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36592/   51900 | consumed samples:     37470208 | elapsed time per iteration (ms): 37673.1 | learning rate: 5.866E-05 | global batch size:  1024 | lm loss: 1.804917E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36593/   51900 | consumed samples:     37471232 | elapsed time per iteration (ms): 37608.7 | learning rate: 5.866E-05 | global batch size:  1024 | lm loss: 1.800921E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36594/   51900 | consumed samples:     37472256 | elapsed time per iteration (ms): 37744.3 | learning rate: 5.865E-05 | global batch size:  1024 | lm loss: 1.808875E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36595/   51900 | consumed samples:     37473280 | elapsed time per iteration (ms): 37635.2 | learning rate: 5.865E-05 | global batch size:  1024 | lm loss: 1.798448E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36596/   51900 | consumed samples:     37474304 | elapsed time per iteration (ms): 37685.0 | learning rate: 5.864E-05 | global batch size:  1024 | lm loss: 1.797313E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36597/   51900 | consumed samples:     37475328 | elapsed time per iteration (ms): 37744.0 | learning rate: 5.864E-05 | global batch size:  1024 | lm loss: 1.798559E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36598/   51900 | consumed samples:     37476352 | elapsed time per iteration (ms): 37660.2 | learning rate: 5.863E-05 | global batch size:  1024 | lm loss: 1.795572E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36599/   51900 | consumed samples:     37477376 | elapsed time per iteration (ms): 37712.5 | learning rate: 5.863E-05 | global batch size:  1024 | lm loss: 1.800685E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36600/   51900 | consumed samples:     37478400 | elapsed time per iteration (ms): 37748.8 | learning rate: 5.862E-05 | global batch size:  1024 | lm loss: 1.829975E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36601/   51900 | consumed samples:     37479424 | elapsed time per iteration (ms): 37662.7 | learning rate: 5.862E-05 | global batch size:  1024 | lm loss: 1.807651E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36602/   51900 | consumed samples:     37480448 | elapsed time per iteration (ms): 37610.8 | learning rate: 5.861E-05 | global batch size:  1024 | lm loss: 1.803729E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36603/   51900 | consumed samples:     37481472 | elapsed time per iteration (ms): 37555.2 | learning rate: 5.861E-05 | global batch size:  1024 | lm loss: 1.815979E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36604/   51900 | consumed samples:     37482496 | elapsed time per iteration (ms): 37668.3 | learning rate: 5.860E-05 | global batch size:  1024 | lm loss: 1.810957E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36605/   51900 | consumed samples:     37483520 | elapsed time per iteration (ms): 37637.1 | learning rate: 5.860E-05 | global batch size:  1024 | lm loss: 1.813233E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36606/   51900 | consumed samples:     37484544 | elapsed time per iteration (ms): 37662.2 | learning rate: 5.860E-05 | global batch size:  1024 | lm loss: 1.821805E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36607/   51900 | consumed samples:     37485568 | elapsed time per iteration (ms): 37587.7 | learning rate: 5.859E-05 | global batch size:  1024 | lm loss: 1.803259E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36608/   51900 | consumed samples:     37486592 | elapsed time per iteration (ms): 37761.6 | learning rate: 5.859E-05 | global batch size:  1024 | lm loss: 1.802463E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36609/   51900 | consumed samples:     37487616 | elapsed time per iteration (ms): 37713.5 | learning rate: 5.858E-05 | global batch size:  1024 | lm loss: 1.814368E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36610/   51900 | consumed samples:     37488640 | elapsed time per iteration (ms): 37519.8 | learning rate: 5.858E-05 | global batch size:  1024 | lm loss: 1.813247E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36611/   51900 | consumed samples:     37489664 | elapsed time per iteration (ms): 37662.9 | learning rate: 5.857E-05 | global batch size:  1024 | lm loss: 1.832723E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36612/   51900 | consumed samples:     37490688 | elapsed time per iteration (ms): 37698.3 | learning rate: 5.857E-05 | global batch size:  1024 | lm loss: 1.803439E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36613/   51900 | consumed samples:     37491712 | elapsed time per iteration (ms): 37751.8 | learning rate: 5.856E-05 | global batch size:  1024 | lm loss: 1.799302E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36614/   51900 | consumed samples:     37492736 | elapsed time per iteration (ms): 37638.5 | learning rate: 5.856E-05 | global batch size:  1024 | lm loss: 1.816075E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36615/   51900 | consumed samples:     37493760 | elapsed time per iteration (ms): 37677.9 | learning rate: 5.855E-05 | global batch size:  1024 | lm loss: 1.842038E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36616/   51900 | consumed samples:     37494784 | elapsed time per iteration (ms): 37603.8 | learning rate: 5.855E-05 | global batch size:  1024 | lm loss: 1.814445E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36617/   51900 | consumed samples:     37495808 | elapsed time per iteration (ms): 37655.0 | learning rate: 5.854E-05 | global batch size:  1024 | lm loss: 1.809727E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36618/   51900 | consumed samples:     37496832 | elapsed time per iteration (ms): 37667.7 | learning rate: 5.854E-05 | global batch size:  1024 | lm loss: 1.800577E+00 | loss scale: 1.0 | grad norm: 0.149 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36619/   51900 | consumed samples:     37497856 | elapsed time per iteration (ms): 37714.6 | learning rate: 5.854E-05 | global batch size:  1024 | lm loss: 1.790411E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36620/   51900 | consumed samples:     37498880 | elapsed time per iteration (ms): 37652.6 | learning rate: 5.853E-05 | global batch size:  1024 | lm loss: 1.800279E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36621/   51900 | consumed samples:     37499904 | elapsed time per iteration (ms): 37687.2 | learning rate: 5.853E-05 | global batch size:  1024 | lm loss: 1.807786E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36622/   51900 | consumed samples:     37500928 | elapsed time per iteration (ms): 37691.6 | learning rate: 5.852E-05 | global batch size:  1024 | lm loss: 1.794149E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36623/   51900 | consumed samples:     37501952 | elapsed time per iteration (ms): 37731.3 | learning rate: 5.852E-05 | global batch size:  1024 | lm loss: 1.822659E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36624/   51900 | consumed samples:     37502976 | elapsed time per iteration (ms): 37673.8 | learning rate: 5.851E-05 | global batch size:  1024 | lm loss: 1.801440E+00 | loss scale: 1.0 | grad norm: 0.129 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36625/   51900 | consumed samples:     37504000 | elapsed time per iteration (ms): 37595.1 | learning rate: 5.851E-05 | global batch size:  1024 | lm loss: 1.812712E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36626/   51900 | consumed samples:     37505024 | elapsed time per iteration (ms): 37664.7 | learning rate: 5.850E-05 | global batch size:  1024 | lm loss: 1.805871E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36627/   51900 | consumed samples:     37506048 | elapsed time per iteration (ms): 37613.6 | learning rate: 5.850E-05 | global batch size:  1024 | lm loss: 1.829955E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36628/   51900 | consumed samples:     37507072 | elapsed time per iteration (ms): 37675.8 | learning rate: 5.849E-05 | global batch size:  1024 | lm loss: 1.815710E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36629/   51900 | consumed samples:     37508096 | elapsed time per iteration (ms): 37651.7 | learning rate: 5.849E-05 | global batch size:  1024 | lm loss: 1.801884E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36630/   51900 | consumed samples:     37509120 | elapsed time per iteration (ms): 37739.5 | learning rate: 5.848E-05 | global batch size:  1024 | lm loss: 1.802887E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36631/   51900 | consumed samples:     37510144 | elapsed time per iteration (ms): 37636.3 | learning rate: 5.848E-05 | global batch size:  1024 | lm loss: 1.810794E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36632/   51900 | consumed samples:     37511168 | elapsed time per iteration (ms): 37760.1 | learning rate: 5.847E-05 | global batch size:  1024 | lm loss: 1.814234E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36633/   51900 | consumed samples:     37512192 | elapsed time per iteration (ms): 37610.9 | learning rate: 5.847E-05 | global batch size:  1024 | lm loss: 1.834536E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36634/   51900 | consumed samples:     37513216 | elapsed time per iteration (ms): 37745.9 | learning rate: 5.847E-05 | global batch size:  1024 | lm loss: 1.813807E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36635/   51900 | consumed samples:     37514240 | elapsed time per iteration (ms): 37785.7 | learning rate: 5.846E-05 | global batch size:  1024 | lm loss: 1.812599E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36636/   51900 | consumed samples:     37515264 | elapsed time per iteration (ms): 37685.9 | learning rate: 5.846E-05 | global batch size:  1024 | lm loss: 1.814464E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36637/   51900 | consumed samples:     37516288 | elapsed time per iteration (ms): 37665.9 | learning rate: 5.845E-05 | global batch size:  1024 | lm loss: 1.809566E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36638/   51900 | consumed samples:     37517312 | elapsed time per iteration (ms): 37701.5 | learning rate: 5.845E-05 | global batch size:  1024 | lm loss: 1.800533E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36639/   51900 | consumed samples:     37518336 | elapsed time per iteration (ms): 37721.9 | learning rate: 5.844E-05 | global batch size:  1024 | lm loss: 1.812479E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36640/   51900 | consumed samples:     37519360 | elapsed time per iteration (ms): 37817.2 | learning rate: 5.844E-05 | global batch size:  1024 | lm loss: 1.803407E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36641/   51900 | consumed samples:     37520384 | elapsed time per iteration (ms): 37535.2 | learning rate: 5.843E-05 | global batch size:  1024 | lm loss: 1.811438E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36642/   51900 | consumed samples:     37521408 | elapsed time per iteration (ms): 37608.8 | learning rate: 5.843E-05 | global batch size:  1024 | lm loss: 1.821813E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36643/   51900 | consumed samples:     37522432 | elapsed time per iteration (ms): 37673.6 | learning rate: 5.842E-05 | global batch size:  1024 | lm loss: 1.809686E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36644/   51900 | consumed samples:     37523456 | elapsed time per iteration (ms): 37730.3 | learning rate: 5.842E-05 | global batch size:  1024 | lm loss: 1.808249E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36645/   51900 | consumed samples:     37524480 | elapsed time per iteration (ms): 37735.0 | learning rate: 5.841E-05 | global batch size:  1024 | lm loss: 1.812724E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36646/   51900 | consumed samples:     37525504 | elapsed time per iteration (ms): 37609.5 | learning rate: 5.841E-05 | global batch size:  1024 | lm loss: 1.814731E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36647/   51900 | consumed samples:     37526528 | elapsed time per iteration (ms): 37669.5 | learning rate: 5.840E-05 | global batch size:  1024 | lm loss: 1.810581E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36648/   51900 | consumed samples:     37527552 | elapsed time per iteration (ms): 37665.8 | learning rate: 5.840E-05 | global batch size:  1024 | lm loss: 1.802653E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36649/   51900 | consumed samples:     37528576 | elapsed time per iteration (ms): 37658.8 | learning rate: 5.840E-05 | global batch size:  1024 | lm loss: 1.823625E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36650/   51900 | consumed samples:     37529600 | elapsed time per iteration (ms): 37728.6 | learning rate: 5.839E-05 | global batch size:  1024 | lm loss: 1.821814E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36651/   51900 | consumed samples:     37530624 | elapsed time per iteration (ms): 37685.0 | learning rate: 5.839E-05 | global batch size:  1024 | lm loss: 1.827439E+00 | loss scale: 1.0 | grad norm: 0.065 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36652/   51900 | consumed samples:     37531648 | elapsed time per iteration (ms): 37757.5 | learning rate: 5.838E-05 | global batch size:  1024 | lm loss: 1.804994E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36653/   51900 | consumed samples:     37532672 | elapsed time per iteration (ms): 37745.4 | learning rate: 5.838E-05 | global batch size:  1024 | lm loss: 1.809161E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36654/   51900 | consumed samples:     37533696 | elapsed time per iteration (ms): 37753.7 | learning rate: 5.837E-05 | global batch size:  1024 | lm loss: 1.808659E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36655/   51900 | consumed samples:     37534720 | elapsed time per iteration (ms): 37746.1 | learning rate: 5.837E-05 | global batch size:  1024 | lm loss: 1.807082E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36656/   51900 | consumed samples:     37535744 | elapsed time per iteration (ms): 37642.1 | learning rate: 5.836E-05 | global batch size:  1024 | lm loss: 1.822425E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36657/   51900 | consumed samples:     37536768 | elapsed time per iteration (ms): 37670.7 | learning rate: 5.836E-05 | global batch size:  1024 | lm loss: 1.808995E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36658/   51900 | consumed samples:     37537792 | elapsed time per iteration (ms): 37634.6 | learning rate: 5.835E-05 | global batch size:  1024 | lm loss: 1.830774E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36659/   51900 | consumed samples:     37538816 | elapsed time per iteration (ms): 37798.0 | learning rate: 5.835E-05 | global batch size:  1024 | lm loss: 1.802230E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36660/   51900 | consumed samples:     37539840 | elapsed time per iteration (ms): 37612.7 | learning rate: 5.834E-05 | global batch size:  1024 | lm loss: 1.805995E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36661/   51900 | consumed samples:     37540864 | elapsed time per iteration (ms): 37604.9 | learning rate: 5.834E-05 | global batch size:  1024 | lm loss: 1.835619E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36662/   51900 | consumed samples:     37541888 | elapsed time per iteration (ms): 37701.5 | learning rate: 5.834E-05 | global batch size:  1024 | lm loss: 1.809993E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36663/   51900 | consumed samples:     37542912 | elapsed time per iteration (ms): 37700.5 | learning rate: 5.833E-05 | global batch size:  1024 | lm loss: 1.792070E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36664/   51900 | consumed samples:     37543936 | elapsed time per iteration (ms): 37665.2 | learning rate: 5.833E-05 | global batch size:  1024 | lm loss: 1.801441E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36665/   51900 | consumed samples:     37544960 | elapsed time per iteration (ms): 37738.9 | learning rate: 5.832E-05 | global batch size:  1024 | lm loss: 1.794248E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36666/   51900 | consumed samples:     37545984 | elapsed time per iteration (ms): 37714.7 | learning rate: 5.832E-05 | global batch size:  1024 | lm loss: 1.826307E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36667/   51900 | consumed samples:     37547008 | elapsed time per iteration (ms): 37771.1 | learning rate: 5.831E-05 | global batch size:  1024 | lm loss: 1.811222E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36668/   51900 | consumed samples:     37548032 | elapsed time per iteration (ms): 37732.1 | learning rate: 5.831E-05 | global batch size:  1024 | lm loss: 1.795229E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36669/   51900 | consumed samples:     37549056 | elapsed time per iteration (ms): 37625.1 | learning rate: 5.830E-05 | global batch size:  1024 | lm loss: 1.807299E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36670/   51900 | consumed samples:     37550080 | elapsed time per iteration (ms): 37589.6 | learning rate: 5.830E-05 | global batch size:  1024 | lm loss: 1.830550E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36671/   51900 | consumed samples:     37551104 | elapsed time per iteration (ms): 37758.7 | learning rate: 5.829E-05 | global batch size:  1024 | lm loss: 1.831802E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36672/   51900 | consumed samples:     37552128 | elapsed time per iteration (ms): 37704.4 | learning rate: 5.829E-05 | global batch size:  1024 | lm loss: 1.814176E+00 | loss scale: 1.0 | grad norm: 0.097 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36673/   51900 | consumed samples:     37553152 | elapsed time per iteration (ms): 37721.1 | learning rate: 5.828E-05 | global batch size:  1024 | lm loss: 1.823973E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36674/   51900 | consumed samples:     37554176 | elapsed time per iteration (ms): 37624.8 | learning rate: 5.828E-05 | global batch size:  1024 | lm loss: 1.808344E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36675/   51900 | consumed samples:     37555200 | elapsed time per iteration (ms): 37669.4 | learning rate: 5.828E-05 | global batch size:  1024 | lm loss: 1.807795E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36676/   51900 | consumed samples:     37556224 | elapsed time per iteration (ms): 37643.1 | learning rate: 5.827E-05 | global batch size:  1024 | lm loss: 1.812597E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36677/   51900 | consumed samples:     37557248 | elapsed time per iteration (ms): 37590.1 | learning rate: 5.827E-05 | global batch size:  1024 | lm loss: 1.819007E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36678/   51900 | consumed samples:     37558272 | elapsed time per iteration (ms): 37745.6 | learning rate: 5.826E-05 | global batch size:  1024 | lm loss: 1.821159E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36679/   51900 | consumed samples:     37559296 | elapsed time per iteration (ms): 37604.5 | learning rate: 5.826E-05 | global batch size:  1024 | lm loss: 1.817149E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36680/   51900 | consumed samples:     37560320 | elapsed time per iteration (ms): 37740.8 | learning rate: 5.825E-05 | global batch size:  1024 | lm loss: 1.833387E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36681/   51900 | consumed samples:     37561344 | elapsed time per iteration (ms): 37605.7 | learning rate: 5.825E-05 | global batch size:  1024 | lm loss: 1.806412E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36682/   51900 | consumed samples:     37562368 | elapsed time per iteration (ms): 37764.2 | learning rate: 5.824E-05 | global batch size:  1024 | lm loss: 1.802978E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36683/   51900 | consumed samples:     37563392 | elapsed time per iteration (ms): 37863.1 | learning rate: 5.824E-05 | global batch size:  1024 | lm loss: 1.801063E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36684/   51900 | consumed samples:     37564416 | elapsed time per iteration (ms): 37662.6 | learning rate: 5.823E-05 | global batch size:  1024 | lm loss: 1.799151E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36685/   51900 | consumed samples:     37565440 | elapsed time per iteration (ms): 37658.9 | learning rate: 5.823E-05 | global batch size:  1024 | lm loss: 1.812632E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36686/   51900 | consumed samples:     37566464 | elapsed time per iteration (ms): 37646.5 | learning rate: 5.822E-05 | global batch size:  1024 | lm loss: 1.796365E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36687/   51900 | consumed samples:     37567488 | elapsed time per iteration (ms): 37716.6 | learning rate: 5.822E-05 | global batch size:  1024 | lm loss: 1.801810E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36688/   51900 | consumed samples:     37568512 | elapsed time per iteration (ms): 37798.2 | learning rate: 5.821E-05 | global batch size:  1024 | lm loss: 1.804132E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36689/   51900 | consumed samples:     37569536 | elapsed time per iteration (ms): 37882.9 | learning rate: 5.821E-05 | global batch size:  1024 | lm loss: 1.800294E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36690/   51900 | consumed samples:     37570560 | elapsed time per iteration (ms): 37641.5 | learning rate: 5.821E-05 | global batch size:  1024 | lm loss: 1.811378E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36691/   51900 | consumed samples:     37571584 | elapsed time per iteration (ms): 37680.2 | learning rate: 5.820E-05 | global batch size:  1024 | lm loss: 1.809341E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36692/   51900 | consumed samples:     37572608 | elapsed time per iteration (ms): 37647.1 | learning rate: 5.820E-05 | global batch size:  1024 | lm loss: 1.811859E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36693/   51900 | consumed samples:     37573632 | elapsed time per iteration (ms): 37596.1 | learning rate: 5.819E-05 | global batch size:  1024 | lm loss: 1.810436E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36694/   51900 | consumed samples:     37574656 | elapsed time per iteration (ms): 37632.1 | learning rate: 5.819E-05 | global batch size:  1024 | lm loss: 1.810548E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36695/   51900 | consumed samples:     37575680 | elapsed time per iteration (ms): 37682.7 | learning rate: 5.818E-05 | global batch size:  1024 | lm loss: 1.814134E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36696/   51900 | consumed samples:     37576704 | elapsed time per iteration (ms): 37650.4 | learning rate: 5.818E-05 | global batch size:  1024 | lm loss: 1.814970E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36697/   51900 | consumed samples:     37577728 | elapsed time per iteration (ms): 37755.6 | learning rate: 5.817E-05 | global batch size:  1024 | lm loss: 1.804059E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36698/   51900 | consumed samples:     37578752 | elapsed time per iteration (ms): 37751.0 | learning rate: 5.817E-05 | global batch size:  1024 | lm loss: 1.822626E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36699/   51900 | consumed samples:     37579776 | elapsed time per iteration (ms): 37666.2 | learning rate: 5.816E-05 | global batch size:  1024 | lm loss: 1.805935E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36700/   51900 | consumed samples:     37580800 | elapsed time per iteration (ms): 37663.1 | learning rate: 5.816E-05 | global batch size:  1024 | lm loss: 1.808532E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36701/   51900 | consumed samples:     37581824 | elapsed time per iteration (ms): 37699.0 | learning rate: 5.815E-05 | global batch size:  1024 | lm loss: 1.815419E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36702/   51900 | consumed samples:     37582848 | elapsed time per iteration (ms): 37686.4 | learning rate: 5.815E-05 | global batch size:  1024 | lm loss: 1.795557E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36703/   51900 | consumed samples:     37583872 | elapsed time per iteration (ms): 37649.8 | learning rate: 5.815E-05 | global batch size:  1024 | lm loss: 1.801272E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36704/   51900 | consumed samples:     37584896 | elapsed time per iteration (ms): 37732.1 | learning rate: 5.814E-05 | global batch size:  1024 | lm loss: 1.817105E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36705/   51900 | consumed samples:     37585920 | elapsed time per iteration (ms): 37658.8 | learning rate: 5.814E-05 | global batch size:  1024 | lm loss: 1.840724E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36706/   51900 | consumed samples:     37586944 | elapsed time per iteration (ms): 37659.5 | learning rate: 5.813E-05 | global batch size:  1024 | lm loss: 1.811196E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36707/   51900 | consumed samples:     37587968 | elapsed time per iteration (ms): 37613.7 | learning rate: 5.813E-05 | global batch size:  1024 | lm loss: 1.818772E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36708/   51900 | consumed samples:     37588992 | elapsed time per iteration (ms): 37615.1 | learning rate: 5.812E-05 | global batch size:  1024 | lm loss: 1.801473E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36709/   51900 | consumed samples:     37590016 | elapsed time per iteration (ms): 37533.8 | learning rate: 5.812E-05 | global batch size:  1024 | lm loss: 1.803619E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36710/   51900 | consumed samples:     37591040 | elapsed time per iteration (ms): 37661.2 | learning rate: 5.811E-05 | global batch size:  1024 | lm loss: 1.824267E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36711/   51900 | consumed samples:     37592064 | elapsed time per iteration (ms): 37677.2 | learning rate: 5.811E-05 | global batch size:  1024 | lm loss: 1.813647E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36712/   51900 | consumed samples:     37593088 | elapsed time per iteration (ms): 37655.7 | learning rate: 5.810E-05 | global batch size:  1024 | lm loss: 1.807290E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36713/   51900 | consumed samples:     37594112 | elapsed time per iteration (ms): 37740.1 | learning rate: 5.810E-05 | global batch size:  1024 | lm loss: 1.795611E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36714/   51900 | consumed samples:     37595136 | elapsed time per iteration (ms): 37814.1 | learning rate: 5.809E-05 | global batch size:  1024 | lm loss: 1.796454E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36715/   51900 | consumed samples:     37596160 | elapsed time per iteration (ms): 37721.8 | learning rate: 5.809E-05 | global batch size:  1024 | lm loss: 1.809489E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36716/   51900 | consumed samples:     37597184 | elapsed time per iteration (ms): 37646.6 | learning rate: 5.809E-05 | global batch size:  1024 | lm loss: 1.842976E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36717/   51900 | consumed samples:     37598208 | elapsed time per iteration (ms): 37592.1 | learning rate: 5.808E-05 | global batch size:  1024 | lm loss: 1.816160E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36718/   51900 | consumed samples:     37599232 | elapsed time per iteration (ms): 37743.5 | learning rate: 5.808E-05 | global batch size:  1024 | lm loss: 1.804657E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36719/   51900 | consumed samples:     37600256 | elapsed time per iteration (ms): 37648.1 | learning rate: 5.807E-05 | global batch size:  1024 | lm loss: 1.801530E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36720/   51900 | consumed samples:     37601280 | elapsed time per iteration (ms): 37684.9 | learning rate: 5.807E-05 | global batch size:  1024 | lm loss: 1.811641E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36721/   51900 | consumed samples:     37602304 | elapsed time per iteration (ms): 37684.3 | learning rate: 5.806E-05 | global batch size:  1024 | lm loss: 1.823430E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36722/   51900 | consumed samples:     37603328 | elapsed time per iteration (ms): 37689.0 | learning rate: 5.806E-05 | global batch size:  1024 | lm loss: 1.804857E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36723/   51900 | consumed samples:     37604352 | elapsed time per iteration (ms): 37683.3 | learning rate: 5.805E-05 | global batch size:  1024 | lm loss: 1.797812E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36724/   51900 | consumed samples:     37605376 | elapsed time per iteration (ms): 37588.8 | learning rate: 5.805E-05 | global batch size:  1024 | lm loss: 1.820285E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36725/   51900 | consumed samples:     37606400 | elapsed time per iteration (ms): 37717.9 | learning rate: 5.804E-05 | global batch size:  1024 | lm loss: 1.804740E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36726/   51900 | consumed samples:     37607424 | elapsed time per iteration (ms): 37720.7 | learning rate: 5.804E-05 | global batch size:  1024 | lm loss: 1.813382E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36727/   51900 | consumed samples:     37608448 | elapsed time per iteration (ms): 37636.7 | learning rate: 5.803E-05 | global batch size:  1024 | lm loss: 1.809069E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36728/   51900 | consumed samples:     37609472 | elapsed time per iteration (ms): 37688.5 | learning rate: 5.803E-05 | global batch size:  1024 | lm loss: 1.800400E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36729/   51900 | consumed samples:     37610496 | elapsed time per iteration (ms): 37607.4 | learning rate: 5.802E-05 | global batch size:  1024 | lm loss: 1.815018E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36730/   51900 | consumed samples:     37611520 | elapsed time per iteration (ms): 37604.6 | learning rate: 5.802E-05 | global batch size:  1024 | lm loss: 1.800459E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36731/   51900 | consumed samples:     37612544 | elapsed time per iteration (ms): 37711.5 | learning rate: 5.802E-05 | global batch size:  1024 | lm loss: 1.812568E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36732/   51900 | consumed samples:     37613568 | elapsed time per iteration (ms): 37661.8 | learning rate: 5.801E-05 | global batch size:  1024 | lm loss: 1.805875E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36733/   51900 | consumed samples:     37614592 | elapsed time per iteration (ms): 37537.8 | learning rate: 5.801E-05 | global batch size:  1024 | lm loss: 1.799932E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36734/   51900 | consumed samples:     37615616 | elapsed time per iteration (ms): 37766.6 | learning rate: 5.800E-05 | global batch size:  1024 | lm loss: 1.808983E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36735/   51900 | consumed samples:     37616640 | elapsed time per iteration (ms): 37648.0 | learning rate: 5.800E-05 | global batch size:  1024 | lm loss: 1.821545E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36736/   51900 | consumed samples:     37617664 | elapsed time per iteration (ms): 37790.8 | learning rate: 5.799E-05 | global batch size:  1024 | lm loss: 1.816237E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36737/   51900 | consumed samples:     37618688 | elapsed time per iteration (ms): 37669.4 | learning rate: 5.799E-05 | global batch size:  1024 | lm loss: 1.823500E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36738/   51900 | consumed samples:     37619712 | elapsed time per iteration (ms): 37692.6 | learning rate: 5.798E-05 | global batch size:  1024 | lm loss: 1.789634E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36739/   51900 | consumed samples:     37620736 | elapsed time per iteration (ms): 37712.0 | learning rate: 5.798E-05 | global batch size:  1024 | lm loss: 1.813005E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36740/   51900 | consumed samples:     37621760 | elapsed time per iteration (ms): 37642.3 | learning rate: 5.797E-05 | global batch size:  1024 | lm loss: 1.798900E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36741/   51900 | consumed samples:     37622784 | elapsed time per iteration (ms): 37689.2 | learning rate: 5.797E-05 | global batch size:  1024 | lm loss: 1.808748E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36742/   51900 | consumed samples:     37623808 | elapsed time per iteration (ms): 37698.2 | learning rate: 5.796E-05 | global batch size:  1024 | lm loss: 1.823558E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36743/   51900 | consumed samples:     37624832 | elapsed time per iteration (ms): 37652.0 | learning rate: 5.796E-05 | global batch size:  1024 | lm loss: 1.829386E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36744/   51900 | consumed samples:     37625856 | elapsed time per iteration (ms): 37667.8 | learning rate: 5.796E-05 | global batch size:  1024 | lm loss: 1.812514E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36745/   51900 | consumed samples:     37626880 | elapsed time per iteration (ms): 37620.5 | learning rate: 5.795E-05 | global batch size:  1024 | lm loss: 1.807366E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36746/   51900 | consumed samples:     37627904 | elapsed time per iteration (ms): 37659.7 | learning rate: 5.795E-05 | global batch size:  1024 | lm loss: 1.801471E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36747/   51900 | consumed samples:     37628928 | elapsed time per iteration (ms): 37642.5 | learning rate: 5.794E-05 | global batch size:  1024 | lm loss: 1.801041E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36748/   51900 | consumed samples:     37629952 | elapsed time per iteration (ms): 37648.5 | learning rate: 5.794E-05 | global batch size:  1024 | lm loss: 1.807528E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36749/   51900 | consumed samples:     37630976 | elapsed time per iteration (ms): 37790.5 | learning rate: 5.793E-05 | global batch size:  1024 | lm loss: 1.817501E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36750/   51900 | consumed samples:     37632000 | elapsed time per iteration (ms): 37675.8 | learning rate: 5.793E-05 | global batch size:  1024 | lm loss: 1.804306E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36751/   51900 | consumed samples:     37633024 | elapsed time per iteration (ms): 37722.5 | learning rate: 5.792E-05 | global batch size:  1024 | lm loss: 1.808744E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36752/   51900 | consumed samples:     37634048 | elapsed time per iteration (ms): 37638.0 | learning rate: 5.792E-05 | global batch size:  1024 | lm loss: 1.815877E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36753/   51900 | consumed samples:     37635072 | elapsed time per iteration (ms): 37616.7 | learning rate: 5.791E-05 | global batch size:  1024 | lm loss: 1.812469E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36754/   51900 | consumed samples:     37636096 | elapsed time per iteration (ms): 37673.8 | learning rate: 5.791E-05 | global batch size:  1024 | lm loss: 1.799591E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36755/   51900 | consumed samples:     37637120 | elapsed time per iteration (ms): 37622.5 | learning rate: 5.790E-05 | global batch size:  1024 | lm loss: 1.797344E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36756/   51900 | consumed samples:     37638144 | elapsed time per iteration (ms): 37742.0 | learning rate: 5.790E-05 | global batch size:  1024 | lm loss: 1.829514E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36757/   51900 | consumed samples:     37639168 | elapsed time per iteration (ms): 37588.8 | learning rate: 5.790E-05 | global batch size:  1024 | lm loss: 1.819330E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36758/   51900 | consumed samples:     37640192 | elapsed time per iteration (ms): 37624.2 | learning rate: 5.789E-05 | global batch size:  1024 | lm loss: 1.803390E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36759/   51900 | consumed samples:     37641216 | elapsed time per iteration (ms): 37632.6 | learning rate: 5.789E-05 | global batch size:  1024 | lm loss: 1.800949E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36760/   51900 | consumed samples:     37642240 | elapsed time per iteration (ms): 37662.6 | learning rate: 5.788E-05 | global batch size:  1024 | lm loss: 1.810244E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36761/   51900 | consumed samples:     37643264 | elapsed time per iteration (ms): 37730.8 | learning rate: 5.788E-05 | global batch size:  1024 | lm loss: 1.808584E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36762/   51900 | consumed samples:     37644288 | elapsed time per iteration (ms): 37568.8 | learning rate: 5.787E-05 | global batch size:  1024 | lm loss: 1.795650E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36763/   51900 | consumed samples:     37645312 | elapsed time per iteration (ms): 37714.9 | learning rate: 5.787E-05 | global batch size:  1024 | lm loss: 1.829009E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36764/   51900 | consumed samples:     37646336 | elapsed time per iteration (ms): 37702.5 | learning rate: 5.786E-05 | global batch size:  1024 | lm loss: 1.783332E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36765/   51900 | consumed samples:     37647360 | elapsed time per iteration (ms): 37653.7 | learning rate: 5.786E-05 | global batch size:  1024 | lm loss: 1.804676E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36766/   51900 | consumed samples:     37648384 | elapsed time per iteration (ms): 37763.6 | learning rate: 5.785E-05 | global batch size:  1024 | lm loss: 1.809584E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36767/   51900 | consumed samples:     37649408 | elapsed time per iteration (ms): 37757.3 | learning rate: 5.785E-05 | global batch size:  1024 | lm loss: 1.807778E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36768/   51900 | consumed samples:     37650432 | elapsed time per iteration (ms): 37673.6 | learning rate: 5.784E-05 | global batch size:  1024 | lm loss: 1.810360E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36769/   51900 | consumed samples:     37651456 | elapsed time per iteration (ms): 37694.4 | learning rate: 5.784E-05 | global batch size:  1024 | lm loss: 1.813372E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36770/   51900 | consumed samples:     37652480 | elapsed time per iteration (ms): 37668.5 | learning rate: 5.784E-05 | global batch size:  1024 | lm loss: 1.804612E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36771/   51900 | consumed samples:     37653504 | elapsed time per iteration (ms): 37693.9 | learning rate: 5.783E-05 | global batch size:  1024 | lm loss: 1.816466E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36772/   51900 | consumed samples:     37654528 | elapsed time per iteration (ms): 37671.9 | learning rate: 5.783E-05 | global batch size:  1024 | lm loss: 1.808372E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36773/   51900 | consumed samples:     37655552 | elapsed time per iteration (ms): 37642.5 | learning rate: 5.782E-05 | global batch size:  1024 | lm loss: 1.829928E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36774/   51900 | consumed samples:     37656576 | elapsed time per iteration (ms): 37680.9 | learning rate: 5.782E-05 | global batch size:  1024 | lm loss: 1.792655E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36775/   51900 | consumed samples:     37657600 | elapsed time per iteration (ms): 37674.9 | learning rate: 5.781E-05 | global batch size:  1024 | lm loss: 1.815104E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36776/   51900 | consumed samples:     37658624 | elapsed time per iteration (ms): 37660.1 | learning rate: 5.781E-05 | global batch size:  1024 | lm loss: 1.803455E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36777/   51900 | consumed samples:     37659648 | elapsed time per iteration (ms): 37635.9 | learning rate: 5.780E-05 | global batch size:  1024 | lm loss: 1.820562E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36778/   51900 | consumed samples:     37660672 | elapsed time per iteration (ms): 37640.3 | learning rate: 5.780E-05 | global batch size:  1024 | lm loss: 1.820359E+00 | loss scale: 1.0 | grad norm: 0.087 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36779/   51900 | consumed samples:     37661696 | elapsed time per iteration (ms): 37736.0 | learning rate: 5.779E-05 | global batch size:  1024 | lm loss: 1.795542E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36780/   51900 | consumed samples:     37662720 | elapsed time per iteration (ms): 37600.5 | learning rate: 5.779E-05 | global batch size:  1024 | lm loss: 1.813355E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36781/   51900 | consumed samples:     37663744 | elapsed time per iteration (ms): 37638.3 | learning rate: 5.778E-05 | global batch size:  1024 | lm loss: 1.782264E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36782/   51900 | consumed samples:     37664768 | elapsed time per iteration (ms): 37599.2 | learning rate: 5.778E-05 | global batch size:  1024 | lm loss: 1.822846E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36783/   51900 | consumed samples:     37665792 | elapsed time per iteration (ms): 37718.0 | learning rate: 5.778E-05 | global batch size:  1024 | lm loss: 1.816858E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36784/   51900 | consumed samples:     37666816 | elapsed time per iteration (ms): 37747.2 | learning rate: 5.777E-05 | global batch size:  1024 | lm loss: 1.806977E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36785/   51900 | consumed samples:     37667840 | elapsed time per iteration (ms): 37646.5 | learning rate: 5.777E-05 | global batch size:  1024 | lm loss: 1.813201E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36786/   51900 | consumed samples:     37668864 | elapsed time per iteration (ms): 37686.1 | learning rate: 5.776E-05 | global batch size:  1024 | lm loss: 1.815992E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36787/   51900 | consumed samples:     37669888 | elapsed time per iteration (ms): 37728.1 | learning rate: 5.776E-05 | global batch size:  1024 | lm loss: 1.798693E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36788/   51900 | consumed samples:     37670912 | elapsed time per iteration (ms): 37771.0 | learning rate: 5.775E-05 | global batch size:  1024 | lm loss: 1.821868E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36789/   51900 | consumed samples:     37671936 | elapsed time per iteration (ms): 37640.0 | learning rate: 5.775E-05 | global batch size:  1024 | lm loss: 1.805379E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36790/   51900 | consumed samples:     37672960 | elapsed time per iteration (ms): 37585.2 | learning rate: 5.774E-05 | global batch size:  1024 | lm loss: 1.805127E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36791/   51900 | consumed samples:     37673984 | elapsed time per iteration (ms): 37573.7 | learning rate: 5.774E-05 | global batch size:  1024 | lm loss: 1.795071E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36792/   51900 | consumed samples:     37675008 | elapsed time per iteration (ms): 37798.3 | learning rate: 5.773E-05 | global batch size:  1024 | lm loss: 1.825405E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36793/   51900 | consumed samples:     37676032 | elapsed time per iteration (ms): 37638.9 | learning rate: 5.773E-05 | global batch size:  1024 | lm loss: 1.813972E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36794/   51900 | consumed samples:     37677056 | elapsed time per iteration (ms): 37695.3 | learning rate: 5.772E-05 | global batch size:  1024 | lm loss: 1.796910E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36795/   51900 | consumed samples:     37678080 | elapsed time per iteration (ms): 37696.7 | learning rate: 5.772E-05 | global batch size:  1024 | lm loss: 1.820472E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36796/   51900 | consumed samples:     37679104 | elapsed time per iteration (ms): 37819.4 | learning rate: 5.772E-05 | global batch size:  1024 | lm loss: 1.800511E+00 | loss scale: 1.0 | grad norm: 0.093 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36797/   51900 | consumed samples:     37680128 | elapsed time per iteration (ms): 37662.2 | learning rate: 5.771E-05 | global batch size:  1024 | lm loss: 1.813595E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36798/   51900 | consumed samples:     37681152 | elapsed time per iteration (ms): 37628.9 | learning rate: 5.771E-05 | global batch size:  1024 | lm loss: 1.799768E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36799/   51900 | consumed samples:     37682176 | elapsed time per iteration (ms): 37678.7 | learning rate: 5.770E-05 | global batch size:  1024 | lm loss: 1.807288E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36800/   51900 | consumed samples:     37683200 | elapsed time per iteration (ms): 37898.7 | learning rate: 5.770E-05 | global batch size:  1024 | lm loss: 1.819885E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36801/   51900 | consumed samples:     37684224 | elapsed time per iteration (ms): 37728.1 | learning rate: 5.769E-05 | global batch size:  1024 | lm loss: 1.804277E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36802/   51900 | consumed samples:     37685248 | elapsed time per iteration (ms): 37749.8 | learning rate: 5.769E-05 | global batch size:  1024 | lm loss: 1.818631E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36803/   51900 | consumed samples:     37686272 | elapsed time per iteration (ms): 37725.6 | learning rate: 5.768E-05 | global batch size:  1024 | lm loss: 1.817002E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36804/   51900 | consumed samples:     37687296 | elapsed time per iteration (ms): 37783.6 | learning rate: 5.768E-05 | global batch size:  1024 | lm loss: 1.821745E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36805/   51900 | consumed samples:     37688320 | elapsed time per iteration (ms): 37688.1 | learning rate: 5.767E-05 | global batch size:  1024 | lm loss: 1.804137E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36806/   51900 | consumed samples:     37689344 | elapsed time per iteration (ms): 37600.9 | learning rate: 5.767E-05 | global batch size:  1024 | lm loss: 1.831685E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36807/   51900 | consumed samples:     37690368 | elapsed time per iteration (ms): 37666.4 | learning rate: 5.766E-05 | global batch size:  1024 | lm loss: 1.797367E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36808/   51900 | consumed samples:     37691392 | elapsed time per iteration (ms): 37648.9 | learning rate: 5.766E-05 | global batch size:  1024 | lm loss: 1.795576E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36809/   51900 | consumed samples:     37692416 | elapsed time per iteration (ms): 37710.6 | learning rate: 5.766E-05 | global batch size:  1024 | lm loss: 1.810903E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36810/   51900 | consumed samples:     37693440 | elapsed time per iteration (ms): 37726.0 | learning rate: 5.765E-05 | global batch size:  1024 | lm loss: 1.815486E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36811/   51900 | consumed samples:     37694464 | elapsed time per iteration (ms): 37632.3 | learning rate: 5.765E-05 | global batch size:  1024 | lm loss: 1.826269E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36812/   51900 | consumed samples:     37695488 | elapsed time per iteration (ms): 37709.9 | learning rate: 5.764E-05 | global batch size:  1024 | lm loss: 1.816603E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36813/   51900 | consumed samples:     37696512 | elapsed time per iteration (ms): 37698.2 | learning rate: 5.764E-05 | global batch size:  1024 | lm loss: 1.814019E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36814/   51900 | consumed samples:     37697536 | elapsed time per iteration (ms): 37600.0 | learning rate: 5.763E-05 | global batch size:  1024 | lm loss: 1.803174E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36815/   51900 | consumed samples:     37698560 | elapsed time per iteration (ms): 37587.3 | learning rate: 5.763E-05 | global batch size:  1024 | lm loss: 1.794776E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36816/   51900 | consumed samples:     37699584 | elapsed time per iteration (ms): 37776.9 | learning rate: 5.762E-05 | global batch size:  1024 | lm loss: 1.822295E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36817/   51900 | consumed samples:     37700608 | elapsed time per iteration (ms): 37618.5 | learning rate: 5.762E-05 | global batch size:  1024 | lm loss: 1.810885E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36818/   51900 | consumed samples:     37701632 | elapsed time per iteration (ms): 37716.6 | learning rate: 5.761E-05 | global batch size:  1024 | lm loss: 1.807762E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36819/   51900 | consumed samples:     37702656 | elapsed time per iteration (ms): 37592.1 | learning rate: 5.761E-05 | global batch size:  1024 | lm loss: 1.803336E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36820/   51900 | consumed samples:     37703680 | elapsed time per iteration (ms): 37777.6 | learning rate: 5.760E-05 | global batch size:  1024 | lm loss: 1.803870E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36821/   51900 | consumed samples:     37704704 | elapsed time per iteration (ms): 37634.6 | learning rate: 5.760E-05 | global batch size:  1024 | lm loss: 1.803072E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36822/   51900 | consumed samples:     37705728 | elapsed time per iteration (ms): 37676.4 | learning rate: 5.760E-05 | global batch size:  1024 | lm loss: 1.818235E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36823/   51900 | consumed samples:     37706752 | elapsed time per iteration (ms): 37635.5 | learning rate: 5.759E-05 | global batch size:  1024 | lm loss: 1.791819E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36824/   51900 | consumed samples:     37707776 | elapsed time per iteration (ms): 37747.3 | learning rate: 5.759E-05 | global batch size:  1024 | lm loss: 1.810311E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36825/   51900 | consumed samples:     37708800 | elapsed time per iteration (ms): 37723.9 | learning rate: 5.758E-05 | global batch size:  1024 | lm loss: 1.812636E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36826/   51900 | consumed samples:     37709824 | elapsed time per iteration (ms): 37769.6 | learning rate: 5.758E-05 | global batch size:  1024 | lm loss: 1.795403E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36827/   51900 | consumed samples:     37710848 | elapsed time per iteration (ms): 37571.5 | learning rate: 5.757E-05 | global batch size:  1024 | lm loss: 1.803474E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36828/   51900 | consumed samples:     37711872 | elapsed time per iteration (ms): 37659.5 | learning rate: 5.757E-05 | global batch size:  1024 | lm loss: 1.818002E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36829/   51900 | consumed samples:     37712896 | elapsed time per iteration (ms): 37725.0 | learning rate: 5.756E-05 | global batch size:  1024 | lm loss: 1.812752E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36830/   51900 | consumed samples:     37713920 | elapsed time per iteration (ms): 37700.8 | learning rate: 5.756E-05 | global batch size:  1024 | lm loss: 1.799421E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36831/   51900 | consumed samples:     37714944 | elapsed time per iteration (ms): 37705.9 | learning rate: 5.755E-05 | global batch size:  1024 | lm loss: 1.806276E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36832/   51900 | consumed samples:     37715968 | elapsed time per iteration (ms): 37772.3 | learning rate: 5.755E-05 | global batch size:  1024 | lm loss: 1.809992E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36833/   51900 | consumed samples:     37716992 | elapsed time per iteration (ms): 37749.9 | learning rate: 5.754E-05 | global batch size:  1024 | lm loss: 1.791881E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36834/   51900 | consumed samples:     37718016 | elapsed time per iteration (ms): 37669.3 | learning rate: 5.754E-05 | global batch size:  1024 | lm loss: 1.804346E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36835/   51900 | consumed samples:     37719040 | elapsed time per iteration (ms): 37761.5 | learning rate: 5.754E-05 | global batch size:  1024 | lm loss: 1.819058E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36836/   51900 | consumed samples:     37720064 | elapsed time per iteration (ms): 37677.9 | learning rate: 5.753E-05 | global batch size:  1024 | lm loss: 1.781866E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36837/   51900 | consumed samples:     37721088 | elapsed time per iteration (ms): 37710.3 | learning rate: 5.753E-05 | global batch size:  1024 | lm loss: 1.807744E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36838/   51900 | consumed samples:     37722112 | elapsed time per iteration (ms): 37686.9 | learning rate: 5.752E-05 | global batch size:  1024 | lm loss: 1.794136E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36839/   51900 | consumed samples:     37723136 | elapsed time per iteration (ms): 37613.8 | learning rate: 5.752E-05 | global batch size:  1024 | lm loss: 1.816586E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36840/   51900 | consumed samples:     37724160 | elapsed time per iteration (ms): 37711.8 | learning rate: 5.751E-05 | global batch size:  1024 | lm loss: 1.807235E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36841/   51900 | consumed samples:     37725184 | elapsed time per iteration (ms): 37715.2 | learning rate: 5.751E-05 | global batch size:  1024 | lm loss: 1.817492E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36842/   51900 | consumed samples:     37726208 | elapsed time per iteration (ms): 37655.9 | learning rate: 5.750E-05 | global batch size:  1024 | lm loss: 1.802397E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36843/   51900 | consumed samples:     37727232 | elapsed time per iteration (ms): 37730.3 | learning rate: 5.750E-05 | global batch size:  1024 | lm loss: 1.799471E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36844/   51900 | consumed samples:     37728256 | elapsed time per iteration (ms): 37719.0 | learning rate: 5.749E-05 | global batch size:  1024 | lm loss: 1.805712E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36845/   51900 | consumed samples:     37729280 | elapsed time per iteration (ms): 37742.2 | learning rate: 5.749E-05 | global batch size:  1024 | lm loss: 1.803303E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36846/   51900 | consumed samples:     37730304 | elapsed time per iteration (ms): 37658.5 | learning rate: 5.749E-05 | global batch size:  1024 | lm loss: 1.829304E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36847/   51900 | consumed samples:     37731328 | elapsed time per iteration (ms): 37605.9 | learning rate: 5.748E-05 | global batch size:  1024 | lm loss: 1.805973E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36848/   51900 | consumed samples:     37732352 | elapsed time per iteration (ms): 37714.6 | learning rate: 5.748E-05 | global batch size:  1024 | lm loss: 1.829221E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36849/   51900 | consumed samples:     37733376 | elapsed time per iteration (ms): 37664.6 | learning rate: 5.747E-05 | global batch size:  1024 | lm loss: 1.810715E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36850/   51900 | consumed samples:     37734400 | elapsed time per iteration (ms): 37716.0 | learning rate: 5.747E-05 | global batch size:  1024 | lm loss: 1.805113E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36851/   51900 | consumed samples:     37735424 | elapsed time per iteration (ms): 37755.8 | learning rate: 5.746E-05 | global batch size:  1024 | lm loss: 1.806230E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36852/   51900 | consumed samples:     37736448 | elapsed time per iteration (ms): 37671.6 | learning rate: 5.746E-05 | global batch size:  1024 | lm loss: 1.800373E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36853/   51900 | consumed samples:     37737472 | elapsed time per iteration (ms): 37614.8 | learning rate: 5.745E-05 | global batch size:  1024 | lm loss: 1.798936E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36854/   51900 | consumed samples:     37738496 | elapsed time per iteration (ms): 37716.2 | learning rate: 5.745E-05 | global batch size:  1024 | lm loss: 1.819324E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36855/   51900 | consumed samples:     37739520 | elapsed time per iteration (ms): 37756.9 | learning rate: 5.744E-05 | global batch size:  1024 | lm loss: 1.801733E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36856/   51900 | consumed samples:     37740544 | elapsed time per iteration (ms): 37687.5 | learning rate: 5.744E-05 | global batch size:  1024 | lm loss: 1.817984E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36857/   51900 | consumed samples:     37741568 | elapsed time per iteration (ms): 37682.9 | learning rate: 5.743E-05 | global batch size:  1024 | lm loss: 1.813779E+00 | loss scale: 1.0 | grad norm: 0.063 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36858/   51900 | consumed samples:     37742592 | elapsed time per iteration (ms): 37631.4 | learning rate: 5.743E-05 | global batch size:  1024 | lm loss: 1.807773E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36859/   51900 | consumed samples:     37743616 | elapsed time per iteration (ms): 37739.7 | learning rate: 5.743E-05 | global batch size:  1024 | lm loss: 1.806899E+00 | loss scale: 1.0 | grad norm: 0.065 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36860/   51900 | consumed samples:     37744640 | elapsed time per iteration (ms): 37679.1 | learning rate: 5.742E-05 | global batch size:  1024 | lm loss: 1.811281E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36861/   51900 | consumed samples:     37745664 | elapsed time per iteration (ms): 37752.8 | learning rate: 5.742E-05 | global batch size:  1024 | lm loss: 1.807383E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36862/   51900 | consumed samples:     37746688 | elapsed time per iteration (ms): 37713.9 | learning rate: 5.741E-05 | global batch size:  1024 | lm loss: 1.787874E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36863/   51900 | consumed samples:     37747712 | elapsed time per iteration (ms): 37672.6 | learning rate: 5.741E-05 | global batch size:  1024 | lm loss: 1.797007E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36864/   51900 | consumed samples:     37748736 | elapsed time per iteration (ms): 37724.2 | learning rate: 5.740E-05 | global batch size:  1024 | lm loss: 1.811679E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36865/   51900 | consumed samples:     37749760 | elapsed time per iteration (ms): 37687.9 | learning rate: 5.740E-05 | global batch size:  1024 | lm loss: 1.809179E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36866/   51900 | consumed samples:     37750784 | elapsed time per iteration (ms): 37626.2 | learning rate: 5.739E-05 | global batch size:  1024 | lm loss: 1.804703E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36867/   51900 | consumed samples:     37751808 | elapsed time per iteration (ms): 37653.0 | learning rate: 5.739E-05 | global batch size:  1024 | lm loss: 1.816248E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36868/   51900 | consumed samples:     37752832 | elapsed time per iteration (ms): 37727.9 | learning rate: 5.738E-05 | global batch size:  1024 | lm loss: 1.805221E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36869/   51900 | consumed samples:     37753856 | elapsed time per iteration (ms): 37685.2 | learning rate: 5.738E-05 | global batch size:  1024 | lm loss: 1.829138E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36870/   51900 | consumed samples:     37754880 | elapsed time per iteration (ms): 37703.0 | learning rate: 5.737E-05 | global batch size:  1024 | lm loss: 1.819000E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36871/   51900 | consumed samples:     37755904 | elapsed time per iteration (ms): 37746.2 | learning rate: 5.737E-05 | global batch size:  1024 | lm loss: 1.810577E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36872/   51900 | consumed samples:     37756928 | elapsed time per iteration (ms): 37687.5 | learning rate: 5.737E-05 | global batch size:  1024 | lm loss: 1.818474E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36873/   51900 | consumed samples:     37757952 | elapsed time per iteration (ms): 37688.0 | learning rate: 5.736E-05 | global batch size:  1024 | lm loss: 1.800628E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36874/   51900 | consumed samples:     37758976 | elapsed time per iteration (ms): 37680.2 | learning rate: 5.736E-05 | global batch size:  1024 | lm loss: 1.812828E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36875/   51900 | consumed samples:     37760000 | elapsed time per iteration (ms): 37690.4 | learning rate: 5.735E-05 | global batch size:  1024 | lm loss: 1.813915E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36876/   51900 | consumed samples:     37761024 | elapsed time per iteration (ms): 37645.4 | learning rate: 5.735E-05 | global batch size:  1024 | lm loss: 1.829499E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36877/   51900 | consumed samples:     37762048 | elapsed time per iteration (ms): 37651.3 | learning rate: 5.734E-05 | global batch size:  1024 | lm loss: 1.804780E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36878/   51900 | consumed samples:     37763072 | elapsed time per iteration (ms): 37574.4 | learning rate: 5.734E-05 | global batch size:  1024 | lm loss: 1.799744E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36879/   51900 | consumed samples:     37764096 | elapsed time per iteration (ms): 37818.8 | learning rate: 5.733E-05 | global batch size:  1024 | lm loss: 1.815843E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36880/   51900 | consumed samples:     37765120 | elapsed time per iteration (ms): 37662.3 | learning rate: 5.733E-05 | global batch size:  1024 | lm loss: 1.813292E+00 | loss scale: 1.0 | grad norm: 0.065 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36881/   51900 | consumed samples:     37766144 | elapsed time per iteration (ms): 37571.5 | learning rate: 5.732E-05 | global batch size:  1024 | lm loss: 1.788435E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36882/   51900 | consumed samples:     37767168 | elapsed time per iteration (ms): 37746.8 | learning rate: 5.732E-05 | global batch size:  1024 | lm loss: 1.813717E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36883/   51900 | consumed samples:     37768192 | elapsed time per iteration (ms): 37655.7 | learning rate: 5.732E-05 | global batch size:  1024 | lm loss: 1.804191E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36884/   51900 | consumed samples:     37769216 | elapsed time per iteration (ms): 37765.0 | learning rate: 5.731E-05 | global batch size:  1024 | lm loss: 1.816273E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36885/   51900 | consumed samples:     37770240 | elapsed time per iteration (ms): 37644.1 | learning rate: 5.731E-05 | global batch size:  1024 | lm loss: 1.794940E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36886/   51900 | consumed samples:     37771264 | elapsed time per iteration (ms): 37686.8 | learning rate: 5.730E-05 | global batch size:  1024 | lm loss: 1.810942E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36887/   51900 | consumed samples:     37772288 | elapsed time per iteration (ms): 37638.7 | learning rate: 5.730E-05 | global batch size:  1024 | lm loss: 1.798529E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36888/   51900 | consumed samples:     37773312 | elapsed time per iteration (ms): 37882.7 | learning rate: 5.729E-05 | global batch size:  1024 | lm loss: 1.794577E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36889/   51900 | consumed samples:     37774336 | elapsed time per iteration (ms): 37658.3 | learning rate: 5.729E-05 | global batch size:  1024 | lm loss: 1.796226E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36890/   51900 | consumed samples:     37775360 | elapsed time per iteration (ms): 37619.3 | learning rate: 5.728E-05 | global batch size:  1024 | lm loss: 1.832247E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36891/   51900 | consumed samples:     37776384 | elapsed time per iteration (ms): 37726.9 | learning rate: 5.728E-05 | global batch size:  1024 | lm loss: 1.790855E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36892/   51900 | consumed samples:     37777408 | elapsed time per iteration (ms): 37765.2 | learning rate: 5.727E-05 | global batch size:  1024 | lm loss: 1.824315E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36893/   51900 | consumed samples:     37778432 | elapsed time per iteration (ms): 37648.8 | learning rate: 5.727E-05 | global batch size:  1024 | lm loss: 1.825319E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36894/   51900 | consumed samples:     37779456 | elapsed time per iteration (ms): 37721.6 | learning rate: 5.726E-05 | global batch size:  1024 | lm loss: 1.806082E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36895/   51900 | consumed samples:     37780480 | elapsed time per iteration (ms): 37736.9 | learning rate: 5.726E-05 | global batch size:  1024 | lm loss: 1.812890E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36896/   51900 | consumed samples:     37781504 | elapsed time per iteration (ms): 37693.5 | learning rate: 5.726E-05 | global batch size:  1024 | lm loss: 1.824351E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36897/   51900 | consumed samples:     37782528 | elapsed time per iteration (ms): 37676.5 | learning rate: 5.725E-05 | global batch size:  1024 | lm loss: 1.801365E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36898/   51900 | consumed samples:     37783552 | elapsed time per iteration (ms): 37886.6 | learning rate: 5.725E-05 | global batch size:  1024 | lm loss: 1.814481E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36899/   51900 | consumed samples:     37784576 | elapsed time per iteration (ms): 37702.1 | learning rate: 5.724E-05 | global batch size:  1024 | lm loss: 1.798086E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36900/   51900 | consumed samples:     37785600 | elapsed time per iteration (ms): 37761.9 | learning rate: 5.724E-05 | global batch size:  1024 | lm loss: 1.806672E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36901/   51900 | consumed samples:     37786624 | elapsed time per iteration (ms): 37614.0 | learning rate: 5.723E-05 | global batch size:  1024 | lm loss: 1.809503E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36902/   51900 | consumed samples:     37787648 | elapsed time per iteration (ms): 37669.0 | learning rate: 5.723E-05 | global batch size:  1024 | lm loss: 1.811419E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36903/   51900 | consumed samples:     37788672 | elapsed time per iteration (ms): 37562.5 | learning rate: 5.722E-05 | global batch size:  1024 | lm loss: 1.818864E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36904/   51900 | consumed samples:     37789696 | elapsed time per iteration (ms): 37573.9 | learning rate: 5.722E-05 | global batch size:  1024 | lm loss: 1.816828E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36905/   51900 | consumed samples:     37790720 | elapsed time per iteration (ms): 37628.7 | learning rate: 5.721E-05 | global batch size:  1024 | lm loss: 1.823965E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36906/   51900 | consumed samples:     37791744 | elapsed time per iteration (ms): 37657.4 | learning rate: 5.721E-05 | global batch size:  1024 | lm loss: 1.812937E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36907/   51900 | consumed samples:     37792768 | elapsed time per iteration (ms): 37662.6 | learning rate: 5.720E-05 | global batch size:  1024 | lm loss: 1.804419E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36908/   51900 | consumed samples:     37793792 | elapsed time per iteration (ms): 37658.7 | learning rate: 5.720E-05 | global batch size:  1024 | lm loss: 1.793892E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36909/   51900 | consumed samples:     37794816 | elapsed time per iteration (ms): 37667.9 | learning rate: 5.720E-05 | global batch size:  1024 | lm loss: 1.816956E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36910/   51900 | consumed samples:     37795840 | elapsed time per iteration (ms): 37627.4 | learning rate: 5.719E-05 | global batch size:  1024 | lm loss: 1.810381E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36911/   51900 | consumed samples:     37796864 | elapsed time per iteration (ms): 37732.0 | learning rate: 5.719E-05 | global batch size:  1024 | lm loss: 1.798777E+00 | loss scale: 1.0 | grad norm: 0.065 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36912/   51900 | consumed samples:     37797888 | elapsed time per iteration (ms): 37752.2 | learning rate: 5.718E-05 | global batch size:  1024 | lm loss: 1.803569E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36913/   51900 | consumed samples:     37798912 | elapsed time per iteration (ms): 37677.7 | learning rate: 5.718E-05 | global batch size:  1024 | lm loss: 1.809512E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36914/   51900 | consumed samples:     37799936 | elapsed time per iteration (ms): 37799.7 | learning rate: 5.717E-05 | global batch size:  1024 | lm loss: 1.809585E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36915/   51900 | consumed samples:     37800960 | elapsed time per iteration (ms): 37659.0 | learning rate: 5.717E-05 | global batch size:  1024 | lm loss: 1.815997E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36916/   51900 | consumed samples:     37801984 | elapsed time per iteration (ms): 37714.9 | learning rate: 5.716E-05 | global batch size:  1024 | lm loss: 1.805853E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36917/   51900 | consumed samples:     37803008 | elapsed time per iteration (ms): 37705.9 | learning rate: 5.716E-05 | global batch size:  1024 | lm loss: 1.815420E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36918/   51900 | consumed samples:     37804032 | elapsed time per iteration (ms): 37764.2 | learning rate: 5.715E-05 | global batch size:  1024 | lm loss: 1.819290E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36919/   51900 | consumed samples:     37805056 | elapsed time per iteration (ms): 37748.2 | learning rate: 5.715E-05 | global batch size:  1024 | lm loss: 1.797380E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36920/   51900 | consumed samples:     37806080 | elapsed time per iteration (ms): 37743.8 | learning rate: 5.715E-05 | global batch size:  1024 | lm loss: 1.827272E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36921/   51900 | consumed samples:     37807104 | elapsed time per iteration (ms): 37752.3 | learning rate: 5.714E-05 | global batch size:  1024 | lm loss: 1.802885E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36922/   51900 | consumed samples:     37808128 | elapsed time per iteration (ms): 37675.0 | learning rate: 5.714E-05 | global batch size:  1024 | lm loss: 1.808129E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36923/   51900 | consumed samples:     37809152 | elapsed time per iteration (ms): 37559.2 | learning rate: 5.713E-05 | global batch size:  1024 | lm loss: 1.798709E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36924/   51900 | consumed samples:     37810176 | elapsed time per iteration (ms): 37536.2 | learning rate: 5.713E-05 | global batch size:  1024 | lm loss: 1.803584E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36925/   51900 | consumed samples:     37811200 | elapsed time per iteration (ms): 37567.1 | learning rate: 5.712E-05 | global batch size:  1024 | lm loss: 1.802514E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36926/   51900 | consumed samples:     37812224 | elapsed time per iteration (ms): 37666.1 | learning rate: 5.712E-05 | global batch size:  1024 | lm loss: 1.813756E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36927/   51900 | consumed samples:     37813248 | elapsed time per iteration (ms): 37622.1 | learning rate: 5.711E-05 | global batch size:  1024 | lm loss: 1.807617E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36928/   51900 | consumed samples:     37814272 | elapsed time per iteration (ms): 37618.6 | learning rate: 5.711E-05 | global batch size:  1024 | lm loss: 1.793724E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36929/   51900 | consumed samples:     37815296 | elapsed time per iteration (ms): 37682.4 | learning rate: 5.710E-05 | global batch size:  1024 | lm loss: 1.806754E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36930/   51900 | consumed samples:     37816320 | elapsed time per iteration (ms): 37658.0 | learning rate: 5.710E-05 | global batch size:  1024 | lm loss: 1.806461E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36931/   51900 | consumed samples:     37817344 | elapsed time per iteration (ms): 37688.2 | learning rate: 5.709E-05 | global batch size:  1024 | lm loss: 1.804002E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36932/   51900 | consumed samples:     37818368 | elapsed time per iteration (ms): 37768.8 | learning rate: 5.709E-05 | global batch size:  1024 | lm loss: 1.792685E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36933/   51900 | consumed samples:     37819392 | elapsed time per iteration (ms): 37674.0 | learning rate: 5.709E-05 | global batch size:  1024 | lm loss: 1.824344E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36934/   51900 | consumed samples:     37820416 | elapsed time per iteration (ms): 37719.9 | learning rate: 5.708E-05 | global batch size:  1024 | lm loss: 1.808276E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36935/   51900 | consumed samples:     37821440 | elapsed time per iteration (ms): 37706.4 | learning rate: 5.708E-05 | global batch size:  1024 | lm loss: 1.818627E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36936/   51900 | consumed samples:     37822464 | elapsed time per iteration (ms): 37700.2 | learning rate: 5.707E-05 | global batch size:  1024 | lm loss: 1.811504E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36937/   51900 | consumed samples:     37823488 | elapsed time per iteration (ms): 37640.2 | learning rate: 5.707E-05 | global batch size:  1024 | lm loss: 1.812903E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36938/   51900 | consumed samples:     37824512 | elapsed time per iteration (ms): 37617.3 | learning rate: 5.706E-05 | global batch size:  1024 | lm loss: 1.817198E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36939/   51900 | consumed samples:     37825536 | elapsed time per iteration (ms): 37761.3 | learning rate: 5.706E-05 | global batch size:  1024 | lm loss: 1.830084E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36940/   51900 | consumed samples:     37826560 | elapsed time per iteration (ms): 37641.9 | learning rate: 5.705E-05 | global batch size:  1024 | lm loss: 1.816786E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36941/   51900 | consumed samples:     37827584 | elapsed time per iteration (ms): 37749.6 | learning rate: 5.705E-05 | global batch size:  1024 | lm loss: 1.793100E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36942/   51900 | consumed samples:     37828608 | elapsed time per iteration (ms): 37766.7 | learning rate: 5.704E-05 | global batch size:  1024 | lm loss: 1.809379E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36943/   51900 | consumed samples:     37829632 | elapsed time per iteration (ms): 37622.2 | learning rate: 5.704E-05 | global batch size:  1024 | lm loss: 1.788607E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36944/   51900 | consumed samples:     37830656 | elapsed time per iteration (ms): 37729.2 | learning rate: 5.704E-05 | global batch size:  1024 | lm loss: 1.808676E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36945/   51900 | consumed samples:     37831680 | elapsed time per iteration (ms): 37634.5 | learning rate: 5.703E-05 | global batch size:  1024 | lm loss: 1.792167E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36946/   51900 | consumed samples:     37832704 | elapsed time per iteration (ms): 37537.8 | learning rate: 5.703E-05 | global batch size:  1024 | lm loss: 1.797300E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36947/   51900 | consumed samples:     37833728 | elapsed time per iteration (ms): 37761.4 | learning rate: 5.702E-05 | global batch size:  1024 | lm loss: 1.824140E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36948/   51900 | consumed samples:     37834752 | elapsed time per iteration (ms): 37567.3 | learning rate: 5.702E-05 | global batch size:  1024 | lm loss: 1.820818E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36949/   51900 | consumed samples:     37835776 | elapsed time per iteration (ms): 37743.4 | learning rate: 5.701E-05 | global batch size:  1024 | lm loss: 1.810050E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36950/   51900 | consumed samples:     37836800 | elapsed time per iteration (ms): 37741.5 | learning rate: 5.701E-05 | global batch size:  1024 | lm loss: 1.808516E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36951/   51900 | consumed samples:     37837824 | elapsed time per iteration (ms): 37736.3 | learning rate: 5.700E-05 | global batch size:  1024 | lm loss: 1.817498E+00 | loss scale: 1.0 | grad norm: 0.064 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36952/   51900 | consumed samples:     37838848 | elapsed time per iteration (ms): 37727.5 | learning rate: 5.700E-05 | global batch size:  1024 | lm loss: 1.810776E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36953/   51900 | consumed samples:     37839872 | elapsed time per iteration (ms): 37704.5 | learning rate: 5.699E-05 | global batch size:  1024 | lm loss: 1.832229E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36954/   51900 | consumed samples:     37840896 | elapsed time per iteration (ms): 37685.6 | learning rate: 5.699E-05 | global batch size:  1024 | lm loss: 1.804096E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36955/   51900 | consumed samples:     37841920 | elapsed time per iteration (ms): 37703.8 | learning rate: 5.698E-05 | global batch size:  1024 | lm loss: 1.804468E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36956/   51900 | consumed samples:     37842944 | elapsed time per iteration (ms): 37674.3 | learning rate: 5.698E-05 | global batch size:  1024 | lm loss: 1.785943E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36957/   51900 | consumed samples:     37843968 | elapsed time per iteration (ms): 37683.3 | learning rate: 5.698E-05 | global batch size:  1024 | lm loss: 1.803551E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36958/   51900 | consumed samples:     37844992 | elapsed time per iteration (ms): 37775.9 | learning rate: 5.697E-05 | global batch size:  1024 | lm loss: 1.828140E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36959/   51900 | consumed samples:     37846016 | elapsed time per iteration (ms): 37642.8 | learning rate: 5.697E-05 | global batch size:  1024 | lm loss: 1.797708E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36960/   51900 | consumed samples:     37847040 | elapsed time per iteration (ms): 37626.2 | learning rate: 5.696E-05 | global batch size:  1024 | lm loss: 1.823437E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36961/   51900 | consumed samples:     37848064 | elapsed time per iteration (ms): 37642.8 | learning rate: 5.696E-05 | global batch size:  1024 | lm loss: 1.815010E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36962/   51900 | consumed samples:     37849088 | elapsed time per iteration (ms): 37704.8 | learning rate: 5.695E-05 | global batch size:  1024 | lm loss: 1.803824E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36963/   51900 | consumed samples:     37850112 | elapsed time per iteration (ms): 37637.5 | learning rate: 5.695E-05 | global batch size:  1024 | lm loss: 1.801364E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36964/   51900 | consumed samples:     37851136 | elapsed time per iteration (ms): 37699.2 | learning rate: 5.694E-05 | global batch size:  1024 | lm loss: 1.801740E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36965/   51900 | consumed samples:     37852160 | elapsed time per iteration (ms): 37685.4 | learning rate: 5.694E-05 | global batch size:  1024 | lm loss: 1.813155E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36966/   51900 | consumed samples:     37853184 | elapsed time per iteration (ms): 37619.2 | learning rate: 5.693E-05 | global batch size:  1024 | lm loss: 1.811876E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36967/   51900 | consumed samples:     37854208 | elapsed time per iteration (ms): 37685.2 | learning rate: 5.693E-05 | global batch size:  1024 | lm loss: 1.819615E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36968/   51900 | consumed samples:     37855232 | elapsed time per iteration (ms): 37714.9 | learning rate: 5.693E-05 | global batch size:  1024 | lm loss: 1.806913E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36969/   51900 | consumed samples:     37856256 | elapsed time per iteration (ms): 37695.3 | learning rate: 5.692E-05 | global batch size:  1024 | lm loss: 1.812451E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36970/   51900 | consumed samples:     37857280 | elapsed time per iteration (ms): 37547.1 | learning rate: 5.692E-05 | global batch size:  1024 | lm loss: 1.802637E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36971/   51900 | consumed samples:     37858304 | elapsed time per iteration (ms): 37687.7 | learning rate: 5.691E-05 | global batch size:  1024 | lm loss: 1.817746E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36972/   51900 | consumed samples:     37859328 | elapsed time per iteration (ms): 37558.6 | learning rate: 5.691E-05 | global batch size:  1024 | lm loss: 1.804001E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36973/   51900 | consumed samples:     37860352 | elapsed time per iteration (ms): 37725.6 | learning rate: 5.690E-05 | global batch size:  1024 | lm loss: 1.797063E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36974/   51900 | consumed samples:     37861376 | elapsed time per iteration (ms): 37756.1 | learning rate: 5.690E-05 | global batch size:  1024 | lm loss: 1.799830E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36975/   51900 | consumed samples:     37862400 | elapsed time per iteration (ms): 37721.8 | learning rate: 5.689E-05 | global batch size:  1024 | lm loss: 1.795967E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36976/   51900 | consumed samples:     37863424 | elapsed time per iteration (ms): 37818.4 | learning rate: 5.689E-05 | global batch size:  1024 | lm loss: 1.811623E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36977/   51900 | consumed samples:     37864448 | elapsed time per iteration (ms): 37651.1 | learning rate: 5.688E-05 | global batch size:  1024 | lm loss: 1.798991E+00 | loss scale: 1.0 | grad norm: 0.065 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36978/   51900 | consumed samples:     37865472 | elapsed time per iteration (ms): 37642.9 | learning rate: 5.688E-05 | global batch size:  1024 | lm loss: 1.822483E+00 | loss scale: 1.0 | grad norm: 0.065 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36979/   51900 | consumed samples:     37866496 | elapsed time per iteration (ms): 37613.9 | learning rate: 5.687E-05 | global batch size:  1024 | lm loss: 1.823198E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36980/   51900 | consumed samples:     37867520 | elapsed time per iteration (ms): 37686.3 | learning rate: 5.687E-05 | global batch size:  1024 | lm loss: 1.809863E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36981/   51900 | consumed samples:     37868544 | elapsed time per iteration (ms): 37705.8 | learning rate: 5.687E-05 | global batch size:  1024 | lm loss: 1.802366E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36982/   51900 | consumed samples:     37869568 | elapsed time per iteration (ms): 37689.7 | learning rate: 5.686E-05 | global batch size:  1024 | lm loss: 1.799748E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36983/   51900 | consumed samples:     37870592 | elapsed time per iteration (ms): 37882.6 | learning rate: 5.686E-05 | global batch size:  1024 | lm loss: 1.810865E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36984/   51900 | consumed samples:     37871616 | elapsed time per iteration (ms): 37649.1 | learning rate: 5.685E-05 | global batch size:  1024 | lm loss: 1.813672E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36985/   51900 | consumed samples:     37872640 | elapsed time per iteration (ms): 37625.5 | learning rate: 5.685E-05 | global batch size:  1024 | lm loss: 1.799819E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36986/   51900 | consumed samples:     37873664 | elapsed time per iteration (ms): 37719.9 | learning rate: 5.684E-05 | global batch size:  1024 | lm loss: 1.815179E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36987/   51900 | consumed samples:     37874688 | elapsed time per iteration (ms): 37667.5 | learning rate: 5.684E-05 | global batch size:  1024 | lm loss: 1.805594E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36988/   51900 | consumed samples:     37875712 | elapsed time per iteration (ms): 37642.6 | learning rate: 5.683E-05 | global batch size:  1024 | lm loss: 1.816242E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36989/   51900 | consumed samples:     37876736 | elapsed time per iteration (ms): 37675.5 | learning rate: 5.683E-05 | global batch size:  1024 | lm loss: 1.811124E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36990/   51900 | consumed samples:     37877760 | elapsed time per iteration (ms): 37651.7 | learning rate: 5.682E-05 | global batch size:  1024 | lm loss: 1.810514E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36991/   51900 | consumed samples:     37878784 | elapsed time per iteration (ms): 37675.4 | learning rate: 5.682E-05 | global batch size:  1024 | lm loss: 1.814513E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36992/   51900 | consumed samples:     37879808 | elapsed time per iteration (ms): 37639.5 | learning rate: 5.682E-05 | global batch size:  1024 | lm loss: 1.824951E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36993/   51900 | consumed samples:     37880832 | elapsed time per iteration (ms): 37645.4 | learning rate: 5.681E-05 | global batch size:  1024 | lm loss: 1.801828E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36994/   51900 | consumed samples:     37881856 | elapsed time per iteration (ms): 37594.0 | learning rate: 5.681E-05 | global batch size:  1024 | lm loss: 1.807633E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36995/   51900 | consumed samples:     37882880 | elapsed time per iteration (ms): 37702.5 | learning rate: 5.680E-05 | global batch size:  1024 | lm loss: 1.803846E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36996/   51900 | consumed samples:     37883904 | elapsed time per iteration (ms): 37705.9 | learning rate: 5.680E-05 | global batch size:  1024 | lm loss: 1.800773E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36997/   51900 | consumed samples:     37884928 | elapsed time per iteration (ms): 37759.0 | learning rate: 5.679E-05 | global batch size:  1024 | lm loss: 1.804858E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36998/   51900 | consumed samples:     37885952 | elapsed time per iteration (ms): 37712.5 | learning rate: 5.679E-05 | global batch size:  1024 | lm loss: 1.802412E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    36999/   51900 | consumed samples:     37886976 | elapsed time per iteration (ms): 37670.8 | learning rate: 5.678E-05 | global batch size:  1024 | lm loss: 1.793405E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37000/   51900 | consumed samples:     37888000 | elapsed time per iteration (ms): 37691.3 | learning rate: 5.678E-05 | global batch size:  1024 | lm loss: 1.807614E+00 | loss scale: 1.0 | grad norm: 0.064 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    save-checkpoint ................................: (138966.60, 138966.77)
 iteration    37001/   51900 | consumed samples:     37889024 | elapsed time per iteration (ms): 37513.3 | learning rate: 5.677E-05 | global batch size:  1024 | lm loss: 1.811277E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37002/   51900 | consumed samples:     37890048 | elapsed time per iteration (ms): 37619.9 | learning rate: 5.677E-05 | global batch size:  1024 | lm loss: 1.813526E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37003/   51900 | consumed samples:     37891072 | elapsed time per iteration (ms): 37629.7 | learning rate: 5.677E-05 | global batch size:  1024 | lm loss: 1.800059E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37004/   51900 | consumed samples:     37892096 | elapsed time per iteration (ms): 37676.7 | learning rate: 5.676E-05 | global batch size:  1024 | lm loss: 1.801416E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37005/   51900 | consumed samples:     37893120 | elapsed time per iteration (ms): 37630.2 | learning rate: 5.676E-05 | global batch size:  1024 | lm loss: 1.820009E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37006/   51900 | consumed samples:     37894144 | elapsed time per iteration (ms): 37628.9 | learning rate: 5.675E-05 | global batch size:  1024 | lm loss: 1.821032E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37007/   51900 | consumed samples:     37895168 | elapsed time per iteration (ms): 37809.9 | learning rate: 5.675E-05 | global batch size:  1024 | lm loss: 1.817321E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37008/   51900 | consumed samples:     37896192 | elapsed time per iteration (ms): 37546.0 | learning rate: 5.674E-05 | global batch size:  1024 | lm loss: 1.776559E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37009/   51900 | consumed samples:     37897216 | elapsed time per iteration (ms): 37818.8 | learning rate: 5.674E-05 | global batch size:  1024 | lm loss: 1.787428E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37010/   51900 | consumed samples:     37898240 | elapsed time per iteration (ms): 37523.3 | learning rate: 5.673E-05 | global batch size:  1024 | lm loss: 1.806257E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37011/   51900 | consumed samples:     37899264 | elapsed time per iteration (ms): 37716.3 | learning rate: 5.673E-05 | global batch size:  1024 | lm loss: 1.806709E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37012/   51900 | consumed samples:     37900288 | elapsed time per iteration (ms): 37579.1 | learning rate: 5.672E-05 | global batch size:  1024 | lm loss: 1.812444E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37013/   51900 | consumed samples:     37901312 | elapsed time per iteration (ms): 37689.9 | learning rate: 5.672E-05 | global batch size:  1024 | lm loss: 1.803477E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37014/   51900 | consumed samples:     37902336 | elapsed time per iteration (ms): 37513.3 | learning rate: 5.672E-05 | global batch size:  1024 | lm loss: 1.799392E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37015/   51900 | consumed samples:     37903360 | elapsed time per iteration (ms): 37708.4 | learning rate: 5.671E-05 | global batch size:  1024 | lm loss: 1.805596E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37016/   51900 | consumed samples:     37904384 | elapsed time per iteration (ms): 37726.1 | learning rate: 5.671E-05 | global batch size:  1024 | lm loss: 1.814895E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37017/   51900 | consumed samples:     37905408 | elapsed time per iteration (ms): 37654.4 | learning rate: 5.670E-05 | global batch size:  1024 | lm loss: 1.813257E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37018/   51900 | consumed samples:     37906432 | elapsed time per iteration (ms): 37645.3 | learning rate: 5.670E-05 | global batch size:  1024 | lm loss: 1.812598E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37019/   51900 | consumed samples:     37907456 | elapsed time per iteration (ms): 37668.5 | learning rate: 5.669E-05 | global batch size:  1024 | lm loss: 1.809228E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37020/   51900 | consumed samples:     37908480 | elapsed time per iteration (ms): 37744.1 | learning rate: 5.669E-05 | global batch size:  1024 | lm loss: 1.798971E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37021/   51900 | consumed samples:     37909504 | elapsed time per iteration (ms): 37676.1 | learning rate: 5.668E-05 | global batch size:  1024 | lm loss: 1.800348E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37022/   51900 | consumed samples:     37910528 | elapsed time per iteration (ms): 37616.2 | learning rate: 5.668E-05 | global batch size:  1024 | lm loss: 1.806699E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37023/   51900 | consumed samples:     37911552 | elapsed time per iteration (ms): 37593.3 | learning rate: 5.667E-05 | global batch size:  1024 | lm loss: 1.810832E+00 | loss scale: 1.0 | grad norm: 0.089 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37024/   51900 | consumed samples:     37912576 | elapsed time per iteration (ms): 37748.6 | learning rate: 5.667E-05 | global batch size:  1024 | lm loss: 1.793180E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37025/   51900 | consumed samples:     37913600 | elapsed time per iteration (ms): 37657.7 | learning rate: 5.666E-05 | global batch size:  1024 | lm loss: 1.815668E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37026/   51900 | consumed samples:     37914624 | elapsed time per iteration (ms): 37669.8 | learning rate: 5.666E-05 | global batch size:  1024 | lm loss: 1.800016E+00 | loss scale: 1.0 | grad norm: 0.065 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37027/   51900 | consumed samples:     37915648 | elapsed time per iteration (ms): 37534.6 | learning rate: 5.666E-05 | global batch size:  1024 | lm loss: 1.821027E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37028/   51900 | consumed samples:     37916672 | elapsed time per iteration (ms): 37669.8 | learning rate: 5.665E-05 | global batch size:  1024 | lm loss: 1.815817E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37029/   51900 | consumed samples:     37917696 | elapsed time per iteration (ms): 37643.2 | learning rate: 5.665E-05 | global batch size:  1024 | lm loss: 1.816212E+00 | loss scale: 1.0 | grad norm: 0.064 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37030/   51900 | consumed samples:     37918720 | elapsed time per iteration (ms): 37644.9 | learning rate: 5.664E-05 | global batch size:  1024 | lm loss: 1.818975E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37031/   51900 | consumed samples:     37919744 | elapsed time per iteration (ms): 37722.3 | learning rate: 5.664E-05 | global batch size:  1024 | lm loss: 1.827019E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37032/   51900 | consumed samples:     37920768 | elapsed time per iteration (ms): 37710.0 | learning rate: 5.663E-05 | global batch size:  1024 | lm loss: 1.813525E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37033/   51900 | consumed samples:     37921792 | elapsed time per iteration (ms): 37598.3 | learning rate: 5.663E-05 | global batch size:  1024 | lm loss: 1.798883E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37034/   51900 | consumed samples:     37922816 | elapsed time per iteration (ms): 37637.3 | learning rate: 5.662E-05 | global batch size:  1024 | lm loss: 1.802048E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37035/   51900 | consumed samples:     37923840 | elapsed time per iteration (ms): 37705.5 | learning rate: 5.662E-05 | global batch size:  1024 | lm loss: 1.795786E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37036/   51900 | consumed samples:     37924864 | elapsed time per iteration (ms): 37672.2 | learning rate: 5.661E-05 | global batch size:  1024 | lm loss: 1.809679E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37037/   51900 | consumed samples:     37925888 | elapsed time per iteration (ms): 37672.5 | learning rate: 5.661E-05 | global batch size:  1024 | lm loss: 1.810961E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37038/   51900 | consumed samples:     37926912 | elapsed time per iteration (ms): 37659.9 | learning rate: 5.661E-05 | global batch size:  1024 | lm loss: 1.799471E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37039/   51900 | consumed samples:     37927936 | elapsed time per iteration (ms): 37656.3 | learning rate: 5.660E-05 | global batch size:  1024 | lm loss: 1.805787E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37040/   51900 | consumed samples:     37928960 | elapsed time per iteration (ms): 37635.8 | learning rate: 5.660E-05 | global batch size:  1024 | lm loss: 1.829577E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37041/   51900 | consumed samples:     37929984 | elapsed time per iteration (ms): 37762.5 | learning rate: 5.659E-05 | global batch size:  1024 | lm loss: 1.808635E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37042/   51900 | consumed samples:     37931008 | elapsed time per iteration (ms): 37650.0 | learning rate: 5.659E-05 | global batch size:  1024 | lm loss: 1.795131E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37043/   51900 | consumed samples:     37932032 | elapsed time per iteration (ms): 37665.1 | learning rate: 5.658E-05 | global batch size:  1024 | lm loss: 1.813670E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37044/   51900 | consumed samples:     37933056 | elapsed time per iteration (ms): 37689.6 | learning rate: 5.658E-05 | global batch size:  1024 | lm loss: 1.811975E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37045/   51900 | consumed samples:     37934080 | elapsed time per iteration (ms): 37701.2 | learning rate: 5.657E-05 | global batch size:  1024 | lm loss: 1.810130E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37046/   51900 | consumed samples:     37935104 | elapsed time per iteration (ms): 37578.7 | learning rate: 5.657E-05 | global batch size:  1024 | lm loss: 1.809578E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37047/   51900 | consumed samples:     37936128 | elapsed time per iteration (ms): 37723.8 | learning rate: 5.656E-05 | global batch size:  1024 | lm loss: 1.809085E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37048/   51900 | consumed samples:     37937152 | elapsed time per iteration (ms): 37619.7 | learning rate: 5.656E-05 | global batch size:  1024 | lm loss: 1.797762E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37049/   51900 | consumed samples:     37938176 | elapsed time per iteration (ms): 37629.7 | learning rate: 5.656E-05 | global batch size:  1024 | lm loss: 1.824257E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37050/   51900 | consumed samples:     37939200 | elapsed time per iteration (ms): 37669.1 | learning rate: 5.655E-05 | global batch size:  1024 | lm loss: 1.816850E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37051/   51900 | consumed samples:     37940224 | elapsed time per iteration (ms): 37636.1 | learning rate: 5.655E-05 | global batch size:  1024 | lm loss: 1.802895E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37052/   51900 | consumed samples:     37941248 | elapsed time per iteration (ms): 37684.2 | learning rate: 5.654E-05 | global batch size:  1024 | lm loss: 1.785485E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37053/   51900 | consumed samples:     37942272 | elapsed time per iteration (ms): 37562.6 | learning rate: 5.654E-05 | global batch size:  1024 | lm loss: 1.816466E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37054/   51900 | consumed samples:     37943296 | elapsed time per iteration (ms): 37696.0 | learning rate: 5.653E-05 | global batch size:  1024 | lm loss: 1.809534E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37055/   51900 | consumed samples:     37944320 | elapsed time per iteration (ms): 37699.5 | learning rate: 5.653E-05 | global batch size:  1024 | lm loss: 1.795289E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37056/   51900 | consumed samples:     37945344 | elapsed time per iteration (ms): 37526.1 | learning rate: 5.652E-05 | global batch size:  1024 | lm loss: 1.802903E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37057/   51900 | consumed samples:     37946368 | elapsed time per iteration (ms): 37567.5 | learning rate: 5.652E-05 | global batch size:  1024 | lm loss: 1.812805E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37058/   51900 | consumed samples:     37947392 | elapsed time per iteration (ms): 37598.8 | learning rate: 5.651E-05 | global batch size:  1024 | lm loss: 1.791863E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37059/   51900 | consumed samples:     37948416 | elapsed time per iteration (ms): 37729.6 | learning rate: 5.651E-05 | global batch size:  1024 | lm loss: 1.800495E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37060/   51900 | consumed samples:     37949440 | elapsed time per iteration (ms): 37578.6 | learning rate: 5.651E-05 | global batch size:  1024 | lm loss: 1.799716E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37061/   51900 | consumed samples:     37950464 | elapsed time per iteration (ms): 37623.3 | learning rate: 5.650E-05 | global batch size:  1024 | lm loss: 1.804442E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37062/   51900 | consumed samples:     37951488 | elapsed time per iteration (ms): 37627.9 | learning rate: 5.650E-05 | global batch size:  1024 | lm loss: 1.810221E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37063/   51900 | consumed samples:     37952512 | elapsed time per iteration (ms): 37689.5 | learning rate: 5.649E-05 | global batch size:  1024 | lm loss: 1.793976E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37064/   51900 | consumed samples:     37953536 | elapsed time per iteration (ms): 37702.0 | learning rate: 5.649E-05 | global batch size:  1024 | lm loss: 1.809019E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37065/   51900 | consumed samples:     37954560 | elapsed time per iteration (ms): 37701.6 | learning rate: 5.648E-05 | global batch size:  1024 | lm loss: 1.801729E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37066/   51900 | consumed samples:     37955584 | elapsed time per iteration (ms): 37688.5 | learning rate: 5.648E-05 | global batch size:  1024 | lm loss: 1.805003E+00 | loss scale: 1.0 | grad norm: 0.101 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37067/   51900 | consumed samples:     37956608 | elapsed time per iteration (ms): 37642.0 | learning rate: 5.647E-05 | global batch size:  1024 | lm loss: 1.809352E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37068/   51900 | consumed samples:     37957632 | elapsed time per iteration (ms): 37710.6 | learning rate: 5.647E-05 | global batch size:  1024 | lm loss: 1.798373E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37069/   51900 | consumed samples:     37958656 | elapsed time per iteration (ms): 37735.1 | learning rate: 5.646E-05 | global batch size:  1024 | lm loss: 1.809539E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37070/   51900 | consumed samples:     37959680 | elapsed time per iteration (ms): 37652.0 | learning rate: 5.646E-05 | global batch size:  1024 | lm loss: 1.807547E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37071/   51900 | consumed samples:     37960704 | elapsed time per iteration (ms): 37690.5 | learning rate: 5.646E-05 | global batch size:  1024 | lm loss: 1.813195E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37072/   51900 | consumed samples:     37961728 | elapsed time per iteration (ms): 37627.7 | learning rate: 5.645E-05 | global batch size:  1024 | lm loss: 1.816146E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37073/   51900 | consumed samples:     37962752 | elapsed time per iteration (ms): 37612.1 | learning rate: 5.645E-05 | global batch size:  1024 | lm loss: 1.804144E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37074/   51900 | consumed samples:     37963776 | elapsed time per iteration (ms): 37773.5 | learning rate: 5.644E-05 | global batch size:  1024 | lm loss: 1.795854E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37075/   51900 | consumed samples:     37964800 | elapsed time per iteration (ms): 37734.9 | learning rate: 5.644E-05 | global batch size:  1024 | lm loss: 1.800680E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37076/   51900 | consumed samples:     37965824 | elapsed time per iteration (ms): 37627.5 | learning rate: 5.643E-05 | global batch size:  1024 | lm loss: 1.827930E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37077/   51900 | consumed samples:     37966848 | elapsed time per iteration (ms): 37578.8 | learning rate: 5.643E-05 | global batch size:  1024 | lm loss: 1.787224E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37078/   51900 | consumed samples:     37967872 | elapsed time per iteration (ms): 37686.3 | learning rate: 5.642E-05 | global batch size:  1024 | lm loss: 1.797515E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37079/   51900 | consumed samples:     37968896 | elapsed time per iteration (ms): 37690.5 | learning rate: 5.642E-05 | global batch size:  1024 | lm loss: 1.792674E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37080/   51900 | consumed samples:     37969920 | elapsed time per iteration (ms): 37706.9 | learning rate: 5.641E-05 | global batch size:  1024 | lm loss: 1.795302E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37081/   51900 | consumed samples:     37970944 | elapsed time per iteration (ms): 37778.8 | learning rate: 5.641E-05 | global batch size:  1024 | lm loss: 1.794378E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37082/   51900 | consumed samples:     37971968 | elapsed time per iteration (ms): 37813.3 | learning rate: 5.640E-05 | global batch size:  1024 | lm loss: 1.811229E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37083/   51900 | consumed samples:     37972992 | elapsed time per iteration (ms): 37654.5 | learning rate: 5.640E-05 | global batch size:  1024 | lm loss: 1.819177E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37084/   51900 | consumed samples:     37974016 | elapsed time per iteration (ms): 37655.9 | learning rate: 5.640E-05 | global batch size:  1024 | lm loss: 1.800009E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37085/   51900 | consumed samples:     37975040 | elapsed time per iteration (ms): 37698.3 | learning rate: 5.639E-05 | global batch size:  1024 | lm loss: 1.823080E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37086/   51900 | consumed samples:     37976064 | elapsed time per iteration (ms): 37642.6 | learning rate: 5.639E-05 | global batch size:  1024 | lm loss: 1.800046E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37087/   51900 | consumed samples:     37977088 | elapsed time per iteration (ms): 37664.5 | learning rate: 5.638E-05 | global batch size:  1024 | lm loss: 1.801048E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37088/   51900 | consumed samples:     37978112 | elapsed time per iteration (ms): 37651.1 | learning rate: 5.638E-05 | global batch size:  1024 | lm loss: 1.808967E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37089/   51900 | consumed samples:     37979136 | elapsed time per iteration (ms): 37693.9 | learning rate: 5.637E-05 | global batch size:  1024 | lm loss: 1.796571E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37090/   51900 | consumed samples:     37980160 | elapsed time per iteration (ms): 37553.9 | learning rate: 5.637E-05 | global batch size:  1024 | lm loss: 1.794242E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37091/   51900 | consumed samples:     37981184 | elapsed time per iteration (ms): 37589.3 | learning rate: 5.636E-05 | global batch size:  1024 | lm loss: 1.799625E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37092/   51900 | consumed samples:     37982208 | elapsed time per iteration (ms): 37682.1 | learning rate: 5.636E-05 | global batch size:  1024 | lm loss: 1.797925E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37093/   51900 | consumed samples:     37983232 | elapsed time per iteration (ms): 37598.8 | learning rate: 5.635E-05 | global batch size:  1024 | lm loss: 1.810133E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37094/   51900 | consumed samples:     37984256 | elapsed time per iteration (ms): 37655.1 | learning rate: 5.635E-05 | global batch size:  1024 | lm loss: 1.800147E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37095/   51900 | consumed samples:     37985280 | elapsed time per iteration (ms): 37657.3 | learning rate: 5.635E-05 | global batch size:  1024 | lm loss: 1.801881E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37096/   51900 | consumed samples:     37986304 | elapsed time per iteration (ms): 37655.1 | learning rate: 5.634E-05 | global batch size:  1024 | lm loss: 1.804801E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37097/   51900 | consumed samples:     37987328 | elapsed time per iteration (ms): 37689.5 | learning rate: 5.634E-05 | global batch size:  1024 | lm loss: 1.809652E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37098/   51900 | consumed samples:     37988352 | elapsed time per iteration (ms): 37678.6 | learning rate: 5.633E-05 | global batch size:  1024 | lm loss: 1.796928E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37099/   51900 | consumed samples:     37989376 | elapsed time per iteration (ms): 37587.6 | learning rate: 5.633E-05 | global batch size:  1024 | lm loss: 1.815067E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37100/   51900 | consumed samples:     37990400 | elapsed time per iteration (ms): 37694.2 | learning rate: 5.632E-05 | global batch size:  1024 | lm loss: 1.803867E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37101/   51900 | consumed samples:     37991424 | elapsed time per iteration (ms): 37677.5 | learning rate: 5.632E-05 | global batch size:  1024 | lm loss: 1.796847E+00 | loss scale: 1.0 | grad norm: 0.064 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37102/   51900 | consumed samples:     37992448 | elapsed time per iteration (ms): 37579.6 | learning rate: 5.631E-05 | global batch size:  1024 | lm loss: 1.817264E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37103/   51900 | consumed samples:     37993472 | elapsed time per iteration (ms): 37690.3 | learning rate: 5.631E-05 | global batch size:  1024 | lm loss: 1.797636E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37104/   51900 | consumed samples:     37994496 | elapsed time per iteration (ms): 37760.9 | learning rate: 5.630E-05 | global batch size:  1024 | lm loss: 1.809944E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37105/   51900 | consumed samples:     37995520 | elapsed time per iteration (ms): 37644.6 | learning rate: 5.630E-05 | global batch size:  1024 | lm loss: 1.800494E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37106/   51900 | consumed samples:     37996544 | elapsed time per iteration (ms): 37698.2 | learning rate: 5.630E-05 | global batch size:  1024 | lm loss: 1.803370E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37107/   51900 | consumed samples:     37997568 | elapsed time per iteration (ms): 37654.0 | learning rate: 5.629E-05 | global batch size:  1024 | lm loss: 1.793353E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37108/   51900 | consumed samples:     37998592 | elapsed time per iteration (ms): 37697.4 | learning rate: 5.629E-05 | global batch size:  1024 | lm loss: 1.816371E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37109/   51900 | consumed samples:     37999616 | elapsed time per iteration (ms): 37617.0 | learning rate: 5.628E-05 | global batch size:  1024 | lm loss: 1.811707E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37110/   51900 | consumed samples:     38000640 | elapsed time per iteration (ms): 37667.6 | learning rate: 5.628E-05 | global batch size:  1024 | lm loss: 1.810266E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37111/   51900 | consumed samples:     38001664 | elapsed time per iteration (ms): 37607.4 | learning rate: 5.627E-05 | global batch size:  1024 | lm loss: 1.816252E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37112/   51900 | consumed samples:     38002688 | elapsed time per iteration (ms): 37613.7 | learning rate: 5.627E-05 | global batch size:  1024 | lm loss: 1.817152E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37113/   51900 | consumed samples:     38003712 | elapsed time per iteration (ms): 37611.2 | learning rate: 5.626E-05 | global batch size:  1024 | lm loss: 1.815090E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37114/   51900 | consumed samples:     38004736 | elapsed time per iteration (ms): 37634.8 | learning rate: 5.626E-05 | global batch size:  1024 | lm loss: 1.818664E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37115/   51900 | consumed samples:     38005760 | elapsed time per iteration (ms): 37699.5 | learning rate: 5.625E-05 | global batch size:  1024 | lm loss: 1.787987E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37116/   51900 | consumed samples:     38006784 | elapsed time per iteration (ms): 37689.8 | learning rate: 5.625E-05 | global batch size:  1024 | lm loss: 1.802290E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37117/   51900 | consumed samples:     38007808 | elapsed time per iteration (ms): 37650.4 | learning rate: 5.625E-05 | global batch size:  1024 | lm loss: 1.806855E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37118/   51900 | consumed samples:     38008832 | elapsed time per iteration (ms): 37797.7 | learning rate: 5.624E-05 | global batch size:  1024 | lm loss: 1.806491E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37119/   51900 | consumed samples:     38009856 | elapsed time per iteration (ms): 37716.6 | learning rate: 5.624E-05 | global batch size:  1024 | lm loss: 1.788723E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37120/   51900 | consumed samples:     38010880 | elapsed time per iteration (ms): 37639.8 | learning rate: 5.623E-05 | global batch size:  1024 | lm loss: 1.830934E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37121/   51900 | consumed samples:     38011904 | elapsed time per iteration (ms): 37688.9 | learning rate: 5.623E-05 | global batch size:  1024 | lm loss: 1.805050E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37122/   51900 | consumed samples:     38012928 | elapsed time per iteration (ms): 37743.3 | learning rate: 5.622E-05 | global batch size:  1024 | lm loss: 1.825090E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37123/   51900 | consumed samples:     38013952 | elapsed time per iteration (ms): 37585.7 | learning rate: 5.622E-05 | global batch size:  1024 | lm loss: 1.814263E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37124/   51900 | consumed samples:     38014976 | elapsed time per iteration (ms): 37644.7 | learning rate: 5.621E-05 | global batch size:  1024 | lm loss: 1.800647E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37125/   51900 | consumed samples:     38016000 | elapsed time per iteration (ms): 37688.0 | learning rate: 5.621E-05 | global batch size:  1024 | lm loss: 1.808862E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37126/   51900 | consumed samples:     38017024 | elapsed time per iteration (ms): 37676.6 | learning rate: 5.620E-05 | global batch size:  1024 | lm loss: 1.817807E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37127/   51900 | consumed samples:     38018048 | elapsed time per iteration (ms): 37621.8 | learning rate: 5.620E-05 | global batch size:  1024 | lm loss: 1.820969E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37128/   51900 | consumed samples:     38019072 | elapsed time per iteration (ms): 37579.5 | learning rate: 5.620E-05 | global batch size:  1024 | lm loss: 1.814029E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37129/   51900 | consumed samples:     38020096 | elapsed time per iteration (ms): 37666.0 | learning rate: 5.619E-05 | global batch size:  1024 | lm loss: 1.811939E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37130/   51900 | consumed samples:     38021120 | elapsed time per iteration (ms): 37650.0 | learning rate: 5.619E-05 | global batch size:  1024 | lm loss: 1.803705E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37131/   51900 | consumed samples:     38022144 | elapsed time per iteration (ms): 37698.8 | learning rate: 5.618E-05 | global batch size:  1024 | lm loss: 1.808147E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37132/   51900 | consumed samples:     38023168 | elapsed time per iteration (ms): 37720.5 | learning rate: 5.618E-05 | global batch size:  1024 | lm loss: 1.794780E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37133/   51900 | consumed samples:     38024192 | elapsed time per iteration (ms): 37641.2 | learning rate: 5.617E-05 | global batch size:  1024 | lm loss: 1.804005E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37134/   51900 | consumed samples:     38025216 | elapsed time per iteration (ms): 37713.9 | learning rate: 5.617E-05 | global batch size:  1024 | lm loss: 1.826134E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37135/   51900 | consumed samples:     38026240 | elapsed time per iteration (ms): 37658.1 | learning rate: 5.616E-05 | global batch size:  1024 | lm loss: 1.824152E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37136/   51900 | consumed samples:     38027264 | elapsed time per iteration (ms): 37716.5 | learning rate: 5.616E-05 | global batch size:  1024 | lm loss: 1.808829E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37137/   51900 | consumed samples:     38028288 | elapsed time per iteration (ms): 37575.3 | learning rate: 5.615E-05 | global batch size:  1024 | lm loss: 1.794268E+00 | loss scale: 1.0 | grad norm: 0.064 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37138/   51900 | consumed samples:     38029312 | elapsed time per iteration (ms): 37542.0 | learning rate: 5.615E-05 | global batch size:  1024 | lm loss: 1.802150E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37139/   51900 | consumed samples:     38030336 | elapsed time per iteration (ms): 37659.2 | learning rate: 5.615E-05 | global batch size:  1024 | lm loss: 1.813083E+00 | loss scale: 1.0 | grad norm: 0.102 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37140/   51900 | consumed samples:     38031360 | elapsed time per iteration (ms): 37670.1 | learning rate: 5.614E-05 | global batch size:  1024 | lm loss: 1.815068E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37141/   51900 | consumed samples:     38032384 | elapsed time per iteration (ms): 37874.7 | learning rate: 5.614E-05 | global batch size:  1024 | lm loss: 1.810817E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37142/   51900 | consumed samples:     38033408 | elapsed time per iteration (ms): 37578.3 | learning rate: 5.613E-05 | global batch size:  1024 | lm loss: 1.802817E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37143/   51900 | consumed samples:     38034432 | elapsed time per iteration (ms): 37683.1 | learning rate: 5.613E-05 | global batch size:  1024 | lm loss: 1.809472E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37144/   51900 | consumed samples:     38035456 | elapsed time per iteration (ms): 37606.8 | learning rate: 5.612E-05 | global batch size:  1024 | lm loss: 1.795225E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37145/   51900 | consumed samples:     38036480 | elapsed time per iteration (ms): 37623.4 | learning rate: 5.612E-05 | global batch size:  1024 | lm loss: 1.797819E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37146/   51900 | consumed samples:     38037504 | elapsed time per iteration (ms): 37701.0 | learning rate: 5.611E-05 | global batch size:  1024 | lm loss: 1.794145E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37147/   51900 | consumed samples:     38038528 | elapsed time per iteration (ms): 37584.9 | learning rate: 5.611E-05 | global batch size:  1024 | lm loss: 1.793230E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37148/   51900 | consumed samples:     38039552 | elapsed time per iteration (ms): 37783.4 | learning rate: 5.611E-05 | global batch size:  1024 | lm loss: 1.800237E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37149/   51900 | consumed samples:     38040576 | elapsed time per iteration (ms): 37606.7 | learning rate: 5.610E-05 | global batch size:  1024 | lm loss: 1.800711E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37150/   51900 | consumed samples:     38041600 | elapsed time per iteration (ms): 37677.0 | learning rate: 5.610E-05 | global batch size:  1024 | lm loss: 1.799002E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37151/   51900 | consumed samples:     38042624 | elapsed time per iteration (ms): 37550.9 | learning rate: 5.609E-05 | global batch size:  1024 | lm loss: 1.799934E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37152/   51900 | consumed samples:     38043648 | elapsed time per iteration (ms): 37658.0 | learning rate: 5.609E-05 | global batch size:  1024 | lm loss: 1.810465E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37153/   51900 | consumed samples:     38044672 | elapsed time per iteration (ms): 37714.5 | learning rate: 5.608E-05 | global batch size:  1024 | lm loss: 1.801912E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37154/   51900 | consumed samples:     38045696 | elapsed time per iteration (ms): 37673.7 | learning rate: 5.608E-05 | global batch size:  1024 | lm loss: 1.812651E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37155/   51900 | consumed samples:     38046720 | elapsed time per iteration (ms): 37674.3 | learning rate: 5.607E-05 | global batch size:  1024 | lm loss: 1.838185E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37156/   51900 | consumed samples:     38047744 | elapsed time per iteration (ms): 37707.1 | learning rate: 5.607E-05 | global batch size:  1024 | lm loss: 1.808818E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37157/   51900 | consumed samples:     38048768 | elapsed time per iteration (ms): 37617.0 | learning rate: 5.606E-05 | global batch size:  1024 | lm loss: 1.797874E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37158/   51900 | consumed samples:     38049792 | elapsed time per iteration (ms): 37723.5 | learning rate: 5.606E-05 | global batch size:  1024 | lm loss: 1.815279E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37159/   51900 | consumed samples:     38050816 | elapsed time per iteration (ms): 37684.1 | learning rate: 5.606E-05 | global batch size:  1024 | lm loss: 1.798762E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37160/   51900 | consumed samples:     38051840 | elapsed time per iteration (ms): 37658.4 | learning rate: 5.605E-05 | global batch size:  1024 | lm loss: 1.799980E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37161/   51900 | consumed samples:     38052864 | elapsed time per iteration (ms): 37677.4 | learning rate: 5.605E-05 | global batch size:  1024 | lm loss: 1.797481E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37162/   51900 | consumed samples:     38053888 | elapsed time per iteration (ms): 37624.1 | learning rate: 5.604E-05 | global batch size:  1024 | lm loss: 1.799469E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37163/   51900 | consumed samples:     38054912 | elapsed time per iteration (ms): 37648.6 | learning rate: 5.604E-05 | global batch size:  1024 | lm loss: 1.811181E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37164/   51900 | consumed samples:     38055936 | elapsed time per iteration (ms): 37618.1 | learning rate: 5.603E-05 | global batch size:  1024 | lm loss: 1.810736E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37165/   51900 | consumed samples:     38056960 | elapsed time per iteration (ms): 37762.5 | learning rate: 5.603E-05 | global batch size:  1024 | lm loss: 1.794546E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37166/   51900 | consumed samples:     38057984 | elapsed time per iteration (ms): 37619.4 | learning rate: 5.602E-05 | global batch size:  1024 | lm loss: 1.831796E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37167/   51900 | consumed samples:     38059008 | elapsed time per iteration (ms): 37713.2 | learning rate: 5.602E-05 | global batch size:  1024 | lm loss: 1.805093E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37168/   51900 | consumed samples:     38060032 | elapsed time per iteration (ms): 37701.5 | learning rate: 5.601E-05 | global batch size:  1024 | lm loss: 1.800876E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37169/   51900 | consumed samples:     38061056 | elapsed time per iteration (ms): 37646.4 | learning rate: 5.601E-05 | global batch size:  1024 | lm loss: 1.813319E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37170/   51900 | consumed samples:     38062080 | elapsed time per iteration (ms): 37653.6 | learning rate: 5.601E-05 | global batch size:  1024 | lm loss: 1.802177E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37171/   51900 | consumed samples:     38063104 | elapsed time per iteration (ms): 37685.4 | learning rate: 5.600E-05 | global batch size:  1024 | lm loss: 1.810865E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37172/   51900 | consumed samples:     38064128 | elapsed time per iteration (ms): 37776.9 | learning rate: 5.600E-05 | global batch size:  1024 | lm loss: 1.790933E+00 | loss scale: 1.0 | grad norm: 0.107 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37173/   51900 | consumed samples:     38065152 | elapsed time per iteration (ms): 37559.8 | learning rate: 5.599E-05 | global batch size:  1024 | lm loss: 1.794569E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37174/   51900 | consumed samples:     38066176 | elapsed time per iteration (ms): 37777.1 | learning rate: 5.599E-05 | global batch size:  1024 | lm loss: 1.810767E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37175/   51900 | consumed samples:     38067200 | elapsed time per iteration (ms): 37627.2 | learning rate: 5.598E-05 | global batch size:  1024 | lm loss: 1.797354E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37176/   51900 | consumed samples:     38068224 | elapsed time per iteration (ms): 37787.4 | learning rate: 5.598E-05 | global batch size:  1024 | lm loss: 1.811666E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37177/   51900 | consumed samples:     38069248 | elapsed time per iteration (ms): 37784.9 | learning rate: 5.597E-05 | global batch size:  1024 | lm loss: 1.798934E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37178/   51900 | consumed samples:     38070272 | elapsed time per iteration (ms): 37687.9 | learning rate: 5.597E-05 | global batch size:  1024 | lm loss: 1.784516E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37179/   51900 | consumed samples:     38071296 | elapsed time per iteration (ms): 37640.4 | learning rate: 5.596E-05 | global batch size:  1024 | lm loss: 1.807643E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37180/   51900 | consumed samples:     38072320 | elapsed time per iteration (ms): 37578.9 | learning rate: 5.596E-05 | global batch size:  1024 | lm loss: 1.799139E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37181/   51900 | consumed samples:     38073344 | elapsed time per iteration (ms): 37754.1 | learning rate: 5.596E-05 | global batch size:  1024 | lm loss: 1.796934E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37182/   51900 | consumed samples:     38074368 | elapsed time per iteration (ms): 37646.3 | learning rate: 5.595E-05 | global batch size:  1024 | lm loss: 1.813502E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37183/   51900 | consumed samples:     38075392 | elapsed time per iteration (ms): 37702.4 | learning rate: 5.595E-05 | global batch size:  1024 | lm loss: 1.813735E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37184/   51900 | consumed samples:     38076416 | elapsed time per iteration (ms): 37671.1 | learning rate: 5.594E-05 | global batch size:  1024 | lm loss: 1.808398E+00 | loss scale: 1.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37185/   51900 | consumed samples:     38077440 | elapsed time per iteration (ms): 37637.8 | learning rate: 5.594E-05 | global batch size:  1024 | lm loss: 1.795648E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37186/   51900 | consumed samples:     38078464 | elapsed time per iteration (ms): 37677.6 | learning rate: 5.593E-05 | global batch size:  1024 | lm loss: 1.796589E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37187/   51900 | consumed samples:     38079488 | elapsed time per iteration (ms): 37567.4 | learning rate: 5.593E-05 | global batch size:  1024 | lm loss: 1.795709E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37188/   51900 | consumed samples:     38080512 | elapsed time per iteration (ms): 37684.8 | learning rate: 5.592E-05 | global batch size:  1024 | lm loss: 1.812482E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37189/   51900 | consumed samples:     38081536 | elapsed time per iteration (ms): 37776.4 | learning rate: 5.592E-05 | global batch size:  1024 | lm loss: 1.807961E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37190/   51900 | consumed samples:     38082560 | elapsed time per iteration (ms): 37591.0 | learning rate: 5.591E-05 | global batch size:  1024 | lm loss: 1.800904E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37191/   51900 | consumed samples:     38083584 | elapsed time per iteration (ms): 37706.1 | learning rate: 5.591E-05 | global batch size:  1024 | lm loss: 1.790895E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37192/   51900 | consumed samples:     38084608 | elapsed time per iteration (ms): 37685.3 | learning rate: 5.591E-05 | global batch size:  1024 | lm loss: 1.807746E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37193/   51900 | consumed samples:     38085632 | elapsed time per iteration (ms): 37605.4 | learning rate: 5.590E-05 | global batch size:  1024 | lm loss: 1.815688E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37194/   51900 | consumed samples:     38086656 | elapsed time per iteration (ms): 37689.5 | learning rate: 5.590E-05 | global batch size:  1024 | lm loss: 1.809549E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37195/   51900 | consumed samples:     38087680 | elapsed time per iteration (ms): 37750.0 | learning rate: 5.589E-05 | global batch size:  1024 | lm loss: 1.795147E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37196/   51900 | consumed samples:     38088704 | elapsed time per iteration (ms): 37624.7 | learning rate: 5.589E-05 | global batch size:  1024 | lm loss: 1.807071E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37197/   51900 | consumed samples:     38089728 | elapsed time per iteration (ms): 37733.4 | learning rate: 5.588E-05 | global batch size:  1024 | lm loss: 1.816321E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37198/   51900 | consumed samples:     38090752 | elapsed time per iteration (ms): 37673.3 | learning rate: 5.588E-05 | global batch size:  1024 | lm loss: 1.810679E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37199/   51900 | consumed samples:     38091776 | elapsed time per iteration (ms): 37647.5 | learning rate: 5.587E-05 | global batch size:  1024 | lm loss: 1.801333E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37200/   51900 | consumed samples:     38092800 | elapsed time per iteration (ms): 37750.2 | learning rate: 5.587E-05 | global batch size:  1024 | lm loss: 1.799461E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37201/   51900 | consumed samples:     38093824 | elapsed time per iteration (ms): 37715.3 | learning rate: 5.586E-05 | global batch size:  1024 | lm loss: 1.805270E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37202/   51900 | consumed samples:     38094848 | elapsed time per iteration (ms): 37935.8 | learning rate: 5.586E-05 | global batch size:  1024 | lm loss: 1.815104E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37203/   51900 | consumed samples:     38095872 | elapsed time per iteration (ms): 37637.2 | learning rate: 5.586E-05 | global batch size:  1024 | lm loss: 1.787511E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37204/   51900 | consumed samples:     38096896 | elapsed time per iteration (ms): 37596.7 | learning rate: 5.585E-05 | global batch size:  1024 | lm loss: 1.821659E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37205/   51900 | consumed samples:     38097920 | elapsed time per iteration (ms): 37639.2 | learning rate: 5.585E-05 | global batch size:  1024 | lm loss: 1.801166E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37206/   51900 | consumed samples:     38098944 | elapsed time per iteration (ms): 37597.2 | learning rate: 5.584E-05 | global batch size:  1024 | lm loss: 1.800848E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37207/   51900 | consumed samples:     38099968 | elapsed time per iteration (ms): 37664.5 | learning rate: 5.584E-05 | global batch size:  1024 | lm loss: 1.818114E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37208/   51900 | consumed samples:     38100992 | elapsed time per iteration (ms): 37572.0 | learning rate: 5.583E-05 | global batch size:  1024 | lm loss: 1.808033E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37209/   51900 | consumed samples:     38102016 | elapsed time per iteration (ms): 37716.7 | learning rate: 5.583E-05 | global batch size:  1024 | lm loss: 1.804525E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37210/   51900 | consumed samples:     38103040 | elapsed time per iteration (ms): 37655.3 | learning rate: 5.582E-05 | global batch size:  1024 | lm loss: 1.807988E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37211/   51900 | consumed samples:     38104064 | elapsed time per iteration (ms): 37747.3 | learning rate: 5.582E-05 | global batch size:  1024 | lm loss: 1.799938E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37212/   51900 | consumed samples:     38105088 | elapsed time per iteration (ms): 37694.1 | learning rate: 5.582E-05 | global batch size:  1024 | lm loss: 1.820904E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37213/   51900 | consumed samples:     38106112 | elapsed time per iteration (ms): 37638.1 | learning rate: 5.581E-05 | global batch size:  1024 | lm loss: 1.821393E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37214/   51900 | consumed samples:     38107136 | elapsed time per iteration (ms): 37679.8 | learning rate: 5.581E-05 | global batch size:  1024 | lm loss: 1.792892E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37215/   51900 | consumed samples:     38108160 | elapsed time per iteration (ms): 37696.4 | learning rate: 5.580E-05 | global batch size:  1024 | lm loss: 1.820520E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37216/   51900 | consumed samples:     38109184 | elapsed time per iteration (ms): 37663.9 | learning rate: 5.580E-05 | global batch size:  1024 | lm loss: 1.799422E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37217/   51900 | consumed samples:     38110208 | elapsed time per iteration (ms): 37545.1 | learning rate: 5.579E-05 | global batch size:  1024 | lm loss: 1.804971E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37218/   51900 | consumed samples:     38111232 | elapsed time per iteration (ms): 37642.6 | learning rate: 5.579E-05 | global batch size:  1024 | lm loss: 1.814893E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37219/   51900 | consumed samples:     38112256 | elapsed time per iteration (ms): 37698.6 | learning rate: 5.578E-05 | global batch size:  1024 | lm loss: 1.825111E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37220/   51900 | consumed samples:     38113280 | elapsed time per iteration (ms): 37710.3 | learning rate: 5.578E-05 | global batch size:  1024 | lm loss: 1.812129E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37221/   51900 | consumed samples:     38114304 | elapsed time per iteration (ms): 37680.1 | learning rate: 5.577E-05 | global batch size:  1024 | lm loss: 1.821418E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37222/   51900 | consumed samples:     38115328 | elapsed time per iteration (ms): 37747.1 | learning rate: 5.577E-05 | global batch size:  1024 | lm loss: 1.831200E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37223/   51900 | consumed samples:     38116352 | elapsed time per iteration (ms): 37638.5 | learning rate: 5.577E-05 | global batch size:  1024 | lm loss: 1.807185E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37224/   51900 | consumed samples:     38117376 | elapsed time per iteration (ms): 37606.5 | learning rate: 5.576E-05 | global batch size:  1024 | lm loss: 1.801322E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37225/   51900 | consumed samples:     38118400 | elapsed time per iteration (ms): 37741.6 | learning rate: 5.576E-05 | global batch size:  1024 | lm loss: 1.809830E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37226/   51900 | consumed samples:     38119424 | elapsed time per iteration (ms): 37744.7 | learning rate: 5.575E-05 | global batch size:  1024 | lm loss: 1.802075E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37227/   51900 | consumed samples:     38120448 | elapsed time per iteration (ms): 37713.7 | learning rate: 5.575E-05 | global batch size:  1024 | lm loss: 1.825388E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37228/   51900 | consumed samples:     38121472 | elapsed time per iteration (ms): 37768.3 | learning rate: 5.574E-05 | global batch size:  1024 | lm loss: 1.816386E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37229/   51900 | consumed samples:     38122496 | elapsed time per iteration (ms): 37576.8 | learning rate: 5.574E-05 | global batch size:  1024 | lm loss: 1.802787E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37230/   51900 | consumed samples:     38123520 | elapsed time per iteration (ms): 37684.1 | learning rate: 5.573E-05 | global batch size:  1024 | lm loss: 1.802379E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37231/   51900 | consumed samples:     38124544 | elapsed time per iteration (ms): 37630.6 | learning rate: 5.573E-05 | global batch size:  1024 | lm loss: 1.818626E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37232/   51900 | consumed samples:     38125568 | elapsed time per iteration (ms): 37657.8 | learning rate: 5.572E-05 | global batch size:  1024 | lm loss: 1.780724E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37233/   51900 | consumed samples:     38126592 | elapsed time per iteration (ms): 37723.8 | learning rate: 5.572E-05 | global batch size:  1024 | lm loss: 1.805636E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37234/   51900 | consumed samples:     38127616 | elapsed time per iteration (ms): 37737.6 | learning rate: 5.572E-05 | global batch size:  1024 | lm loss: 1.793993E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37235/   51900 | consumed samples:     38128640 | elapsed time per iteration (ms): 37631.1 | learning rate: 5.571E-05 | global batch size:  1024 | lm loss: 1.822503E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37236/   51900 | consumed samples:     38129664 | elapsed time per iteration (ms): 37579.5 | learning rate: 5.571E-05 | global batch size:  1024 | lm loss: 1.815980E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37237/   51900 | consumed samples:     38130688 | elapsed time per iteration (ms): 37652.7 | learning rate: 5.570E-05 | global batch size:  1024 | lm loss: 1.801782E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37238/   51900 | consumed samples:     38131712 | elapsed time per iteration (ms): 37669.5 | learning rate: 5.570E-05 | global batch size:  1024 | lm loss: 1.800398E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37239/   51900 | consumed samples:     38132736 | elapsed time per iteration (ms): 37723.4 | learning rate: 5.569E-05 | global batch size:  1024 | lm loss: 1.798323E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37240/   51900 | consumed samples:     38133760 | elapsed time per iteration (ms): 37688.0 | learning rate: 5.569E-05 | global batch size:  1024 | lm loss: 1.792551E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37241/   51900 | consumed samples:     38134784 | elapsed time per iteration (ms): 37693.7 | learning rate: 5.568E-05 | global batch size:  1024 | lm loss: 1.804127E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37242/   51900 | consumed samples:     38135808 | elapsed time per iteration (ms): 37718.5 | learning rate: 5.568E-05 | global batch size:  1024 | lm loss: 1.794540E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37243/   51900 | consumed samples:     38136832 | elapsed time per iteration (ms): 37595.3 | learning rate: 5.567E-05 | global batch size:  1024 | lm loss: 1.788484E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37244/   51900 | consumed samples:     38137856 | elapsed time per iteration (ms): 37638.4 | learning rate: 5.567E-05 | global batch size:  1024 | lm loss: 1.804568E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37245/   51900 | consumed samples:     38138880 | elapsed time per iteration (ms): 37690.8 | learning rate: 5.567E-05 | global batch size:  1024 | lm loss: 1.803470E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37246/   51900 | consumed samples:     38139904 | elapsed time per iteration (ms): 37696.4 | learning rate: 5.566E-05 | global batch size:  1024 | lm loss: 1.795228E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37247/   51900 | consumed samples:     38140928 | elapsed time per iteration (ms): 37634.1 | learning rate: 5.566E-05 | global batch size:  1024 | lm loss: 1.809616E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37248/   51900 | consumed samples:     38141952 | elapsed time per iteration (ms): 37648.9 | learning rate: 5.565E-05 | global batch size:  1024 | lm loss: 1.809571E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37249/   51900 | consumed samples:     38142976 | elapsed time per iteration (ms): 37745.4 | learning rate: 5.565E-05 | global batch size:  1024 | lm loss: 1.790399E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37250/   51900 | consumed samples:     38144000 | elapsed time per iteration (ms): 37699.5 | learning rate: 5.564E-05 | global batch size:  1024 | lm loss: 1.794259E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37251/   51900 | consumed samples:     38145024 | elapsed time per iteration (ms): 37720.4 | learning rate: 5.564E-05 | global batch size:  1024 | lm loss: 1.810925E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37252/   51900 | consumed samples:     38146048 | elapsed time per iteration (ms): 37709.6 | learning rate: 5.563E-05 | global batch size:  1024 | lm loss: 1.813180E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37253/   51900 | consumed samples:     38147072 | elapsed time per iteration (ms): 37689.3 | learning rate: 5.563E-05 | global batch size:  1024 | lm loss: 1.793262E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37254/   51900 | consumed samples:     38148096 | elapsed time per iteration (ms): 37753.8 | learning rate: 5.563E-05 | global batch size:  1024 | lm loss: 1.810243E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37255/   51900 | consumed samples:     38149120 | elapsed time per iteration (ms): 37694.8 | learning rate: 5.562E-05 | global batch size:  1024 | lm loss: 1.800983E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37256/   51900 | consumed samples:     38150144 | elapsed time per iteration (ms): 37696.5 | learning rate: 5.562E-05 | global batch size:  1024 | lm loss: 1.819383E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37257/   51900 | consumed samples:     38151168 | elapsed time per iteration (ms): 37660.7 | learning rate: 5.561E-05 | global batch size:  1024 | lm loss: 1.795993E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37258/   51900 | consumed samples:     38152192 | elapsed time per iteration (ms): 37724.6 | learning rate: 5.561E-05 | global batch size:  1024 | lm loss: 1.808872E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37259/   51900 | consumed samples:     38153216 | elapsed time per iteration (ms): 37571.7 | learning rate: 5.560E-05 | global batch size:  1024 | lm loss: 1.824279E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37260/   51900 | consumed samples:     38154240 | elapsed time per iteration (ms): 37629.2 | learning rate: 5.560E-05 | global batch size:  1024 | lm loss: 1.799367E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37261/   51900 | consumed samples:     38155264 | elapsed time per iteration (ms): 37592.3 | learning rate: 5.559E-05 | global batch size:  1024 | lm loss: 1.815371E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37262/   51900 | consumed samples:     38156288 | elapsed time per iteration (ms): 37795.0 | learning rate: 5.559E-05 | global batch size:  1024 | lm loss: 1.819944E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37263/   51900 | consumed samples:     38157312 | elapsed time per iteration (ms): 37741.7 | learning rate: 5.558E-05 | global batch size:  1024 | lm loss: 1.797597E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37264/   51900 | consumed samples:     38158336 | elapsed time per iteration (ms): 37721.1 | learning rate: 5.558E-05 | global batch size:  1024 | lm loss: 1.805334E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37265/   51900 | consumed samples:     38159360 | elapsed time per iteration (ms): 37746.0 | learning rate: 5.558E-05 | global batch size:  1024 | lm loss: 1.819677E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37266/   51900 | consumed samples:     38160384 | elapsed time per iteration (ms): 37710.9 | learning rate: 5.557E-05 | global batch size:  1024 | lm loss: 1.813176E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37267/   51900 | consumed samples:     38161408 | elapsed time per iteration (ms): 37665.2 | learning rate: 5.557E-05 | global batch size:  1024 | lm loss: 1.810281E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37268/   51900 | consumed samples:     38162432 | elapsed time per iteration (ms): 37689.3 | learning rate: 5.556E-05 | global batch size:  1024 | lm loss: 1.825181E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37269/   51900 | consumed samples:     38163456 | elapsed time per iteration (ms): 37665.1 | learning rate: 5.556E-05 | global batch size:  1024 | lm loss: 1.792836E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37270/   51900 | consumed samples:     38164480 | elapsed time per iteration (ms): 37714.3 | learning rate: 5.555E-05 | global batch size:  1024 | lm loss: 1.806646E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37271/   51900 | consumed samples:     38165504 | elapsed time per iteration (ms): 37819.5 | learning rate: 5.555E-05 | global batch size:  1024 | lm loss: 1.797268E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37272/   51900 | consumed samples:     38166528 | elapsed time per iteration (ms): 37710.4 | learning rate: 5.554E-05 | global batch size:  1024 | lm loss: 1.809540E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37273/   51900 | consumed samples:     38167552 | elapsed time per iteration (ms): 37685.8 | learning rate: 5.554E-05 | global batch size:  1024 | lm loss: 1.809485E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37274/   51900 | consumed samples:     38168576 | elapsed time per iteration (ms): 37751.9 | learning rate: 5.553E-05 | global batch size:  1024 | lm loss: 1.798040E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37275/   51900 | consumed samples:     38169600 | elapsed time per iteration (ms): 37661.4 | learning rate: 5.553E-05 | global batch size:  1024 | lm loss: 1.829688E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37276/   51900 | consumed samples:     38170624 | elapsed time per iteration (ms): 37662.9 | learning rate: 5.553E-05 | global batch size:  1024 | lm loss: 1.816130E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37277/   51900 | consumed samples:     38171648 | elapsed time per iteration (ms): 37729.0 | learning rate: 5.552E-05 | global batch size:  1024 | lm loss: 1.818635E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37278/   51900 | consumed samples:     38172672 | elapsed time per iteration (ms): 37637.6 | learning rate: 5.552E-05 | global batch size:  1024 | lm loss: 1.806651E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37279/   51900 | consumed samples:     38173696 | elapsed time per iteration (ms): 37718.7 | learning rate: 5.551E-05 | global batch size:  1024 | lm loss: 1.809558E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37280/   51900 | consumed samples:     38174720 | elapsed time per iteration (ms): 37725.1 | learning rate: 5.551E-05 | global batch size:  1024 | lm loss: 1.800256E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37281/   51900 | consumed samples:     38175744 | elapsed time per iteration (ms): 37675.4 | learning rate: 5.550E-05 | global batch size:  1024 | lm loss: 1.800102E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37282/   51900 | consumed samples:     38176768 | elapsed time per iteration (ms): 37769.1 | learning rate: 5.550E-05 | global batch size:  1024 | lm loss: 1.811009E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37283/   51900 | consumed samples:     38177792 | elapsed time per iteration (ms): 37701.6 | learning rate: 5.549E-05 | global batch size:  1024 | lm loss: 1.804017E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37284/   51900 | consumed samples:     38178816 | elapsed time per iteration (ms): 37638.3 | learning rate: 5.549E-05 | global batch size:  1024 | lm loss: 1.809191E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37285/   51900 | consumed samples:     38179840 | elapsed time per iteration (ms): 37686.4 | learning rate: 5.549E-05 | global batch size:  1024 | lm loss: 1.808708E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37286/   51900 | consumed samples:     38180864 | elapsed time per iteration (ms): 37611.7 | learning rate: 5.548E-05 | global batch size:  1024 | lm loss: 1.805047E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37287/   51900 | consumed samples:     38181888 | elapsed time per iteration (ms): 37693.5 | learning rate: 5.548E-05 | global batch size:  1024 | lm loss: 1.807564E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37288/   51900 | consumed samples:     38182912 | elapsed time per iteration (ms): 37617.2 | learning rate: 5.547E-05 | global batch size:  1024 | lm loss: 1.822316E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37289/   51900 | consumed samples:     38183936 | elapsed time per iteration (ms): 37794.6 | learning rate: 5.547E-05 | global batch size:  1024 | lm loss: 1.804829E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37290/   51900 | consumed samples:     38184960 | elapsed time per iteration (ms): 37642.3 | learning rate: 5.546E-05 | global batch size:  1024 | lm loss: 1.812891E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37291/   51900 | consumed samples:     38185984 | elapsed time per iteration (ms): 37615.1 | learning rate: 5.546E-05 | global batch size:  1024 | lm loss: 1.805619E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37292/   51900 | consumed samples:     38187008 | elapsed time per iteration (ms): 37779.1 | learning rate: 5.545E-05 | global batch size:  1024 | lm loss: 1.808354E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37293/   51900 | consumed samples:     38188032 | elapsed time per iteration (ms): 37703.0 | learning rate: 5.545E-05 | global batch size:  1024 | lm loss: 1.801934E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37294/   51900 | consumed samples:     38189056 | elapsed time per iteration (ms): 37712.6 | learning rate: 5.544E-05 | global batch size:  1024 | lm loss: 1.810176E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37295/   51900 | consumed samples:     38190080 | elapsed time per iteration (ms): 37635.5 | learning rate: 5.544E-05 | global batch size:  1024 | lm loss: 1.803917E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37296/   51900 | consumed samples:     38191104 | elapsed time per iteration (ms): 37771.1 | learning rate: 5.544E-05 | global batch size:  1024 | lm loss: 1.797237E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37297/   51900 | consumed samples:     38192128 | elapsed time per iteration (ms): 37685.9 | learning rate: 5.543E-05 | global batch size:  1024 | lm loss: 1.787456E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37298/   51900 | consumed samples:     38193152 | elapsed time per iteration (ms): 37683.9 | learning rate: 5.543E-05 | global batch size:  1024 | lm loss: 1.800891E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37299/   51900 | consumed samples:     38194176 | elapsed time per iteration (ms): 37723.8 | learning rate: 5.542E-05 | global batch size:  1024 | lm loss: 1.805396E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37300/   51900 | consumed samples:     38195200 | elapsed time per iteration (ms): 37685.0 | learning rate: 5.542E-05 | global batch size:  1024 | lm loss: 1.817651E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37301/   51900 | consumed samples:     38196224 | elapsed time per iteration (ms): 37595.9 | learning rate: 5.541E-05 | global batch size:  1024 | lm loss: 1.831496E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37302/   51900 | consumed samples:     38197248 | elapsed time per iteration (ms): 37690.0 | learning rate: 5.541E-05 | global batch size:  1024 | lm loss: 1.784196E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37303/   51900 | consumed samples:     38198272 | elapsed time per iteration (ms): 37700.0 | learning rate: 5.540E-05 | global batch size:  1024 | lm loss: 1.805391E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37304/   51900 | consumed samples:     38199296 | elapsed time per iteration (ms): 37725.0 | learning rate: 5.540E-05 | global batch size:  1024 | lm loss: 1.807098E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37305/   51900 | consumed samples:     38200320 | elapsed time per iteration (ms): 37690.9 | learning rate: 5.540E-05 | global batch size:  1024 | lm loss: 1.814986E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37306/   51900 | consumed samples:     38201344 | elapsed time per iteration (ms): 37613.5 | learning rate: 5.539E-05 | global batch size:  1024 | lm loss: 1.801272E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37307/   51900 | consumed samples:     38202368 | elapsed time per iteration (ms): 37623.5 | learning rate: 5.539E-05 | global batch size:  1024 | lm loss: 1.804352E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37308/   51900 | consumed samples:     38203392 | elapsed time per iteration (ms): 37622.9 | learning rate: 5.538E-05 | global batch size:  1024 | lm loss: 1.804895E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37309/   51900 | consumed samples:     38204416 | elapsed time per iteration (ms): 37730.9 | learning rate: 5.538E-05 | global batch size:  1024 | lm loss: 1.796435E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37310/   51900 | consumed samples:     38205440 | elapsed time per iteration (ms): 37541.9 | learning rate: 5.537E-05 | global batch size:  1024 | lm loss: 1.814155E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37311/   51900 | consumed samples:     38206464 | elapsed time per iteration (ms): 37697.4 | learning rate: 5.537E-05 | global batch size:  1024 | lm loss: 1.794350E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37312/   51900 | consumed samples:     38207488 | elapsed time per iteration (ms): 37703.0 | learning rate: 5.536E-05 | global batch size:  1024 | lm loss: 1.782240E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37313/   51900 | consumed samples:     38208512 | elapsed time per iteration (ms): 37684.4 | learning rate: 5.536E-05 | global batch size:  1024 | lm loss: 1.805708E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37314/   51900 | consumed samples:     38209536 | elapsed time per iteration (ms): 37657.9 | learning rate: 5.535E-05 | global batch size:  1024 | lm loss: 1.805229E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37315/   51900 | consumed samples:     38210560 | elapsed time per iteration (ms): 37656.9 | learning rate: 5.535E-05 | global batch size:  1024 | lm loss: 1.789039E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37316/   51900 | consumed samples:     38211584 | elapsed time per iteration (ms): 37702.6 | learning rate: 5.535E-05 | global batch size:  1024 | lm loss: 1.807362E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37317/   51900 | consumed samples:     38212608 | elapsed time per iteration (ms): 37695.0 | learning rate: 5.534E-05 | global batch size:  1024 | lm loss: 1.800143E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37318/   51900 | consumed samples:     38213632 | elapsed time per iteration (ms): 37651.8 | learning rate: 5.534E-05 | global batch size:  1024 | lm loss: 1.809359E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37319/   51900 | consumed samples:     38214656 | elapsed time per iteration (ms): 37652.2 | learning rate: 5.533E-05 | global batch size:  1024 | lm loss: 1.788662E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37320/   51900 | consumed samples:     38215680 | elapsed time per iteration (ms): 37753.3 | learning rate: 5.533E-05 | global batch size:  1024 | lm loss: 1.797764E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37321/   51900 | consumed samples:     38216704 | elapsed time per iteration (ms): 37601.7 | learning rate: 5.532E-05 | global batch size:  1024 | lm loss: 1.817597E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37322/   51900 | consumed samples:     38217728 | elapsed time per iteration (ms): 37721.2 | learning rate: 5.532E-05 | global batch size:  1024 | lm loss: 1.774315E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37323/   51900 | consumed samples:     38218752 | elapsed time per iteration (ms): 37682.4 | learning rate: 5.531E-05 | global batch size:  1024 | lm loss: 1.812272E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37324/   51900 | consumed samples:     38219776 | elapsed time per iteration (ms): 37721.4 | learning rate: 5.531E-05 | global batch size:  1024 | lm loss: 1.796408E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37325/   51900 | consumed samples:     38220800 | elapsed time per iteration (ms): 37712.6 | learning rate: 5.531E-05 | global batch size:  1024 | lm loss: 1.807970E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37326/   51900 | consumed samples:     38221824 | elapsed time per iteration (ms): 37723.4 | learning rate: 5.530E-05 | global batch size:  1024 | lm loss: 1.804939E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37327/   51900 | consumed samples:     38222848 | elapsed time per iteration (ms): 37757.2 | learning rate: 5.530E-05 | global batch size:  1024 | lm loss: 1.806412E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37328/   51900 | consumed samples:     38223872 | elapsed time per iteration (ms): 37690.3 | learning rate: 5.529E-05 | global batch size:  1024 | lm loss: 1.804072E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37329/   51900 | consumed samples:     38224896 | elapsed time per iteration (ms): 37638.0 | learning rate: 5.529E-05 | global batch size:  1024 | lm loss: 1.803094E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37330/   51900 | consumed samples:     38225920 | elapsed time per iteration (ms): 37661.3 | learning rate: 5.528E-05 | global batch size:  1024 | lm loss: 1.810672E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37331/   51900 | consumed samples:     38226944 | elapsed time per iteration (ms): 37705.1 | learning rate: 5.528E-05 | global batch size:  1024 | lm loss: 1.800854E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37332/   51900 | consumed samples:     38227968 | elapsed time per iteration (ms): 37549.2 | learning rate: 5.527E-05 | global batch size:  1024 | lm loss: 1.790712E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37333/   51900 | consumed samples:     38228992 | elapsed time per iteration (ms): 37651.7 | learning rate: 5.527E-05 | global batch size:  1024 | lm loss: 1.786301E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37334/   51900 | consumed samples:     38230016 | elapsed time per iteration (ms): 37714.7 | learning rate: 5.526E-05 | global batch size:  1024 | lm loss: 1.794900E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37335/   51900 | consumed samples:     38231040 | elapsed time per iteration (ms): 37606.2 | learning rate: 5.526E-05 | global batch size:  1024 | lm loss: 1.808403E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37336/   51900 | consumed samples:     38232064 | elapsed time per iteration (ms): 37640.2 | learning rate: 5.526E-05 | global batch size:  1024 | lm loss: 1.805402E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37337/   51900 | consumed samples:     38233088 | elapsed time per iteration (ms): 37692.9 | learning rate: 5.525E-05 | global batch size:  1024 | lm loss: 1.809935E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37338/   51900 | consumed samples:     38234112 | elapsed time per iteration (ms): 37633.0 | learning rate: 5.525E-05 | global batch size:  1024 | lm loss: 1.815829E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37339/   51900 | consumed samples:     38235136 | elapsed time per iteration (ms): 37606.4 | learning rate: 5.524E-05 | global batch size:  1024 | lm loss: 1.803649E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37340/   51900 | consumed samples:     38236160 | elapsed time per iteration (ms): 37680.8 | learning rate: 5.524E-05 | global batch size:  1024 | lm loss: 1.817951E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37341/   51900 | consumed samples:     38237184 | elapsed time per iteration (ms): 37623.4 | learning rate: 5.523E-05 | global batch size:  1024 | lm loss: 1.805943E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37342/   51900 | consumed samples:     38238208 | elapsed time per iteration (ms): 37710.2 | learning rate: 5.523E-05 | global batch size:  1024 | lm loss: 1.804252E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37343/   51900 | consumed samples:     38239232 | elapsed time per iteration (ms): 37892.7 | learning rate: 5.522E-05 | global batch size:  1024 | lm loss: 1.815427E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37344/   51900 | consumed samples:     38240256 | elapsed time per iteration (ms): 37665.7 | learning rate: 5.522E-05 | global batch size:  1024 | lm loss: 1.800595E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37345/   51900 | consumed samples:     38241280 | elapsed time per iteration (ms): 37635.9 | learning rate: 5.522E-05 | global batch size:  1024 | lm loss: 1.799851E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37346/   51900 | consumed samples:     38242304 | elapsed time per iteration (ms): 37676.2 | learning rate: 5.521E-05 | global batch size:  1024 | lm loss: 1.808752E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37347/   51900 | consumed samples:     38243328 | elapsed time per iteration (ms): 37594.7 | learning rate: 5.521E-05 | global batch size:  1024 | lm loss: 1.797668E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37348/   51900 | consumed samples:     38244352 | elapsed time per iteration (ms): 37738.0 | learning rate: 5.520E-05 | global batch size:  1024 | lm loss: 1.826513E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37349/   51900 | consumed samples:     38245376 | elapsed time per iteration (ms): 37626.8 | learning rate: 5.520E-05 | global batch size:  1024 | lm loss: 1.798674E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37350/   51900 | consumed samples:     38246400 | elapsed time per iteration (ms): 37704.5 | learning rate: 5.519E-05 | global batch size:  1024 | lm loss: 1.813585E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37351/   51900 | consumed samples:     38247424 | elapsed time per iteration (ms): 37694.0 | learning rate: 5.519E-05 | global batch size:  1024 | lm loss: 1.799055E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37352/   51900 | consumed samples:     38248448 | elapsed time per iteration (ms): 37741.5 | learning rate: 5.518E-05 | global batch size:  1024 | lm loss: 1.812482E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37353/   51900 | consumed samples:     38249472 | elapsed time per iteration (ms): 37637.1 | learning rate: 5.518E-05 | global batch size:  1024 | lm loss: 1.790919E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37354/   51900 | consumed samples:     38250496 | elapsed time per iteration (ms): 37657.7 | learning rate: 5.517E-05 | global batch size:  1024 | lm loss: 1.803544E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37355/   51900 | consumed samples:     38251520 | elapsed time per iteration (ms): 37730.1 | learning rate: 5.517E-05 | global batch size:  1024 | lm loss: 1.820410E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37356/   51900 | consumed samples:     38252544 | elapsed time per iteration (ms): 37653.3 | learning rate: 5.517E-05 | global batch size:  1024 | lm loss: 1.803045E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37357/   51900 | consumed samples:     38253568 | elapsed time per iteration (ms): 37614.1 | learning rate: 5.516E-05 | global batch size:  1024 | lm loss: 1.811664E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37358/   51900 | consumed samples:     38254592 | elapsed time per iteration (ms): 37622.1 | learning rate: 5.516E-05 | global batch size:  1024 | lm loss: 1.814529E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37359/   51900 | consumed samples:     38255616 | elapsed time per iteration (ms): 37639.9 | learning rate: 5.515E-05 | global batch size:  1024 | lm loss: 1.805696E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37360/   51900 | consumed samples:     38256640 | elapsed time per iteration (ms): 37646.0 | learning rate: 5.515E-05 | global batch size:  1024 | lm loss: 1.803182E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37361/   51900 | consumed samples:     38257664 | elapsed time per iteration (ms): 37665.7 | learning rate: 5.514E-05 | global batch size:  1024 | lm loss: 1.772753E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37362/   51900 | consumed samples:     38258688 | elapsed time per iteration (ms): 37600.7 | learning rate: 5.514E-05 | global batch size:  1024 | lm loss: 1.792516E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37363/   51900 | consumed samples:     38259712 | elapsed time per iteration (ms): 37704.2 | learning rate: 5.513E-05 | global batch size:  1024 | lm loss: 1.812063E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37364/   51900 | consumed samples:     38260736 | elapsed time per iteration (ms): 37785.2 | learning rate: 5.513E-05 | global batch size:  1024 | lm loss: 1.805069E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37365/   51900 | consumed samples:     38261760 | elapsed time per iteration (ms): 37775.3 | learning rate: 5.513E-05 | global batch size:  1024 | lm loss: 1.809307E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37366/   51900 | consumed samples:     38262784 | elapsed time per iteration (ms): 37615.2 | learning rate: 5.512E-05 | global batch size:  1024 | lm loss: 1.799973E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37367/   51900 | consumed samples:     38263808 | elapsed time per iteration (ms): 37707.2 | learning rate: 5.512E-05 | global batch size:  1024 | lm loss: 1.810684E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37368/   51900 | consumed samples:     38264832 | elapsed time per iteration (ms): 37656.6 | learning rate: 5.511E-05 | global batch size:  1024 | lm loss: 1.807490E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37369/   51900 | consumed samples:     38265856 | elapsed time per iteration (ms): 37625.8 | learning rate: 5.511E-05 | global batch size:  1024 | lm loss: 1.816611E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37370/   51900 | consumed samples:     38266880 | elapsed time per iteration (ms): 37729.0 | learning rate: 5.510E-05 | global batch size:  1024 | lm loss: 1.819644E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37371/   51900 | consumed samples:     38267904 | elapsed time per iteration (ms): 37796.2 | learning rate: 5.510E-05 | global batch size:  1024 | lm loss: 1.820359E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37372/   51900 | consumed samples:     38268928 | elapsed time per iteration (ms): 37743.2 | learning rate: 5.509E-05 | global batch size:  1024 | lm loss: 1.801845E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37373/   51900 | consumed samples:     38269952 | elapsed time per iteration (ms): 37817.5 | learning rate: 5.509E-05 | global batch size:  1024 | lm loss: 1.814206E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37374/   51900 | consumed samples:     38270976 | elapsed time per iteration (ms): 37620.7 | learning rate: 5.508E-05 | global batch size:  1024 | lm loss: 1.811978E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37375/   51900 | consumed samples:     38272000 | elapsed time per iteration (ms): 37734.5 | learning rate: 5.508E-05 | global batch size:  1024 | lm loss: 1.825356E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37376/   51900 | consumed samples:     38273024 | elapsed time per iteration (ms): 37645.7 | learning rate: 5.508E-05 | global batch size:  1024 | lm loss: 1.805692E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37377/   51900 | consumed samples:     38274048 | elapsed time per iteration (ms): 37631.7 | learning rate: 5.507E-05 | global batch size:  1024 | lm loss: 1.807311E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37378/   51900 | consumed samples:     38275072 | elapsed time per iteration (ms): 37650.5 | learning rate: 5.507E-05 | global batch size:  1024 | lm loss: 1.814273E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37379/   51900 | consumed samples:     38276096 | elapsed time per iteration (ms): 37777.1 | learning rate: 5.506E-05 | global batch size:  1024 | lm loss: 1.795103E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37380/   51900 | consumed samples:     38277120 | elapsed time per iteration (ms): 37555.5 | learning rate: 5.506E-05 | global batch size:  1024 | lm loss: 1.813751E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37381/   51900 | consumed samples:     38278144 | elapsed time per iteration (ms): 37691.7 | learning rate: 5.505E-05 | global batch size:  1024 | lm loss: 1.816275E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37382/   51900 | consumed samples:     38279168 | elapsed time per iteration (ms): 37547.7 | learning rate: 5.505E-05 | global batch size:  1024 | lm loss: 1.792105E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37383/   51900 | consumed samples:     38280192 | elapsed time per iteration (ms): 37644.2 | learning rate: 5.504E-05 | global batch size:  1024 | lm loss: 1.798954E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37384/   51900 | consumed samples:     38281216 | elapsed time per iteration (ms): 37599.5 | learning rate: 5.504E-05 | global batch size:  1024 | lm loss: 1.789974E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37385/   51900 | consumed samples:     38282240 | elapsed time per iteration (ms): 37782.0 | learning rate: 5.504E-05 | global batch size:  1024 | lm loss: 1.811681E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37386/   51900 | consumed samples:     38283264 | elapsed time per iteration (ms): 37578.9 | learning rate: 5.503E-05 | global batch size:  1024 | lm loss: 1.800941E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37387/   51900 | consumed samples:     38284288 | elapsed time per iteration (ms): 37721.1 | learning rate: 5.503E-05 | global batch size:  1024 | lm loss: 1.802935E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37388/   51900 | consumed samples:     38285312 | elapsed time per iteration (ms): 37623.8 | learning rate: 5.502E-05 | global batch size:  1024 | lm loss: 1.816566E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37389/   51900 | consumed samples:     38286336 | elapsed time per iteration (ms): 37646.5 | learning rate: 5.502E-05 | global batch size:  1024 | lm loss: 1.808130E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37390/   51900 | consumed samples:     38287360 | elapsed time per iteration (ms): 37638.2 | learning rate: 5.501E-05 | global batch size:  1024 | lm loss: 1.800130E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37391/   51900 | consumed samples:     38288384 | elapsed time per iteration (ms): 37623.3 | learning rate: 5.501E-05 | global batch size:  1024 | lm loss: 1.819126E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37392/   51900 | consumed samples:     38289408 | elapsed time per iteration (ms): 37622.2 | learning rate: 5.500E-05 | global batch size:  1024 | lm loss: 1.802397E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37393/   51900 | consumed samples:     38290432 | elapsed time per iteration (ms): 37611.8 | learning rate: 5.500E-05 | global batch size:  1024 | lm loss: 1.795783E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37394/   51900 | consumed samples:     38291456 | elapsed time per iteration (ms): 37607.7 | learning rate: 5.500E-05 | global batch size:  1024 | lm loss: 1.789927E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37395/   51900 | consumed samples:     38292480 | elapsed time per iteration (ms): 37640.2 | learning rate: 5.499E-05 | global batch size:  1024 | lm loss: 1.816050E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37396/   51900 | consumed samples:     38293504 | elapsed time per iteration (ms): 37560.4 | learning rate: 5.499E-05 | global batch size:  1024 | lm loss: 1.812264E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37397/   51900 | consumed samples:     38294528 | elapsed time per iteration (ms): 37598.7 | learning rate: 5.498E-05 | global batch size:  1024 | lm loss: 1.813205E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37398/   51900 | consumed samples:     38295552 | elapsed time per iteration (ms): 37594.7 | learning rate: 5.498E-05 | global batch size:  1024 | lm loss: 1.801163E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37399/   51900 | consumed samples:     38296576 | elapsed time per iteration (ms): 37700.1 | learning rate: 5.497E-05 | global batch size:  1024 | lm loss: 1.800622E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37400/   51900 | consumed samples:     38297600 | elapsed time per iteration (ms): 37723.9 | learning rate: 5.497E-05 | global batch size:  1024 | lm loss: 1.813102E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37401/   51900 | consumed samples:     38298624 | elapsed time per iteration (ms): 37661.8 | learning rate: 5.496E-05 | global batch size:  1024 | lm loss: 1.793794E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37402/   51900 | consumed samples:     38299648 | elapsed time per iteration (ms): 37533.2 | learning rate: 5.496E-05 | global batch size:  1024 | lm loss: 1.803771E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37403/   51900 | consumed samples:     38300672 | elapsed time per iteration (ms): 37705.6 | learning rate: 5.495E-05 | global batch size:  1024 | lm loss: 1.804047E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37404/   51900 | consumed samples:     38301696 | elapsed time per iteration (ms): 37777.9 | learning rate: 5.495E-05 | global batch size:  1024 | lm loss: 1.812210E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37405/   51900 | consumed samples:     38302720 | elapsed time per iteration (ms): 37711.9 | learning rate: 5.495E-05 | global batch size:  1024 | lm loss: 1.795894E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37406/   51900 | consumed samples:     38303744 | elapsed time per iteration (ms): 37716.3 | learning rate: 5.494E-05 | global batch size:  1024 | lm loss: 1.810131E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37407/   51900 | consumed samples:     38304768 | elapsed time per iteration (ms): 37561.3 | learning rate: 5.494E-05 | global batch size:  1024 | lm loss: 1.801433E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37408/   51900 | consumed samples:     38305792 | elapsed time per iteration (ms): 37632.6 | learning rate: 5.493E-05 | global batch size:  1024 | lm loss: 1.802126E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37409/   51900 | consumed samples:     38306816 | elapsed time per iteration (ms): 37610.2 | learning rate: 5.493E-05 | global batch size:  1024 | lm loss: 1.804256E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37410/   51900 | consumed samples:     38307840 | elapsed time per iteration (ms): 37725.8 | learning rate: 5.492E-05 | global batch size:  1024 | lm loss: 1.799428E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37411/   51900 | consumed samples:     38308864 | elapsed time per iteration (ms): 37665.8 | learning rate: 5.492E-05 | global batch size:  1024 | lm loss: 1.792999E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37412/   51900 | consumed samples:     38309888 | elapsed time per iteration (ms): 37615.4 | learning rate: 5.491E-05 | global batch size:  1024 | lm loss: 1.796009E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37413/   51900 | consumed samples:     38310912 | elapsed time per iteration (ms): 37698.4 | learning rate: 5.491E-05 | global batch size:  1024 | lm loss: 1.819330E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37414/   51900 | consumed samples:     38311936 | elapsed time per iteration (ms): 37700.5 | learning rate: 5.491E-05 | global batch size:  1024 | lm loss: 1.801839E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37415/   51900 | consumed samples:     38312960 | elapsed time per iteration (ms): 37705.5 | learning rate: 5.490E-05 | global batch size:  1024 | lm loss: 1.796753E+00 | loss scale: 1.0 | grad norm: 0.064 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37416/   51900 | consumed samples:     38313984 | elapsed time per iteration (ms): 37674.8 | learning rate: 5.490E-05 | global batch size:  1024 | lm loss: 1.796765E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37417/   51900 | consumed samples:     38315008 | elapsed time per iteration (ms): 37659.1 | learning rate: 5.489E-05 | global batch size:  1024 | lm loss: 1.812277E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37418/   51900 | consumed samples:     38316032 | elapsed time per iteration (ms): 37618.8 | learning rate: 5.489E-05 | global batch size:  1024 | lm loss: 1.818532E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37419/   51900 | consumed samples:     38317056 | elapsed time per iteration (ms): 37756.8 | learning rate: 5.488E-05 | global batch size:  1024 | lm loss: 1.796807E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37420/   51900 | consumed samples:     38318080 | elapsed time per iteration (ms): 37625.6 | learning rate: 5.488E-05 | global batch size:  1024 | lm loss: 1.818896E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37421/   51900 | consumed samples:     38319104 | elapsed time per iteration (ms): 37691.2 | learning rate: 5.487E-05 | global batch size:  1024 | lm loss: 1.816115E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37422/   51900 | consumed samples:     38320128 | elapsed time per iteration (ms): 37809.9 | learning rate: 5.487E-05 | global batch size:  1024 | lm loss: 1.812400E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37423/   51900 | consumed samples:     38321152 | elapsed time per iteration (ms): 37727.2 | learning rate: 5.487E-05 | global batch size:  1024 | lm loss: 1.810552E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37424/   51900 | consumed samples:     38322176 | elapsed time per iteration (ms): 37650.1 | learning rate: 5.486E-05 | global batch size:  1024 | lm loss: 1.828444E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37425/   51900 | consumed samples:     38323200 | elapsed time per iteration (ms): 37723.3 | learning rate: 5.486E-05 | global batch size:  1024 | lm loss: 1.797289E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37426/   51900 | consumed samples:     38324224 | elapsed time per iteration (ms): 37718.1 | learning rate: 5.485E-05 | global batch size:  1024 | lm loss: 1.795662E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37427/   51900 | consumed samples:     38325248 | elapsed time per iteration (ms): 37604.8 | learning rate: 5.485E-05 | global batch size:  1024 | lm loss: 1.802842E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37428/   51900 | consumed samples:     38326272 | elapsed time per iteration (ms): 37648.1 | learning rate: 5.484E-05 | global batch size:  1024 | lm loss: 1.796500E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37429/   51900 | consumed samples:     38327296 | elapsed time per iteration (ms): 37589.0 | learning rate: 5.484E-05 | global batch size:  1024 | lm loss: 1.805004E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37430/   51900 | consumed samples:     38328320 | elapsed time per iteration (ms): 37565.7 | learning rate: 5.483E-05 | global batch size:  1024 | lm loss: 1.798384E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37431/   51900 | consumed samples:     38329344 | elapsed time per iteration (ms): 37568.2 | learning rate: 5.483E-05 | global batch size:  1024 | lm loss: 1.797154E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37432/   51900 | consumed samples:     38330368 | elapsed time per iteration (ms): 37732.2 | learning rate: 5.482E-05 | global batch size:  1024 | lm loss: 1.800866E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37433/   51900 | consumed samples:     38331392 | elapsed time per iteration (ms): 37663.8 | learning rate: 5.482E-05 | global batch size:  1024 | lm loss: 1.810161E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37434/   51900 | consumed samples:     38332416 | elapsed time per iteration (ms): 37737.0 | learning rate: 5.482E-05 | global batch size:  1024 | lm loss: 1.809990E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37435/   51900 | consumed samples:     38333440 | elapsed time per iteration (ms): 37653.4 | learning rate: 5.481E-05 | global batch size:  1024 | lm loss: 1.811586E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37436/   51900 | consumed samples:     38334464 | elapsed time per iteration (ms): 37657.9 | learning rate: 5.481E-05 | global batch size:  1024 | lm loss: 1.799194E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37437/   51900 | consumed samples:     38335488 | elapsed time per iteration (ms): 37666.1 | learning rate: 5.480E-05 | global batch size:  1024 | lm loss: 1.798254E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37438/   51900 | consumed samples:     38336512 | elapsed time per iteration (ms): 37628.5 | learning rate: 5.480E-05 | global batch size:  1024 | lm loss: 1.812644E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37439/   51900 | consumed samples:     38337536 | elapsed time per iteration (ms): 37673.2 | learning rate: 5.479E-05 | global batch size:  1024 | lm loss: 1.819347E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37440/   51900 | consumed samples:     38338560 | elapsed time per iteration (ms): 37687.9 | learning rate: 5.479E-05 | global batch size:  1024 | lm loss: 1.822051E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37441/   51900 | consumed samples:     38339584 | elapsed time per iteration (ms): 37565.8 | learning rate: 5.478E-05 | global batch size:  1024 | lm loss: 1.815777E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37442/   51900 | consumed samples:     38340608 | elapsed time per iteration (ms): 37701.5 | learning rate: 5.478E-05 | global batch size:  1024 | lm loss: 1.806524E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37443/   51900 | consumed samples:     38341632 | elapsed time per iteration (ms): 37619.2 | learning rate: 5.478E-05 | global batch size:  1024 | lm loss: 1.805250E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37444/   51900 | consumed samples:     38342656 | elapsed time per iteration (ms): 37611.1 | learning rate: 5.477E-05 | global batch size:  1024 | lm loss: 1.804177E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37445/   51900 | consumed samples:     38343680 | elapsed time per iteration (ms): 37715.4 | learning rate: 5.477E-05 | global batch size:  1024 | lm loss: 1.819803E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37446/   51900 | consumed samples:     38344704 | elapsed time per iteration (ms): 37742.3 | learning rate: 5.476E-05 | global batch size:  1024 | lm loss: 1.797399E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37447/   51900 | consumed samples:     38345728 | elapsed time per iteration (ms): 37589.1 | learning rate: 5.476E-05 | global batch size:  1024 | lm loss: 1.810265E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37448/   51900 | consumed samples:     38346752 | elapsed time per iteration (ms): 37607.2 | learning rate: 5.475E-05 | global batch size:  1024 | lm loss: 1.803098E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37449/   51900 | consumed samples:     38347776 | elapsed time per iteration (ms): 37654.4 | learning rate: 5.475E-05 | global batch size:  1024 | lm loss: 1.798772E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37450/   51900 | consumed samples:     38348800 | elapsed time per iteration (ms): 37507.7 | learning rate: 5.474E-05 | global batch size:  1024 | lm loss: 1.807351E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37451/   51900 | consumed samples:     38349824 | elapsed time per iteration (ms): 37612.9 | learning rate: 5.474E-05 | global batch size:  1024 | lm loss: 1.818389E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37452/   51900 | consumed samples:     38350848 | elapsed time per iteration (ms): 37628.1 | learning rate: 5.474E-05 | global batch size:  1024 | lm loss: 1.789951E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37453/   51900 | consumed samples:     38351872 | elapsed time per iteration (ms): 37603.7 | learning rate: 5.473E-05 | global batch size:  1024 | lm loss: 1.807237E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37454/   51900 | consumed samples:     38352896 | elapsed time per iteration (ms): 37639.3 | learning rate: 5.473E-05 | global batch size:  1024 | lm loss: 1.801355E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37455/   51900 | consumed samples:     38353920 | elapsed time per iteration (ms): 37638.6 | learning rate: 5.472E-05 | global batch size:  1024 | lm loss: 1.794624E+00 | loss scale: 1.0 | grad norm: 0.065 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37456/   51900 | consumed samples:     38354944 | elapsed time per iteration (ms): 37687.9 | learning rate: 5.472E-05 | global batch size:  1024 | lm loss: 1.809664E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37457/   51900 | consumed samples:     38355968 | elapsed time per iteration (ms): 37756.2 | learning rate: 5.471E-05 | global batch size:  1024 | lm loss: 1.810145E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37458/   51900 | consumed samples:     38356992 | elapsed time per iteration (ms): 37662.2 | learning rate: 5.471E-05 | global batch size:  1024 | lm loss: 1.798989E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37459/   51900 | consumed samples:     38358016 | elapsed time per iteration (ms): 37647.5 | learning rate: 5.470E-05 | global batch size:  1024 | lm loss: 1.795162E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37460/   51900 | consumed samples:     38359040 | elapsed time per iteration (ms): 37752.4 | learning rate: 5.470E-05 | global batch size:  1024 | lm loss: 1.803392E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37461/   51900 | consumed samples:     38360064 | elapsed time per iteration (ms): 37731.4 | learning rate: 5.470E-05 | global batch size:  1024 | lm loss: 1.807330E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37462/   51900 | consumed samples:     38361088 | elapsed time per iteration (ms): 37737.9 | learning rate: 5.469E-05 | global batch size:  1024 | lm loss: 1.803362E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37463/   51900 | consumed samples:     38362112 | elapsed time per iteration (ms): 37658.1 | learning rate: 5.469E-05 | global batch size:  1024 | lm loss: 1.807477E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37464/   51900 | consumed samples:     38363136 | elapsed time per iteration (ms): 37746.5 | learning rate: 5.468E-05 | global batch size:  1024 | lm loss: 1.790702E+00 | loss scale: 1.0 | grad norm: 0.063 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37465/   51900 | consumed samples:     38364160 | elapsed time per iteration (ms): 37694.7 | learning rate: 5.468E-05 | global batch size:  1024 | lm loss: 1.793634E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37466/   51900 | consumed samples:     38365184 | elapsed time per iteration (ms): 37623.2 | learning rate: 5.467E-05 | global batch size:  1024 | lm loss: 1.804579E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37467/   51900 | consumed samples:     38366208 | elapsed time per iteration (ms): 37642.6 | learning rate: 5.467E-05 | global batch size:  1024 | lm loss: 1.808774E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37468/   51900 | consumed samples:     38367232 | elapsed time per iteration (ms): 37574.7 | learning rate: 5.466E-05 | global batch size:  1024 | lm loss: 1.824057E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37469/   51900 | consumed samples:     38368256 | elapsed time per iteration (ms): 37716.6 | learning rate: 5.466E-05 | global batch size:  1024 | lm loss: 1.812078E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37470/   51900 | consumed samples:     38369280 | elapsed time per iteration (ms): 37627.1 | learning rate: 5.465E-05 | global batch size:  1024 | lm loss: 1.814405E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37471/   51900 | consumed samples:     38370304 | elapsed time per iteration (ms): 37708.8 | learning rate: 5.465E-05 | global batch size:  1024 | lm loss: 1.803226E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37472/   51900 | consumed samples:     38371328 | elapsed time per iteration (ms): 37605.1 | learning rate: 5.465E-05 | global batch size:  1024 | lm loss: 1.797166E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37473/   51900 | consumed samples:     38372352 | elapsed time per iteration (ms): 37583.9 | learning rate: 5.464E-05 | global batch size:  1024 | lm loss: 1.813593E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37474/   51900 | consumed samples:     38373376 | elapsed time per iteration (ms): 37642.6 | learning rate: 5.464E-05 | global batch size:  1024 | lm loss: 1.822619E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37475/   51900 | consumed samples:     38374400 | elapsed time per iteration (ms): 37682.6 | learning rate: 5.463E-05 | global batch size:  1024 | lm loss: 1.812620E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37476/   51900 | consumed samples:     38375424 | elapsed time per iteration (ms): 37645.8 | learning rate: 5.463E-05 | global batch size:  1024 | lm loss: 1.803257E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37477/   51900 | consumed samples:     38376448 | elapsed time per iteration (ms): 37683.8 | learning rate: 5.462E-05 | global batch size:  1024 | lm loss: 1.804394E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37478/   51900 | consumed samples:     38377472 | elapsed time per iteration (ms): 37629.7 | learning rate: 5.462E-05 | global batch size:  1024 | lm loss: 1.795549E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37479/   51900 | consumed samples:     38378496 | elapsed time per iteration (ms): 37606.3 | learning rate: 5.461E-05 | global batch size:  1024 | lm loss: 1.807891E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37480/   51900 | consumed samples:     38379520 | elapsed time per iteration (ms): 37676.3 | learning rate: 5.461E-05 | global batch size:  1024 | lm loss: 1.804911E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37481/   51900 | consumed samples:     38380544 | elapsed time per iteration (ms): 37669.0 | learning rate: 5.461E-05 | global batch size:  1024 | lm loss: 1.793052E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37482/   51900 | consumed samples:     38381568 | elapsed time per iteration (ms): 37604.3 | learning rate: 5.460E-05 | global batch size:  1024 | lm loss: 1.812225E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37483/   51900 | consumed samples:     38382592 | elapsed time per iteration (ms): 37650.7 | learning rate: 5.460E-05 | global batch size:  1024 | lm loss: 1.810265E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37484/   51900 | consumed samples:     38383616 | elapsed time per iteration (ms): 37589.1 | learning rate: 5.459E-05 | global batch size:  1024 | lm loss: 1.820860E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37485/   51900 | consumed samples:     38384640 | elapsed time per iteration (ms): 37609.2 | learning rate: 5.459E-05 | global batch size:  1024 | lm loss: 1.788157E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37486/   51900 | consumed samples:     38385664 | elapsed time per iteration (ms): 37695.5 | learning rate: 5.458E-05 | global batch size:  1024 | lm loss: 1.805232E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37487/   51900 | consumed samples:     38386688 | elapsed time per iteration (ms): 37715.3 | learning rate: 5.458E-05 | global batch size:  1024 | lm loss: 1.801524E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37488/   51900 | consumed samples:     38387712 | elapsed time per iteration (ms): 37726.8 | learning rate: 5.457E-05 | global batch size:  1024 | lm loss: 1.785060E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37489/   51900 | consumed samples:     38388736 | elapsed time per iteration (ms): 37801.0 | learning rate: 5.457E-05 | global batch size:  1024 | lm loss: 1.801056E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37490/   51900 | consumed samples:     38389760 | elapsed time per iteration (ms): 37592.3 | learning rate: 5.457E-05 | global batch size:  1024 | lm loss: 1.777101E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37491/   51900 | consumed samples:     38390784 | elapsed time per iteration (ms): 37709.3 | learning rate: 5.456E-05 | global batch size:  1024 | lm loss: 1.787328E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37492/   51900 | consumed samples:     38391808 | elapsed time per iteration (ms): 37823.4 | learning rate: 5.456E-05 | global batch size:  1024 | lm loss: 1.811060E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37493/   51900 | consumed samples:     38392832 | elapsed time per iteration (ms): 37629.2 | learning rate: 5.455E-05 | global batch size:  1024 | lm loss: 1.799549E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37494/   51900 | consumed samples:     38393856 | elapsed time per iteration (ms): 37605.9 | learning rate: 5.455E-05 | global batch size:  1024 | lm loss: 1.800260E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37495/   51900 | consumed samples:     38394880 | elapsed time per iteration (ms): 37651.5 | learning rate: 5.454E-05 | global batch size:  1024 | lm loss: 1.803753E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37496/   51900 | consumed samples:     38395904 | elapsed time per iteration (ms): 37665.0 | learning rate: 5.454E-05 | global batch size:  1024 | lm loss: 1.799625E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37497/   51900 | consumed samples:     38396928 | elapsed time per iteration (ms): 37778.2 | learning rate: 5.453E-05 | global batch size:  1024 | lm loss: 1.827175E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37498/   51900 | consumed samples:     38397952 | elapsed time per iteration (ms): 37615.0 | learning rate: 5.453E-05 | global batch size:  1024 | lm loss: 1.812239E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37499/   51900 | consumed samples:     38398976 | elapsed time per iteration (ms): 37648.8 | learning rate: 5.453E-05 | global batch size:  1024 | lm loss: 1.798401E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37500/   51900 | consumed samples:     38400000 | elapsed time per iteration (ms): 37801.0 | learning rate: 5.452E-05 | global batch size:  1024 | lm loss: 1.798775E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    save-checkpoint ................................: (145667.45, 145667.53)
 iteration    37501/   51900 | consumed samples:     38401024 | elapsed time per iteration (ms): 37217.4 | learning rate: 5.452E-05 | global batch size:  1024 | lm loss: 1.804387E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37502/   51900 | consumed samples:     38402048 | elapsed time per iteration (ms): 37605.1 | learning rate: 5.451E-05 | global batch size:  1024 | lm loss: 1.822343E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37503/   51900 | consumed samples:     38403072 | elapsed time per iteration (ms): 37566.4 | learning rate: 5.451E-05 | global batch size:  1024 | lm loss: 1.803388E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37504/   51900 | consumed samples:     38404096 | elapsed time per iteration (ms): 37656.3 | learning rate: 5.450E-05 | global batch size:  1024 | lm loss: 1.820281E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37505/   51900 | consumed samples:     38405120 | elapsed time per iteration (ms): 37695.3 | learning rate: 5.450E-05 | global batch size:  1024 | lm loss: 1.814657E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37506/   51900 | consumed samples:     38406144 | elapsed time per iteration (ms): 37743.2 | learning rate: 5.449E-05 | global batch size:  1024 | lm loss: 1.804251E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37507/   51900 | consumed samples:     38407168 | elapsed time per iteration (ms): 37745.2 | learning rate: 5.449E-05 | global batch size:  1024 | lm loss: 1.817975E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37508/   51900 | consumed samples:     38408192 | elapsed time per iteration (ms): 37657.4 | learning rate: 5.449E-05 | global batch size:  1024 | lm loss: 1.803959E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37509/   51900 | consumed samples:     38409216 | elapsed time per iteration (ms): 37647.3 | learning rate: 5.448E-05 | global batch size:  1024 | lm loss: 1.789141E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37510/   51900 | consumed samples:     38410240 | elapsed time per iteration (ms): 37558.1 | learning rate: 5.448E-05 | global batch size:  1024 | lm loss: 1.822704E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37511/   51900 | consumed samples:     38411264 | elapsed time per iteration (ms): 37658.4 | learning rate: 5.447E-05 | global batch size:  1024 | lm loss: 1.804276E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37512/   51900 | consumed samples:     38412288 | elapsed time per iteration (ms): 37721.6 | learning rate: 5.447E-05 | global batch size:  1024 | lm loss: 1.790688E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37513/   51900 | consumed samples:     38413312 | elapsed time per iteration (ms): 37736.2 | learning rate: 5.446E-05 | global batch size:  1024 | lm loss: 1.810513E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37514/   51900 | consumed samples:     38414336 | elapsed time per iteration (ms): 37634.2 | learning rate: 5.446E-05 | global batch size:  1024 | lm loss: 1.807724E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37515/   51900 | consumed samples:     38415360 | elapsed time per iteration (ms): 37709.1 | learning rate: 5.445E-05 | global batch size:  1024 | lm loss: 1.807992E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37516/   51900 | consumed samples:     38416384 | elapsed time per iteration (ms): 37578.1 | learning rate: 5.445E-05 | global batch size:  1024 | lm loss: 1.809168E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37517/   51900 | consumed samples:     38417408 | elapsed time per iteration (ms): 37617.5 | learning rate: 5.445E-05 | global batch size:  1024 | lm loss: 1.818614E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37518/   51900 | consumed samples:     38418432 | elapsed time per iteration (ms): 37594.9 | learning rate: 5.444E-05 | global batch size:  1024 | lm loss: 1.793529E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37519/   51900 | consumed samples:     38419456 | elapsed time per iteration (ms): 37690.8 | learning rate: 5.444E-05 | global batch size:  1024 | lm loss: 1.819058E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37520/   51900 | consumed samples:     38420480 | elapsed time per iteration (ms): 37602.9 | learning rate: 5.443E-05 | global batch size:  1024 | lm loss: 1.818191E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37521/   51900 | consumed samples:     38421504 | elapsed time per iteration (ms): 37614.7 | learning rate: 5.443E-05 | global batch size:  1024 | lm loss: 1.803287E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37522/   51900 | consumed samples:     38422528 | elapsed time per iteration (ms): 37604.3 | learning rate: 5.442E-05 | global batch size:  1024 | lm loss: 1.797054E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37523/   51900 | consumed samples:     38423552 | elapsed time per iteration (ms): 37616.2 | learning rate: 5.442E-05 | global batch size:  1024 | lm loss: 1.785252E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37524/   51900 | consumed samples:     38424576 | elapsed time per iteration (ms): 37650.4 | learning rate: 5.441E-05 | global batch size:  1024 | lm loss: 1.788923E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37525/   51900 | consumed samples:     38425600 | elapsed time per iteration (ms): 37624.1 | learning rate: 5.441E-05 | global batch size:  1024 | lm loss: 1.809609E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37526/   51900 | consumed samples:     38426624 | elapsed time per iteration (ms): 37583.6 | learning rate: 5.441E-05 | global batch size:  1024 | lm loss: 1.802222E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37527/   51900 | consumed samples:     38427648 | elapsed time per iteration (ms): 37680.1 | learning rate: 5.440E-05 | global batch size:  1024 | lm loss: 1.818364E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37528/   51900 | consumed samples:     38428672 | elapsed time per iteration (ms): 37616.8 | learning rate: 5.440E-05 | global batch size:  1024 | lm loss: 1.799094E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37529/   51900 | consumed samples:     38429696 | elapsed time per iteration (ms): 37583.9 | learning rate: 5.439E-05 | global batch size:  1024 | lm loss: 1.806160E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37530/   51900 | consumed samples:     38430720 | elapsed time per iteration (ms): 37546.0 | learning rate: 5.439E-05 | global batch size:  1024 | lm loss: 1.810740E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37531/   51900 | consumed samples:     38431744 | elapsed time per iteration (ms): 37704.6 | learning rate: 5.438E-05 | global batch size:  1024 | lm loss: 1.817651E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37532/   51900 | consumed samples:     38432768 | elapsed time per iteration (ms): 37661.8 | learning rate: 5.438E-05 | global batch size:  1024 | lm loss: 1.798988E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37533/   51900 | consumed samples:     38433792 | elapsed time per iteration (ms): 37707.5 | learning rate: 5.437E-05 | global batch size:  1024 | lm loss: 1.820552E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37534/   51900 | consumed samples:     38434816 | elapsed time per iteration (ms): 37631.3 | learning rate: 5.437E-05 | global batch size:  1024 | lm loss: 1.811159E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37535/   51900 | consumed samples:     38435840 | elapsed time per iteration (ms): 37611.8 | learning rate: 5.437E-05 | global batch size:  1024 | lm loss: 1.798298E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37536/   51900 | consumed samples:     38436864 | elapsed time per iteration (ms): 37673.3 | learning rate: 5.436E-05 | global batch size:  1024 | lm loss: 1.796554E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37537/   51900 | consumed samples:     38437888 | elapsed time per iteration (ms): 37692.9 | learning rate: 5.436E-05 | global batch size:  1024 | lm loss: 1.796724E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37538/   51900 | consumed samples:     38438912 | elapsed time per iteration (ms): 37633.7 | learning rate: 5.435E-05 | global batch size:  1024 | lm loss: 1.813198E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37539/   51900 | consumed samples:     38439936 | elapsed time per iteration (ms): 37582.4 | learning rate: 5.435E-05 | global batch size:  1024 | lm loss: 1.817992E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37540/   51900 | consumed samples:     38440960 | elapsed time per iteration (ms): 37685.4 | learning rate: 5.434E-05 | global batch size:  1024 | lm loss: 1.830809E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37541/   51900 | consumed samples:     38441984 | elapsed time per iteration (ms): 37601.3 | learning rate: 5.434E-05 | global batch size:  1024 | lm loss: 1.804690E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37542/   51900 | consumed samples:     38443008 | elapsed time per iteration (ms): 37716.3 | learning rate: 5.433E-05 | global batch size:  1024 | lm loss: 1.811082E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37543/   51900 | consumed samples:     38444032 | elapsed time per iteration (ms): 37739.1 | learning rate: 5.433E-05 | global batch size:  1024 | lm loss: 1.804611E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37544/   51900 | consumed samples:     38445056 | elapsed time per iteration (ms): 37574.0 | learning rate: 5.432E-05 | global batch size:  1024 | lm loss: 1.789508E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37545/   51900 | consumed samples:     38446080 | elapsed time per iteration (ms): 37577.4 | learning rate: 5.432E-05 | global batch size:  1024 | lm loss: 1.796181E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37546/   51900 | consumed samples:     38447104 | elapsed time per iteration (ms): 37633.5 | learning rate: 5.432E-05 | global batch size:  1024 | lm loss: 1.810864E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37547/   51900 | consumed samples:     38448128 | elapsed time per iteration (ms): 37655.9 | learning rate: 5.431E-05 | global batch size:  1024 | lm loss: 1.811947E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37548/   51900 | consumed samples:     38449152 | elapsed time per iteration (ms): 37638.9 | learning rate: 5.431E-05 | global batch size:  1024 | lm loss: 1.802356E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37549/   51900 | consumed samples:     38450176 | elapsed time per iteration (ms): 37573.4 | learning rate: 5.430E-05 | global batch size:  1024 | lm loss: 1.797346E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37550/   51900 | consumed samples:     38451200 | elapsed time per iteration (ms): 37551.6 | learning rate: 5.430E-05 | global batch size:  1024 | lm loss: 1.799652E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37551/   51900 | consumed samples:     38452224 | elapsed time per iteration (ms): 37590.0 | learning rate: 5.429E-05 | global batch size:  1024 | lm loss: 1.809957E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37552/   51900 | consumed samples:     38453248 | elapsed time per iteration (ms): 37691.6 | learning rate: 5.429E-05 | global batch size:  1024 | lm loss: 1.810018E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37553/   51900 | consumed samples:     38454272 | elapsed time per iteration (ms): 37657.6 | learning rate: 5.428E-05 | global batch size:  1024 | lm loss: 1.812117E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37554/   51900 | consumed samples:     38455296 | elapsed time per iteration (ms): 37701.1 | learning rate: 5.428E-05 | global batch size:  1024 | lm loss: 1.787918E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37555/   51900 | consumed samples:     38456320 | elapsed time per iteration (ms): 37637.6 | learning rate: 5.428E-05 | global batch size:  1024 | lm loss: 1.796842E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37556/   51900 | consumed samples:     38457344 | elapsed time per iteration (ms): 37642.3 | learning rate: 5.427E-05 | global batch size:  1024 | lm loss: 1.811120E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37557/   51900 | consumed samples:     38458368 | elapsed time per iteration (ms): 37672.5 | learning rate: 5.427E-05 | global batch size:  1024 | lm loss: 1.804798E+00 | loss scale: 1.0 | grad norm: 0.065 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37558/   51900 | consumed samples:     38459392 | elapsed time per iteration (ms): 37754.4 | learning rate: 5.426E-05 | global batch size:  1024 | lm loss: 1.794806E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37559/   51900 | consumed samples:     38460416 | elapsed time per iteration (ms): 37677.2 | learning rate: 5.426E-05 | global batch size:  1024 | lm loss: 1.788378E+00 | loss scale: 1.0 | grad norm: 0.065 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37560/   51900 | consumed samples:     38461440 | elapsed time per iteration (ms): 37726.4 | learning rate: 5.425E-05 | global batch size:  1024 | lm loss: 1.812373E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37561/   51900 | consumed samples:     38462464 | elapsed time per iteration (ms): 37683.9 | learning rate: 5.425E-05 | global batch size:  1024 | lm loss: 1.797564E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37562/   51900 | consumed samples:     38463488 | elapsed time per iteration (ms): 37577.3 | learning rate: 5.424E-05 | global batch size:  1024 | lm loss: 1.809159E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37563/   51900 | consumed samples:     38464512 | elapsed time per iteration (ms): 37716.6 | learning rate: 5.424E-05 | global batch size:  1024 | lm loss: 1.809747E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37564/   51900 | consumed samples:     38465536 | elapsed time per iteration (ms): 37639.2 | learning rate: 5.424E-05 | global batch size:  1024 | lm loss: 1.792471E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37565/   51900 | consumed samples:     38466560 | elapsed time per iteration (ms): 37635.5 | learning rate: 5.423E-05 | global batch size:  1024 | lm loss: 1.819147E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37566/   51900 | consumed samples:     38467584 | elapsed time per iteration (ms): 37725.7 | learning rate: 5.423E-05 | global batch size:  1024 | lm loss: 1.793561E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37567/   51900 | consumed samples:     38468608 | elapsed time per iteration (ms): 37688.5 | learning rate: 5.422E-05 | global batch size:  1024 | lm loss: 1.804810E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37568/   51900 | consumed samples:     38469632 | elapsed time per iteration (ms): 37598.0 | learning rate: 5.422E-05 | global batch size:  1024 | lm loss: 1.813505E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37569/   51900 | consumed samples:     38470656 | elapsed time per iteration (ms): 37576.5 | learning rate: 5.421E-05 | global batch size:  1024 | lm loss: 1.817627E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37570/   51900 | consumed samples:     38471680 | elapsed time per iteration (ms): 37617.9 | learning rate: 5.421E-05 | global batch size:  1024 | lm loss: 1.808670E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37571/   51900 | consumed samples:     38472704 | elapsed time per iteration (ms): 37666.5 | learning rate: 5.420E-05 | global batch size:  1024 | lm loss: 1.803129E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37572/   51900 | consumed samples:     38473728 | elapsed time per iteration (ms): 37603.1 | learning rate: 5.420E-05 | global batch size:  1024 | lm loss: 1.805616E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37573/   51900 | consumed samples:     38474752 | elapsed time per iteration (ms): 37700.2 | learning rate: 5.420E-05 | global batch size:  1024 | lm loss: 1.784279E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37574/   51900 | consumed samples:     38475776 | elapsed time per iteration (ms): 37769.7 | learning rate: 5.419E-05 | global batch size:  1024 | lm loss: 1.809774E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37575/   51900 | consumed samples:     38476800 | elapsed time per iteration (ms): 37788.5 | learning rate: 5.419E-05 | global batch size:  1024 | lm loss: 1.809993E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37576/   51900 | consumed samples:     38477824 | elapsed time per iteration (ms): 37680.9 | learning rate: 5.418E-05 | global batch size:  1024 | lm loss: 1.801365E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37577/   51900 | consumed samples:     38478848 | elapsed time per iteration (ms): 37705.3 | learning rate: 5.418E-05 | global batch size:  1024 | lm loss: 1.797915E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37578/   51900 | consumed samples:     38479872 | elapsed time per iteration (ms): 37526.7 | learning rate: 5.417E-05 | global batch size:  1024 | lm loss: 1.812230E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37579/   51900 | consumed samples:     38480896 | elapsed time per iteration (ms): 37584.6 | learning rate: 5.417E-05 | global batch size:  1024 | lm loss: 1.810017E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37580/   51900 | consumed samples:     38481920 | elapsed time per iteration (ms): 37618.0 | learning rate: 5.416E-05 | global batch size:  1024 | lm loss: 1.805517E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37581/   51900 | consumed samples:     38482944 | elapsed time per iteration (ms): 37681.5 | learning rate: 5.416E-05 | global batch size:  1024 | lm loss: 1.792534E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37582/   51900 | consumed samples:     38483968 | elapsed time per iteration (ms): 37761.0 | learning rate: 5.416E-05 | global batch size:  1024 | lm loss: 1.808022E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37583/   51900 | consumed samples:     38484992 | elapsed time per iteration (ms): 37700.6 | learning rate: 5.415E-05 | global batch size:  1024 | lm loss: 1.794326E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37584/   51900 | consumed samples:     38486016 | elapsed time per iteration (ms): 37757.1 | learning rate: 5.415E-05 | global batch size:  1024 | lm loss: 1.820146E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37585/   51900 | consumed samples:     38487040 | elapsed time per iteration (ms): 37604.1 | learning rate: 5.414E-05 | global batch size:  1024 | lm loss: 1.810483E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37586/   51900 | consumed samples:     38488064 | elapsed time per iteration (ms): 37661.5 | learning rate: 5.414E-05 | global batch size:  1024 | lm loss: 1.819224E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37587/   51900 | consumed samples:     38489088 | elapsed time per iteration (ms): 37687.6 | learning rate: 5.413E-05 | global batch size:  1024 | lm loss: 1.794075E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37588/   51900 | consumed samples:     38490112 | elapsed time per iteration (ms): 37626.8 | learning rate: 5.413E-05 | global batch size:  1024 | lm loss: 1.810467E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37589/   51900 | consumed samples:     38491136 | elapsed time per iteration (ms): 37626.7 | learning rate: 5.412E-05 | global batch size:  1024 | lm loss: 1.807517E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37590/   51900 | consumed samples:     38492160 | elapsed time per iteration (ms): 37597.9 | learning rate: 5.412E-05 | global batch size:  1024 | lm loss: 1.805592E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37591/   51900 | consumed samples:     38493184 | elapsed time per iteration (ms): 37740.9 | learning rate: 5.412E-05 | global batch size:  1024 | lm loss: 1.794026E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37592/   51900 | consumed samples:     38494208 | elapsed time per iteration (ms): 37698.5 | learning rate: 5.411E-05 | global batch size:  1024 | lm loss: 1.798746E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37593/   51900 | consumed samples:     38495232 | elapsed time per iteration (ms): 37626.2 | learning rate: 5.411E-05 | global batch size:  1024 | lm loss: 1.803463E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37594/   51900 | consumed samples:     38496256 | elapsed time per iteration (ms): 37762.2 | learning rate: 5.410E-05 | global batch size:  1024 | lm loss: 1.791290E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37595/   51900 | consumed samples:     38497280 | elapsed time per iteration (ms): 37667.1 | learning rate: 5.410E-05 | global batch size:  1024 | lm loss: 1.790944E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37596/   51900 | consumed samples:     38498304 | elapsed time per iteration (ms): 37683.1 | learning rate: 5.409E-05 | global batch size:  1024 | lm loss: 1.823387E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37597/   51900 | consumed samples:     38499328 | elapsed time per iteration (ms): 37655.9 | learning rate: 5.409E-05 | global batch size:  1024 | lm loss: 1.811336E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37598/   51900 | consumed samples:     38500352 | elapsed time per iteration (ms): 37692.8 | learning rate: 5.408E-05 | global batch size:  1024 | lm loss: 1.804116E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37599/   51900 | consumed samples:     38501376 | elapsed time per iteration (ms): 37529.8 | learning rate: 5.408E-05 | global batch size:  1024 | lm loss: 1.801955E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37600/   51900 | consumed samples:     38502400 | elapsed time per iteration (ms): 37718.0 | learning rate: 5.408E-05 | global batch size:  1024 | lm loss: 1.826914E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37601/   51900 | consumed samples:     38503424 | elapsed time per iteration (ms): 37618.6 | learning rate: 5.407E-05 | global batch size:  1024 | lm loss: 1.781535E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37602/   51900 | consumed samples:     38504448 | elapsed time per iteration (ms): 37727.0 | learning rate: 5.407E-05 | global batch size:  1024 | lm loss: 1.801287E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37603/   51900 | consumed samples:     38505472 | elapsed time per iteration (ms): 37669.5 | learning rate: 5.406E-05 | global batch size:  1024 | lm loss: 1.805366E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37604/   51900 | consumed samples:     38506496 | elapsed time per iteration (ms): 37564.5 | learning rate: 5.406E-05 | global batch size:  1024 | lm loss: 1.802044E+00 | loss scale: 1.0 | grad norm: 0.065 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37605/   51900 | consumed samples:     38507520 | elapsed time per iteration (ms): 37728.5 | learning rate: 5.405E-05 | global batch size:  1024 | lm loss: 1.804394E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37606/   51900 | consumed samples:     38508544 | elapsed time per iteration (ms): 37658.5 | learning rate: 5.405E-05 | global batch size:  1024 | lm loss: 1.810932E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37607/   51900 | consumed samples:     38509568 | elapsed time per iteration (ms): 37672.4 | learning rate: 5.404E-05 | global batch size:  1024 | lm loss: 1.799377E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37608/   51900 | consumed samples:     38510592 | elapsed time per iteration (ms): 37640.4 | learning rate: 5.404E-05 | global batch size:  1024 | lm loss: 1.814640E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37609/   51900 | consumed samples:     38511616 | elapsed time per iteration (ms): 37632.8 | learning rate: 5.404E-05 | global batch size:  1024 | lm loss: 1.807203E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37610/   51900 | consumed samples:     38512640 | elapsed time per iteration (ms): 37701.7 | learning rate: 5.403E-05 | global batch size:  1024 | lm loss: 1.818741E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37611/   51900 | consumed samples:     38513664 | elapsed time per iteration (ms): 37602.7 | learning rate: 5.403E-05 | global batch size:  1024 | lm loss: 1.795074E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37612/   51900 | consumed samples:     38514688 | elapsed time per iteration (ms): 37532.5 | learning rate: 5.402E-05 | global batch size:  1024 | lm loss: 1.798672E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37613/   51900 | consumed samples:     38515712 | elapsed time per iteration (ms): 37665.1 | learning rate: 5.402E-05 | global batch size:  1024 | lm loss: 1.827212E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37614/   51900 | consumed samples:     38516736 | elapsed time per iteration (ms): 37748.2 | learning rate: 5.401E-05 | global batch size:  1024 | lm loss: 1.801625E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37615/   51900 | consumed samples:     38517760 | elapsed time per iteration (ms): 37617.1 | learning rate: 5.401E-05 | global batch size:  1024 | lm loss: 1.837267E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37616/   51900 | consumed samples:     38518784 | elapsed time per iteration (ms): 37562.7 | learning rate: 5.400E-05 | global batch size:  1024 | lm loss: 1.809341E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37617/   51900 | consumed samples:     38519808 | elapsed time per iteration (ms): 37517.8 | learning rate: 5.400E-05 | global batch size:  1024 | lm loss: 1.806614E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37618/   51900 | consumed samples:     38520832 | elapsed time per iteration (ms): 37697.3 | learning rate: 5.400E-05 | global batch size:  1024 | lm loss: 1.805629E+00 | loss scale: 1.0 | grad norm: 0.087 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37619/   51900 | consumed samples:     38521856 | elapsed time per iteration (ms): 37638.9 | learning rate: 5.399E-05 | global batch size:  1024 | lm loss: 1.818164E+00 | loss scale: 1.0 | grad norm: 0.094 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37620/   51900 | consumed samples:     38522880 | elapsed time per iteration (ms): 37656.8 | learning rate: 5.399E-05 | global batch size:  1024 | lm loss: 1.827068E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37621/   51900 | consumed samples:     38523904 | elapsed time per iteration (ms): 37725.1 | learning rate: 5.398E-05 | global batch size:  1024 | lm loss: 1.807145E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37622/   51900 | consumed samples:     38524928 | elapsed time per iteration (ms): 37636.5 | learning rate: 5.398E-05 | global batch size:  1024 | lm loss: 1.818889E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37623/   51900 | consumed samples:     38525952 | elapsed time per iteration (ms): 37591.1 | learning rate: 5.397E-05 | global batch size:  1024 | lm loss: 1.800076E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37624/   51900 | consumed samples:     38526976 | elapsed time per iteration (ms): 37783.7 | learning rate: 5.397E-05 | global batch size:  1024 | lm loss: 1.810858E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37625/   51900 | consumed samples:     38528000 | elapsed time per iteration (ms): 37720.7 | learning rate: 5.397E-05 | global batch size:  1024 | lm loss: 1.818270E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37626/   51900 | consumed samples:     38529024 | elapsed time per iteration (ms): 37710.2 | learning rate: 5.396E-05 | global batch size:  1024 | lm loss: 1.809813E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37627/   51900 | consumed samples:     38530048 | elapsed time per iteration (ms): 37763.8 | learning rate: 5.396E-05 | global batch size:  1024 | lm loss: 1.799906E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37628/   51900 | consumed samples:     38531072 | elapsed time per iteration (ms): 37696.3 | learning rate: 5.395E-05 | global batch size:  1024 | lm loss: 1.822512E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37629/   51900 | consumed samples:     38532096 | elapsed time per iteration (ms): 37490.9 | learning rate: 5.395E-05 | global batch size:  1024 | lm loss: 1.802343E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37630/   51900 | consumed samples:     38533120 | elapsed time per iteration (ms): 37724.9 | learning rate: 5.394E-05 | global batch size:  1024 | lm loss: 1.813376E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37631/   51900 | consumed samples:     38534144 | elapsed time per iteration (ms): 37726.4 | learning rate: 5.394E-05 | global batch size:  1024 | lm loss: 1.808163E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37632/   51900 | consumed samples:     38535168 | elapsed time per iteration (ms): 37725.9 | learning rate: 5.393E-05 | global batch size:  1024 | lm loss: 1.809595E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37633/   51900 | consumed samples:     38536192 | elapsed time per iteration (ms): 37598.5 | learning rate: 5.393E-05 | global batch size:  1024 | lm loss: 1.806540E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37634/   51900 | consumed samples:     38537216 | elapsed time per iteration (ms): 37790.1 | learning rate: 5.393E-05 | global batch size:  1024 | lm loss: 1.817078E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37635/   51900 | consumed samples:     38538240 | elapsed time per iteration (ms): 37597.1 | learning rate: 5.392E-05 | global batch size:  1024 | lm loss: 1.814698E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37636/   51900 | consumed samples:     38539264 | elapsed time per iteration (ms): 37700.5 | learning rate: 5.392E-05 | global batch size:  1024 | lm loss: 1.787984E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37637/   51900 | consumed samples:     38540288 | elapsed time per iteration (ms): 37760.2 | learning rate: 5.391E-05 | global batch size:  1024 | lm loss: 1.800337E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37638/   51900 | consumed samples:     38541312 | elapsed time per iteration (ms): 37631.6 | learning rate: 5.391E-05 | global batch size:  1024 | lm loss: 1.815181E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37639/   51900 | consumed samples:     38542336 | elapsed time per iteration (ms): 37616.0 | learning rate: 5.390E-05 | global batch size:  1024 | lm loss: 1.817415E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37640/   51900 | consumed samples:     38543360 | elapsed time per iteration (ms): 37600.5 | learning rate: 5.390E-05 | global batch size:  1024 | lm loss: 1.804999E+00 | loss scale: 1.0 | grad norm: 0.116 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37641/   51900 | consumed samples:     38544384 | elapsed time per iteration (ms): 37679.8 | learning rate: 5.389E-05 | global batch size:  1024 | lm loss: 1.816744E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37642/   51900 | consumed samples:     38545408 | elapsed time per iteration (ms): 37680.7 | learning rate: 5.389E-05 | global batch size:  1024 | lm loss: 1.796067E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37643/   51900 | consumed samples:     38546432 | elapsed time per iteration (ms): 37685.6 | learning rate: 5.389E-05 | global batch size:  1024 | lm loss: 1.814467E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37644/   51900 | consumed samples:     38547456 | elapsed time per iteration (ms): 37631.1 | learning rate: 5.388E-05 | global batch size:  1024 | lm loss: 1.791513E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37645/   51900 | consumed samples:     38548480 | elapsed time per iteration (ms): 37711.6 | learning rate: 5.388E-05 | global batch size:  1024 | lm loss: 1.806277E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37646/   51900 | consumed samples:     38549504 | elapsed time per iteration (ms): 37739.5 | learning rate: 5.387E-05 | global batch size:  1024 | lm loss: 1.791441E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37647/   51900 | consumed samples:     38550528 | elapsed time per iteration (ms): 37610.6 | learning rate: 5.387E-05 | global batch size:  1024 | lm loss: 1.794259E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37648/   51900 | consumed samples:     38551552 | elapsed time per iteration (ms): 37691.6 | learning rate: 5.386E-05 | global batch size:  1024 | lm loss: 1.793667E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37649/   51900 | consumed samples:     38552576 | elapsed time per iteration (ms): 37680.3 | learning rate: 5.386E-05 | global batch size:  1024 | lm loss: 1.823922E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37650/   51900 | consumed samples:     38553600 | elapsed time per iteration (ms): 37786.5 | learning rate: 5.385E-05 | global batch size:  1024 | lm loss: 1.792784E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37651/   51900 | consumed samples:     38554624 | elapsed time per iteration (ms): 37719.3 | learning rate: 5.385E-05 | global batch size:  1024 | lm loss: 1.816997E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37652/   51900 | consumed samples:     38555648 | elapsed time per iteration (ms): 37711.6 | learning rate: 5.385E-05 | global batch size:  1024 | lm loss: 1.790475E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37653/   51900 | consumed samples:     38556672 | elapsed time per iteration (ms): 37623.7 | learning rate: 5.384E-05 | global batch size:  1024 | lm loss: 1.809961E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37654/   51900 | consumed samples:     38557696 | elapsed time per iteration (ms): 37576.8 | learning rate: 5.384E-05 | global batch size:  1024 | lm loss: 1.800488E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37655/   51900 | consumed samples:     38558720 | elapsed time per iteration (ms): 37638.4 | learning rate: 5.383E-05 | global batch size:  1024 | lm loss: 1.797370E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37656/   51900 | consumed samples:     38559744 | elapsed time per iteration (ms): 37632.7 | learning rate: 5.383E-05 | global batch size:  1024 | lm loss: 1.799595E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37657/   51900 | consumed samples:     38560768 | elapsed time per iteration (ms): 37630.8 | learning rate: 5.382E-05 | global batch size:  1024 | lm loss: 1.806899E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37658/   51900 | consumed samples:     38561792 | elapsed time per iteration (ms): 37742.3 | learning rate: 5.382E-05 | global batch size:  1024 | lm loss: 1.809186E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37659/   51900 | consumed samples:     38562816 | elapsed time per iteration (ms): 37697.5 | learning rate: 5.381E-05 | global batch size:  1024 | lm loss: 1.792228E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37660/   51900 | consumed samples:     38563840 | elapsed time per iteration (ms): 37619.7 | learning rate: 5.381E-05 | global batch size:  1024 | lm loss: 1.794845E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37661/   51900 | consumed samples:     38564864 | elapsed time per iteration (ms): 37669.8 | learning rate: 5.381E-05 | global batch size:  1024 | lm loss: 1.814568E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37662/   51900 | consumed samples:     38565888 | elapsed time per iteration (ms): 37676.9 | learning rate: 5.380E-05 | global batch size:  1024 | lm loss: 1.790331E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37663/   51900 | consumed samples:     38566912 | elapsed time per iteration (ms): 37711.6 | learning rate: 5.380E-05 | global batch size:  1024 | lm loss: 1.814709E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37664/   51900 | consumed samples:     38567936 | elapsed time per iteration (ms): 37602.4 | learning rate: 5.379E-05 | global batch size:  1024 | lm loss: 1.788552E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37665/   51900 | consumed samples:     38568960 | elapsed time per iteration (ms): 37635.2 | learning rate: 5.379E-05 | global batch size:  1024 | lm loss: 1.807197E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37666/   51900 | consumed samples:     38569984 | elapsed time per iteration (ms): 37647.9 | learning rate: 5.378E-05 | global batch size:  1024 | lm loss: 1.812713E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37667/   51900 | consumed samples:     38571008 | elapsed time per iteration (ms): 37716.9 | learning rate: 5.378E-05 | global batch size:  1024 | lm loss: 1.811887E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37668/   51900 | consumed samples:     38572032 | elapsed time per iteration (ms): 37736.4 | learning rate: 5.377E-05 | global batch size:  1024 | lm loss: 1.817155E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37669/   51900 | consumed samples:     38573056 | elapsed time per iteration (ms): 37692.5 | learning rate: 5.377E-05 | global batch size:  1024 | lm loss: 1.806715E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37670/   51900 | consumed samples:     38574080 | elapsed time per iteration (ms): 37601.5 | learning rate: 5.377E-05 | global batch size:  1024 | lm loss: 1.809436E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37671/   51900 | consumed samples:     38575104 | elapsed time per iteration (ms): 37674.6 | learning rate: 5.376E-05 | global batch size:  1024 | lm loss: 1.813368E+00 | loss scale: 1.0 | grad norm: 0.065 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37672/   51900 | consumed samples:     38576128 | elapsed time per iteration (ms): 37660.9 | learning rate: 5.376E-05 | global batch size:  1024 | lm loss: 1.811169E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37673/   51900 | consumed samples:     38577152 | elapsed time per iteration (ms): 37710.1 | learning rate: 5.375E-05 | global batch size:  1024 | lm loss: 1.796563E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37674/   51900 | consumed samples:     38578176 | elapsed time per iteration (ms): 37625.2 | learning rate: 5.375E-05 | global batch size:  1024 | lm loss: 1.816571E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37675/   51900 | consumed samples:     38579200 | elapsed time per iteration (ms): 37757.4 | learning rate: 5.374E-05 | global batch size:  1024 | lm loss: 1.799823E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37676/   51900 | consumed samples:     38580224 | elapsed time per iteration (ms): 37686.3 | learning rate: 5.374E-05 | global batch size:  1024 | lm loss: 1.796166E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37677/   51900 | consumed samples:     38581248 | elapsed time per iteration (ms): 37584.3 | learning rate: 5.373E-05 | global batch size:  1024 | lm loss: 1.784871E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37678/   51900 | consumed samples:     38582272 | elapsed time per iteration (ms): 37735.1 | learning rate: 5.373E-05 | global batch size:  1024 | lm loss: 1.801072E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37679/   51900 | consumed samples:     38583296 | elapsed time per iteration (ms): 37753.9 | learning rate: 5.373E-05 | global batch size:  1024 | lm loss: 1.822871E+00 | loss scale: 1.0 | grad norm: 0.065 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37680/   51900 | consumed samples:     38584320 | elapsed time per iteration (ms): 37523.3 | learning rate: 5.372E-05 | global batch size:  1024 | lm loss: 1.808021E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37681/   51900 | consumed samples:     38585344 | elapsed time per iteration (ms): 37657.5 | learning rate: 5.372E-05 | global batch size:  1024 | lm loss: 1.813500E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37682/   51900 | consumed samples:     38586368 | elapsed time per iteration (ms): 37695.8 | learning rate: 5.371E-05 | global batch size:  1024 | lm loss: 1.799187E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37683/   51900 | consumed samples:     38587392 | elapsed time per iteration (ms): 37682.9 | learning rate: 5.371E-05 | global batch size:  1024 | lm loss: 1.793504E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37684/   51900 | consumed samples:     38588416 | elapsed time per iteration (ms): 37747.0 | learning rate: 5.370E-05 | global batch size:  1024 | lm loss: 1.808167E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37685/   51900 | consumed samples:     38589440 | elapsed time per iteration (ms): 37668.8 | learning rate: 5.370E-05 | global batch size:  1024 | lm loss: 1.820232E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37686/   51900 | consumed samples:     38590464 | elapsed time per iteration (ms): 37711.7 | learning rate: 5.370E-05 | global batch size:  1024 | lm loss: 1.807659E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37687/   51900 | consumed samples:     38591488 | elapsed time per iteration (ms): 37586.5 | learning rate: 5.369E-05 | global batch size:  1024 | lm loss: 1.812670E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37688/   51900 | consumed samples:     38592512 | elapsed time per iteration (ms): 37725.2 | learning rate: 5.369E-05 | global batch size:  1024 | lm loss: 1.818866E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37689/   51900 | consumed samples:     38593536 | elapsed time per iteration (ms): 37692.8 | learning rate: 5.368E-05 | global batch size:  1024 | lm loss: 1.803055E+00 | loss scale: 1.0 | grad norm: 0.064 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37690/   51900 | consumed samples:     38594560 | elapsed time per iteration (ms): 37738.6 | learning rate: 5.368E-05 | global batch size:  1024 | lm loss: 1.793933E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37691/   51900 | consumed samples:     38595584 | elapsed time per iteration (ms): 37673.0 | learning rate: 5.367E-05 | global batch size:  1024 | lm loss: 1.806243E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37692/   51900 | consumed samples:     38596608 | elapsed time per iteration (ms): 37761.5 | learning rate: 5.367E-05 | global batch size:  1024 | lm loss: 1.804108E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37693/   51900 | consumed samples:     38597632 | elapsed time per iteration (ms): 37605.2 | learning rate: 5.366E-05 | global batch size:  1024 | lm loss: 1.790724E+00 | loss scale: 1.0 | grad norm: 0.344 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37694/   51900 | consumed samples:     38598656 | elapsed time per iteration (ms): 37575.6 | learning rate: 5.366E-05 | global batch size:  1024 | lm loss: 1.797691E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37695/   51900 | consumed samples:     38599680 | elapsed time per iteration (ms): 37611.4 | learning rate: 5.366E-05 | global batch size:  1024 | lm loss: 1.796386E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37696/   51900 | consumed samples:     38600704 | elapsed time per iteration (ms): 37768.6 | learning rate: 5.365E-05 | global batch size:  1024 | lm loss: 1.815769E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37697/   51900 | consumed samples:     38601728 | elapsed time per iteration (ms): 37790.9 | learning rate: 5.365E-05 | global batch size:  1024 | lm loss: 1.818271E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37698/   51900 | consumed samples:     38602752 | elapsed time per iteration (ms): 37609.5 | learning rate: 5.364E-05 | global batch size:  1024 | lm loss: 1.805314E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37699/   51900 | consumed samples:     38603776 | elapsed time per iteration (ms): 37653.9 | learning rate: 5.364E-05 | global batch size:  1024 | lm loss: 1.817122E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37700/   51900 | consumed samples:     38604800 | elapsed time per iteration (ms): 37748.5 | learning rate: 5.363E-05 | global batch size:  1024 | lm loss: 1.819714E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37701/   51900 | consumed samples:     38605824 | elapsed time per iteration (ms): 37739.7 | learning rate: 5.363E-05 | global batch size:  1024 | lm loss: 1.807657E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37702/   51900 | consumed samples:     38606848 | elapsed time per iteration (ms): 37625.7 | learning rate: 5.362E-05 | global batch size:  1024 | lm loss: 1.806036E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37703/   51900 | consumed samples:     38607872 | elapsed time per iteration (ms): 37764.2 | learning rate: 5.362E-05 | global batch size:  1024 | lm loss: 1.792221E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37704/   51900 | consumed samples:     38608896 | elapsed time per iteration (ms): 37705.9 | learning rate: 5.362E-05 | global batch size:  1024 | lm loss: 1.817529E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37705/   51900 | consumed samples:     38609920 | elapsed time per iteration (ms): 37682.3 | learning rate: 5.361E-05 | global batch size:  1024 | lm loss: 1.809654E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37706/   51900 | consumed samples:     38610944 | elapsed time per iteration (ms): 37759.1 | learning rate: 5.361E-05 | global batch size:  1024 | lm loss: 1.805082E+00 | loss scale: 1.0 | grad norm: 0.155 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37707/   51900 | consumed samples:     38611968 | elapsed time per iteration (ms): 37683.7 | learning rate: 5.360E-05 | global batch size:  1024 | lm loss: 1.809665E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37708/   51900 | consumed samples:     38612992 | elapsed time per iteration (ms): 37754.8 | learning rate: 5.360E-05 | global batch size:  1024 | lm loss: 1.801081E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37709/   51900 | consumed samples:     38614016 | elapsed time per iteration (ms): 37638.3 | learning rate: 5.359E-05 | global batch size:  1024 | lm loss: 1.813139E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37710/   51900 | consumed samples:     38615040 | elapsed time per iteration (ms): 37637.7 | learning rate: 5.359E-05 | global batch size:  1024 | lm loss: 1.802392E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37711/   51900 | consumed samples:     38616064 | elapsed time per iteration (ms): 37666.1 | learning rate: 5.358E-05 | global batch size:  1024 | lm loss: 1.795622E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37712/   51900 | consumed samples:     38617088 | elapsed time per iteration (ms): 37639.8 | learning rate: 5.358E-05 | global batch size:  1024 | lm loss: 1.805081E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37713/   51900 | consumed samples:     38618112 | elapsed time per iteration (ms): 37737.5 | learning rate: 5.358E-05 | global batch size:  1024 | lm loss: 1.810932E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37714/   51900 | consumed samples:     38619136 | elapsed time per iteration (ms): 37708.7 | learning rate: 5.357E-05 | global batch size:  1024 | lm loss: 1.809179E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37715/   51900 | consumed samples:     38620160 | elapsed time per iteration (ms): 37569.1 | learning rate: 5.357E-05 | global batch size:  1024 | lm loss: 1.797750E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37716/   51900 | consumed samples:     38621184 | elapsed time per iteration (ms): 37657.4 | learning rate: 5.356E-05 | global batch size:  1024 | lm loss: 1.783507E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37717/   51900 | consumed samples:     38622208 | elapsed time per iteration (ms): 37580.7 | learning rate: 5.356E-05 | global batch size:  1024 | lm loss: 1.796903E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37718/   51900 | consumed samples:     38623232 | elapsed time per iteration (ms): 37638.3 | learning rate: 5.355E-05 | global batch size:  1024 | lm loss: 1.802578E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37719/   51900 | consumed samples:     38624256 | elapsed time per iteration (ms): 37684.9 | learning rate: 5.355E-05 | global batch size:  1024 | lm loss: 1.813653E+00 | loss scale: 1.0 | grad norm: 0.065 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37720/   51900 | consumed samples:     38625280 | elapsed time per iteration (ms): 37728.7 | learning rate: 5.354E-05 | global batch size:  1024 | lm loss: 1.806670E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37721/   51900 | consumed samples:     38626304 | elapsed time per iteration (ms): 37598.8 | learning rate: 5.354E-05 | global batch size:  1024 | lm loss: 1.801183E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37722/   51900 | consumed samples:     38627328 | elapsed time per iteration (ms): 37609.2 | learning rate: 5.354E-05 | global batch size:  1024 | lm loss: 1.790812E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37723/   51900 | consumed samples:     38628352 | elapsed time per iteration (ms): 37646.0 | learning rate: 5.353E-05 | global batch size:  1024 | lm loss: 1.784821E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37724/   51900 | consumed samples:     38629376 | elapsed time per iteration (ms): 37661.0 | learning rate: 5.353E-05 | global batch size:  1024 | lm loss: 1.811735E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37725/   51900 | consumed samples:     38630400 | elapsed time per iteration (ms): 37572.4 | learning rate: 5.352E-05 | global batch size:  1024 | lm loss: 1.810025E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37726/   51900 | consumed samples:     38631424 | elapsed time per iteration (ms): 37748.3 | learning rate: 5.352E-05 | global batch size:  1024 | lm loss: 1.795422E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37727/   51900 | consumed samples:     38632448 | elapsed time per iteration (ms): 37637.9 | learning rate: 5.351E-05 | global batch size:  1024 | lm loss: 1.805725E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37728/   51900 | consumed samples:     38633472 | elapsed time per iteration (ms): 37589.9 | learning rate: 5.351E-05 | global batch size:  1024 | lm loss: 1.793272E+00 | loss scale: 1.0 | grad norm: 0.064 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37729/   51900 | consumed samples:     38634496 | elapsed time per iteration (ms): 37627.6 | learning rate: 5.351E-05 | global batch size:  1024 | lm loss: 1.797296E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37730/   51900 | consumed samples:     38635520 | elapsed time per iteration (ms): 37645.1 | learning rate: 5.350E-05 | global batch size:  1024 | lm loss: 1.813889E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37731/   51900 | consumed samples:     38636544 | elapsed time per iteration (ms): 37698.7 | learning rate: 5.350E-05 | global batch size:  1024 | lm loss: 1.803435E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37732/   51900 | consumed samples:     38637568 | elapsed time per iteration (ms): 37691.7 | learning rate: 5.349E-05 | global batch size:  1024 | lm loss: 1.795518E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37733/   51900 | consumed samples:     38638592 | elapsed time per iteration (ms): 37745.6 | learning rate: 5.349E-05 | global batch size:  1024 | lm loss: 1.792091E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37734/   51900 | consumed samples:     38639616 | elapsed time per iteration (ms): 37605.4 | learning rate: 5.348E-05 | global batch size:  1024 | lm loss: 1.814881E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37735/   51900 | consumed samples:     38640640 | elapsed time per iteration (ms): 37616.5 | learning rate: 5.348E-05 | global batch size:  1024 | lm loss: 1.813982E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37736/   51900 | consumed samples:     38641664 | elapsed time per iteration (ms): 37568.4 | learning rate: 5.347E-05 | global batch size:  1024 | lm loss: 1.799098E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37737/   51900 | consumed samples:     38642688 | elapsed time per iteration (ms): 37611.2 | learning rate: 5.347E-05 | global batch size:  1024 | lm loss: 1.804582E+00 | loss scale: 1.0 | grad norm: 0.065 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37738/   51900 | consumed samples:     38643712 | elapsed time per iteration (ms): 37745.7 | learning rate: 5.347E-05 | global batch size:  1024 | lm loss: 1.808948E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37739/   51900 | consumed samples:     38644736 | elapsed time per iteration (ms): 37765.4 | learning rate: 5.346E-05 | global batch size:  1024 | lm loss: 1.795417E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37740/   51900 | consumed samples:     38645760 | elapsed time per iteration (ms): 37638.2 | learning rate: 5.346E-05 | global batch size:  1024 | lm loss: 1.807355E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37741/   51900 | consumed samples:     38646784 | elapsed time per iteration (ms): 37789.2 | learning rate: 5.345E-05 | global batch size:  1024 | lm loss: 1.806389E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37742/   51900 | consumed samples:     38647808 | elapsed time per iteration (ms): 37836.4 | learning rate: 5.345E-05 | global batch size:  1024 | lm loss: 1.819476E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37743/   51900 | consumed samples:     38648832 | elapsed time per iteration (ms): 37609.3 | learning rate: 5.344E-05 | global batch size:  1024 | lm loss: 1.794925E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37744/   51900 | consumed samples:     38649856 | elapsed time per iteration (ms): 37627.4 | learning rate: 5.344E-05 | global batch size:  1024 | lm loss: 1.806847E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37745/   51900 | consumed samples:     38650880 | elapsed time per iteration (ms): 37674.4 | learning rate: 5.343E-05 | global batch size:  1024 | lm loss: 1.793574E+00 | loss scale: 1.0 | grad norm: 0.063 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37746/   51900 | consumed samples:     38651904 | elapsed time per iteration (ms): 37646.3 | learning rate: 5.343E-05 | global batch size:  1024 | lm loss: 1.799408E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37747/   51900 | consumed samples:     38652928 | elapsed time per iteration (ms): 37783.4 | learning rate: 5.343E-05 | global batch size:  1024 | lm loss: 1.801821E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37748/   51900 | consumed samples:     38653952 | elapsed time per iteration (ms): 37593.0 | learning rate: 5.342E-05 | global batch size:  1024 | lm loss: 1.808585E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37749/   51900 | consumed samples:     38654976 | elapsed time per iteration (ms): 37674.3 | learning rate: 5.342E-05 | global batch size:  1024 | lm loss: 1.803600E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37750/   51900 | consumed samples:     38656000 | elapsed time per iteration (ms): 37639.5 | learning rate: 5.341E-05 | global batch size:  1024 | lm loss: 1.815101E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37751/   51900 | consumed samples:     38657024 | elapsed time per iteration (ms): 37782.4 | learning rate: 5.341E-05 | global batch size:  1024 | lm loss: 1.801488E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37752/   51900 | consumed samples:     38658048 | elapsed time per iteration (ms): 37719.1 | learning rate: 5.340E-05 | global batch size:  1024 | lm loss: 1.806371E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37753/   51900 | consumed samples:     38659072 | elapsed time per iteration (ms): 37655.2 | learning rate: 5.340E-05 | global batch size:  1024 | lm loss: 1.789132E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37754/   51900 | consumed samples:     38660096 | elapsed time per iteration (ms): 37637.0 | learning rate: 5.339E-05 | global batch size:  1024 | lm loss: 1.803077E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37755/   51900 | consumed samples:     38661120 | elapsed time per iteration (ms): 37644.0 | learning rate: 5.339E-05 | global batch size:  1024 | lm loss: 1.810156E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37756/   51900 | consumed samples:     38662144 | elapsed time per iteration (ms): 37599.6 | learning rate: 5.339E-05 | global batch size:  1024 | lm loss: 1.825716E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37757/   51900 | consumed samples:     38663168 | elapsed time per iteration (ms): 37795.1 | learning rate: 5.338E-05 | global batch size:  1024 | lm loss: 1.793259E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37758/   51900 | consumed samples:     38664192 | elapsed time per iteration (ms): 37554.3 | learning rate: 5.338E-05 | global batch size:  1024 | lm loss: 1.798803E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37759/   51900 | consumed samples:     38665216 | elapsed time per iteration (ms): 37508.7 | learning rate: 5.337E-05 | global batch size:  1024 | lm loss: 1.794991E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37760/   51900 | consumed samples:     38666240 | elapsed time per iteration (ms): 37862.8 | learning rate: 5.337E-05 | global batch size:  1024 | lm loss: 1.776562E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37761/   51900 | consumed samples:     38667264 | elapsed time per iteration (ms): 37668.6 | learning rate: 5.336E-05 | global batch size:  1024 | lm loss: 1.807486E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37762/   51900 | consumed samples:     38668288 | elapsed time per iteration (ms): 37659.8 | learning rate: 5.336E-05 | global batch size:  1024 | lm loss: 1.803962E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37763/   51900 | consumed samples:     38669312 | elapsed time per iteration (ms): 37580.5 | learning rate: 5.336E-05 | global batch size:  1024 | lm loss: 1.783899E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37764/   51900 | consumed samples:     38670336 | elapsed time per iteration (ms): 37635.3 | learning rate: 5.335E-05 | global batch size:  1024 | lm loss: 1.785809E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37765/   51900 | consumed samples:     38671360 | elapsed time per iteration (ms): 37604.5 | learning rate: 5.335E-05 | global batch size:  1024 | lm loss: 1.801104E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37766/   51900 | consumed samples:     38672384 | elapsed time per iteration (ms): 37716.2 | learning rate: 5.334E-05 | global batch size:  1024 | lm loss: 1.805697E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37767/   51900 | consumed samples:     38673408 | elapsed time per iteration (ms): 37659.4 | learning rate: 5.334E-05 | global batch size:  1024 | lm loss: 1.815766E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37768/   51900 | consumed samples:     38674432 | elapsed time per iteration (ms): 37654.7 | learning rate: 5.333E-05 | global batch size:  1024 | lm loss: 1.810484E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37769/   51900 | consumed samples:     38675456 | elapsed time per iteration (ms): 37666.7 | learning rate: 5.333E-05 | global batch size:  1024 | lm loss: 1.808389E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37770/   51900 | consumed samples:     38676480 | elapsed time per iteration (ms): 37640.0 | learning rate: 5.332E-05 | global batch size:  1024 | lm loss: 1.793466E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37771/   51900 | consumed samples:     38677504 | elapsed time per iteration (ms): 37587.4 | learning rate: 5.332E-05 | global batch size:  1024 | lm loss: 1.803036E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37772/   51900 | consumed samples:     38678528 | elapsed time per iteration (ms): 37712.4 | learning rate: 5.332E-05 | global batch size:  1024 | lm loss: 1.805545E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37773/   51900 | consumed samples:     38679552 | elapsed time per iteration (ms): 37662.8 | learning rate: 5.331E-05 | global batch size:  1024 | lm loss: 1.825546E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37774/   51900 | consumed samples:     38680576 | elapsed time per iteration (ms): 37553.8 | learning rate: 5.331E-05 | global batch size:  1024 | lm loss: 1.802698E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37775/   51900 | consumed samples:     38681600 | elapsed time per iteration (ms): 37603.1 | learning rate: 5.330E-05 | global batch size:  1024 | lm loss: 1.809064E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37776/   51900 | consumed samples:     38682624 | elapsed time per iteration (ms): 37618.8 | learning rate: 5.330E-05 | global batch size:  1024 | lm loss: 1.795062E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37777/   51900 | consumed samples:     38683648 | elapsed time per iteration (ms): 37678.7 | learning rate: 5.329E-05 | global batch size:  1024 | lm loss: 1.806598E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37778/   51900 | consumed samples:     38684672 | elapsed time per iteration (ms): 37666.8 | learning rate: 5.329E-05 | global batch size:  1024 | lm loss: 1.799961E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37779/   51900 | consumed samples:     38685696 | elapsed time per iteration (ms): 37621.3 | learning rate: 5.328E-05 | global batch size:  1024 | lm loss: 1.805861E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37780/   51900 | consumed samples:     38686720 | elapsed time per iteration (ms): 37707.0 | learning rate: 5.328E-05 | global batch size:  1024 | lm loss: 1.793240E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37781/   51900 | consumed samples:     38687744 | elapsed time per iteration (ms): 37647.1 | learning rate: 5.328E-05 | global batch size:  1024 | lm loss: 1.814418E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37782/   51900 | consumed samples:     38688768 | elapsed time per iteration (ms): 37716.8 | learning rate: 5.327E-05 | global batch size:  1024 | lm loss: 1.801238E+00 | loss scale: 1.0 | grad norm: 0.065 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37783/   51900 | consumed samples:     38689792 | elapsed time per iteration (ms): 37654.2 | learning rate: 5.327E-05 | global batch size:  1024 | lm loss: 1.798053E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37784/   51900 | consumed samples:     38690816 | elapsed time per iteration (ms): 37597.5 | learning rate: 5.326E-05 | global batch size:  1024 | lm loss: 1.807058E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37785/   51900 | consumed samples:     38691840 | elapsed time per iteration (ms): 37709.3 | learning rate: 5.326E-05 | global batch size:  1024 | lm loss: 1.803113E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37786/   51900 | consumed samples:     38692864 | elapsed time per iteration (ms): 37617.7 | learning rate: 5.325E-05 | global batch size:  1024 | lm loss: 1.818051E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37787/   51900 | consumed samples:     38693888 | elapsed time per iteration (ms): 37612.6 | learning rate: 5.325E-05 | global batch size:  1024 | lm loss: 1.821282E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37788/   51900 | consumed samples:     38694912 | elapsed time per iteration (ms): 37636.0 | learning rate: 5.325E-05 | global batch size:  1024 | lm loss: 1.821687E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37789/   51900 | consumed samples:     38695936 | elapsed time per iteration (ms): 37628.3 | learning rate: 5.324E-05 | global batch size:  1024 | lm loss: 1.805042E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37790/   51900 | consumed samples:     38696960 | elapsed time per iteration (ms): 37702.1 | learning rate: 5.324E-05 | global batch size:  1024 | lm loss: 1.796966E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37791/   51900 | consumed samples:     38697984 | elapsed time per iteration (ms): 37634.1 | learning rate: 5.323E-05 | global batch size:  1024 | lm loss: 1.822325E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37792/   51900 | consumed samples:     38699008 | elapsed time per iteration (ms): 37582.6 | learning rate: 5.323E-05 | global batch size:  1024 | lm loss: 1.815634E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37793/   51900 | consumed samples:     38700032 | elapsed time per iteration (ms): 37730.4 | learning rate: 5.322E-05 | global batch size:  1024 | lm loss: 1.798292E+00 | loss scale: 1.0 | grad norm: 0.099 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37794/   51900 | consumed samples:     38701056 | elapsed time per iteration (ms): 37671.3 | learning rate: 5.322E-05 | global batch size:  1024 | lm loss: 1.808491E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37795/   51900 | consumed samples:     38702080 | elapsed time per iteration (ms): 37630.5 | learning rate: 5.321E-05 | global batch size:  1024 | lm loss: 1.813747E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37796/   51900 | consumed samples:     38703104 | elapsed time per iteration (ms): 37655.8 | learning rate: 5.321E-05 | global batch size:  1024 | lm loss: 1.809571E+00 | loss scale: 1.0 | grad norm: 0.092 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37797/   51900 | consumed samples:     38704128 | elapsed time per iteration (ms): 37583.5 | learning rate: 5.321E-05 | global batch size:  1024 | lm loss: 1.804525E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37798/   51900 | consumed samples:     38705152 | elapsed time per iteration (ms): 37526.0 | learning rate: 5.320E-05 | global batch size:  1024 | lm loss: 1.808782E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37799/   51900 | consumed samples:     38706176 | elapsed time per iteration (ms): 37668.1 | learning rate: 5.320E-05 | global batch size:  1024 | lm loss: 1.806285E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37800/   51900 | consumed samples:     38707200 | elapsed time per iteration (ms): 37792.9 | learning rate: 5.319E-05 | global batch size:  1024 | lm loss: 1.799924E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37801/   51900 | consumed samples:     38708224 | elapsed time per iteration (ms): 37711.5 | learning rate: 5.319E-05 | global batch size:  1024 | lm loss: 1.797281E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37802/   51900 | consumed samples:     38709248 | elapsed time per iteration (ms): 37619.1 | learning rate: 5.318E-05 | global batch size:  1024 | lm loss: 1.801549E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37803/   51900 | consumed samples:     38710272 | elapsed time per iteration (ms): 37642.7 | learning rate: 5.318E-05 | global batch size:  1024 | lm loss: 1.799867E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37804/   51900 | consumed samples:     38711296 | elapsed time per iteration (ms): 37725.7 | learning rate: 5.317E-05 | global batch size:  1024 | lm loss: 1.810188E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37805/   51900 | consumed samples:     38712320 | elapsed time per iteration (ms): 37635.8 | learning rate: 5.317E-05 | global batch size:  1024 | lm loss: 1.800035E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37806/   51900 | consumed samples:     38713344 | elapsed time per iteration (ms): 37678.4 | learning rate: 5.317E-05 | global batch size:  1024 | lm loss: 1.802198E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37807/   51900 | consumed samples:     38714368 | elapsed time per iteration (ms): 37768.2 | learning rate: 5.316E-05 | global batch size:  1024 | lm loss: 1.805502E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37808/   51900 | consumed samples:     38715392 | elapsed time per iteration (ms): 37650.2 | learning rate: 5.316E-05 | global batch size:  1024 | lm loss: 1.820398E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37809/   51900 | consumed samples:     38716416 | elapsed time per iteration (ms): 37644.9 | learning rate: 5.315E-05 | global batch size:  1024 | lm loss: 1.805135E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37810/   51900 | consumed samples:     38717440 | elapsed time per iteration (ms): 37727.9 | learning rate: 5.315E-05 | global batch size:  1024 | lm loss: 1.810107E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37811/   51900 | consumed samples:     38718464 | elapsed time per iteration (ms): 37653.3 | learning rate: 5.314E-05 | global batch size:  1024 | lm loss: 1.797936E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37812/   51900 | consumed samples:     38719488 | elapsed time per iteration (ms): 37746.7 | learning rate: 5.314E-05 | global batch size:  1024 | lm loss: 1.819135E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37813/   51900 | consumed samples:     38720512 | elapsed time per iteration (ms): 37604.8 | learning rate: 5.314E-05 | global batch size:  1024 | lm loss: 1.824574E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37814/   51900 | consumed samples:     38721536 | elapsed time per iteration (ms): 37688.5 | learning rate: 5.313E-05 | global batch size:  1024 | lm loss: 1.817593E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37815/   51900 | consumed samples:     38722560 | elapsed time per iteration (ms): 37674.2 | learning rate: 5.313E-05 | global batch size:  1024 | lm loss: 1.813309E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37816/   51900 | consumed samples:     38723584 | elapsed time per iteration (ms): 37612.3 | learning rate: 5.312E-05 | global batch size:  1024 | lm loss: 1.805991E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37817/   51900 | consumed samples:     38724608 | elapsed time per iteration (ms): 37575.4 | learning rate: 5.312E-05 | global batch size:  1024 | lm loss: 1.799029E+00 | loss scale: 1.0 | grad norm: 0.064 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37818/   51900 | consumed samples:     38725632 | elapsed time per iteration (ms): 37634.0 | learning rate: 5.311E-05 | global batch size:  1024 | lm loss: 1.807455E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37819/   51900 | consumed samples:     38726656 | elapsed time per iteration (ms): 37682.6 | learning rate: 5.311E-05 | global batch size:  1024 | lm loss: 1.795192E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37820/   51900 | consumed samples:     38727680 | elapsed time per iteration (ms): 37676.7 | learning rate: 5.310E-05 | global batch size:  1024 | lm loss: 1.800608E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37821/   51900 | consumed samples:     38728704 | elapsed time per iteration (ms): 37777.5 | learning rate: 5.310E-05 | global batch size:  1024 | lm loss: 1.825330E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37822/   51900 | consumed samples:     38729728 | elapsed time per iteration (ms): 37792.8 | learning rate: 5.310E-05 | global batch size:  1024 | lm loss: 1.806215E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37823/   51900 | consumed samples:     38730752 | elapsed time per iteration (ms): 37735.0 | learning rate: 5.309E-05 | global batch size:  1024 | lm loss: 1.786696E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37824/   51900 | consumed samples:     38731776 | elapsed time per iteration (ms): 37643.9 | learning rate: 5.309E-05 | global batch size:  1024 | lm loss: 1.814299E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37825/   51900 | consumed samples:     38732800 | elapsed time per iteration (ms): 37671.7 | learning rate: 5.308E-05 | global batch size:  1024 | lm loss: 1.806007E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37826/   51900 | consumed samples:     38733824 | elapsed time per iteration (ms): 37643.5 | learning rate: 5.308E-05 | global batch size:  1024 | lm loss: 1.795164E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37827/   51900 | consumed samples:     38734848 | elapsed time per iteration (ms): 37539.1 | learning rate: 5.307E-05 | global batch size:  1024 | lm loss: 1.821033E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37828/   51900 | consumed samples:     38735872 | elapsed time per iteration (ms): 37588.4 | learning rate: 5.307E-05 | global batch size:  1024 | lm loss: 1.797885E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37829/   51900 | consumed samples:     38736896 | elapsed time per iteration (ms): 37585.9 | learning rate: 5.307E-05 | global batch size:  1024 | lm loss: 1.825374E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37830/   51900 | consumed samples:     38737920 | elapsed time per iteration (ms): 37673.6 | learning rate: 5.306E-05 | global batch size:  1024 | lm loss: 1.819157E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37831/   51900 | consumed samples:     38738944 | elapsed time per iteration (ms): 37653.4 | learning rate: 5.306E-05 | global batch size:  1024 | lm loss: 1.796826E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37832/   51900 | consumed samples:     38739968 | elapsed time per iteration (ms): 37608.2 | learning rate: 5.305E-05 | global batch size:  1024 | lm loss: 1.804644E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37833/   51900 | consumed samples:     38740992 | elapsed time per iteration (ms): 37683.2 | learning rate: 5.305E-05 | global batch size:  1024 | lm loss: 1.798989E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37834/   51900 | consumed samples:     38742016 | elapsed time per iteration (ms): 37544.7 | learning rate: 5.304E-05 | global batch size:  1024 | lm loss: 1.820722E+00 | loss scale: 1.0 | grad norm: 0.064 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37835/   51900 | consumed samples:     38743040 | elapsed time per iteration (ms): 37646.7 | learning rate: 5.304E-05 | global batch size:  1024 | lm loss: 1.822716E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37836/   51900 | consumed samples:     38744064 | elapsed time per iteration (ms): 37632.9 | learning rate: 5.303E-05 | global batch size:  1024 | lm loss: 1.802882E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37837/   51900 | consumed samples:     38745088 | elapsed time per iteration (ms): 37609.5 | learning rate: 5.303E-05 | global batch size:  1024 | lm loss: 1.791790E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37838/   51900 | consumed samples:     38746112 | elapsed time per iteration (ms): 37646.2 | learning rate: 5.303E-05 | global batch size:  1024 | lm loss: 1.815310E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37839/   51900 | consumed samples:     38747136 | elapsed time per iteration (ms): 37689.4 | learning rate: 5.302E-05 | global batch size:  1024 | lm loss: 1.808037E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37840/   51900 | consumed samples:     38748160 | elapsed time per iteration (ms): 37642.6 | learning rate: 5.302E-05 | global batch size:  1024 | lm loss: 1.785357E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37841/   51900 | consumed samples:     38749184 | elapsed time per iteration (ms): 37585.3 | learning rate: 5.301E-05 | global batch size:  1024 | lm loss: 1.797241E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37842/   51900 | consumed samples:     38750208 | elapsed time per iteration (ms): 37591.3 | learning rate: 5.301E-05 | global batch size:  1024 | lm loss: 1.811375E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37843/   51900 | consumed samples:     38751232 | elapsed time per iteration (ms): 37790.2 | learning rate: 5.300E-05 | global batch size:  1024 | lm loss: 1.787205E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37844/   51900 | consumed samples:     38752256 | elapsed time per iteration (ms): 37670.7 | learning rate: 5.300E-05 | global batch size:  1024 | lm loss: 1.808151E+00 | loss scale: 1.0 | grad norm: 0.064 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37845/   51900 | consumed samples:     38753280 | elapsed time per iteration (ms): 37636.3 | learning rate: 5.299E-05 | global batch size:  1024 | lm loss: 1.809511E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37846/   51900 | consumed samples:     38754304 | elapsed time per iteration (ms): 37564.6 | learning rate: 5.299E-05 | global batch size:  1024 | lm loss: 1.793011E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37847/   51900 | consumed samples:     38755328 | elapsed time per iteration (ms): 37673.8 | learning rate: 5.299E-05 | global batch size:  1024 | lm loss: 1.803969E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37848/   51900 | consumed samples:     38756352 | elapsed time per iteration (ms): 37644.1 | learning rate: 5.298E-05 | global batch size:  1024 | lm loss: 1.821275E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37849/   51900 | consumed samples:     38757376 | elapsed time per iteration (ms): 37603.3 | learning rate: 5.298E-05 | global batch size:  1024 | lm loss: 1.796830E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37850/   51900 | consumed samples:     38758400 | elapsed time per iteration (ms): 37625.9 | learning rate: 5.297E-05 | global batch size:  1024 | lm loss: 1.814171E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37851/   51900 | consumed samples:     38759424 | elapsed time per iteration (ms): 37665.3 | learning rate: 5.297E-05 | global batch size:  1024 | lm loss: 1.823903E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37852/   51900 | consumed samples:     38760448 | elapsed time per iteration (ms): 37599.5 | learning rate: 5.296E-05 | global batch size:  1024 | lm loss: 1.815508E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37853/   51900 | consumed samples:     38761472 | elapsed time per iteration (ms): 37575.7 | learning rate: 5.296E-05 | global batch size:  1024 | lm loss: 1.796974E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37854/   51900 | consumed samples:     38762496 | elapsed time per iteration (ms): 37610.2 | learning rate: 5.296E-05 | global batch size:  1024 | lm loss: 1.805159E+00 | loss scale: 1.0 | grad norm: 0.065 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37855/   51900 | consumed samples:     38763520 | elapsed time per iteration (ms): 37700.6 | learning rate: 5.295E-05 | global batch size:  1024 | lm loss: 1.801487E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37856/   51900 | consumed samples:     38764544 | elapsed time per iteration (ms): 37770.5 | learning rate: 5.295E-05 | global batch size:  1024 | lm loss: 1.810784E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37857/   51900 | consumed samples:     38765568 | elapsed time per iteration (ms): 37678.1 | learning rate: 5.294E-05 | global batch size:  1024 | lm loss: 1.802153E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37858/   51900 | consumed samples:     38766592 | elapsed time per iteration (ms): 37641.1 | learning rate: 5.294E-05 | global batch size:  1024 | lm loss: 1.803448E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37859/   51900 | consumed samples:     38767616 | elapsed time per iteration (ms): 37583.4 | learning rate: 5.293E-05 | global batch size:  1024 | lm loss: 1.810298E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37860/   51900 | consumed samples:     38768640 | elapsed time per iteration (ms): 37589.8 | learning rate: 5.293E-05 | global batch size:  1024 | lm loss: 1.797659E+00 | loss scale: 1.0 | grad norm: 0.305 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37861/   51900 | consumed samples:     38769664 | elapsed time per iteration (ms): 37648.5 | learning rate: 5.292E-05 | global batch size:  1024 | lm loss: 1.802702E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37862/   51900 | consumed samples:     38770688 | elapsed time per iteration (ms): 37677.6 | learning rate: 5.292E-05 | global batch size:  1024 | lm loss: 1.795665E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37863/   51900 | consumed samples:     38771712 | elapsed time per iteration (ms): 37764.4 | learning rate: 5.292E-05 | global batch size:  1024 | lm loss: 1.811626E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37864/   51900 | consumed samples:     38772736 | elapsed time per iteration (ms): 37600.6 | learning rate: 5.291E-05 | global batch size:  1024 | lm loss: 1.803652E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37865/   51900 | consumed samples:     38773760 | elapsed time per iteration (ms): 37723.2 | learning rate: 5.291E-05 | global batch size:  1024 | lm loss: 1.797847E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37866/   51900 | consumed samples:     38774784 | elapsed time per iteration (ms): 37696.9 | learning rate: 5.290E-05 | global batch size:  1024 | lm loss: 1.790008E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37867/   51900 | consumed samples:     38775808 | elapsed time per iteration (ms): 37751.4 | learning rate: 5.290E-05 | global batch size:  1024 | lm loss: 1.808498E+00 | loss scale: 1.0 | grad norm: 0.093 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37868/   51900 | consumed samples:     38776832 | elapsed time per iteration (ms): 37629.6 | learning rate: 5.289E-05 | global batch size:  1024 | lm loss: 1.791290E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37869/   51900 | consumed samples:     38777856 | elapsed time per iteration (ms): 37723.7 | learning rate: 5.289E-05 | global batch size:  1024 | lm loss: 1.788725E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37870/   51900 | consumed samples:     38778880 | elapsed time per iteration (ms): 37739.4 | learning rate: 5.289E-05 | global batch size:  1024 | lm loss: 1.808066E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37871/   51900 | consumed samples:     38779904 | elapsed time per iteration (ms): 37672.7 | learning rate: 5.288E-05 | global batch size:  1024 | lm loss: 1.817693E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37872/   51900 | consumed samples:     38780928 | elapsed time per iteration (ms): 37676.0 | learning rate: 5.288E-05 | global batch size:  1024 | lm loss: 1.830005E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37873/   51900 | consumed samples:     38781952 | elapsed time per iteration (ms): 37702.9 | learning rate: 5.287E-05 | global batch size:  1024 | lm loss: 1.805315E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37874/   51900 | consumed samples:     38782976 | elapsed time per iteration (ms): 37736.9 | learning rate: 5.287E-05 | global batch size:  1024 | lm loss: 1.807776E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37875/   51900 | consumed samples:     38784000 | elapsed time per iteration (ms): 37553.9 | learning rate: 5.286E-05 | global batch size:  1024 | lm loss: 1.799776E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37876/   51900 | consumed samples:     38785024 | elapsed time per iteration (ms): 37619.7 | learning rate: 5.286E-05 | global batch size:  1024 | lm loss: 1.809842E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37877/   51900 | consumed samples:     38786048 | elapsed time per iteration (ms): 37702.8 | learning rate: 5.285E-05 | global batch size:  1024 | lm loss: 1.821641E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37878/   51900 | consumed samples:     38787072 | elapsed time per iteration (ms): 37623.0 | learning rate: 5.285E-05 | global batch size:  1024 | lm loss: 1.792918E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37879/   51900 | consumed samples:     38788096 | elapsed time per iteration (ms): 37709.4 | learning rate: 5.285E-05 | global batch size:  1024 | lm loss: 1.807555E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37880/   51900 | consumed samples:     38789120 | elapsed time per iteration (ms): 37665.3 | learning rate: 5.284E-05 | global batch size:  1024 | lm loss: 1.797291E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37881/   51900 | consumed samples:     38790144 | elapsed time per iteration (ms): 37745.6 | learning rate: 5.284E-05 | global batch size:  1024 | lm loss: 1.802738E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37882/   51900 | consumed samples:     38791168 | elapsed time per iteration (ms): 37760.5 | learning rate: 5.283E-05 | global batch size:  1024 | lm loss: 1.805972E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37883/   51900 | consumed samples:     38792192 | elapsed time per iteration (ms): 37631.7 | learning rate: 5.283E-05 | global batch size:  1024 | lm loss: 1.802420E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37884/   51900 | consumed samples:     38793216 | elapsed time per iteration (ms): 37626.3 | learning rate: 5.282E-05 | global batch size:  1024 | lm loss: 1.819671E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37885/   51900 | consumed samples:     38794240 | elapsed time per iteration (ms): 37675.2 | learning rate: 5.282E-05 | global batch size:  1024 | lm loss: 1.809517E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37886/   51900 | consumed samples:     38795264 | elapsed time per iteration (ms): 37681.6 | learning rate: 5.282E-05 | global batch size:  1024 | lm loss: 1.787729E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37887/   51900 | consumed samples:     38796288 | elapsed time per iteration (ms): 37809.6 | learning rate: 5.281E-05 | global batch size:  1024 | lm loss: 1.801394E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37888/   51900 | consumed samples:     38797312 | elapsed time per iteration (ms): 37649.8 | learning rate: 5.281E-05 | global batch size:  1024 | lm loss: 1.813640E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37889/   51900 | consumed samples:     38798336 | elapsed time per iteration (ms): 37689.8 | learning rate: 5.280E-05 | global batch size:  1024 | lm loss: 1.803306E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37890/   51900 | consumed samples:     38799360 | elapsed time per iteration (ms): 37763.5 | learning rate: 5.280E-05 | global batch size:  1024 | lm loss: 1.806608E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37891/   51900 | consumed samples:     38800384 | elapsed time per iteration (ms): 37767.3 | learning rate: 5.279E-05 | global batch size:  1024 | lm loss: 1.795120E+00 | loss scale: 1.0 | grad norm: 0.065 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37892/   51900 | consumed samples:     38801408 | elapsed time per iteration (ms): 37625.5 | learning rate: 5.279E-05 | global batch size:  1024 | lm loss: 1.818439E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37893/   51900 | consumed samples:     38802432 | elapsed time per iteration (ms): 37547.3 | learning rate: 5.278E-05 | global batch size:  1024 | lm loss: 1.799423E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37894/   51900 | consumed samples:     38803456 | elapsed time per iteration (ms): 37727.6 | learning rate: 5.278E-05 | global batch size:  1024 | lm loss: 1.809675E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37895/   51900 | consumed samples:     38804480 | elapsed time per iteration (ms): 37780.4 | learning rate: 5.278E-05 | global batch size:  1024 | lm loss: 1.797527E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37896/   51900 | consumed samples:     38805504 | elapsed time per iteration (ms): 37643.1 | learning rate: 5.277E-05 | global batch size:  1024 | lm loss: 1.802045E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37897/   51900 | consumed samples:     38806528 | elapsed time per iteration (ms): 37623.2 | learning rate: 5.277E-05 | global batch size:  1024 | lm loss: 1.792826E+00 | loss scale: 1.0 | grad norm: 0.064 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37898/   51900 | consumed samples:     38807552 | elapsed time per iteration (ms): 37684.1 | learning rate: 5.276E-05 | global batch size:  1024 | lm loss: 1.810418E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37899/   51900 | consumed samples:     38808576 | elapsed time per iteration (ms): 37607.5 | learning rate: 5.276E-05 | global batch size:  1024 | lm loss: 1.822055E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37900/   51900 | consumed samples:     38809600 | elapsed time per iteration (ms): 37635.8 | learning rate: 5.275E-05 | global batch size:  1024 | lm loss: 1.805139E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37901/   51900 | consumed samples:     38810624 | elapsed time per iteration (ms): 37670.3 | learning rate: 5.275E-05 | global batch size:  1024 | lm loss: 1.806082E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37902/   51900 | consumed samples:     38811648 | elapsed time per iteration (ms): 37563.4 | learning rate: 5.275E-05 | global batch size:  1024 | lm loss: 1.783753E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37903/   51900 | consumed samples:     38812672 | elapsed time per iteration (ms): 37711.2 | learning rate: 5.274E-05 | global batch size:  1024 | lm loss: 1.789435E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37904/   51900 | consumed samples:     38813696 | elapsed time per iteration (ms): 37646.1 | learning rate: 5.274E-05 | global batch size:  1024 | lm loss: 1.812372E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37905/   51900 | consumed samples:     38814720 | elapsed time per iteration (ms): 37613.6 | learning rate: 5.273E-05 | global batch size:  1024 | lm loss: 1.820297E+00 | loss scale: 1.0 | grad norm: 0.065 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37906/   51900 | consumed samples:     38815744 | elapsed time per iteration (ms): 37564.2 | learning rate: 5.273E-05 | global batch size:  1024 | lm loss: 1.792773E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37907/   51900 | consumed samples:     38816768 | elapsed time per iteration (ms): 37680.7 | learning rate: 5.272E-05 | global batch size:  1024 | lm loss: 1.821033E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37908/   51900 | consumed samples:     38817792 | elapsed time per iteration (ms): 37709.7 | learning rate: 5.272E-05 | global batch size:  1024 | lm loss: 1.805935E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37909/   51900 | consumed samples:     38818816 | elapsed time per iteration (ms): 37684.2 | learning rate: 5.271E-05 | global batch size:  1024 | lm loss: 1.789353E+00 | loss scale: 1.0 | grad norm: 0.065 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37910/   51900 | consumed samples:     38819840 | elapsed time per iteration (ms): 37722.2 | learning rate: 5.271E-05 | global batch size:  1024 | lm loss: 1.798810E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37911/   51900 | consumed samples:     38820864 | elapsed time per iteration (ms): 37617.9 | learning rate: 5.271E-05 | global batch size:  1024 | lm loss: 1.791075E+00 | loss scale: 1.0 | grad norm: 0.065 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37912/   51900 | consumed samples:     38821888 | elapsed time per iteration (ms): 37637.0 | learning rate: 5.270E-05 | global batch size:  1024 | lm loss: 1.828337E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37913/   51900 | consumed samples:     38822912 | elapsed time per iteration (ms): 37638.5 | learning rate: 5.270E-05 | global batch size:  1024 | lm loss: 1.811550E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37914/   51900 | consumed samples:     38823936 | elapsed time per iteration (ms): 37817.0 | learning rate: 5.269E-05 | global batch size:  1024 | lm loss: 1.807506E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37915/   51900 | consumed samples:     38824960 | elapsed time per iteration (ms): 37738.4 | learning rate: 5.269E-05 | global batch size:  1024 | lm loss: 1.802058E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37916/   51900 | consumed samples:     38825984 | elapsed time per iteration (ms): 37765.2 | learning rate: 5.268E-05 | global batch size:  1024 | lm loss: 1.798160E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37917/   51900 | consumed samples:     38827008 | elapsed time per iteration (ms): 37738.6 | learning rate: 5.268E-05 | global batch size:  1024 | lm loss: 1.811351E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37918/   51900 | consumed samples:     38828032 | elapsed time per iteration (ms): 37705.0 | learning rate: 5.268E-05 | global batch size:  1024 | lm loss: 1.816939E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37919/   51900 | consumed samples:     38829056 | elapsed time per iteration (ms): 37678.4 | learning rate: 5.267E-05 | global batch size:  1024 | lm loss: 1.794201E+00 | loss scale: 1.0 | grad norm: 0.065 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37920/   51900 | consumed samples:     38830080 | elapsed time per iteration (ms): 37652.7 | learning rate: 5.267E-05 | global batch size:  1024 | lm loss: 1.807686E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37921/   51900 | consumed samples:     38831104 | elapsed time per iteration (ms): 37693.0 | learning rate: 5.266E-05 | global batch size:  1024 | lm loss: 1.796318E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37922/   51900 | consumed samples:     38832128 | elapsed time per iteration (ms): 37717.5 | learning rate: 5.266E-05 | global batch size:  1024 | lm loss: 1.799846E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37923/   51900 | consumed samples:     38833152 | elapsed time per iteration (ms): 37614.3 | learning rate: 5.265E-05 | global batch size:  1024 | lm loss: 1.819702E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37924/   51900 | consumed samples:     38834176 | elapsed time per iteration (ms): 37711.9 | learning rate: 5.265E-05 | global batch size:  1024 | lm loss: 1.804414E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37925/   51900 | consumed samples:     38835200 | elapsed time per iteration (ms): 37733.5 | learning rate: 5.264E-05 | global batch size:  1024 | lm loss: 1.786501E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37926/   51900 | consumed samples:     38836224 | elapsed time per iteration (ms): 37594.2 | learning rate: 5.264E-05 | global batch size:  1024 | lm loss: 1.823316E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37927/   51900 | consumed samples:     38837248 | elapsed time per iteration (ms): 37642.2 | learning rate: 5.264E-05 | global batch size:  1024 | lm loss: 1.804978E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37928/   51900 | consumed samples:     38838272 | elapsed time per iteration (ms): 37571.9 | learning rate: 5.263E-05 | global batch size:  1024 | lm loss: 1.824169E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37929/   51900 | consumed samples:     38839296 | elapsed time per iteration (ms): 37697.9 | learning rate: 5.263E-05 | global batch size:  1024 | lm loss: 1.807228E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37930/   51900 | consumed samples:     38840320 | elapsed time per iteration (ms): 37664.2 | learning rate: 5.262E-05 | global batch size:  1024 | lm loss: 1.807274E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37931/   51900 | consumed samples:     38841344 | elapsed time per iteration (ms): 37755.3 | learning rate: 5.262E-05 | global batch size:  1024 | lm loss: 1.812408E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37932/   51900 | consumed samples:     38842368 | elapsed time per iteration (ms): 37698.6 | learning rate: 5.261E-05 | global batch size:  1024 | lm loss: 1.822319E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37933/   51900 | consumed samples:     38843392 | elapsed time per iteration (ms): 37577.2 | learning rate: 5.261E-05 | global batch size:  1024 | lm loss: 1.798427E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37934/   51900 | consumed samples:     38844416 | elapsed time per iteration (ms): 37630.6 | learning rate: 5.261E-05 | global batch size:  1024 | lm loss: 1.804103E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37935/   51900 | consumed samples:     38845440 | elapsed time per iteration (ms): 37643.3 | learning rate: 5.260E-05 | global batch size:  1024 | lm loss: 1.786947E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37936/   51900 | consumed samples:     38846464 | elapsed time per iteration (ms): 37642.1 | learning rate: 5.260E-05 | global batch size:  1024 | lm loss: 1.814224E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37937/   51900 | consumed samples:     38847488 | elapsed time per iteration (ms): 37786.5 | learning rate: 5.259E-05 | global batch size:  1024 | lm loss: 1.793949E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37938/   51900 | consumed samples:     38848512 | elapsed time per iteration (ms): 37630.6 | learning rate: 5.259E-05 | global batch size:  1024 | lm loss: 1.796023E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37939/   51900 | consumed samples:     38849536 | elapsed time per iteration (ms): 37723.0 | learning rate: 5.258E-05 | global batch size:  1024 | lm loss: 1.792669E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37940/   51900 | consumed samples:     38850560 | elapsed time per iteration (ms): 37554.9 | learning rate: 5.258E-05 | global batch size:  1024 | lm loss: 1.805282E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37941/   51900 | consumed samples:     38851584 | elapsed time per iteration (ms): 37582.7 | learning rate: 5.258E-05 | global batch size:  1024 | lm loss: 1.818777E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37942/   51900 | consumed samples:     38852608 | elapsed time per iteration (ms): 37615.9 | learning rate: 5.257E-05 | global batch size:  1024 | lm loss: 1.809584E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37943/   51900 | consumed samples:     38853632 | elapsed time per iteration (ms): 37671.8 | learning rate: 5.257E-05 | global batch size:  1024 | lm loss: 1.816904E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37944/   51900 | consumed samples:     38854656 | elapsed time per iteration (ms): 37638.6 | learning rate: 5.256E-05 | global batch size:  1024 | lm loss: 1.807947E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37945/   51900 | consumed samples:     38855680 | elapsed time per iteration (ms): 37698.2 | learning rate: 5.256E-05 | global batch size:  1024 | lm loss: 1.792911E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37946/   51900 | consumed samples:     38856704 | elapsed time per iteration (ms): 37704.3 | learning rate: 5.255E-05 | global batch size:  1024 | lm loss: 1.817344E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37947/   51900 | consumed samples:     38857728 | elapsed time per iteration (ms): 37690.5 | learning rate: 5.255E-05 | global batch size:  1024 | lm loss: 1.817489E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37948/   51900 | consumed samples:     38858752 | elapsed time per iteration (ms): 37760.9 | learning rate: 5.254E-05 | global batch size:  1024 | lm loss: 1.789084E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37949/   51900 | consumed samples:     38859776 | elapsed time per iteration (ms): 37728.0 | learning rate: 5.254E-05 | global batch size:  1024 | lm loss: 1.806372E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37950/   51900 | consumed samples:     38860800 | elapsed time per iteration (ms): 37739.8 | learning rate: 5.254E-05 | global batch size:  1024 | lm loss: 1.812132E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37951/   51900 | consumed samples:     38861824 | elapsed time per iteration (ms): 37741.5 | learning rate: 5.253E-05 | global batch size:  1024 | lm loss: 1.803663E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37952/   51900 | consumed samples:     38862848 | elapsed time per iteration (ms): 37749.0 | learning rate: 5.253E-05 | global batch size:  1024 | lm loss: 1.815124E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37953/   51900 | consumed samples:     38863872 | elapsed time per iteration (ms): 37633.8 | learning rate: 5.252E-05 | global batch size:  1024 | lm loss: 1.806724E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37954/   51900 | consumed samples:     38864896 | elapsed time per iteration (ms): 37802.3 | learning rate: 5.252E-05 | global batch size:  1024 | lm loss: 1.811007E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37955/   51900 | consumed samples:     38865920 | elapsed time per iteration (ms): 37761.4 | learning rate: 5.251E-05 | global batch size:  1024 | lm loss: 1.838306E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37956/   51900 | consumed samples:     38866944 | elapsed time per iteration (ms): 37688.1 | learning rate: 5.251E-05 | global batch size:  1024 | lm loss: 1.815459E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37957/   51900 | consumed samples:     38867968 | elapsed time per iteration (ms): 37705.9 | learning rate: 5.251E-05 | global batch size:  1024 | lm loss: 1.811424E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37958/   51900 | consumed samples:     38868992 | elapsed time per iteration (ms): 37779.6 | learning rate: 5.250E-05 | global batch size:  1024 | lm loss: 1.795444E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37959/   51900 | consumed samples:     38870016 | elapsed time per iteration (ms): 37684.7 | learning rate: 5.250E-05 | global batch size:  1024 | lm loss: 1.805417E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37960/   51900 | consumed samples:     38871040 | elapsed time per iteration (ms): 37701.1 | learning rate: 5.249E-05 | global batch size:  1024 | lm loss: 1.799046E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37961/   51900 | consumed samples:     38872064 | elapsed time per iteration (ms): 37641.4 | learning rate: 5.249E-05 | global batch size:  1024 | lm loss: 1.797508E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37962/   51900 | consumed samples:     38873088 | elapsed time per iteration (ms): 37627.0 | learning rate: 5.248E-05 | global batch size:  1024 | lm loss: 1.830663E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37963/   51900 | consumed samples:     38874112 | elapsed time per iteration (ms): 37644.9 | learning rate: 5.248E-05 | global batch size:  1024 | lm loss: 1.820831E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37964/   51900 | consumed samples:     38875136 | elapsed time per iteration (ms): 37610.7 | learning rate: 5.247E-05 | global batch size:  1024 | lm loss: 1.802233E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37965/   51900 | consumed samples:     38876160 | elapsed time per iteration (ms): 37714.3 | learning rate: 5.247E-05 | global batch size:  1024 | lm loss: 1.799070E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37966/   51900 | consumed samples:     38877184 | elapsed time per iteration (ms): 37701.9 | learning rate: 5.247E-05 | global batch size:  1024 | lm loss: 1.800360E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37967/   51900 | consumed samples:     38878208 | elapsed time per iteration (ms): 37714.0 | learning rate: 5.246E-05 | global batch size:  1024 | lm loss: 1.824443E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37968/   51900 | consumed samples:     38879232 | elapsed time per iteration (ms): 37680.7 | learning rate: 5.246E-05 | global batch size:  1024 | lm loss: 1.793780E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37969/   51900 | consumed samples:     38880256 | elapsed time per iteration (ms): 37693.5 | learning rate: 5.245E-05 | global batch size:  1024 | lm loss: 1.813155E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37970/   51900 | consumed samples:     38881280 | elapsed time per iteration (ms): 37611.7 | learning rate: 5.245E-05 | global batch size:  1024 | lm loss: 1.798702E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37971/   51900 | consumed samples:     38882304 | elapsed time per iteration (ms): 37617.1 | learning rate: 5.244E-05 | global batch size:  1024 | lm loss: 1.803670E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37972/   51900 | consumed samples:     38883328 | elapsed time per iteration (ms): 37682.8 | learning rate: 5.244E-05 | global batch size:  1024 | lm loss: 1.806777E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37973/   51900 | consumed samples:     38884352 | elapsed time per iteration (ms): 37776.8 | learning rate: 5.244E-05 | global batch size:  1024 | lm loss: 1.806009E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37974/   51900 | consumed samples:     38885376 | elapsed time per iteration (ms): 37578.3 | learning rate: 5.243E-05 | global batch size:  1024 | lm loss: 1.804118E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37975/   51900 | consumed samples:     38886400 | elapsed time per iteration (ms): 37729.8 | learning rate: 5.243E-05 | global batch size:  1024 | lm loss: 1.813565E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37976/   51900 | consumed samples:     38887424 | elapsed time per iteration (ms): 37722.1 | learning rate: 5.242E-05 | global batch size:  1024 | lm loss: 1.812139E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37977/   51900 | consumed samples:     38888448 | elapsed time per iteration (ms): 37631.3 | learning rate: 5.242E-05 | global batch size:  1024 | lm loss: 1.792066E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37978/   51900 | consumed samples:     38889472 | elapsed time per iteration (ms): 37701.7 | learning rate: 5.241E-05 | global batch size:  1024 | lm loss: 1.828205E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37979/   51900 | consumed samples:     38890496 | elapsed time per iteration (ms): 37742.7 | learning rate: 5.241E-05 | global batch size:  1024 | lm loss: 1.810621E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37980/   51900 | consumed samples:     38891520 | elapsed time per iteration (ms): 37624.4 | learning rate: 5.241E-05 | global batch size:  1024 | lm loss: 1.807377E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37981/   51900 | consumed samples:     38892544 | elapsed time per iteration (ms): 37637.1 | learning rate: 5.240E-05 | global batch size:  1024 | lm loss: 1.829946E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37982/   51900 | consumed samples:     38893568 | elapsed time per iteration (ms): 37619.5 | learning rate: 5.240E-05 | global batch size:  1024 | lm loss: 1.776655E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37983/   51900 | consumed samples:     38894592 | elapsed time per iteration (ms): 37703.9 | learning rate: 5.239E-05 | global batch size:  1024 | lm loss: 1.803457E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37984/   51900 | consumed samples:     38895616 | elapsed time per iteration (ms): 37700.7 | learning rate: 5.239E-05 | global batch size:  1024 | lm loss: 1.814041E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37985/   51900 | consumed samples:     38896640 | elapsed time per iteration (ms): 37599.4 | learning rate: 5.238E-05 | global batch size:  1024 | lm loss: 1.803998E+00 | loss scale: 1.0 | grad norm: 0.065 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37986/   51900 | consumed samples:     38897664 | elapsed time per iteration (ms): 37704.3 | learning rate: 5.238E-05 | global batch size:  1024 | lm loss: 1.810439E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37987/   51900 | consumed samples:     38898688 | elapsed time per iteration (ms): 37898.1 | learning rate: 5.237E-05 | global batch size:  1024 | lm loss: 1.812771E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37988/   51900 | consumed samples:     38899712 | elapsed time per iteration (ms): 37711.1 | learning rate: 5.237E-05 | global batch size:  1024 | lm loss: 1.810624E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37989/   51900 | consumed samples:     38900736 | elapsed time per iteration (ms): 37629.9 | learning rate: 5.237E-05 | global batch size:  1024 | lm loss: 1.797259E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37990/   51900 | consumed samples:     38901760 | elapsed time per iteration (ms): 37658.1 | learning rate: 5.236E-05 | global batch size:  1024 | lm loss: 1.799528E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37991/   51900 | consumed samples:     38902784 | elapsed time per iteration (ms): 37717.4 | learning rate: 5.236E-05 | global batch size:  1024 | lm loss: 1.788715E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37992/   51900 | consumed samples:     38903808 | elapsed time per iteration (ms): 37660.0 | learning rate: 5.235E-05 | global batch size:  1024 | lm loss: 1.798609E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37993/   51900 | consumed samples:     38904832 | elapsed time per iteration (ms): 37769.5 | learning rate: 5.235E-05 | global batch size:  1024 | lm loss: 1.800292E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37994/   51900 | consumed samples:     38905856 | elapsed time per iteration (ms): 37659.2 | learning rate: 5.234E-05 | global batch size:  1024 | lm loss: 1.828804E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37995/   51900 | consumed samples:     38906880 | elapsed time per iteration (ms): 37698.2 | learning rate: 5.234E-05 | global batch size:  1024 | lm loss: 1.791039E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37996/   51900 | consumed samples:     38907904 | elapsed time per iteration (ms): 37649.7 | learning rate: 5.234E-05 | global batch size:  1024 | lm loss: 1.797527E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37997/   51900 | consumed samples:     38908928 | elapsed time per iteration (ms): 37669.8 | learning rate: 5.233E-05 | global batch size:  1024 | lm loss: 1.803962E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37998/   51900 | consumed samples:     38909952 | elapsed time per iteration (ms): 37619.0 | learning rate: 5.233E-05 | global batch size:  1024 | lm loss: 1.813355E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    37999/   51900 | consumed samples:     38910976 | elapsed time per iteration (ms): 37576.2 | learning rate: 5.232E-05 | global batch size:  1024 | lm loss: 1.811083E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38000/   51900 | consumed samples:     38912000 | elapsed time per iteration (ms): 37672.5 | learning rate: 5.232E-05 | global batch size:  1024 | lm loss: 1.799734E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    save-checkpoint ................................: (147008.19, 147008.30)
 iteration    38001/   51900 | consumed samples:     38913024 | elapsed time per iteration (ms): 37123.9 | learning rate: 5.231E-05 | global batch size:  1024 | lm loss: 1.789134E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38002/   51900 | consumed samples:     38914048 | elapsed time per iteration (ms): 37549.8 | learning rate: 5.231E-05 | global batch size:  1024 | lm loss: 1.823075E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38003/   51900 | consumed samples:     38915072 | elapsed time per iteration (ms): 37683.0 | learning rate: 5.231E-05 | global batch size:  1024 | lm loss: 1.802067E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38004/   51900 | consumed samples:     38916096 | elapsed time per iteration (ms): 37647.5 | learning rate: 5.230E-05 | global batch size:  1024 | lm loss: 1.805360E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38005/   51900 | consumed samples:     38917120 | elapsed time per iteration (ms): 37575.9 | learning rate: 5.230E-05 | global batch size:  1024 | lm loss: 1.792276E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38006/   51900 | consumed samples:     38918144 | elapsed time per iteration (ms): 37717.0 | learning rate: 5.229E-05 | global batch size:  1024 | lm loss: 1.798895E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38007/   51900 | consumed samples:     38919168 | elapsed time per iteration (ms): 37553.9 | learning rate: 5.229E-05 | global batch size:  1024 | lm loss: 1.809507E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38008/   51900 | consumed samples:     38920192 | elapsed time per iteration (ms): 37654.4 | learning rate: 5.228E-05 | global batch size:  1024 | lm loss: 1.809736E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38009/   51900 | consumed samples:     38921216 | elapsed time per iteration (ms): 37636.5 | learning rate: 5.228E-05 | global batch size:  1024 | lm loss: 1.805571E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38010/   51900 | consumed samples:     38922240 | elapsed time per iteration (ms): 37654.6 | learning rate: 5.227E-05 | global batch size:  1024 | lm loss: 1.798531E+00 | loss scale: 1.0 | grad norm: 0.065 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38011/   51900 | consumed samples:     38923264 | elapsed time per iteration (ms): 37663.6 | learning rate: 5.227E-05 | global batch size:  1024 | lm loss: 1.805892E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38012/   51900 | consumed samples:     38924288 | elapsed time per iteration (ms): 37507.4 | learning rate: 5.227E-05 | global batch size:  1024 | lm loss: 1.805991E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38013/   51900 | consumed samples:     38925312 | elapsed time per iteration (ms): 37503.8 | learning rate: 5.226E-05 | global batch size:  1024 | lm loss: 1.816748E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38014/   51900 | consumed samples:     38926336 | elapsed time per iteration (ms): 37747.2 | learning rate: 5.226E-05 | global batch size:  1024 | lm loss: 1.794398E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38015/   51900 | consumed samples:     38927360 | elapsed time per iteration (ms): 37584.2 | learning rate: 5.225E-05 | global batch size:  1024 | lm loss: 1.809894E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38016/   51900 | consumed samples:     38928384 | elapsed time per iteration (ms): 37678.5 | learning rate: 5.225E-05 | global batch size:  1024 | lm loss: 1.817958E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38017/   51900 | consumed samples:     38929408 | elapsed time per iteration (ms): 37634.3 | learning rate: 5.224E-05 | global batch size:  1024 | lm loss: 1.810302E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38018/   51900 | consumed samples:     38930432 | elapsed time per iteration (ms): 37677.7 | learning rate: 5.224E-05 | global batch size:  1024 | lm loss: 1.799612E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38019/   51900 | consumed samples:     38931456 | elapsed time per iteration (ms): 37654.4 | learning rate: 5.224E-05 | global batch size:  1024 | lm loss: 1.802955E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38020/   51900 | consumed samples:     38932480 | elapsed time per iteration (ms): 37612.9 | learning rate: 5.223E-05 | global batch size:  1024 | lm loss: 1.781300E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38021/   51900 | consumed samples:     38933504 | elapsed time per iteration (ms): 37661.6 | learning rate: 5.223E-05 | global batch size:  1024 | lm loss: 1.821406E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38022/   51900 | consumed samples:     38934528 | elapsed time per iteration (ms): 37569.7 | learning rate: 5.222E-05 | global batch size:  1024 | lm loss: 1.807422E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38023/   51900 | consumed samples:     38935552 | elapsed time per iteration (ms): 37706.9 | learning rate: 5.222E-05 | global batch size:  1024 | lm loss: 1.796291E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38024/   51900 | consumed samples:     38936576 | elapsed time per iteration (ms): 37654.8 | learning rate: 5.221E-05 | global batch size:  1024 | lm loss: 1.793498E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38025/   51900 | consumed samples:     38937600 | elapsed time per iteration (ms): 37738.9 | learning rate: 5.221E-05 | global batch size:  1024 | lm loss: 1.808341E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38026/   51900 | consumed samples:     38938624 | elapsed time per iteration (ms): 37657.4 | learning rate: 5.221E-05 | global batch size:  1024 | lm loss: 1.798958E+00 | loss scale: 1.0 | grad norm: 0.065 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38027/   51900 | consumed samples:     38939648 | elapsed time per iteration (ms): 37710.3 | learning rate: 5.220E-05 | global batch size:  1024 | lm loss: 1.800011E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38028/   51900 | consumed samples:     38940672 | elapsed time per iteration (ms): 37554.3 | learning rate: 5.220E-05 | global batch size:  1024 | lm loss: 1.806149E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38029/   51900 | consumed samples:     38941696 | elapsed time per iteration (ms): 37637.9 | learning rate: 5.219E-05 | global batch size:  1024 | lm loss: 1.807845E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38030/   51900 | consumed samples:     38942720 | elapsed time per iteration (ms): 37648.4 | learning rate: 5.219E-05 | global batch size:  1024 | lm loss: 1.809615E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38031/   51900 | consumed samples:     38943744 | elapsed time per iteration (ms): 37766.1 | learning rate: 5.218E-05 | global batch size:  1024 | lm loss: 1.806057E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38032/   51900 | consumed samples:     38944768 | elapsed time per iteration (ms): 37649.1 | learning rate: 5.218E-05 | global batch size:  1024 | lm loss: 1.804478E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38033/   51900 | consumed samples:     38945792 | elapsed time per iteration (ms): 37641.6 | learning rate: 5.217E-05 | global batch size:  1024 | lm loss: 1.798202E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38034/   51900 | consumed samples:     38946816 | elapsed time per iteration (ms): 37553.9 | learning rate: 5.217E-05 | global batch size:  1024 | lm loss: 1.822927E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38035/   51900 | consumed samples:     38947840 | elapsed time per iteration (ms): 37609.2 | learning rate: 5.217E-05 | global batch size:  1024 | lm loss: 1.820621E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38036/   51900 | consumed samples:     38948864 | elapsed time per iteration (ms): 37613.8 | learning rate: 5.216E-05 | global batch size:  1024 | lm loss: 1.810372E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38037/   51900 | consumed samples:     38949888 | elapsed time per iteration (ms): 37604.2 | learning rate: 5.216E-05 | global batch size:  1024 | lm loss: 1.789224E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38038/   51900 | consumed samples:     38950912 | elapsed time per iteration (ms): 37650.1 | learning rate: 5.215E-05 | global batch size:  1024 | lm loss: 1.808918E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38039/   51900 | consumed samples:     38951936 | elapsed time per iteration (ms): 37614.4 | learning rate: 5.215E-05 | global batch size:  1024 | lm loss: 1.812259E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38040/   51900 | consumed samples:     38952960 | elapsed time per iteration (ms): 37610.4 | learning rate: 5.214E-05 | global batch size:  1024 | lm loss: 1.817047E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38041/   51900 | consumed samples:     38953984 | elapsed time per iteration (ms): 37686.9 | learning rate: 5.214E-05 | global batch size:  1024 | lm loss: 1.794434E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38042/   51900 | consumed samples:     38955008 | elapsed time per iteration (ms): 37572.8 | learning rate: 5.214E-05 | global batch size:  1024 | lm loss: 1.804877E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38043/   51900 | consumed samples:     38956032 | elapsed time per iteration (ms): 37704.8 | learning rate: 5.213E-05 | global batch size:  1024 | lm loss: 1.809278E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38044/   51900 | consumed samples:     38957056 | elapsed time per iteration (ms): 37545.3 | learning rate: 5.213E-05 | global batch size:  1024 | lm loss: 1.806774E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38045/   51900 | consumed samples:     38958080 | elapsed time per iteration (ms): 37646.2 | learning rate: 5.212E-05 | global batch size:  1024 | lm loss: 1.811043E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38046/   51900 | consumed samples:     38959104 | elapsed time per iteration (ms): 37611.5 | learning rate: 5.212E-05 | global batch size:  1024 | lm loss: 1.796685E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38047/   51900 | consumed samples:     38960128 | elapsed time per iteration (ms): 37623.4 | learning rate: 5.211E-05 | global batch size:  1024 | lm loss: 1.788936E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38048/   51900 | consumed samples:     38961152 | elapsed time per iteration (ms): 37509.1 | learning rate: 5.211E-05 | global batch size:  1024 | lm loss: 1.788401E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38049/   51900 | consumed samples:     38962176 | elapsed time per iteration (ms): 37604.0 | learning rate: 5.211E-05 | global batch size:  1024 | lm loss: 1.796806E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38050/   51900 | consumed samples:     38963200 | elapsed time per iteration (ms): 37639.6 | learning rate: 5.210E-05 | global batch size:  1024 | lm loss: 1.790375E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38051/   51900 | consumed samples:     38964224 | elapsed time per iteration (ms): 37605.0 | learning rate: 5.210E-05 | global batch size:  1024 | lm loss: 1.789638E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38052/   51900 | consumed samples:     38965248 | elapsed time per iteration (ms): 37757.6 | learning rate: 5.209E-05 | global batch size:  1024 | lm loss: 1.809758E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38053/   51900 | consumed samples:     38966272 | elapsed time per iteration (ms): 37533.6 | learning rate: 5.209E-05 | global batch size:  1024 | lm loss: 1.803501E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38054/   51900 | consumed samples:     38967296 | elapsed time per iteration (ms): 37567.9 | learning rate: 5.208E-05 | global batch size:  1024 | lm loss: 1.804292E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38055/   51900 | consumed samples:     38968320 | elapsed time per iteration (ms): 37703.0 | learning rate: 5.208E-05 | global batch size:  1024 | lm loss: 1.810349E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38056/   51900 | consumed samples:     38969344 | elapsed time per iteration (ms): 37656.7 | learning rate: 5.207E-05 | global batch size:  1024 | lm loss: 1.818113E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38057/   51900 | consumed samples:     38970368 | elapsed time per iteration (ms): 37558.6 | learning rate: 5.207E-05 | global batch size:  1024 | lm loss: 1.791186E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38058/   51900 | consumed samples:     38971392 | elapsed time per iteration (ms): 37797.0 | learning rate: 5.207E-05 | global batch size:  1024 | lm loss: 1.792204E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38059/   51900 | consumed samples:     38972416 | elapsed time per iteration (ms): 37698.1 | learning rate: 5.206E-05 | global batch size:  1024 | lm loss: 1.811124E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38060/   51900 | consumed samples:     38973440 | elapsed time per iteration (ms): 37577.9 | learning rate: 5.206E-05 | global batch size:  1024 | lm loss: 1.825575E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38061/   51900 | consumed samples:     38974464 | elapsed time per iteration (ms): 37506.0 | learning rate: 5.205E-05 | global batch size:  1024 | lm loss: 1.800269E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38062/   51900 | consumed samples:     38975488 | elapsed time per iteration (ms): 37601.4 | learning rate: 5.205E-05 | global batch size:  1024 | lm loss: 1.786495E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38063/   51900 | consumed samples:     38976512 | elapsed time per iteration (ms): 37613.4 | learning rate: 5.204E-05 | global batch size:  1024 | lm loss: 1.800121E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38064/   51900 | consumed samples:     38977536 | elapsed time per iteration (ms): 37582.9 | learning rate: 5.204E-05 | global batch size:  1024 | lm loss: 1.801349E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38065/   51900 | consumed samples:     38978560 | elapsed time per iteration (ms): 37671.2 | learning rate: 5.204E-05 | global batch size:  1024 | lm loss: 1.814069E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38066/   51900 | consumed samples:     38979584 | elapsed time per iteration (ms): 37605.5 | learning rate: 5.203E-05 | global batch size:  1024 | lm loss: 1.805856E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38067/   51900 | consumed samples:     38980608 | elapsed time per iteration (ms): 37658.0 | learning rate: 5.203E-05 | global batch size:  1024 | lm loss: 1.811135E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38068/   51900 | consumed samples:     38981632 | elapsed time per iteration (ms): 37687.4 | learning rate: 5.202E-05 | global batch size:  1024 | lm loss: 1.828149E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38069/   51900 | consumed samples:     38982656 | elapsed time per iteration (ms): 37685.2 | learning rate: 5.202E-05 | global batch size:  1024 | lm loss: 1.824232E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38070/   51900 | consumed samples:     38983680 | elapsed time per iteration (ms): 37658.8 | learning rate: 5.201E-05 | global batch size:  1024 | lm loss: 1.818485E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38071/   51900 | consumed samples:     38984704 | elapsed time per iteration (ms): 37612.1 | learning rate: 5.201E-05 | global batch size:  1024 | lm loss: 1.806802E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38072/   51900 | consumed samples:     38985728 | elapsed time per iteration (ms): 37736.4 | learning rate: 5.201E-05 | global batch size:  1024 | lm loss: 1.791540E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38073/   51900 | consumed samples:     38986752 | elapsed time per iteration (ms): 37710.1 | learning rate: 5.200E-05 | global batch size:  1024 | lm loss: 1.819642E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38074/   51900 | consumed samples:     38987776 | elapsed time per iteration (ms): 37645.8 | learning rate: 5.200E-05 | global batch size:  1024 | lm loss: 1.808066E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38075/   51900 | consumed samples:     38988800 | elapsed time per iteration (ms): 37614.7 | learning rate: 5.199E-05 | global batch size:  1024 | lm loss: 1.791347E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38076/   51900 | consumed samples:     38989824 | elapsed time per iteration (ms): 37715.8 | learning rate: 5.199E-05 | global batch size:  1024 | lm loss: 1.794742E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38077/   51900 | consumed samples:     38990848 | elapsed time per iteration (ms): 37659.6 | learning rate: 5.198E-05 | global batch size:  1024 | lm loss: 1.808208E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38078/   51900 | consumed samples:     38991872 | elapsed time per iteration (ms): 37632.4 | learning rate: 5.198E-05 | global batch size:  1024 | lm loss: 1.805559E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38079/   51900 | consumed samples:     38992896 | elapsed time per iteration (ms): 37710.7 | learning rate: 5.198E-05 | global batch size:  1024 | lm loss: 1.800518E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38080/   51900 | consumed samples:     38993920 | elapsed time per iteration (ms): 37670.9 | learning rate: 5.197E-05 | global batch size:  1024 | lm loss: 1.811017E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38081/   51900 | consumed samples:     38994944 | elapsed time per iteration (ms): 37592.2 | learning rate: 5.197E-05 | global batch size:  1024 | lm loss: 1.818914E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38082/   51900 | consumed samples:     38995968 | elapsed time per iteration (ms): 37716.0 | learning rate: 5.196E-05 | global batch size:  1024 | lm loss: 1.813856E+00 | loss scale: 1.0 | grad norm: 0.088 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38083/   51900 | consumed samples:     38996992 | elapsed time per iteration (ms): 37605.0 | learning rate: 5.196E-05 | global batch size:  1024 | lm loss: 1.788515E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38084/   51900 | consumed samples:     38998016 | elapsed time per iteration (ms): 37644.8 | learning rate: 5.195E-05 | global batch size:  1024 | lm loss: 1.795688E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38085/   51900 | consumed samples:     38999040 | elapsed time per iteration (ms): 37635.6 | learning rate: 5.195E-05 | global batch size:  1024 | lm loss: 1.808804E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38086/   51900 | consumed samples:     39000064 | elapsed time per iteration (ms): 37607.8 | learning rate: 5.194E-05 | global batch size:  1024 | lm loss: 1.809564E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38087/   51900 | consumed samples:     39001088 | elapsed time per iteration (ms): 37678.8 | learning rate: 5.194E-05 | global batch size:  1024 | lm loss: 1.814750E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38088/   51900 | consumed samples:     39002112 | elapsed time per iteration (ms): 37703.2 | learning rate: 5.194E-05 | global batch size:  1024 | lm loss: 1.796046E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38089/   51900 | consumed samples:     39003136 | elapsed time per iteration (ms): 37622.3 | learning rate: 5.193E-05 | global batch size:  1024 | lm loss: 1.801689E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38090/   51900 | consumed samples:     39004160 | elapsed time per iteration (ms): 37616.7 | learning rate: 5.193E-05 | global batch size:  1024 | lm loss: 1.779858E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38091/   51900 | consumed samples:     39005184 | elapsed time per iteration (ms): 37569.0 | learning rate: 5.192E-05 | global batch size:  1024 | lm loss: 1.812221E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38092/   51900 | consumed samples:     39006208 | elapsed time per iteration (ms): 37715.7 | learning rate: 5.192E-05 | global batch size:  1024 | lm loss: 1.814722E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38093/   51900 | consumed samples:     39007232 | elapsed time per iteration (ms): 37636.0 | learning rate: 5.191E-05 | global batch size:  1024 | lm loss: 1.817030E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38094/   51900 | consumed samples:     39008256 | elapsed time per iteration (ms): 37671.2 | learning rate: 5.191E-05 | global batch size:  1024 | lm loss: 1.796913E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38095/   51900 | consumed samples:     39009280 | elapsed time per iteration (ms): 37701.5 | learning rate: 5.191E-05 | global batch size:  1024 | lm loss: 1.803244E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38096/   51900 | consumed samples:     39010304 | elapsed time per iteration (ms): 37625.6 | learning rate: 5.190E-05 | global batch size:  1024 | lm loss: 1.814463E+00 | loss scale: 1.0 | grad norm: 0.065 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38097/   51900 | consumed samples:     39011328 | elapsed time per iteration (ms): 37640.0 | learning rate: 5.190E-05 | global batch size:  1024 | lm loss: 1.804340E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38098/   51900 | consumed samples:     39012352 | elapsed time per iteration (ms): 37557.0 | learning rate: 5.189E-05 | global batch size:  1024 | lm loss: 1.811076E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38099/   51900 | consumed samples:     39013376 | elapsed time per iteration (ms): 37665.7 | learning rate: 5.189E-05 | global batch size:  1024 | lm loss: 1.808461E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38100/   51900 | consumed samples:     39014400 | elapsed time per iteration (ms): 37703.6 | learning rate: 5.188E-05 | global batch size:  1024 | lm loss: 1.834598E+00 | loss scale: 1.0 | grad norm: 0.064 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38101/   51900 | consumed samples:     39015424 | elapsed time per iteration (ms): 37644.6 | learning rate: 5.188E-05 | global batch size:  1024 | lm loss: 1.810129E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38102/   51900 | consumed samples:     39016448 | elapsed time per iteration (ms): 37650.5 | learning rate: 5.188E-05 | global batch size:  1024 | lm loss: 1.809241E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38103/   51900 | consumed samples:     39017472 | elapsed time per iteration (ms): 37740.0 | learning rate: 5.187E-05 | global batch size:  1024 | lm loss: 1.807348E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38104/   51900 | consumed samples:     39018496 | elapsed time per iteration (ms): 37640.4 | learning rate: 5.187E-05 | global batch size:  1024 | lm loss: 1.807257E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38105/   51900 | consumed samples:     39019520 | elapsed time per iteration (ms): 37574.3 | learning rate: 5.186E-05 | global batch size:  1024 | lm loss: 1.821449E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38106/   51900 | consumed samples:     39020544 | elapsed time per iteration (ms): 37733.9 | learning rate: 5.186E-05 | global batch size:  1024 | lm loss: 1.789798E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38107/   51900 | consumed samples:     39021568 | elapsed time per iteration (ms): 37709.9 | learning rate: 5.185E-05 | global batch size:  1024 | lm loss: 1.826342E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38108/   51900 | consumed samples:     39022592 | elapsed time per iteration (ms): 37633.8 | learning rate: 5.185E-05 | global batch size:  1024 | lm loss: 1.786188E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38109/   51900 | consumed samples:     39023616 | elapsed time per iteration (ms): 37698.5 | learning rate: 5.185E-05 | global batch size:  1024 | lm loss: 1.801533E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38110/   51900 | consumed samples:     39024640 | elapsed time per iteration (ms): 37661.0 | learning rate: 5.184E-05 | global batch size:  1024 | lm loss: 1.806037E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38111/   51900 | consumed samples:     39025664 | elapsed time per iteration (ms): 37661.9 | learning rate: 5.184E-05 | global batch size:  1024 | lm loss: 1.800009E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38112/   51900 | consumed samples:     39026688 | elapsed time per iteration (ms): 37590.4 | learning rate: 5.183E-05 | global batch size:  1024 | lm loss: 1.807032E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38113/   51900 | consumed samples:     39027712 | elapsed time per iteration (ms): 37742.1 | learning rate: 5.183E-05 | global batch size:  1024 | lm loss: 1.807410E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38114/   51900 | consumed samples:     39028736 | elapsed time per iteration (ms): 37670.5 | learning rate: 5.182E-05 | global batch size:  1024 | lm loss: 1.816135E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38115/   51900 | consumed samples:     39029760 | elapsed time per iteration (ms): 37749.7 | learning rate: 5.182E-05 | global batch size:  1024 | lm loss: 1.801643E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38116/   51900 | consumed samples:     39030784 | elapsed time per iteration (ms): 37715.4 | learning rate: 5.182E-05 | global batch size:  1024 | lm loss: 1.791281E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38117/   51900 | consumed samples:     39031808 | elapsed time per iteration (ms): 37525.9 | learning rate: 5.181E-05 | global batch size:  1024 | lm loss: 1.814632E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38118/   51900 | consumed samples:     39032832 | elapsed time per iteration (ms): 37587.2 | learning rate: 5.181E-05 | global batch size:  1024 | lm loss: 1.803427E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38119/   51900 | consumed samples:     39033856 | elapsed time per iteration (ms): 37689.2 | learning rate: 5.180E-05 | global batch size:  1024 | lm loss: 1.797202E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38120/   51900 | consumed samples:     39034880 | elapsed time per iteration (ms): 37684.7 | learning rate: 5.180E-05 | global batch size:  1024 | lm loss: 1.801705E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38121/   51900 | consumed samples:     39035904 | elapsed time per iteration (ms): 37746.6 | learning rate: 5.179E-05 | global batch size:  1024 | lm loss: 1.796709E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38122/   51900 | consumed samples:     39036928 | elapsed time per iteration (ms): 37620.1 | learning rate: 5.179E-05 | global batch size:  1024 | lm loss: 1.801244E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38123/   51900 | consumed samples:     39037952 | elapsed time per iteration (ms): 37626.3 | learning rate: 5.178E-05 | global batch size:  1024 | lm loss: 1.801004E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38124/   51900 | consumed samples:     39038976 | elapsed time per iteration (ms): 37628.4 | learning rate: 5.178E-05 | global batch size:  1024 | lm loss: 1.821590E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38125/   51900 | consumed samples:     39040000 | elapsed time per iteration (ms): 37579.9 | learning rate: 5.178E-05 | global batch size:  1024 | lm loss: 1.803649E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38126/   51900 | consumed samples:     39041024 | elapsed time per iteration (ms): 37621.9 | learning rate: 5.177E-05 | global batch size:  1024 | lm loss: 1.791495E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38127/   51900 | consumed samples:     39042048 | elapsed time per iteration (ms): 37734.8 | learning rate: 5.177E-05 | global batch size:  1024 | lm loss: 1.797116E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38128/   51900 | consumed samples:     39043072 | elapsed time per iteration (ms): 37757.7 | learning rate: 5.176E-05 | global batch size:  1024 | lm loss: 1.792632E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38129/   51900 | consumed samples:     39044096 | elapsed time per iteration (ms): 37675.2 | learning rate: 5.176E-05 | global batch size:  1024 | lm loss: 1.821477E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38130/   51900 | consumed samples:     39045120 | elapsed time per iteration (ms): 37653.8 | learning rate: 5.175E-05 | global batch size:  1024 | lm loss: 1.812207E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38131/   51900 | consumed samples:     39046144 | elapsed time per iteration (ms): 37630.8 | learning rate: 5.175E-05 | global batch size:  1024 | lm loss: 1.807436E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38132/   51900 | consumed samples:     39047168 | elapsed time per iteration (ms): 37598.4 | learning rate: 5.175E-05 | global batch size:  1024 | lm loss: 1.793357E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38133/   51900 | consumed samples:     39048192 | elapsed time per iteration (ms): 37684.6 | learning rate: 5.174E-05 | global batch size:  1024 | lm loss: 1.806337E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38134/   51900 | consumed samples:     39049216 | elapsed time per iteration (ms): 37607.0 | learning rate: 5.174E-05 | global batch size:  1024 | lm loss: 1.825346E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38135/   51900 | consumed samples:     39050240 | elapsed time per iteration (ms): 37661.9 | learning rate: 5.173E-05 | global batch size:  1024 | lm loss: 1.810471E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38136/   51900 | consumed samples:     39051264 | elapsed time per iteration (ms): 37656.7 | learning rate: 5.173E-05 | global batch size:  1024 | lm loss: 1.792169E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38137/   51900 | consumed samples:     39052288 | elapsed time per iteration (ms): 37577.3 | learning rate: 5.172E-05 | global batch size:  1024 | lm loss: 1.798860E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38138/   51900 | consumed samples:     39053312 | elapsed time per iteration (ms): 37681.0 | learning rate: 5.172E-05 | global batch size:  1024 | lm loss: 1.803199E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38139/   51900 | consumed samples:     39054336 | elapsed time per iteration (ms): 37687.9 | learning rate: 5.172E-05 | global batch size:  1024 | lm loss: 1.807861E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38140/   51900 | consumed samples:     39055360 | elapsed time per iteration (ms): 37567.8 | learning rate: 5.171E-05 | global batch size:  1024 | lm loss: 1.809103E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38141/   51900 | consumed samples:     39056384 | elapsed time per iteration (ms): 37748.7 | learning rate: 5.171E-05 | global batch size:  1024 | lm loss: 1.792713E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38142/   51900 | consumed samples:     39057408 | elapsed time per iteration (ms): 37750.4 | learning rate: 5.170E-05 | global batch size:  1024 | lm loss: 1.809945E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38143/   51900 | consumed samples:     39058432 | elapsed time per iteration (ms): 37818.3 | learning rate: 5.170E-05 | global batch size:  1024 | lm loss: 1.802152E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38144/   51900 | consumed samples:     39059456 | elapsed time per iteration (ms): 37604.1 | learning rate: 5.169E-05 | global batch size:  1024 | lm loss: 1.804334E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38145/   51900 | consumed samples:     39060480 | elapsed time per iteration (ms): 37616.9 | learning rate: 5.169E-05 | global batch size:  1024 | lm loss: 1.803407E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38146/   51900 | consumed samples:     39061504 | elapsed time per iteration (ms): 37563.5 | learning rate: 5.169E-05 | global batch size:  1024 | lm loss: 1.811210E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38147/   51900 | consumed samples:     39062528 | elapsed time per iteration (ms): 37721.7 | learning rate: 5.168E-05 | global batch size:  1024 | lm loss: 1.813824E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38148/   51900 | consumed samples:     39063552 | elapsed time per iteration (ms): 37738.8 | learning rate: 5.168E-05 | global batch size:  1024 | lm loss: 1.794870E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38149/   51900 | consumed samples:     39064576 | elapsed time per iteration (ms): 37588.4 | learning rate: 5.167E-05 | global batch size:  1024 | lm loss: 1.806483E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38150/   51900 | consumed samples:     39065600 | elapsed time per iteration (ms): 37599.1 | learning rate: 5.167E-05 | global batch size:  1024 | lm loss: 1.798912E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38151/   51900 | consumed samples:     39066624 | elapsed time per iteration (ms): 37748.7 | learning rate: 5.166E-05 | global batch size:  1024 | lm loss: 1.799268E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38152/   51900 | consumed samples:     39067648 | elapsed time per iteration (ms): 37714.2 | learning rate: 5.166E-05 | global batch size:  1024 | lm loss: 1.792849E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38153/   51900 | consumed samples:     39068672 | elapsed time per iteration (ms): 37587.8 | learning rate: 5.166E-05 | global batch size:  1024 | lm loss: 1.801472E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38154/   51900 | consumed samples:     39069696 | elapsed time per iteration (ms): 37747.0 | learning rate: 5.165E-05 | global batch size:  1024 | lm loss: 1.799612E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38155/   51900 | consumed samples:     39070720 | elapsed time per iteration (ms): 37722.5 | learning rate: 5.165E-05 | global batch size:  1024 | lm loss: 1.823789E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38156/   51900 | consumed samples:     39071744 | elapsed time per iteration (ms): 37619.4 | learning rate: 5.164E-05 | global batch size:  1024 | lm loss: 1.812555E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38157/   51900 | consumed samples:     39072768 | elapsed time per iteration (ms): 37736.2 | learning rate: 5.164E-05 | global batch size:  1024 | lm loss: 1.806766E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38158/   51900 | consumed samples:     39073792 | elapsed time per iteration (ms): 37671.0 | learning rate: 5.163E-05 | global batch size:  1024 | lm loss: 1.817747E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38159/   51900 | consumed samples:     39074816 | elapsed time per iteration (ms): 37677.4 | learning rate: 5.163E-05 | global batch size:  1024 | lm loss: 1.808601E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38160/   51900 | consumed samples:     39075840 | elapsed time per iteration (ms): 37695.6 | learning rate: 5.163E-05 | global batch size:  1024 | lm loss: 1.813193E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38161/   51900 | consumed samples:     39076864 | elapsed time per iteration (ms): 37697.9 | learning rate: 5.162E-05 | global batch size:  1024 | lm loss: 1.799670E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38162/   51900 | consumed samples:     39077888 | elapsed time per iteration (ms): 37580.8 | learning rate: 5.162E-05 | global batch size:  1024 | lm loss: 1.807879E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38163/   51900 | consumed samples:     39078912 | elapsed time per iteration (ms): 37754.8 | learning rate: 5.161E-05 | global batch size:  1024 | lm loss: 1.786284E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38164/   51900 | consumed samples:     39079936 | elapsed time per iteration (ms): 37633.6 | learning rate: 5.161E-05 | global batch size:  1024 | lm loss: 1.798046E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38165/   51900 | consumed samples:     39080960 | elapsed time per iteration (ms): 37610.8 | learning rate: 5.160E-05 | global batch size:  1024 | lm loss: 1.807799E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38166/   51900 | consumed samples:     39081984 | elapsed time per iteration (ms): 37598.1 | learning rate: 5.160E-05 | global batch size:  1024 | lm loss: 1.801596E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38167/   51900 | consumed samples:     39083008 | elapsed time per iteration (ms): 37632.1 | learning rate: 5.159E-05 | global batch size:  1024 | lm loss: 1.803414E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38168/   51900 | consumed samples:     39084032 | elapsed time per iteration (ms): 37738.8 | learning rate: 5.159E-05 | global batch size:  1024 | lm loss: 1.781134E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38169/   51900 | consumed samples:     39085056 | elapsed time per iteration (ms): 37692.4 | learning rate: 5.159E-05 | global batch size:  1024 | lm loss: 1.805403E+00 | loss scale: 1.0 | grad norm: 0.065 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38170/   51900 | consumed samples:     39086080 | elapsed time per iteration (ms): 37719.8 | learning rate: 5.158E-05 | global batch size:  1024 | lm loss: 1.791817E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38171/   51900 | consumed samples:     39087104 | elapsed time per iteration (ms): 37523.6 | learning rate: 5.158E-05 | global batch size:  1024 | lm loss: 1.816013E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38172/   51900 | consumed samples:     39088128 | elapsed time per iteration (ms): 37660.0 | learning rate: 5.157E-05 | global batch size:  1024 | lm loss: 1.799341E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38173/   51900 | consumed samples:     39089152 | elapsed time per iteration (ms): 37628.0 | learning rate: 5.157E-05 | global batch size:  1024 | lm loss: 1.813309E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38174/   51900 | consumed samples:     39090176 | elapsed time per iteration (ms): 37621.9 | learning rate: 5.156E-05 | global batch size:  1024 | lm loss: 1.797026E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38175/   51900 | consumed samples:     39091200 | elapsed time per iteration (ms): 37628.9 | learning rate: 5.156E-05 | global batch size:  1024 | lm loss: 1.818391E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38176/   51900 | consumed samples:     39092224 | elapsed time per iteration (ms): 37751.3 | learning rate: 5.156E-05 | global batch size:  1024 | lm loss: 1.804191E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38177/   51900 | consumed samples:     39093248 | elapsed time per iteration (ms): 37713.9 | learning rate: 5.155E-05 | global batch size:  1024 | lm loss: 1.807267E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38178/   51900 | consumed samples:     39094272 | elapsed time per iteration (ms): 37586.5 | learning rate: 5.155E-05 | global batch size:  1024 | lm loss: 1.782767E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38179/   51900 | consumed samples:     39095296 | elapsed time per iteration (ms): 37737.1 | learning rate: 5.154E-05 | global batch size:  1024 | lm loss: 1.820766E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38180/   51900 | consumed samples:     39096320 | elapsed time per iteration (ms): 37658.2 | learning rate: 5.154E-05 | global batch size:  1024 | lm loss: 1.826558E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38181/   51900 | consumed samples:     39097344 | elapsed time per iteration (ms): 37606.0 | learning rate: 5.153E-05 | global batch size:  1024 | lm loss: 1.798933E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38182/   51900 | consumed samples:     39098368 | elapsed time per iteration (ms): 37779.3 | learning rate: 5.153E-05 | global batch size:  1024 | lm loss: 1.835284E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38183/   51900 | consumed samples:     39099392 | elapsed time per iteration (ms): 37730.5 | learning rate: 5.153E-05 | global batch size:  1024 | lm loss: 1.813462E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38184/   51900 | consumed samples:     39100416 | elapsed time per iteration (ms): 37727.2 | learning rate: 5.152E-05 | global batch size:  1024 | lm loss: 1.797830E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38185/   51900 | consumed samples:     39101440 | elapsed time per iteration (ms): 37820.4 | learning rate: 5.152E-05 | global batch size:  1024 | lm loss: 1.808842E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38186/   51900 | consumed samples:     39102464 | elapsed time per iteration (ms): 37779.0 | learning rate: 5.151E-05 | global batch size:  1024 | lm loss: 1.797877E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38187/   51900 | consumed samples:     39103488 | elapsed time per iteration (ms): 37748.6 | learning rate: 5.151E-05 | global batch size:  1024 | lm loss: 1.787633E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38188/   51900 | consumed samples:     39104512 | elapsed time per iteration (ms): 37586.4 | learning rate: 5.150E-05 | global batch size:  1024 | lm loss: 1.800159E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38189/   51900 | consumed samples:     39105536 | elapsed time per iteration (ms): 37620.6 | learning rate: 5.150E-05 | global batch size:  1024 | lm loss: 1.818697E+00 | loss scale: 1.0 | grad norm: 0.065 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38190/   51900 | consumed samples:     39106560 | elapsed time per iteration (ms): 37751.9 | learning rate: 5.150E-05 | global batch size:  1024 | lm loss: 1.808507E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38191/   51900 | consumed samples:     39107584 | elapsed time per iteration (ms): 37644.2 | learning rate: 5.149E-05 | global batch size:  1024 | lm loss: 1.807660E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38192/   51900 | consumed samples:     39108608 | elapsed time per iteration (ms): 37706.9 | learning rate: 5.149E-05 | global batch size:  1024 | lm loss: 1.797328E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38193/   51900 | consumed samples:     39109632 | elapsed time per iteration (ms): 37614.9 | learning rate: 5.148E-05 | global batch size:  1024 | lm loss: 1.823792E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38194/   51900 | consumed samples:     39110656 | elapsed time per iteration (ms): 37682.3 | learning rate: 5.148E-05 | global batch size:  1024 | lm loss: 1.805746E+00 | loss scale: 1.0 | grad norm: 0.065 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38195/   51900 | consumed samples:     39111680 | elapsed time per iteration (ms): 37684.9 | learning rate: 5.147E-05 | global batch size:  1024 | lm loss: 1.806125E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38196/   51900 | consumed samples:     39112704 | elapsed time per iteration (ms): 37766.5 | learning rate: 5.147E-05 | global batch size:  1024 | lm loss: 1.799477E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38197/   51900 | consumed samples:     39113728 | elapsed time per iteration (ms): 37731.4 | learning rate: 5.147E-05 | global batch size:  1024 | lm loss: 1.811750E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38198/   51900 | consumed samples:     39114752 | elapsed time per iteration (ms): 37635.2 | learning rate: 5.146E-05 | global batch size:  1024 | lm loss: 1.798729E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38199/   51900 | consumed samples:     39115776 | elapsed time per iteration (ms): 37683.2 | learning rate: 5.146E-05 | global batch size:  1024 | lm loss: 1.805938E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38200/   51900 | consumed samples:     39116800 | elapsed time per iteration (ms): 37677.9 | learning rate: 5.145E-05 | global batch size:  1024 | lm loss: 1.806041E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38201/   51900 | consumed samples:     39117824 | elapsed time per iteration (ms): 37641.4 | learning rate: 5.145E-05 | global batch size:  1024 | lm loss: 1.804057E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38202/   51900 | consumed samples:     39118848 | elapsed time per iteration (ms): 37755.5 | learning rate: 5.144E-05 | global batch size:  1024 | lm loss: 1.803088E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38203/   51900 | consumed samples:     39119872 | elapsed time per iteration (ms): 37659.1 | learning rate: 5.144E-05 | global batch size:  1024 | lm loss: 1.809641E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38204/   51900 | consumed samples:     39120896 | elapsed time per iteration (ms): 37682.5 | learning rate: 5.144E-05 | global batch size:  1024 | lm loss: 1.806495E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38205/   51900 | consumed samples:     39121920 | elapsed time per iteration (ms): 37626.4 | learning rate: 5.143E-05 | global batch size:  1024 | lm loss: 1.793959E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38206/   51900 | consumed samples:     39122944 | elapsed time per iteration (ms): 37646.9 | learning rate: 5.143E-05 | global batch size:  1024 | lm loss: 1.798096E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38207/   51900 | consumed samples:     39123968 | elapsed time per iteration (ms): 37663.2 | learning rate: 5.142E-05 | global batch size:  1024 | lm loss: 1.808468E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38208/   51900 | consumed samples:     39124992 | elapsed time per iteration (ms): 37795.1 | learning rate: 5.142E-05 | global batch size:  1024 | lm loss: 1.788446E+00 | loss scale: 1.0 | grad norm: 0.064 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38209/   51900 | consumed samples:     39126016 | elapsed time per iteration (ms): 37793.9 | learning rate: 5.141E-05 | global batch size:  1024 | lm loss: 1.807246E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38210/   51900 | consumed samples:     39127040 | elapsed time per iteration (ms): 37762.8 | learning rate: 5.141E-05 | global batch size:  1024 | lm loss: 1.816856E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38211/   51900 | consumed samples:     39128064 | elapsed time per iteration (ms): 37671.3 | learning rate: 5.141E-05 | global batch size:  1024 | lm loss: 1.807239E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38212/   51900 | consumed samples:     39129088 | elapsed time per iteration (ms): 37625.7 | learning rate: 5.140E-05 | global batch size:  1024 | lm loss: 1.808712E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38213/   51900 | consumed samples:     39130112 | elapsed time per iteration (ms): 37648.6 | learning rate: 5.140E-05 | global batch size:  1024 | lm loss: 1.807724E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38214/   51900 | consumed samples:     39131136 | elapsed time per iteration (ms): 37634.5 | learning rate: 5.139E-05 | global batch size:  1024 | lm loss: 1.794183E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38215/   51900 | consumed samples:     39132160 | elapsed time per iteration (ms): 37709.3 | learning rate: 5.139E-05 | global batch size:  1024 | lm loss: 1.810509E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38216/   51900 | consumed samples:     39133184 | elapsed time per iteration (ms): 37635.8 | learning rate: 5.138E-05 | global batch size:  1024 | lm loss: 1.802652E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38217/   51900 | consumed samples:     39134208 | elapsed time per iteration (ms): 37571.6 | learning rate: 5.138E-05 | global batch size:  1024 | lm loss: 1.832211E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38218/   51900 | consumed samples:     39135232 | elapsed time per iteration (ms): 37751.1 | learning rate: 5.138E-05 | global batch size:  1024 | lm loss: 1.792657E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38219/   51900 | consumed samples:     39136256 | elapsed time per iteration (ms): 37735.6 | learning rate: 5.137E-05 | global batch size:  1024 | lm loss: 1.805947E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38220/   51900 | consumed samples:     39137280 | elapsed time per iteration (ms): 37780.8 | learning rate: 5.137E-05 | global batch size:  1024 | lm loss: 1.774309E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38221/   51900 | consumed samples:     39138304 | elapsed time per iteration (ms): 37648.3 | learning rate: 5.136E-05 | global batch size:  1024 | lm loss: 1.789616E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38222/   51900 | consumed samples:     39139328 | elapsed time per iteration (ms): 37690.3 | learning rate: 5.136E-05 | global batch size:  1024 | lm loss: 1.808736E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38223/   51900 | consumed samples:     39140352 | elapsed time per iteration (ms): 37597.1 | learning rate: 5.135E-05 | global batch size:  1024 | lm loss: 1.780374E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38224/   51900 | consumed samples:     39141376 | elapsed time per iteration (ms): 37659.7 | learning rate: 5.135E-05 | global batch size:  1024 | lm loss: 1.802304E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38225/   51900 | consumed samples:     39142400 | elapsed time per iteration (ms): 37701.1 | learning rate: 5.135E-05 | global batch size:  1024 | lm loss: 1.819811E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38226/   51900 | consumed samples:     39143424 | elapsed time per iteration (ms): 37760.9 | learning rate: 5.134E-05 | global batch size:  1024 | lm loss: 1.828291E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38227/   51900 | consumed samples:     39144448 | elapsed time per iteration (ms): 37600.0 | learning rate: 5.134E-05 | global batch size:  1024 | lm loss: 1.791214E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38228/   51900 | consumed samples:     39145472 | elapsed time per iteration (ms): 37680.1 | learning rate: 5.133E-05 | global batch size:  1024 | lm loss: 1.826217E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38229/   51900 | consumed samples:     39146496 | elapsed time per iteration (ms): 37633.6 | learning rate: 5.133E-05 | global batch size:  1024 | lm loss: 1.803275E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38230/   51900 | consumed samples:     39147520 | elapsed time per iteration (ms): 37655.7 | learning rate: 5.132E-05 | global batch size:  1024 | lm loss: 1.801801E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38231/   51900 | consumed samples:     39148544 | elapsed time per iteration (ms): 37579.7 | learning rate: 5.132E-05 | global batch size:  1024 | lm loss: 1.808260E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38232/   51900 | consumed samples:     39149568 | elapsed time per iteration (ms): 37658.7 | learning rate: 5.132E-05 | global batch size:  1024 | lm loss: 1.809724E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38233/   51900 | consumed samples:     39150592 | elapsed time per iteration (ms): 37727.2 | learning rate: 5.131E-05 | global batch size:  1024 | lm loss: 1.820684E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38234/   51900 | consumed samples:     39151616 | elapsed time per iteration (ms): 37677.9 | learning rate: 5.131E-05 | global batch size:  1024 | lm loss: 1.823579E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38235/   51900 | consumed samples:     39152640 | elapsed time per iteration (ms): 37602.5 | learning rate: 5.130E-05 | global batch size:  1024 | lm loss: 1.786689E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38236/   51900 | consumed samples:     39153664 | elapsed time per iteration (ms): 37747.0 | learning rate: 5.130E-05 | global batch size:  1024 | lm loss: 1.795956E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38237/   51900 | consumed samples:     39154688 | elapsed time per iteration (ms): 37633.2 | learning rate: 5.129E-05 | global batch size:  1024 | lm loss: 1.818761E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38238/   51900 | consumed samples:     39155712 | elapsed time per iteration (ms): 37680.7 | learning rate: 5.129E-05 | global batch size:  1024 | lm loss: 1.782970E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38239/   51900 | consumed samples:     39156736 | elapsed time per iteration (ms): 37678.5 | learning rate: 5.129E-05 | global batch size:  1024 | lm loss: 1.790006E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38240/   51900 | consumed samples:     39157760 | elapsed time per iteration (ms): 37697.7 | learning rate: 5.128E-05 | global batch size:  1024 | lm loss: 1.793719E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38241/   51900 | consumed samples:     39158784 | elapsed time per iteration (ms): 37626.6 | learning rate: 5.128E-05 | global batch size:  1024 | lm loss: 1.799574E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38242/   51900 | consumed samples:     39159808 | elapsed time per iteration (ms): 37597.0 | learning rate: 5.127E-05 | global batch size:  1024 | lm loss: 1.816834E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38243/   51900 | consumed samples:     39160832 | elapsed time per iteration (ms): 37751.1 | learning rate: 5.127E-05 | global batch size:  1024 | lm loss: 1.816014E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38244/   51900 | consumed samples:     39161856 | elapsed time per iteration (ms): 37616.7 | learning rate: 5.126E-05 | global batch size:  1024 | lm loss: 1.796810E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38245/   51900 | consumed samples:     39162880 | elapsed time per iteration (ms): 37645.6 | learning rate: 5.126E-05 | global batch size:  1024 | lm loss: 1.798680E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38246/   51900 | consumed samples:     39163904 | elapsed time per iteration (ms): 37639.8 | learning rate: 5.126E-05 | global batch size:  1024 | lm loss: 1.781866E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38247/   51900 | consumed samples:     39164928 | elapsed time per iteration (ms): 37652.8 | learning rate: 5.125E-05 | global batch size:  1024 | lm loss: 1.813742E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38248/   51900 | consumed samples:     39165952 | elapsed time per iteration (ms): 37704.8 | learning rate: 5.125E-05 | global batch size:  1024 | lm loss: 1.785147E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38249/   51900 | consumed samples:     39166976 | elapsed time per iteration (ms): 37761.8 | learning rate: 5.124E-05 | global batch size:  1024 | lm loss: 1.796316E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38250/   51900 | consumed samples:     39168000 | elapsed time per iteration (ms): 37635.1 | learning rate: 5.124E-05 | global batch size:  1024 | lm loss: 1.809325E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38251/   51900 | consumed samples:     39169024 | elapsed time per iteration (ms): 37669.4 | learning rate: 5.123E-05 | global batch size:  1024 | lm loss: 1.795724E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38252/   51900 | consumed samples:     39170048 | elapsed time per iteration (ms): 37672.9 | learning rate: 5.123E-05 | global batch size:  1024 | lm loss: 1.819271E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38253/   51900 | consumed samples:     39171072 | elapsed time per iteration (ms): 37635.6 | learning rate: 5.123E-05 | global batch size:  1024 | lm loss: 1.781311E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38254/   51900 | consumed samples:     39172096 | elapsed time per iteration (ms): 37666.9 | learning rate: 5.122E-05 | global batch size:  1024 | lm loss: 1.793970E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38255/   51900 | consumed samples:     39173120 | elapsed time per iteration (ms): 37655.1 | learning rate: 5.122E-05 | global batch size:  1024 | lm loss: 1.805285E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38256/   51900 | consumed samples:     39174144 | elapsed time per iteration (ms): 37609.7 | learning rate: 5.121E-05 | global batch size:  1024 | lm loss: 1.799841E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38257/   51900 | consumed samples:     39175168 | elapsed time per iteration (ms): 37704.2 | learning rate: 5.121E-05 | global batch size:  1024 | lm loss: 1.817621E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38258/   51900 | consumed samples:     39176192 | elapsed time per iteration (ms): 37661.2 | learning rate: 5.120E-05 | global batch size:  1024 | lm loss: 1.810434E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38259/   51900 | consumed samples:     39177216 | elapsed time per iteration (ms): 37624.1 | learning rate: 5.120E-05 | global batch size:  1024 | lm loss: 1.801862E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38260/   51900 | consumed samples:     39178240 | elapsed time per iteration (ms): 37675.9 | learning rate: 5.120E-05 | global batch size:  1024 | lm loss: 1.808204E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38261/   51900 | consumed samples:     39179264 | elapsed time per iteration (ms): 37633.2 | learning rate: 5.119E-05 | global batch size:  1024 | lm loss: 1.806743E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38262/   51900 | consumed samples:     39180288 | elapsed time per iteration (ms): 37751.7 | learning rate: 5.119E-05 | global batch size:  1024 | lm loss: 1.793699E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38263/   51900 | consumed samples:     39181312 | elapsed time per iteration (ms): 37720.0 | learning rate: 5.118E-05 | global batch size:  1024 | lm loss: 1.806017E+00 | loss scale: 1.0 | grad norm: 0.101 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38264/   51900 | consumed samples:     39182336 | elapsed time per iteration (ms): 37632.8 | learning rate: 5.118E-05 | global batch size:  1024 | lm loss: 1.799640E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38265/   51900 | consumed samples:     39183360 | elapsed time per iteration (ms): 37789.7 | learning rate: 5.117E-05 | global batch size:  1024 | lm loss: 1.808713E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38266/   51900 | consumed samples:     39184384 | elapsed time per iteration (ms): 37695.0 | learning rate: 5.117E-05 | global batch size:  1024 | lm loss: 1.806146E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38267/   51900 | consumed samples:     39185408 | elapsed time per iteration (ms): 37660.8 | learning rate: 5.116E-05 | global batch size:  1024 | lm loss: 1.808205E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38268/   51900 | consumed samples:     39186432 | elapsed time per iteration (ms): 37721.0 | learning rate: 5.116E-05 | global batch size:  1024 | lm loss: 1.805755E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38269/   51900 | consumed samples:     39187456 | elapsed time per iteration (ms): 37621.2 | learning rate: 5.116E-05 | global batch size:  1024 | lm loss: 1.801195E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38270/   51900 | consumed samples:     39188480 | elapsed time per iteration (ms): 37685.1 | learning rate: 5.115E-05 | global batch size:  1024 | lm loss: 1.806664E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38271/   51900 | consumed samples:     39189504 | elapsed time per iteration (ms): 37680.8 | learning rate: 5.115E-05 | global batch size:  1024 | lm loss: 1.814174E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38272/   51900 | consumed samples:     39190528 | elapsed time per iteration (ms): 37694.7 | learning rate: 5.114E-05 | global batch size:  1024 | lm loss: 1.783621E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38273/   51900 | consumed samples:     39191552 | elapsed time per iteration (ms): 37730.1 | learning rate: 5.114E-05 | global batch size:  1024 | lm loss: 1.786948E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38274/   51900 | consumed samples:     39192576 | elapsed time per iteration (ms): 37685.6 | learning rate: 5.113E-05 | global batch size:  1024 | lm loss: 1.797044E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38275/   51900 | consumed samples:     39193600 | elapsed time per iteration (ms): 37682.8 | learning rate: 5.113E-05 | global batch size:  1024 | lm loss: 1.799755E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38276/   51900 | consumed samples:     39194624 | elapsed time per iteration (ms): 37747.9 | learning rate: 5.113E-05 | global batch size:  1024 | lm loss: 1.787273E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38277/   51900 | consumed samples:     39195648 | elapsed time per iteration (ms): 37685.0 | learning rate: 5.112E-05 | global batch size:  1024 | lm loss: 1.781659E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38278/   51900 | consumed samples:     39196672 | elapsed time per iteration (ms): 37585.3 | learning rate: 5.112E-05 | global batch size:  1024 | lm loss: 1.804181E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38279/   51900 | consumed samples:     39197696 | elapsed time per iteration (ms): 37636.0 | learning rate: 5.111E-05 | global batch size:  1024 | lm loss: 1.811411E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38280/   51900 | consumed samples:     39198720 | elapsed time per iteration (ms): 37709.1 | learning rate: 5.111E-05 | global batch size:  1024 | lm loss: 1.784238E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38281/   51900 | consumed samples:     39199744 | elapsed time per iteration (ms): 37644.3 | learning rate: 5.110E-05 | global batch size:  1024 | lm loss: 1.800285E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38282/   51900 | consumed samples:     39200768 | elapsed time per iteration (ms): 37658.2 | learning rate: 5.110E-05 | global batch size:  1024 | lm loss: 1.808597E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38283/   51900 | consumed samples:     39201792 | elapsed time per iteration (ms): 37766.8 | learning rate: 5.110E-05 | global batch size:  1024 | lm loss: 1.786383E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38284/   51900 | consumed samples:     39202816 | elapsed time per iteration (ms): 37726.3 | learning rate: 5.109E-05 | global batch size:  1024 | lm loss: 1.817326E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38285/   51900 | consumed samples:     39203840 | elapsed time per iteration (ms): 37709.6 | learning rate: 5.109E-05 | global batch size:  1024 | lm loss: 1.808595E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38286/   51900 | consumed samples:     39204864 | elapsed time per iteration (ms): 37720.5 | learning rate: 5.108E-05 | global batch size:  1024 | lm loss: 1.804489E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38287/   51900 | consumed samples:     39205888 | elapsed time per iteration (ms): 37711.4 | learning rate: 5.108E-05 | global batch size:  1024 | lm loss: 1.790726E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38288/   51900 | consumed samples:     39206912 | elapsed time per iteration (ms): 37691.0 | learning rate: 5.107E-05 | global batch size:  1024 | lm loss: 1.791924E+00 | loss scale: 1.0 | grad norm: 0.064 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38289/   51900 | consumed samples:     39207936 | elapsed time per iteration (ms): 37717.2 | learning rate: 5.107E-05 | global batch size:  1024 | lm loss: 1.795690E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38290/   51900 | consumed samples:     39208960 | elapsed time per iteration (ms): 37744.9 | learning rate: 5.107E-05 | global batch size:  1024 | lm loss: 1.815578E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38291/   51900 | consumed samples:     39209984 | elapsed time per iteration (ms): 37663.6 | learning rate: 5.106E-05 | global batch size:  1024 | lm loss: 1.794149E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38292/   51900 | consumed samples:     39211008 | elapsed time per iteration (ms): 37703.5 | learning rate: 5.106E-05 | global batch size:  1024 | lm loss: 1.787674E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38293/   51900 | consumed samples:     39212032 | elapsed time per iteration (ms): 37727.8 | learning rate: 5.105E-05 | global batch size:  1024 | lm loss: 1.800902E+00 | loss scale: 1.0 | grad norm: 0.065 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38294/   51900 | consumed samples:     39213056 | elapsed time per iteration (ms): 37709.1 | learning rate: 5.105E-05 | global batch size:  1024 | lm loss: 1.811308E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38295/   51900 | consumed samples:     39214080 | elapsed time per iteration (ms): 37645.1 | learning rate: 5.105E-05 | global batch size:  1024 | lm loss: 1.808583E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38296/   51900 | consumed samples:     39215104 | elapsed time per iteration (ms): 37583.2 | learning rate: 5.104E-05 | global batch size:  1024 | lm loss: 1.790563E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38297/   51900 | consumed samples:     39216128 | elapsed time per iteration (ms): 37692.8 | learning rate: 5.104E-05 | global batch size:  1024 | lm loss: 1.788510E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38298/   51900 | consumed samples:     39217152 | elapsed time per iteration (ms): 37683.2 | learning rate: 5.103E-05 | global batch size:  1024 | lm loss: 1.804882E+00 | loss scale: 1.0 | grad norm: 0.065 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38299/   51900 | consumed samples:     39218176 | elapsed time per iteration (ms): 37662.6 | learning rate: 5.103E-05 | global batch size:  1024 | lm loss: 1.817513E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38300/   51900 | consumed samples:     39219200 | elapsed time per iteration (ms): 37666.3 | learning rate: 5.102E-05 | global batch size:  1024 | lm loss: 1.798596E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38301/   51900 | consumed samples:     39220224 | elapsed time per iteration (ms): 37711.5 | learning rate: 5.102E-05 | global batch size:  1024 | lm loss: 1.814432E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38302/   51900 | consumed samples:     39221248 | elapsed time per iteration (ms): 37669.3 | learning rate: 5.102E-05 | global batch size:  1024 | lm loss: 1.786769E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38303/   51900 | consumed samples:     39222272 | elapsed time per iteration (ms): 37638.3 | learning rate: 5.101E-05 | global batch size:  1024 | lm loss: 1.802477E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38304/   51900 | consumed samples:     39223296 | elapsed time per iteration (ms): 37816.8 | learning rate: 5.101E-05 | global batch size:  1024 | lm loss: 1.798748E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38305/   51900 | consumed samples:     39224320 | elapsed time per iteration (ms): 37781.8 | learning rate: 5.100E-05 | global batch size:  1024 | lm loss: 1.805816E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38306/   51900 | consumed samples:     39225344 | elapsed time per iteration (ms): 37652.5 | learning rate: 5.100E-05 | global batch size:  1024 | lm loss: 1.796654E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38307/   51900 | consumed samples:     39226368 | elapsed time per iteration (ms): 37624.8 | learning rate: 5.099E-05 | global batch size:  1024 | lm loss: 1.816662E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38308/   51900 | consumed samples:     39227392 | elapsed time per iteration (ms): 37752.3 | learning rate: 5.099E-05 | global batch size:  1024 | lm loss: 1.790919E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38309/   51900 | consumed samples:     39228416 | elapsed time per iteration (ms): 37656.5 | learning rate: 5.099E-05 | global batch size:  1024 | lm loss: 1.802260E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38310/   51900 | consumed samples:     39229440 | elapsed time per iteration (ms): 37662.0 | learning rate: 5.098E-05 | global batch size:  1024 | lm loss: 1.807937E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38311/   51900 | consumed samples:     39230464 | elapsed time per iteration (ms): 37710.5 | learning rate: 5.098E-05 | global batch size:  1024 | lm loss: 1.797972E+00 | loss scale: 1.0 | grad norm: 0.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38312/   51900 | consumed samples:     39231488 | elapsed time per iteration (ms): 37666.7 | learning rate: 5.097E-05 | global batch size:  1024 | lm loss: 1.803042E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38313/   51900 | consumed samples:     39232512 | elapsed time per iteration (ms): 37631.8 | learning rate: 5.097E-05 | global batch size:  1024 | lm loss: 1.795657E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38314/   51900 | consumed samples:     39233536 | elapsed time per iteration (ms): 37811.2 | learning rate: 5.096E-05 | global batch size:  1024 | lm loss: 1.802846E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38315/   51900 | consumed samples:     39234560 | elapsed time per iteration (ms): 37697.9 | learning rate: 5.096E-05 | global batch size:  1024 | lm loss: 1.801651E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38316/   51900 | consumed samples:     39235584 | elapsed time per iteration (ms): 37650.4 | learning rate: 5.096E-05 | global batch size:  1024 | lm loss: 1.801268E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38317/   51900 | consumed samples:     39236608 | elapsed time per iteration (ms): 37711.8 | learning rate: 5.095E-05 | global batch size:  1024 | lm loss: 1.802380E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38318/   51900 | consumed samples:     39237632 | elapsed time per iteration (ms): 37808.7 | learning rate: 5.095E-05 | global batch size:  1024 | lm loss: 1.793749E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38319/   51900 | consumed samples:     39238656 | elapsed time per iteration (ms): 37707.7 | learning rate: 5.094E-05 | global batch size:  1024 | lm loss: 1.808848E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38320/   51900 | consumed samples:     39239680 | elapsed time per iteration (ms): 37654.6 | learning rate: 5.094E-05 | global batch size:  1024 | lm loss: 1.802725E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38321/   51900 | consumed samples:     39240704 | elapsed time per iteration (ms): 37683.3 | learning rate: 5.093E-05 | global batch size:  1024 | lm loss: 1.815383E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38322/   51900 | consumed samples:     39241728 | elapsed time per iteration (ms): 37650.8 | learning rate: 5.093E-05 | global batch size:  1024 | lm loss: 1.778955E+00 | loss scale: 1.0 | grad norm: 0.088 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38323/   51900 | consumed samples:     39242752 | elapsed time per iteration (ms): 37818.8 | learning rate: 5.093E-05 | global batch size:  1024 | lm loss: 1.780492E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38324/   51900 | consumed samples:     39243776 | elapsed time per iteration (ms): 37608.6 | learning rate: 5.092E-05 | global batch size:  1024 | lm loss: 1.789872E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38325/   51900 | consumed samples:     39244800 | elapsed time per iteration (ms): 37709.4 | learning rate: 5.092E-05 | global batch size:  1024 | lm loss: 1.801913E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38326/   51900 | consumed samples:     39245824 | elapsed time per iteration (ms): 37695.8 | learning rate: 5.091E-05 | global batch size:  1024 | lm loss: 1.783778E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38327/   51900 | consumed samples:     39246848 | elapsed time per iteration (ms): 37624.3 | learning rate: 5.091E-05 | global batch size:  1024 | lm loss: 1.809172E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38328/   51900 | consumed samples:     39247872 | elapsed time per iteration (ms): 37561.5 | learning rate: 5.090E-05 | global batch size:  1024 | lm loss: 1.801068E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38329/   51900 | consumed samples:     39248896 | elapsed time per iteration (ms): 37692.2 | learning rate: 5.090E-05 | global batch size:  1024 | lm loss: 1.812559E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38330/   51900 | consumed samples:     39249920 | elapsed time per iteration (ms): 37700.6 | learning rate: 5.090E-05 | global batch size:  1024 | lm loss: 1.799000E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38331/   51900 | consumed samples:     39250944 | elapsed time per iteration (ms): 37732.2 | learning rate: 5.089E-05 | global batch size:  1024 | lm loss: 1.798903E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38332/   51900 | consumed samples:     39251968 | elapsed time per iteration (ms): 37819.2 | learning rate: 5.089E-05 | global batch size:  1024 | lm loss: 1.806299E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38333/   51900 | consumed samples:     39252992 | elapsed time per iteration (ms): 37612.3 | learning rate: 5.088E-05 | global batch size:  1024 | lm loss: 1.820056E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38334/   51900 | consumed samples:     39254016 | elapsed time per iteration (ms): 37653.9 | learning rate: 5.088E-05 | global batch size:  1024 | lm loss: 1.813866E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38335/   51900 | consumed samples:     39255040 | elapsed time per iteration (ms): 37716.3 | learning rate: 5.087E-05 | global batch size:  1024 | lm loss: 1.811718E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38336/   51900 | consumed samples:     39256064 | elapsed time per iteration (ms): 37689.2 | learning rate: 5.087E-05 | global batch size:  1024 | lm loss: 1.804404E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38337/   51900 | consumed samples:     39257088 | elapsed time per iteration (ms): 37627.3 | learning rate: 5.087E-05 | global batch size:  1024 | lm loss: 1.807195E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38338/   51900 | consumed samples:     39258112 | elapsed time per iteration (ms): 37729.8 | learning rate: 5.086E-05 | global batch size:  1024 | lm loss: 1.793744E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38339/   51900 | consumed samples:     39259136 | elapsed time per iteration (ms): 37533.2 | learning rate: 5.086E-05 | global batch size:  1024 | lm loss: 1.804133E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38340/   51900 | consumed samples:     39260160 | elapsed time per iteration (ms): 37706.3 | learning rate: 5.085E-05 | global batch size:  1024 | lm loss: 1.791001E+00 | loss scale: 1.0 | grad norm: 0.110 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38341/   51900 | consumed samples:     39261184 | elapsed time per iteration (ms): 37647.1 | learning rate: 5.085E-05 | global batch size:  1024 | lm loss: 1.791195E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38342/   51900 | consumed samples:     39262208 | elapsed time per iteration (ms): 37726.5 | learning rate: 5.084E-05 | global batch size:  1024 | lm loss: 1.797720E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38343/   51900 | consumed samples:     39263232 | elapsed time per iteration (ms): 37625.5 | learning rate: 5.084E-05 | global batch size:  1024 | lm loss: 1.801543E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38344/   51900 | consumed samples:     39264256 | elapsed time per iteration (ms): 37692.6 | learning rate: 5.084E-05 | global batch size:  1024 | lm loss: 1.806456E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38345/   51900 | consumed samples:     39265280 | elapsed time per iteration (ms): 37749.5 | learning rate: 5.083E-05 | global batch size:  1024 | lm loss: 1.787106E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38346/   51900 | consumed samples:     39266304 | elapsed time per iteration (ms): 37677.2 | learning rate: 5.083E-05 | global batch size:  1024 | lm loss: 1.793634E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38347/   51900 | consumed samples:     39267328 | elapsed time per iteration (ms): 37658.8 | learning rate: 5.082E-05 | global batch size:  1024 | lm loss: 1.802878E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38348/   51900 | consumed samples:     39268352 | elapsed time per iteration (ms): 37565.8 | learning rate: 5.082E-05 | global batch size:  1024 | lm loss: 1.799752E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38349/   51900 | consumed samples:     39269376 | elapsed time per iteration (ms): 37610.5 | learning rate: 5.081E-05 | global batch size:  1024 | lm loss: 1.811236E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38350/   51900 | consumed samples:     39270400 | elapsed time per iteration (ms): 37660.7 | learning rate: 5.081E-05 | global batch size:  1024 | lm loss: 1.797604E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38351/   51900 | consumed samples:     39271424 | elapsed time per iteration (ms): 37671.4 | learning rate: 5.081E-05 | global batch size:  1024 | lm loss: 1.811909E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38352/   51900 | consumed samples:     39272448 | elapsed time per iteration (ms): 37581.5 | learning rate: 5.080E-05 | global batch size:  1024 | lm loss: 1.807697E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38353/   51900 | consumed samples:     39273472 | elapsed time per iteration (ms): 37677.7 | learning rate: 5.080E-05 | global batch size:  1024 | lm loss: 1.799396E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38354/   51900 | consumed samples:     39274496 | elapsed time per iteration (ms): 37609.8 | learning rate: 5.079E-05 | global batch size:  1024 | lm loss: 1.798026E+00 | loss scale: 1.0 | grad norm: 0.093 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38355/   51900 | consumed samples:     39275520 | elapsed time per iteration (ms): 37739.6 | learning rate: 5.079E-05 | global batch size:  1024 | lm loss: 1.809461E+00 | loss scale: 1.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38356/   51900 | consumed samples:     39276544 | elapsed time per iteration (ms): 37702.9 | learning rate: 5.078E-05 | global batch size:  1024 | lm loss: 1.804120E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38357/   51900 | consumed samples:     39277568 | elapsed time per iteration (ms): 37673.3 | learning rate: 5.078E-05 | global batch size:  1024 | lm loss: 1.806434E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38358/   51900 | consumed samples:     39278592 | elapsed time per iteration (ms): 37633.2 | learning rate: 5.078E-05 | global batch size:  1024 | lm loss: 1.808528E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38359/   51900 | consumed samples:     39279616 | elapsed time per iteration (ms): 37672.5 | learning rate: 5.077E-05 | global batch size:  1024 | lm loss: 1.805174E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38360/   51900 | consumed samples:     39280640 | elapsed time per iteration (ms): 37622.0 | learning rate: 5.077E-05 | global batch size:  1024 | lm loss: 1.786526E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38361/   51900 | consumed samples:     39281664 | elapsed time per iteration (ms): 37855.2 | learning rate: 5.076E-05 | global batch size:  1024 | lm loss: 1.818979E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38362/   51900 | consumed samples:     39282688 | elapsed time per iteration (ms): 37628.7 | learning rate: 5.076E-05 | global batch size:  1024 | lm loss: 1.793895E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38363/   51900 | consumed samples:     39283712 | elapsed time per iteration (ms): 37712.2 | learning rate: 5.075E-05 | global batch size:  1024 | lm loss: 1.798971E+00 | loss scale: 1.0 | grad norm: 0.064 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38364/   51900 | consumed samples:     39284736 | elapsed time per iteration (ms): 37685.6 | learning rate: 5.075E-05 | global batch size:  1024 | lm loss: 1.806375E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38365/   51900 | consumed samples:     39285760 | elapsed time per iteration (ms): 37767.9 | learning rate: 5.075E-05 | global batch size:  1024 | lm loss: 1.795723E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38366/   51900 | consumed samples:     39286784 | elapsed time per iteration (ms): 37689.6 | learning rate: 5.074E-05 | global batch size:  1024 | lm loss: 1.807365E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38367/   51900 | consumed samples:     39287808 | elapsed time per iteration (ms): 37592.7 | learning rate: 5.074E-05 | global batch size:  1024 | lm loss: 1.789646E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38368/   51900 | consumed samples:     39288832 | elapsed time per iteration (ms): 37705.5 | learning rate: 5.073E-05 | global batch size:  1024 | lm loss: 1.790709E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38369/   51900 | consumed samples:     39289856 | elapsed time per iteration (ms): 37664.3 | learning rate: 5.073E-05 | global batch size:  1024 | lm loss: 1.814582E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38370/   51900 | consumed samples:     39290880 | elapsed time per iteration (ms): 37687.8 | learning rate: 5.072E-05 | global batch size:  1024 | lm loss: 1.799462E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38371/   51900 | consumed samples:     39291904 | elapsed time per iteration (ms): 37710.7 | learning rate: 5.072E-05 | global batch size:  1024 | lm loss: 1.804841E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38372/   51900 | consumed samples:     39292928 | elapsed time per iteration (ms): 37628.4 | learning rate: 5.072E-05 | global batch size:  1024 | lm loss: 1.801288E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38373/   51900 | consumed samples:     39293952 | elapsed time per iteration (ms): 37688.3 | learning rate: 5.071E-05 | global batch size:  1024 | lm loss: 1.793703E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38374/   51900 | consumed samples:     39294976 | elapsed time per iteration (ms): 37639.2 | learning rate: 5.071E-05 | global batch size:  1024 | lm loss: 1.818316E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38375/   51900 | consumed samples:     39296000 | elapsed time per iteration (ms): 37642.6 | learning rate: 5.070E-05 | global batch size:  1024 | lm loss: 1.790025E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38376/   51900 | consumed samples:     39297024 | elapsed time per iteration (ms): 37659.3 | learning rate: 5.070E-05 | global batch size:  1024 | lm loss: 1.800563E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38377/   51900 | consumed samples:     39298048 | elapsed time per iteration (ms): 37699.8 | learning rate: 5.069E-05 | global batch size:  1024 | lm loss: 1.790960E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38378/   51900 | consumed samples:     39299072 | elapsed time per iteration (ms): 37802.5 | learning rate: 5.069E-05 | global batch size:  1024 | lm loss: 1.806678E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38379/   51900 | consumed samples:     39300096 | elapsed time per iteration (ms): 37592.3 | learning rate: 5.069E-05 | global batch size:  1024 | lm loss: 1.805148E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38380/   51900 | consumed samples:     39301120 | elapsed time per iteration (ms): 37539.3 | learning rate: 5.068E-05 | global batch size:  1024 | lm loss: 1.794305E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38381/   51900 | consumed samples:     39302144 | elapsed time per iteration (ms): 37649.9 | learning rate: 5.068E-05 | global batch size:  1024 | lm loss: 1.806131E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38382/   51900 | consumed samples:     39303168 | elapsed time per iteration (ms): 37704.0 | learning rate: 5.067E-05 | global batch size:  1024 | lm loss: 1.805797E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38383/   51900 | consumed samples:     39304192 | elapsed time per iteration (ms): 37663.5 | learning rate: 5.067E-05 | global batch size:  1024 | lm loss: 1.798820E+00 | loss scale: 1.0 | grad norm: 0.062 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38384/   51900 | consumed samples:     39305216 | elapsed time per iteration (ms): 37696.9 | learning rate: 5.066E-05 | global batch size:  1024 | lm loss: 1.798630E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38385/   51900 | consumed samples:     39306240 | elapsed time per iteration (ms): 37648.9 | learning rate: 5.066E-05 | global batch size:  1024 | lm loss: 1.795349E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38386/   51900 | consumed samples:     39307264 | elapsed time per iteration (ms): 37645.4 | learning rate: 5.066E-05 | global batch size:  1024 | lm loss: 1.806801E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38387/   51900 | consumed samples:     39308288 | elapsed time per iteration (ms): 37655.1 | learning rate: 5.065E-05 | global batch size:  1024 | lm loss: 1.784046E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38388/   51900 | consumed samples:     39309312 | elapsed time per iteration (ms): 37587.4 | learning rate: 5.065E-05 | global batch size:  1024 | lm loss: 1.804547E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38389/   51900 | consumed samples:     39310336 | elapsed time per iteration (ms): 37699.7 | learning rate: 5.064E-05 | global batch size:  1024 | lm loss: 1.784232E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38390/   51900 | consumed samples:     39311360 | elapsed time per iteration (ms): 37626.5 | learning rate: 5.064E-05 | global batch size:  1024 | lm loss: 1.812949E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38391/   51900 | consumed samples:     39312384 | elapsed time per iteration (ms): 37581.7 | learning rate: 5.064E-05 | global batch size:  1024 | lm loss: 1.793077E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38392/   51900 | consumed samples:     39313408 | elapsed time per iteration (ms): 37656.8 | learning rate: 5.063E-05 | global batch size:  1024 | lm loss: 1.796838E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38393/   51900 | consumed samples:     39314432 | elapsed time per iteration (ms): 37724.3 | learning rate: 5.063E-05 | global batch size:  1024 | lm loss: 1.824374E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38394/   51900 | consumed samples:     39315456 | elapsed time per iteration (ms): 37583.3 | learning rate: 5.062E-05 | global batch size:  1024 | lm loss: 1.796543E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38395/   51900 | consumed samples:     39316480 | elapsed time per iteration (ms): 37709.1 | learning rate: 5.062E-05 | global batch size:  1024 | lm loss: 1.781649E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38396/   51900 | consumed samples:     39317504 | elapsed time per iteration (ms): 37673.8 | learning rate: 5.061E-05 | global batch size:  1024 | lm loss: 1.794947E+00 | loss scale: 1.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38397/   51900 | consumed samples:     39318528 | elapsed time per iteration (ms): 37637.4 | learning rate: 5.061E-05 | global batch size:  1024 | lm loss: 1.824517E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38398/   51900 | consumed samples:     39319552 | elapsed time per iteration (ms): 37783.4 | learning rate: 5.061E-05 | global batch size:  1024 | lm loss: 1.819560E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38399/   51900 | consumed samples:     39320576 | elapsed time per iteration (ms): 37688.7 | learning rate: 5.060E-05 | global batch size:  1024 | lm loss: 1.813808E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38400/   51900 | consumed samples:     39321600 | elapsed time per iteration (ms): 37647.3 | learning rate: 5.060E-05 | global batch size:  1024 | lm loss: 1.800872E+00 | loss scale: 1.0 | grad norm: 0.105 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38401/   51900 | consumed samples:     39322624 | elapsed time per iteration (ms): 37606.7 | learning rate: 5.059E-05 | global batch size:  1024 | lm loss: 1.800849E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38402/   51900 | consumed samples:     39323648 | elapsed time per iteration (ms): 37758.4 | learning rate: 5.059E-05 | global batch size:  1024 | lm loss: 1.815920E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38403/   51900 | consumed samples:     39324672 | elapsed time per iteration (ms): 37751.4 | learning rate: 5.058E-05 | global batch size:  1024 | lm loss: 1.793398E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38404/   51900 | consumed samples:     39325696 | elapsed time per iteration (ms): 37726.9 | learning rate: 5.058E-05 | global batch size:  1024 | lm loss: 1.812016E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38405/   51900 | consumed samples:     39326720 | elapsed time per iteration (ms): 37638.5 | learning rate: 5.058E-05 | global batch size:  1024 | lm loss: 1.793215E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38406/   51900 | consumed samples:     39327744 | elapsed time per iteration (ms): 37776.0 | learning rate: 5.057E-05 | global batch size:  1024 | lm loss: 1.809575E+00 | loss scale: 1.0 | grad norm: 0.065 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38407/   51900 | consumed samples:     39328768 | elapsed time per iteration (ms): 37584.3 | learning rate: 5.057E-05 | global batch size:  1024 | lm loss: 1.792581E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38408/   51900 | consumed samples:     39329792 | elapsed time per iteration (ms): 37707.9 | learning rate: 5.056E-05 | global batch size:  1024 | lm loss: 1.780901E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38409/   51900 | consumed samples:     39330816 | elapsed time per iteration (ms): 37677.5 | learning rate: 5.056E-05 | global batch size:  1024 | lm loss: 1.802332E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38410/   51900 | consumed samples:     39331840 | elapsed time per iteration (ms): 37697.4 | learning rate: 5.055E-05 | global batch size:  1024 | lm loss: 1.810793E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38411/   51900 | consumed samples:     39332864 | elapsed time per iteration (ms): 37645.5 | learning rate: 5.055E-05 | global batch size:  1024 | lm loss: 1.811458E+00 | loss scale: 1.0 | grad norm: 0.089 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38412/   51900 | consumed samples:     39333888 | elapsed time per iteration (ms): 37668.7 | learning rate: 5.055E-05 | global batch size:  1024 | lm loss: 1.798291E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38413/   51900 | consumed samples:     39334912 | elapsed time per iteration (ms): 37685.1 | learning rate: 5.054E-05 | global batch size:  1024 | lm loss: 1.802124E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38414/   51900 | consumed samples:     39335936 | elapsed time per iteration (ms): 37758.6 | learning rate: 5.054E-05 | global batch size:  1024 | lm loss: 1.795868E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38415/   51900 | consumed samples:     39336960 | elapsed time per iteration (ms): 37719.5 | learning rate: 5.053E-05 | global batch size:  1024 | lm loss: 1.809976E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38416/   51900 | consumed samples:     39337984 | elapsed time per iteration (ms): 37841.4 | learning rate: 5.053E-05 | global batch size:  1024 | lm loss: 1.790902E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38417/   51900 | consumed samples:     39339008 | elapsed time per iteration (ms): 37722.6 | learning rate: 5.052E-05 | global batch size:  1024 | lm loss: 1.802788E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38418/   51900 | consumed samples:     39340032 | elapsed time per iteration (ms): 37777.7 | learning rate: 5.052E-05 | global batch size:  1024 | lm loss: 1.808710E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38419/   51900 | consumed samples:     39341056 | elapsed time per iteration (ms): 37667.9 | learning rate: 5.052E-05 | global batch size:  1024 | lm loss: 1.796637E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38420/   51900 | consumed samples:     39342080 | elapsed time per iteration (ms): 37806.4 | learning rate: 5.051E-05 | global batch size:  1024 | lm loss: 1.795270E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38421/   51900 | consumed samples:     39343104 | elapsed time per iteration (ms): 37636.2 | learning rate: 5.051E-05 | global batch size:  1024 | lm loss: 1.815474E+00 | loss scale: 1.0 | grad norm: 0.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38422/   51900 | consumed samples:     39344128 | elapsed time per iteration (ms): 37727.7 | learning rate: 5.050E-05 | global batch size:  1024 | lm loss: 1.797274E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38423/   51900 | consumed samples:     39345152 | elapsed time per iteration (ms): 37675.5 | learning rate: 5.050E-05 | global batch size:  1024 | lm loss: 1.817399E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38424/   51900 | consumed samples:     39346176 | elapsed time per iteration (ms): 37745.7 | learning rate: 5.049E-05 | global batch size:  1024 | lm loss: 1.797293E+00 | loss scale: 1.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38425/   51900 | consumed samples:     39347200 | elapsed time per iteration (ms): 37715.8 | learning rate: 5.049E-05 | global batch size:  1024 | lm loss: 1.799452E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38426/   51900 | consumed samples:     39348224 | elapsed time per iteration (ms): 37747.1 | learning rate: 5.049E-05 | global batch size:  1024 | lm loss: 1.804009E+00 | loss scale: 1.0 | grad norm: 0.065 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38427/   51900 | consumed samples:     39349248 | elapsed time per iteration (ms): 37613.2 | learning rate: 5.048E-05 | global batch size:  1024 | lm loss: 1.809681E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38428/   51900 | consumed samples:     39350272 | elapsed time per iteration (ms): 37723.9 | learning rate: 5.048E-05 | global batch size:  1024 | lm loss: 1.799747E+00 | loss scale: 1.0 | grad norm: 0.064 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38429/   51900 | consumed samples:     39351296 | elapsed time per iteration (ms): 37758.7 | learning rate: 5.047E-05 | global batch size:  1024 | lm loss: 1.797890E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38430/   51900 | consumed samples:     39352320 | elapsed time per iteration (ms): 37699.8 | learning rate: 5.047E-05 | global batch size:  1024 | lm loss: 1.803902E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38431/   51900 | consumed samples:     39353344 | elapsed time per iteration (ms): 37630.7 | learning rate: 5.046E-05 | global batch size:  1024 | lm loss: 1.799219E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38432/   51900 | consumed samples:     39354368 | elapsed time per iteration (ms): 37648.4 | learning rate: 5.046E-05 | global batch size:  1024 | lm loss: 1.800392E+00 | loss scale: 1.0 | grad norm: 0.064 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38433/   51900 | consumed samples:     39355392 | elapsed time per iteration (ms): 37719.6 | learning rate: 5.046E-05 | global batch size:  1024 | lm loss: 1.796077E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38434/   51900 | consumed samples:     39356416 | elapsed time per iteration (ms): 37575.3 | learning rate: 5.045E-05 | global batch size:  1024 | lm loss: 1.797713E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38435/   51900 | consumed samples:     39357440 | elapsed time per iteration (ms): 37731.5 | learning rate: 5.045E-05 | global batch size:  1024 | lm loss: 1.803494E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38436/   51900 | consumed samples:     39358464 | elapsed time per iteration (ms): 37641.7 | learning rate: 5.044E-05 | global batch size:  1024 | lm loss: 1.779212E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38437/   51900 | consumed samples:     39359488 | elapsed time per iteration (ms): 37580.7 | learning rate: 5.044E-05 | global batch size:  1024 | lm loss: 1.799223E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38438/   51900 | consumed samples:     39360512 | elapsed time per iteration (ms): 37619.6 | learning rate: 5.044E-05 | global batch size:  1024 | lm loss: 1.791603E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38439/   51900 | consumed samples:     39361536 | elapsed time per iteration (ms): 37817.0 | learning rate: 5.043E-05 | global batch size:  1024 | lm loss: 1.819546E+00 | loss scale: 1.0 | grad norm: 0.065 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38440/   51900 | consumed samples:     39362560 | elapsed time per iteration (ms): 37734.5 | learning rate: 5.043E-05 | global batch size:  1024 | lm loss: 1.790214E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38441/   51900 | consumed samples:     39363584 | elapsed time per iteration (ms): 37743.9 | learning rate: 5.042E-05 | global batch size:  1024 | lm loss: 1.783775E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38442/   51900 | consumed samples:     39364608 | elapsed time per iteration (ms): 37681.5 | learning rate: 5.042E-05 | global batch size:  1024 | lm loss: 1.793616E+00 | loss scale: 1.0 | grad norm: 0.063 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38443/   51900 | consumed samples:     39365632 | elapsed time per iteration (ms): 37630.0 | learning rate: 5.041E-05 | global batch size:  1024 | lm loss: 1.777523E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38444/   51900 | consumed samples:     39366656 | elapsed time per iteration (ms): 37754.4 | learning rate: 5.041E-05 | global batch size:  1024 | lm loss: 1.789986E+00 | loss scale: 1.0 | grad norm: 0.065 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38445/   51900 | consumed samples:     39367680 | elapsed time per iteration (ms): 37694.0 | learning rate: 5.041E-05 | global batch size:  1024 | lm loss: 1.810248E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38446/   51900 | consumed samples:     39368704 | elapsed time per iteration (ms): 37607.1 | learning rate: 5.040E-05 | global batch size:  1024 | lm loss: 1.792967E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38447/   51900 | consumed samples:     39369728 | elapsed time per iteration (ms): 37596.3 | learning rate: 5.040E-05 | global batch size:  1024 | lm loss: 1.822998E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38448/   51900 | consumed samples:     39370752 | elapsed time per iteration (ms): 37612.6 | learning rate: 5.039E-05 | global batch size:  1024 | lm loss: 1.816267E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38449/   51900 | consumed samples:     39371776 | elapsed time per iteration (ms): 37765.9 | learning rate: 5.039E-05 | global batch size:  1024 | lm loss: 1.804212E+00 | loss scale: 1.0 | grad norm: 0.065 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38450/   51900 | consumed samples:     39372800 | elapsed time per iteration (ms): 37679.2 | learning rate: 5.038E-05 | global batch size:  1024 | lm loss: 1.797007E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38451/   51900 | consumed samples:     39373824 | elapsed time per iteration (ms): 37593.6 | learning rate: 5.038E-05 | global batch size:  1024 | lm loss: 1.794179E+00 | loss scale: 1.0 | grad norm: 0.063 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38452/   51900 | consumed samples:     39374848 | elapsed time per iteration (ms): 37806.9 | learning rate: 5.038E-05 | global batch size:  1024 | lm loss: 1.817491E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38453/   51900 | consumed samples:     39375872 | elapsed time per iteration (ms): 37570.1 | learning rate: 5.037E-05 | global batch size:  1024 | lm loss: 1.810940E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38454/   51900 | consumed samples:     39376896 | elapsed time per iteration (ms): 37588.6 | learning rate: 5.037E-05 | global batch size:  1024 | lm loss: 1.806043E+00 | loss scale: 1.0 | grad norm: 0.065 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38455/   51900 | consumed samples:     39377920 | elapsed time per iteration (ms): 37596.3 | learning rate: 5.036E-05 | global batch size:  1024 | lm loss: 1.818134E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38456/   51900 | consumed samples:     39378944 | elapsed time per iteration (ms): 37659.7 | learning rate: 5.036E-05 | global batch size:  1024 | lm loss: 1.796170E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38457/   51900 | consumed samples:     39379968 | elapsed time per iteration (ms): 37771.0 | learning rate: 5.035E-05 | global batch size:  1024 | lm loss: 1.798656E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38458/   51900 | consumed samples:     39380992 | elapsed time per iteration (ms): 37724.9 | learning rate: 5.035E-05 | global batch size:  1024 | lm loss: 1.806624E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38459/   51900 | consumed samples:     39382016 | elapsed time per iteration (ms): 37640.7 | learning rate: 5.035E-05 | global batch size:  1024 | lm loss: 1.806172E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38460/   51900 | consumed samples:     39383040 | elapsed time per iteration (ms): 37645.6 | learning rate: 5.034E-05 | global batch size:  1024 | lm loss: 1.798755E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38461/   51900 | consumed samples:     39384064 | elapsed time per iteration (ms): 37600.9 | learning rate: 5.034E-05 | global batch size:  1024 | lm loss: 1.808425E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38462/   51900 | consumed samples:     39385088 | elapsed time per iteration (ms): 37738.7 | learning rate: 5.033E-05 | global batch size:  1024 | lm loss: 1.792988E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38463/   51900 | consumed samples:     39386112 | elapsed time per iteration (ms): 37538.6 | learning rate: 5.033E-05 | global batch size:  1024 | lm loss: 1.778073E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38464/   51900 | consumed samples:     39387136 | elapsed time per iteration (ms): 37604.5 | learning rate: 5.032E-05 | global batch size:  1024 | lm loss: 1.813992E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38465/   51900 | consumed samples:     39388160 | elapsed time per iteration (ms): 37639.8 | learning rate: 5.032E-05 | global batch size:  1024 | lm loss: 1.809809E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38466/   51900 | consumed samples:     39389184 | elapsed time per iteration (ms): 37676.1 | learning rate: 5.032E-05 | global batch size:  1024 | lm loss: 1.794784E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38467/   51900 | consumed samples:     39390208 | elapsed time per iteration (ms): 37696.5 | learning rate: 5.031E-05 | global batch size:  1024 | lm loss: 1.802887E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38468/   51900 | consumed samples:     39391232 | elapsed time per iteration (ms): 37710.9 | learning rate: 5.031E-05 | global batch size:  1024 | lm loss: 1.778407E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38469/   51900 | consumed samples:     39392256 | elapsed time per iteration (ms): 37650.3 | learning rate: 5.030E-05 | global batch size:  1024 | lm loss: 1.786761E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38470/   51900 | consumed samples:     39393280 | elapsed time per iteration (ms): 37602.7 | learning rate: 5.030E-05 | global batch size:  1024 | lm loss: 1.800964E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38471/   51900 | consumed samples:     39394304 | elapsed time per iteration (ms): 37734.8 | learning rate: 5.030E-05 | global batch size:  1024 | lm loss: 1.816919E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38472/   51900 | consumed samples:     39395328 | elapsed time per iteration (ms): 37711.7 | learning rate: 5.029E-05 | global batch size:  1024 | lm loss: 1.801314E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38473/   51900 | consumed samples:     39396352 | elapsed time per iteration (ms): 37609.1 | learning rate: 5.029E-05 | global batch size:  1024 | lm loss: 1.809891E+00 | loss scale: 1.0 | grad norm: 0.075 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38474/   51900 | consumed samples:     39397376 | elapsed time per iteration (ms): 37705.9 | learning rate: 5.028E-05 | global batch size:  1024 | lm loss: 1.796881E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38475/   51900 | consumed samples:     39398400 | elapsed time per iteration (ms): 37662.2 | learning rate: 5.028E-05 | global batch size:  1024 | lm loss: 1.791693E+00 | loss scale: 1.0 | grad norm: 0.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38476/   51900 | consumed samples:     39399424 | elapsed time per iteration (ms): 37697.1 | learning rate: 5.027E-05 | global batch size:  1024 | lm loss: 1.788832E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38477/   51900 | consumed samples:     39400448 | elapsed time per iteration (ms): 37682.9 | learning rate: 5.027E-05 | global batch size:  1024 | lm loss: 1.819228E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38478/   51900 | consumed samples:     39401472 | elapsed time per iteration (ms): 37664.4 | learning rate: 5.027E-05 | global batch size:  1024 | lm loss: 1.797811E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38479/   51900 | consumed samples:     39402496 | elapsed time per iteration (ms): 37636.0 | learning rate: 5.026E-05 | global batch size:  1024 | lm loss: 1.807589E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38480/   51900 | consumed samples:     39403520 | elapsed time per iteration (ms): 37622.7 | learning rate: 5.026E-05 | global batch size:  1024 | lm loss: 1.795066E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38481/   51900 | consumed samples:     39404544 | elapsed time per iteration (ms): 37636.8 | learning rate: 5.025E-05 | global batch size:  1024 | lm loss: 1.794358E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38482/   51900 | consumed samples:     39405568 | elapsed time per iteration (ms): 37682.8 | learning rate: 5.025E-05 | global batch size:  1024 | lm loss: 1.793064E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38483/   51900 | consumed samples:     39406592 | elapsed time per iteration (ms): 37709.0 | learning rate: 5.024E-05 | global batch size:  1024 | lm loss: 1.794131E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38484/   51900 | consumed samples:     39407616 | elapsed time per iteration (ms): 37661.6 | learning rate: 5.024E-05 | global batch size:  1024 | lm loss: 1.811252E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38485/   51900 | consumed samples:     39408640 | elapsed time per iteration (ms): 37671.3 | learning rate: 5.024E-05 | global batch size:  1024 | lm loss: 1.790086E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38486/   51900 | consumed samples:     39409664 | elapsed time per iteration (ms): 37647.2 | learning rate: 5.023E-05 | global batch size:  1024 | lm loss: 1.791228E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38487/   51900 | consumed samples:     39410688 | elapsed time per iteration (ms): 37678.7 | learning rate: 5.023E-05 | global batch size:  1024 | lm loss: 1.807000E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38488/   51900 | consumed samples:     39411712 | elapsed time per iteration (ms): 37590.6 | learning rate: 5.022E-05 | global batch size:  1024 | lm loss: 1.790716E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38489/   51900 | consumed samples:     39412736 | elapsed time per iteration (ms): 37703.4 | learning rate: 5.022E-05 | global batch size:  1024 | lm loss: 1.795007E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38490/   51900 | consumed samples:     39413760 | elapsed time per iteration (ms): 37667.3 | learning rate: 5.021E-05 | global batch size:  1024 | lm loss: 1.792197E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38491/   51900 | consumed samples:     39414784 | elapsed time per iteration (ms): 37740.0 | learning rate: 5.021E-05 | global batch size:  1024 | lm loss: 1.802491E+00 | loss scale: 1.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38492/   51900 | consumed samples:     39415808 | elapsed time per iteration (ms): 37655.8 | learning rate: 5.021E-05 | global batch size:  1024 | lm loss: 1.813120E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38493/   51900 | consumed samples:     39416832 | elapsed time per iteration (ms): 37681.3 | learning rate: 5.020E-05 | global batch size:  1024 | lm loss: 1.816483E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38494/   51900 | consumed samples:     39417856 | elapsed time per iteration (ms): 37692.1 | learning rate: 5.020E-05 | global batch size:  1024 | lm loss: 1.800990E+00 | loss scale: 1.0 | grad norm: 0.091 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38495/   51900 | consumed samples:     39418880 | elapsed time per iteration (ms): 37610.7 | learning rate: 5.019E-05 | global batch size:  1024 | lm loss: 1.800303E+00 | loss scale: 1.0 | grad norm: 0.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38496/   51900 | consumed samples:     39419904 | elapsed time per iteration (ms): 37758.9 | learning rate: 5.019E-05 | global batch size:  1024 | lm loss: 1.793397E+00 | loss scale: 1.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38497/   51900 | consumed samples:     39420928 | elapsed time per iteration (ms): 37764.1 | learning rate: 5.018E-05 | global batch size:  1024 | lm loss: 1.791017E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38498/   51900 | consumed samples:     39421952 | elapsed time per iteration (ms): 37730.2 | learning rate: 5.018E-05 | global batch size:  1024 | lm loss: 1.793860E+00 | loss scale: 1.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38499/   51900 | consumed samples:     39422976 | elapsed time per iteration (ms): 37636.2 | learning rate: 5.018E-05 | global batch size:  1024 | lm loss: 1.805703E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38500/   51900 | consumed samples:     39424000 | elapsed time per iteration (ms): 37775.3 | learning rate: 5.017E-05 | global batch size:  1024 | lm loss: 1.806364E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
(min, max) time across ranks (ms):
    save-checkpoint ................................: (135379.23, 135379.33)
 iteration    38501/   51900 | consumed samples:     39425024 | elapsed time per iteration (ms): 37473.0 | learning rate: 5.017E-05 | global batch size:  1024 | lm loss: 1.785731E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38502/   51900 | consumed samples:     39426048 | elapsed time per iteration (ms): 37648.4 | learning rate: 5.016E-05 | global batch size:  1024 | lm loss: 1.815707E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38503/   51900 | consumed samples:     39427072 | elapsed time per iteration (ms): 37549.0 | learning rate: 5.016E-05 | global batch size:  1024 | lm loss: 1.787555E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38504/   51900 | consumed samples:     39428096 | elapsed time per iteration (ms): 37568.6 | learning rate: 5.016E-05 | global batch size:  1024 | lm loss: 1.800637E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38505/   51900 | consumed samples:     39429120 | elapsed time per iteration (ms): 37666.4 | learning rate: 5.015E-05 | global batch size:  1024 | lm loss: 1.788929E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38506/   51900 | consumed samples:     39430144 | elapsed time per iteration (ms): 37655.7 | learning rate: 5.015E-05 | global batch size:  1024 | lm loss: 1.808427E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38507/   51900 | consumed samples:     39431168 | elapsed time per iteration (ms): 37638.4 | learning rate: 5.014E-05 | global batch size:  1024 | lm loss: 1.786168E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38508/   51900 | consumed samples:     39432192 | elapsed time per iteration (ms): 37690.7 | learning rate: 5.014E-05 | global batch size:  1024 | lm loss: 1.792942E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38509/   51900 | consumed samples:     39433216 | elapsed time per iteration (ms): 37598.0 | learning rate: 5.013E-05 | global batch size:  1024 | lm loss: 1.818919E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38510/   51900 | consumed samples:     39434240 | elapsed time per iteration (ms): 37534.9 | learning rate: 5.013E-05 | global batch size:  1024 | lm loss: 1.822715E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38511/   51900 | consumed samples:     39435264 | elapsed time per iteration (ms): 37739.8 | learning rate: 5.013E-05 | global batch size:  1024 | lm loss: 1.809681E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38512/   51900 | consumed samples:     39436288 | elapsed time per iteration (ms): 37530.7 | learning rate: 5.012E-05 | global batch size:  1024 | lm loss: 1.815750E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38513/   51900 | consumed samples:     39437312 | elapsed time per iteration (ms): 37695.5 | learning rate: 5.012E-05 | global batch size:  1024 | lm loss: 1.813932E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38514/   51900 | consumed samples:     39438336 | elapsed time per iteration (ms): 37725.6 | learning rate: 5.011E-05 | global batch size:  1024 | lm loss: 1.805595E+00 | loss scale: 1.0 | grad norm: 0.064 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38515/   51900 | consumed samples:     39439360 | elapsed time per iteration (ms): 37620.7 | learning rate: 5.011E-05 | global batch size:  1024 | lm loss: 1.775648E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38516/   51900 | consumed samples:     39440384 | elapsed time per iteration (ms): 37754.6 | learning rate: 5.010E-05 | global batch size:  1024 | lm loss: 1.803162E+00 | loss scale: 1.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38517/   51900 | consumed samples:     39441408 | elapsed time per iteration (ms): 37657.3 | learning rate: 5.010E-05 | global batch size:  1024 | lm loss: 1.828553E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38518/   51900 | consumed samples:     39442432 | elapsed time per iteration (ms): 37674.0 | learning rate: 5.010E-05 | global batch size:  1024 | lm loss: 1.804153E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38519/   51900 | consumed samples:     39443456 | elapsed time per iteration (ms): 37701.8 | learning rate: 5.009E-05 | global batch size:  1024 | lm loss: 1.812423E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38520/   51900 | consumed samples:     39444480 | elapsed time per iteration (ms): 37671.3 | learning rate: 5.009E-05 | global batch size:  1024 | lm loss: 1.797316E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38521/   51900 | consumed samples:     39445504 | elapsed time per iteration (ms): 37717.2 | learning rate: 5.008E-05 | global batch size:  1024 | lm loss: 1.817257E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38522/   51900 | consumed samples:     39446528 | elapsed time per iteration (ms): 37690.2 | learning rate: 5.008E-05 | global batch size:  1024 | lm loss: 1.799727E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38523/   51900 | consumed samples:     39447552 | elapsed time per iteration (ms): 37670.0 | learning rate: 5.007E-05 | global batch size:  1024 | lm loss: 1.793861E+00 | loss scale: 1.0 | grad norm: 0.065 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38524/   51900 | consumed samples:     39448576 | elapsed time per iteration (ms): 37735.8 | learning rate: 5.007E-05 | global batch size:  1024 | lm loss: 1.789668E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38525/   51900 | consumed samples:     39449600 | elapsed time per iteration (ms): 37578.4 | learning rate: 5.007E-05 | global batch size:  1024 | lm loss: 1.812400E+00 | loss scale: 1.0 | grad norm: 0.065 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38526/   51900 | consumed samples:     39450624 | elapsed time per iteration (ms): 37629.6 | learning rate: 5.006E-05 | global batch size:  1024 | lm loss: 1.806635E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38527/   51900 | consumed samples:     39451648 | elapsed time per iteration (ms): 37524.7 | learning rate: 5.006E-05 | global batch size:  1024 | lm loss: 1.783019E+00 | loss scale: 1.0 | grad norm: 0.064 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38528/   51900 | consumed samples:     39452672 | elapsed time per iteration (ms): 37815.7 | learning rate: 5.005E-05 | global batch size:  1024 | lm loss: 1.792580E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38529/   51900 | consumed samples:     39453696 | elapsed time per iteration (ms): 37567.0 | learning rate: 5.005E-05 | global batch size:  1024 | lm loss: 1.805014E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38530/   51900 | consumed samples:     39454720 | elapsed time per iteration (ms): 37672.9 | learning rate: 5.005E-05 | global batch size:  1024 | lm loss: 1.782915E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38531/   51900 | consumed samples:     39455744 | elapsed time per iteration (ms): 37544.1 | learning rate: 5.004E-05 | global batch size:  1024 | lm loss: 1.814325E+00 | loss scale: 1.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38532/   51900 | consumed samples:     39456768 | elapsed time per iteration (ms): 37712.9 | learning rate: 5.004E-05 | global batch size:  1024 | lm loss: 1.802459E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38533/   51900 | consumed samples:     39457792 | elapsed time per iteration (ms): 37686.6 | learning rate: 5.003E-05 | global batch size:  1024 | lm loss: 1.812833E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38534/   51900 | consumed samples:     39458816 | elapsed time per iteration (ms): 37660.4 | learning rate: 5.003E-05 | global batch size:  1024 | lm loss: 1.801010E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38535/   51900 | consumed samples:     39459840 | elapsed time per iteration (ms): 37586.2 | learning rate: 5.002E-05 | global batch size:  1024 | lm loss: 1.785557E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38536/   51900 | consumed samples:     39460864 | elapsed time per iteration (ms): 37758.2 | learning rate: 5.002E-05 | global batch size:  1024 | lm loss: 1.799373E+00 | loss scale: 1.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38537/   51900 | consumed samples:     39461888 | elapsed time per iteration (ms): 37693.6 | learning rate: 5.002E-05 | global batch size:  1024 | lm loss: 1.814210E+00 | loss scale: 1.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38538/   51900 | consumed samples:     39462912 | elapsed time per iteration (ms): 37708.5 | learning rate: 5.001E-05 | global batch size:  1024 | lm loss: 1.802887E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38539/   51900 | consumed samples:     39463936 | elapsed time per iteration (ms): 37784.2 | learning rate: 5.001E-05 | global batch size:  1024 | lm loss: 1.777130E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38540/   51900 | consumed samples:     39464960 | elapsed time per iteration (ms): 37619.6 | learning rate: 5.000E-05 | global batch size:  1024 | lm loss: 1.813147E+00 | loss scale: 1.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38541/   51900 | consumed samples:     39465984 | elapsed time per iteration (ms): 37646.3 | learning rate: 5.000E-05 | global batch size:  1024 | lm loss: 1.800629E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38542/   51900 | consumed samples:     39467008 | elapsed time per iteration (ms): 37742.3 | learning rate: 4.999E-05 | global batch size:  1024 | lm loss: 1.796851E+00 | loss scale: 1.0 | grad norm: 0.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38543/   51900 | consumed samples:     39468032 | elapsed time per iteration (ms): 37714.3 | learning rate: 4.999E-05 | global batch size:  1024 | lm loss: 1.811022E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38544/   51900 | consumed samples:     39469056 | elapsed time per iteration (ms): 37682.2 | learning rate: 4.999E-05 | global batch size:  1024 | lm loss: 1.794219E+00 | loss scale: 1.0 | grad norm: 0.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38545/   51900 | consumed samples:     39470080 | elapsed time per iteration (ms): 37598.3 | learning rate: 4.998E-05 | global batch size:  1024 | lm loss: 1.798114E+00 | loss scale: 1.0 | grad norm: 0.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration    38546/   51900 | consumed samples:     39471104 | elapsed time per iteration (ms): 37686.0 | learning rate: 4.998E-05 | global batch size:  1024 | lm loss: 1.799720E+00 | loss scale: 1.0 | grad norm: 0.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
